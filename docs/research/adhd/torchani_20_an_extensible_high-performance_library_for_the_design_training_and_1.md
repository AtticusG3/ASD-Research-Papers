---
title: 'TorchANI 2.0: An Extensible, High-Performance Library for the Design, Training,
  and Use of NN-IPs.**DOI:** 10.1021/acs.jcim.5c01853'
authors:
- IgnacioPickering
- JinzeXue
- KateHuddleston
- NicholasTerrel
- Adrian ERoitberg
journal: Journal of chemical information and modeling
doi: 10.1021/acs.jcim.5c01853
publication_date: ''
source: Processed from scraped content
processing_date: '2025-10-21T22:15:10.117421'
content_type: research_paper
conditions:
- adhd
topics: []
categories:
- adhd
reading_level: academic
audience:
- professional
- researcher
patient_friendly: false
search_priority: standard
keywords: []
search_tags:
- adhd
- academic
- peer-reviewed
- research
---

# TorchANI 2.0: An Extensible, High-Performance Library for the Design, Training, and Use of NN-IPs.**DOI:** 10.1021/acs.jcim.5c01853

**Authors:** IgnacioPickering, JinzeXue, KateHuddleston, NicholasTerrel, Adrian ERoitberg

**Journal:** Journal of chemical information and modeling

**DOI:** 10.1021/acs.jcim.5c01853

## Abstract

In this work, we introduce TorchANI 2.0, a significantly improved version of the free and open source TorchANI software package for training and evaluation of ANI (ANAKIN-ME) deep learning models. TorchANI 2.0 builds upon the foundation of its predecessor, while addressing its limitations and introducing new features. These changes greatly enhance its extensibility, performance, and suitability as a framework for developing models ready for molecular dynamics applications. These improvements include the introduction of a modular system to add arbitrary pairwise potentials to models, CUDA-accelerated optimization for faster and more memory-efficient calculation of local atomic features, and a batched system for better performance of network ensembles, among others. Our benchmarks demonstrate that TorchANI 2.0 achieves significant speedup over previous versions in both training and inference, and the library enhancements allow users to train physically constrained models that better represent important qualities of chemical systems. We demonstrate this by introducing three new ANI models that incorporate these features and evaluating their capabilities.

**Date:** 2025-10-17
**Category:** adhd
**Source:** pubmed
**Scraped at:** 2025-10-21T10:57:27.464467
**Source URL:** https://pubmed.ncbi.nlm.nih.gov/?term=10.1021/acs.jcim.5c01853## AbstractIn this work, we introduce TorchANI 2.0, a significantly improved version of the free and open source TorchANI software package for training and evaluation of ANI (ANAKIN-ME) deep learning models. TorchANI 2.0 builds upon the foundation of its predecessor, while addressing its limitations and introducing new features. These changes greatly enhance its extensibility, performance, and suitability as a framework for developing models ready for molecular dynamics applications. These improvements include the introduction of a modular system to add arbitrary pairwise potentials to models, CUDA-accelerated optimization for faster and more memory-efficient calculation of local atomic features, and a batched system for better performance of network ensembles, among others. Our benchmarks demonstrate that TorchANI 2.0 achieves significant speedup over previous versions in both training and inference, and the library enhancements allow users to train physically constrained models that better represent important qualities of chemical systems. We demonstrate this by introducing three new ANI models that incorporate these features and evaluating their capabilities.## Full Text ContentAbstract AbstractIn this work, we introduce TorchANI 2.0, a significantly improved version of the free and open source TorchANI software package for training and evaluation of ANI (ANAKIN-ME) deep learning models. TorchANI 2.0 builds upon the foundation of its predecessor, while addressing its limitations and introducing new features. These changes greatly enhance its extensibility, performance, and suitability as a framework for developing models ready for molecular dynamics applications. These improvements include the introduction of a modular system to add arbitrary pairwise potentials to models, CUDA-accelerated optimization for faster and more memory-efficient calculation of local atomic features, and a batched system for better performance of network ensembles, among others. Our benchmarks demonstrate that TorchANI 2.0 achieves significant speedup over previous versions in both training and inference, and the library enhancements allow users to train physically constrained models that better represent important qualities of chemical systems. We demonstrate this by introducing three new ANI models that incorporate these features and evaluating their capabilities.---
*This content was automatically scraped by Webscraping Agent A*