---
title: Diagnosing autism spectrum disorders using a double deep Q-Network framework
  based on social media footprints.**DOI:** 10.3389/fmed.2025.1646249
authors:
- Nesren SFarhah
- Ahmed AbdullahAlqarni
- NadhemEbrahim
- SultanAhmad
journal: Frontiers in medicine
doi: 10.3389/fmed.2025.1646249
publication_date: ''
source: Processed from scraped content
processing_date: '2025-10-21T22:15:04.761004'
content_type: research_paper
conditions:
- asd
- related_disorders
topics: []
categories:
- asd
- related-disorders
reading_level: academic
audience:
- professional
- researcher
patient_friendly: false
search_priority: standard
keywords:
- adults
- behavioral
search_tags:
- asd
- related_disorders
- peer-reviewed
- academic
- research
---

# Diagnosing autism spectrum disorders using a double deep Q-Network framework based on social media footprints.**DOI:** 10.3389/fmed.2025.1646249

**Authors:** Nesren SFarhah, Ahmed AbdullahAlqarni, NadhemEbrahim, SultanAhmad

**Journal:** Frontiers in medicine

**DOI:** 10.3389/fmed.2025.1646249

## Abstract

Social media is increasingly used in many contexts within the healthcare sector. The improved prevalence of Internet use via computers or mobile devices presents an opportunity for social media to serve as a tool for the rapid and direct distribution of essential health information. Autism spectrum disorders (ASD) are a comprehensive neurodevelopmental syndrome with enduring effects. Twitter has become a platform for the ASD community, offering substantial assistance to its members by disseminating information on their beliefs and perspectives via language and emotional expression. Adults with ASD have considerable social and emotional challenges, while also demonstrating abilities and interests in screen-based technologies.
The novelty of this research lies in its use in the context of Twitter to analyze and identify ASD. This research used Twitter as the primary data source to examine the behavioral traits and immediate emotional expressions of persons with ASD. We applied Convolutional Neural Networks with Long Short-Term Memory (CNN-LSTM), LSTM, and Double Deep Q-network (DDQN-Inspired) using a standardized dataset including 172 tweets from the ASD class and 158 tweets from the non-ASD class. The dataset was processed to exclude lowercase text and special characters, followed by a tokenization approach to convert the text into integer word sequences. The encoding was used to transform the classes into binary labels. Following preprocessing, the proposed framework was implemented to identify ASD.
The findings of the DDQN-inspired model demonstrate a high precision of 87% compared to the proposed model. This finding demonstrates the potential of the proposed approach for identifying ASD based on social media content.
Ultimately, the proposed system was compared against the existing system that used the same dataset. The proposed approach is based on variations in the text of social media interactions, which can assist physicians and clinicians in performing symptom studies within digital footprint environments.

The novelty of this research lies in its use in the context of Twitter to analyze and identify ASD. This research used Twitter as the primary data source to examine the behavioral traits and immediate emotional expressions of persons with ASD. We applied Convolutional Neural Networks with Long Short-Term Memory (CNN-LSTM), LSTM, and Double Deep Q-network (DDQN-Inspired) using a standardized dataset including 172 tweets from the ASD class and 158 tweets from the non-ASD class. The dataset was processed to exclude lowercase text and special characters, followed by a tokenization approach to convert the text into integer word sequences. The encoding was used to transform the classes into binary labels. Following preprocessing, the proposed framework was implemented to identify ASD.
The findings of the DDQN-inspired model demonstrate a high precision of 87% compared to the proposed model. This finding demonstrates the potential of the proposed approach for identifying ASD based on social media content.
Ultimately, the proposed system was compared against the existing system that used the same dataset. The proposed approach is based on variations in the text of social media interactions, which can assist physicians and clinicians in performing symptom studies within digital footprint environments.## Full Text## Abstract
| crossref full text | google scholar 4. alhujaili, n, platt, e, khalid-khan, s, and groll, d. comparison of social media use among adolescents with autism spectrum disorder and non-asd adolescents. adolesc health med ther . (2022) 13:15–21. doi: 10.2147/ahmt.s344591 pubmed abstract | crossref full text | google scholar 5. angulo-jiménez, h, and dethorne, l. narratives about autism: an analysis of youtube videos by individuals who self-identify as autistic. am j speech lang pathol . (2019) 28:569–90. doi: 10.1044/2018_ajslp-18-0045 crossref full text | google scholar 6. pew research center. (2021). available online at: https://www.pewresearch.org/internet/2021/04/07/social-media-use-in-2021/ google scholar 7. liu, j-b, guan, l, cao, j, and chen, l. coherence analysis for a class of polygon networks with the noise disturbance. ieee trans syst man cybern syst . (2025) 2025:326. doi: 10.1109/tsmc.2025.3559326 crossref full text | google scholar 8. al-nefaie, ah, aldhyani, th, sultan, ha, and alzahrani eidah, m. application of artificial intelligence in modern healthcare for diagnosis of autism spectrum disorder. front med . (2025) 12:1569464. doi: 10.3389/fmed.2025.1569464 crossref full text | google scholar 9. kim, b, jeong, d, kim, jg, hong, h, and han, k. v-dat (virtual reality data analysis tool): supporting self-awareness for autistic people from multimodal vr sensor data . in: proceedings of the uist 2023—proceedings of the 36th annual acm symposium on user interface software and technology, san francisco, ca, usa, 29 october–1 november 2023. (2023). google scholar 10. chen, c, chander, a, and uchino, k. guided play: digital sensing and coaching for stereotypical play behavior in children with autism . in proceedings of the international conference on intelligent user interfaces, proceedings iui, marina del ray, ca, usa, 17–20 march 2019; part f1476. pp. 208–217. (2019). google scholar 11. parui, s, samanta, d, chakravorty, n, ghosh, u, and rodrigues, jj. artificial intelligence and sensor-based autism spectrum disorder diagnosis using brain connectivity analysis. comput electr eng . (2023) 108:108720. doi: 10.1016/j.compeleceng.2023.108720 crossref full text | google scholar 12. golestan, s, soleiman, p, and moradi, h. a comprehensive review of technologies used for screening, assessment, and rehabilitation of autism spectrum disorder. arxiv . (2018) 2018:10986. doi: 10.48550/arxiv.1807.10986 crossref full text | google scholar 13. neeharika, ch, and riyazuddin, ym. developing an artificial intelligence based model for autism spectrum disorder detection in children. j adv res appl sci eng technol . (2023) 32:57–72. doi: 10.37934/araset.32.1.5772 crossref full text | google scholar 14. wall, dp, dally, r, luyster, r, jung, j-y, and deluca, tf. use of artificial intelligence to shorten the behavioral diagnosis of autism. plos one . (2012) 7:e43855. doi: 10.1371/journal.pone.0043855 pubmed abstract | crossref full text | google scholar 15. alzakari, sa, allinjawi, a, aldrees, a, zamzami, n, umer, m, innab, n, et al. early detection of autism spectrum disorder using explainable ai and optimized teaching strategies. j neurosci methods . (2025) 413:110315. doi: 10.1016/j.jneumeth.2024.110315 pubmed abstract | crossref full text | google scholar 16. heunis, t, aldrich, c, peters, j, jeste, s, sahin, m, scheffer, c, et al. recurrence quantification analysis of resting state eeg signals in autism spectrum disorder—a systematic methodological exploration of technical and demographic confounders in the search for biomarkers. bmc med . (2018) 16:101. doi: 10.1186/s12916-018-1086-7 crossref full text | google scholar 17. vicnesh, j, wei, jke, oh, sl, arunkumar, n, abdulhay, e, ciaccio, ej, et al. autism spectrum disorder diagnostic system using hos bispectrum with eeg signals. int j environ res public health . (2020) 17:971. doi: 10.3390/ijerph17030971 crossref full text | google scholar 18. novielli, p, romano, d, magarelli, m, diacono, d, monaco, a, amoroso, n, et al. personalized identification of autism-related bacteria in the gut microbiome using explainable artificial intelligence. iscience . (2024) 27:110709. doi: 10.1016/j.isci.2024.110709 pubmed abstract | crossref full text | google scholar 19. bosl, wj, tager-flusberg, h, and nelson, ca. eeg analytics for early detection of autism spectrum disorder: a data-driven approach. sci rep . (2018) 8:1–20. doi: 10.1038/s41598-018-24318-x pubmed abstract | crossref full text | google scholar 20. beykikhoshk, a, arandjelović, o, phung, d, venkatesh, s, and caelli, t. using twitter to learn about the autism community. soc netw anal min . (2015) 5:261. doi: 10.1007/s13278-015-0261- crossref full text | google scholar 21. mazurek, mo. social media use among adults with autism spectrum disorders. comput hum behav . (2013) 29:1709–14. doi: 10.1016/j.chb.2013.02.004 crossref full text | google scholar 22. onnela, j, and rauch, sl. harnessing smartphone-based digital phenotyping to enhance behavioral and mental health. neuropsychopharmacology . (2016) 41:1691–6. doi: 10.1038/npp.2016.7.npp20167 pubmed abstract | crossref full text | google scholar 23. tomeny, ts, vargo, cj, and el-toukhy, s. geographic and demographic correlates of autism-related anti-vaccine beliefs on twitter, 2009–2015. soc sci med . (2017) 191:168–75. doi: 10.1016/j.socscimed.2017.08.041 pubmed abstract | crossref full text | google scholar 24. tárraga-mínguez, r, gómez-marí, i, and sanz-cervera, p. what motivates internet users to search for asperger syndrome and autism on google? int j environ res public health . (2020) 17:9386. doi: 10.3390/ijerph17249386 pubmed abstract | crossref full text | google scholar 25. hartwell, m, keener, a, coffey, s, chesher, t, torgerson, t, and vassar, m. brief report: public awareness of asperger syndrome following greta thunberg appearances. j autism dev disord . (2020) 51:2104–8. doi: 10.1007/s10803-020-04651-9 pubmed abstract | crossref full text | google scholar 26. rubio-martín, s, garcía-ordás, mt, bayón-gutiérrez, m, prieto-fernández, n, and benítez-andrades, ja. “ early detection of autism spectrum disorder through ai-powered analysis of social media texts ,” 2023 ieee 36th international symposium on computer-based medical systems (cbms), l’aquila, italy, pp. 235–240. (2023). google scholar 27. jaiswal, a, and washington, p. using #actuallyautistic on twitter for precision diagnosis of autism spectrum disorder: machine learning study. jmir form res . (2024) 8:e52660. doi: 10.2196/52660 crossref full text | google scholar keywords: autism spectrum disorders, diagnosing, social media, deep learning, disabilities, artificial intelligence citation: farhah ns, alqarni aa, ebrahim n and ahmad s (2025) diagnosing autism spectrum disorders using a double deep q-network framework based on social media footprints. front. med . 12:1646249. doi: 10.3389/fmed.2025.1646249 received: 16 june 2025; accepted: 28 july 2025; published: 20 august 2025. edited by: pardeep sangwan , maharaja surajmal institute of technology, india reviewed by: jia-bao liu , anhui jianzhu university, china muhammad adnan , kohat university of science and technology, pakistan copyright © 2025 farhah, alqarni, ebrahim and ahmad. this is an open-access article distributed under the terms of the creative commons attribution license (cc by) . the use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. no use, distribution or reproduction is permitted which does not comply with these terms. *correspondence: nesren s. farhah, bi5myxjoywhac2v1lmvkds5zyq== ; nadhem ebrahim, bmvicmfoaw1adwfrcm9ulmvkdq== ; sultan ahmad, cy5hbglzagvyqhbzyxuuzwr1lnnh disclaimer: all claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. any product that may be evaluated in this article or claim that may be made by its manufacturer is not guaranteed or endorsed by the publisher. download article download pdf readcube epub xml share on export citation endnote reference manager simple text file bibtex 1,193 total views 132 downloads citation numbers are available from dimensions view article impact view altmetric score share on edited by p s pardeep sangwan reviewed by j l jia-bao liu m a muhammad adnan table of contents abstract 1 introduction 2 materials and methods 3 performance of the framework 4 experiment and discussion results 5 conclusion data availability statement ethics statement author contributions funding conflict of interest generative ai statement publisher’s note references export citation endnote reference manager simple text file bibtex check for updates frontiers' impact articles published with frontiers have received 12 million total citations your research is the real superpower - learn how we maximise its impact through our leading community journals explore our impact metrics supplementary material download article download download pdf readcube epub xml guidelines author guidelines services for authors policies and publication ethics editor guidelines fee policy explore articles research topics journals how we publish outreach frontiers forum frontiers policy labs frontiers for young minds frontiers planet prize connect help center emails and alerts contact us submit career opportunities follow us © 2025 frontiers media s.a. all rights reserved privacy policy | terms and conditions [["shallowreactive",1],{"data":2,"state":4,"once":10,"_errors":11,"serverrendered":13,"path":14,"pinia":15},["shallowreactive",3],{},["reactive",5],{"$ssite-config":6},{"env":7,"name":8,"url":9},"production","frontiers articles","https://article-pages-2024.frontiersin.org/",["set"],["shallowreactive",12],{},true,"/journals/medicine/articles/10.3389/fmed.2025.1646249/full",["reactive",16],{"main":17,"user":514,"article":515,"articlehub":766,"mainheader":770},{"ibar":18,"footer":268,"newslettercomponent":-1,"snackbaritem":350,"toggleshowsnackbar":351,"contentfuljournal":352,"graphjournal":416,"settingsfeaturesswitchers":420,"templatetogglebanner":421,"tenantconfig":479},{"tenantlogo":19,"journallogo":19,"aboutus":20,"submiturl":113,"showsubmitbutton":13,"journal":114,"sectionterm":199,"aboutjournal":200,"mainlinks":249,"journallinks":256,"helpcenterlink":265},"",[21,38,47,71,87],{"title":22,"links":23},"who we are",[24,29,32,35],{"text":25,"url":26,"target":27,"arialabel":28},"mission and values","https://www.frontiersin.org/about/mission","_self",null,{"text":30,"url":31,"target":27,"arialabel":28},"history","https://www.frontiersin.org/about/history",{"text":33,"url":34,"target":27,"arialabel":28},"leadership","https://www.frontiersin.org/about/leadership",{"text":36,"url":37,"target":27,"arialabel":28},"awards","https://www.frontiersin.org/about/awards",{"title":39,"links":40},"impact and progress",[41,44],{"text":42,"url":43,"target":27,"arialabel":28},"frontiers' impact","https://www.frontiersin.org/about/impact",{"text":45,"url":46,"target":27,"arialabel":28},"our annual reports","https://www.frontiersin.org/about/annual-reports",{"title":48,"links":49},"publishing model",[50,53,56,59,62,65,68],{"text":51,"url":52,"target":27,"arialabel":28},"how we publish","https://www.frontiersin.org/about/how-we-publish",{"text":54,"url":55,"target":27,"arialabel":28},"open access","https://www.frontiersin.org/about/open-access",{"text":57,"url":58,"target":27,"arialabel":28},"peer review","https://www.frontiersin.org/about/peer-review",{"text":60,"url":61,"target":27,"arialabel":28},"research integrity","https://www.frontiersin.org/about/research-integrity",{"text":63,"url":64,"target":27,"arialabel":28},"research topics","https://www.frontiersin.org/about/research-topics",{"text":66,"url":67,"target":27,"arialabel":28},"fair² data management","https://www.frontiersin.org/about/fair-data-management",{"text":69,"url":70,"target":27,"arialabel":28},"fee policy","https://www.frontiersin.org/about/fee-policy",{"title":72,"links":73},"services",[74,78,81,84],{"text":75,"url":76,"target":77,"arialabel":28},"societies","https://publishingpartnerships.frontiersin.org/","_blank",{"text":79,"url":80,"target":27,"arialabel":28},"national consortia","https://www.frontiersin.org/open-access-agreements/consortia",{"text":82,"url":83,"target":27,"arialabel":28},"institutional partnerships","https://www.frontiersin.org/about/open-access-agreements",{"text":85,"url":86,"target":27,"arialabel":28},"collaborators","https://www.frontiersin.org/about/collaborators",{"title":88,"links":89},"more from frontiers",[90,94,97,101,105,109],{"text":91,"url":92,"target":77,"arialabel":93},"frontiers forum","https://forum.frontiersin.org/","this link will take you to the frontiers forum website",{"text":95,"url":96,"target":27,"arialabel":28},"frontiers planet prize","https://www.frontiersin.org/about/frontiers-planet-prize",{"text":98,"url":99,"target":77,"arialabel":100},"press office","https://pressoffice.frontiersin.org/","this link will take you to the frontiers press office website",{"text":102,"url":103,"target":27,"arialabel":104},"sustainability","https://www.frontiersin.org/about/sustainability","link to information about frontiers' sustainability",{"text":106,"url":107,"target":77,"arialabel":108},"career opportunities","https://careers.frontiersin.org/","this link will take you to the frontiers careers website",{"text":110,"url":111,"target":27,"arialabel":112},"contact us","https://www.frontiersin.org/about/contact","this link will take you to the help pages to contact our support team","https://www.frontiersin.org/submission/submit?domainid=2&fieldid=39&specialtyid=0&entitytype=2&entityid=602",{"id":115,"name":116,"slug":117,"sections":118},602,"frontiers in medicine","medicine",[119,123,127,131,135,139,143,147,151,155,159,163,167,171,175,179,183,187,191,195],{"id":120,"name":121,"slug":122},797,"dermatology","dermatology",{"id":124,"name":125,"slug":126},842,"family medicine and primary care","family-medicine-and-primary-care",{"id":128,"name":129,"slug":130},681,"gastroenterology","gastroenterology",{"id":132,"name":133,"slug":134},1321,"gene and cell therapy","gene-and-cell-therapy",{"id":136,"name":137,"slug":138},790,"geriatric medicine","geriatric-medicine",{"id":140,"name":141,"slug":142},1969,"healthcare professions education","healthcare-professions-education",{"id":144,"name":145,"slug":146},752,"hematology","hematology",{"id":148,"name":149,"slug":150},3648,"hepatobiliary diseases","hepatobiliary-diseases",{"id":152,"name":153,"slug":154},3379,"infectious diseases: pathogenesis and therapy","infectious-diseases-pathogenesis-and-therapy",{"id":156,"name":157,"slug":158},1139,"intensive care medicine and anesthesiology","intensive-care-medicine-and-anesthesiology",{"id":160,"name":161,"slug":162},768,"nephrology","nephrology",{"id":164,"name":165,"slug":166},815,"nuclear medicine","nuclear-medicine",{"id":168,"name":169,"slug":170},2526,"obstetrics and gynecology","obstetrics-and-gynecology",{"id":172,"name":173,"slug":174},1635,"ophthalmology","ophthalmology",{"id":176,"name":177,"slug":178},618,"pathology","pathology",{"id":180,"name":181,"slug":182},1307,"precision medicine","precision-medicine",{"id":184,"name":185,"slug":186},678,"pulmonary medicine","pulmonary-medicine",{"id":188,"name":189,"slug":190},1306,"regulatory science","regulatory-science",{"id":192,"name":193,"slug":194},662,"rheumatology","rheumatology",{"id":196,"name":197,"slug":198},1318,"translational medicine","translational-medicine","sections",[201,225],{"title":202,"links":203},"scope",[204,207,210,213,216,219,222],{"text":205,"url":206,"target":27,"arialabel":28},"field chief editors","https://www.frontiersin.org/journals/medicine/about#about-editors",{"text":208,"url":209,"target":27,"arialabel":28},"mission & scope","https://www.frontiersin.org/journals/medicine/about#about-scope",{"text":211,"url":212,"target":27,"arialabel":28},"facts","https://www.frontiersin.org/journals/medicine/about#about-facts",{"text":214,"url":215,"target":27,"arialabel":28},"journal sections","https://www.frontiersin.org/journals/medicine/about#about-submission",{"text":217,"url":218,"target":27,"arialabel":28},"open access statement","https://www.frontiersin.org/journals/medicine/about#about-open",{"text":220,"url":221,"target":27,"arialabel":28},"copyright statement","https://www.frontiersin.org/journals/medicine/about#copyright-statement",{"text":223,"url":224,"target":27,"arialabel":28},"quality","https://www.frontiersin.org/journals/medicine/about#about-quality",{"title":226,"links":227},"for authors",[228,231,234,237,240,243,246],{"text":229,"url":230,"target":27,"arialabel":28},"why submit?","https://www.frontiersin.org/journals/medicine/for-authors/why-submit",{"text":232,"url":233,"target":27,"arialabel":28},"article types","https://www.frontiersin.org/journals/medicine/for-authors/article-types",{"text":235,"url":236,"target":27,"arialabel":28},"author guidelines","https://www.frontiersin.org/journals/medicine/for-authors/author-guidelines",{"text":238,"url":239,"target":27,"arialabel":28},"editor guidelines","https://www.frontiersin.org/journals/medicine/for-authors/editor-guidelines",{"text":241,"url":242,"target":27,"arialabel":28},"publishing fees","https://www.frontiersin.org/journals/medicine/for-authors/publishing-fees",{"text":244,"url":245,"target":27,"arialabel":28},"submission checklist","https://www.frontiersin.org/journals/medicine/for-authors/submission-checklist",{"text":247,"url":248,"target":27,"arialabel":28},"contact editorial office","https://www.frontiersin.org/journals/medicine/for-authors/contact-editorial-office",[250,253],{"text":251,"url":252,"target":27,"arialabel":28},"all journals","https://www.frontiersin.org/journals",{"text":254,"url":255,"target":27,"arialabel":28},"all articles","https://www.frontiersin.org/articles",[257,260,262],{"text":258,"url":259,"target":27,"arialabel":28},"articles","articles",{"text":63,"url":261,"target":27,"arialabel":28},"research-topics",{"text":263,"url":264,"target":27,"arialabel":28},"editorial board","editors",{"text":266,"url":267,"target":77,"arialabel":266},"help center","https://helpcenter.frontiersin.org",{"blocks":269,"sociallinks":323,"copyright":347,"termsandconditionsurl":348,"privacypolicyurl":349},[270,284,294,308],{"title":271,"links":272},"guidelines",[273,275,278,281,283],{"text":235,"url":274,"target":27,"arialabel":28},"https://www.frontiersin.org/guidelines/author-guidelines",{"text":276,"url":277,"target":27,"arialabel":28},"services for authors","https://www.frontiersin.org/for-authors/author-services",{"text":279,"url":280,"target":27,"arialabel":28},"policies and publication ethics","https://www.frontiersin.org/guidelines/policies-and-publication-ethics",{"text":238,"url":282,"target":27,"arialabel":28},"https://www.frontiersin.org/guidelines/editor-guidelines",{"text":69,"url":70,"target":27,"arialabel":28},{"title":285,"links":286},"explore",[287,288,291,293],{"text":258,"url":255,"target":27,"arialabel":28},{"text":289,"url":290,"target":27,"arialabel":28},"research topics ","https://www.frontiersin.org/research-topics",{"text":292,"url":252,"target":27,"arialabel":28},"journals",{"text":51,"url":52,"target":27,"arialabel":28},{"title":295,"links":296},"outreach",[297,300,303,307],{"text":298,"url":92,"target":77,"arialabel":299},"frontiers forum ","frontiers forum website",{"text":301,"url":302,"target":77,"arialabel":28},"frontiers policy labs ","https://policylabs.frontiersin.org/",{"text":304,"url":305,"target":77,"arialabel":306},"frontiers for young minds","https://kids.frontiersin.org/","frontiers for young minds journal",{"text":95,"url":96,"target":27,"arialabel":28},{"title":309,"links":310},"connect",[311,312,316,319,322],{"text":266,"url":267,"target":77,"arialabel":266},{"text":313,"url":314,"target":77,"arialabel":315},"emails and alerts ","https://subscription-management.frontiersin.org/emails/preferences#block0","subscribe to frontiers emails",{"text":317,"url":111,"target":27,"arialabel":318},"contact us ","subscribe to newsletter",{"text":320,"url":321,"target":27,"arialabel":28},"submit","https://www.frontiersin.org/submission/submit",{"text":106,"url":107,"target":77,"arialabel":28},[324,332,337,342],{"link":325,"type":328,"color":329,"icon":330,"size":331,"hiddentext":13},{"text":326,"url":327,"target":77,"arialabel":326},"frontiers facebook","https://www.facebook.com/frontiersin","link","grey","facebook","medium",{"link":333,"type":328,"color":329,"icon":336,"size":331,"hiddentext":13},{"text":334,"url":335,"target":77,"arialabel":28},"frontiers twitter","https://twitter.com/frontiersin","twitter",{"link":338,"type":328,"color":329,"icon":341,"size":331,"hiddentext":13},{"text":339,"url":340,"target":77,"arialabel":28},"frontiers linkedin","https://www.linkedin.com/company/frontiers","linkedin",{"link":343,"type":328,"color":329,"icon":346,"size":331,"hiddentext":13},{"text":344,"url":345,"target":77,"arialabel":28},"frontiers instagram","https://www.instagram.com/frontiersin_","instagram","frontiers media s.a. all rights reserved","https://www.frontiersin.org/legal/terms-and-conditions","https://www.frontiersin.org/legal/privacy-policy",{},false,{"__typename":353,"identifier":115,"name":116,"slug":117,"banner":354,"description":409,"mission":410,"palette":411,"impactfactor":412,"citescore":413,"citations":414,"showtagline":28,"twitter":415},"journal",[355],{"id":356,"src":357,"name":358,"tags":359,"type":367,"width":368,"height":369,"idhash":370,"archive":371,"brandid":372,"limited":371,"filesize":373,"ispublic":374,"original":375,"copyright":376,"extension":377,"thumbnails":379,"datecreated":387,"description":388,"orientation":389,"usercreated":390,"watermarked":371,"datemodified":387,"datepublished":391,"ecsarchivefiles":392,"propertyoptions":393,"property_channel":398,"property_sub-type":400,"property_asset_type":402,"activeoriginalfocuspoint":404,"property_office_department":407},"3501f557-cafa-4218-930c20d1d930c78c","https://d2csxpduxe849s.cloudfront.net/media/e32629c6-9347-4f84-81feaef7bfa342b3/3501f557-cafa-4218-930c20d1d930c78c/webimage-5988957c-0534-4338-984381d67214c0af.png","fmed_main visual_purple_website",[360,361,362,363,364,365,366],"professional","medical","research","biotechnology","scientific","analy","lab","image",7360,4912,"67388dad93685635",0,"22c10171-81b3-4da6-99342f272a32e8bb",13595017,1,"https://brand.frontiersin.org/m/67388dad93685635/original/fmed_main-visual_purple_website.jpg","copyright (c) 2018 rosshelen/shutterstock. no use without permission.",[378],"jpg",{"mini":380,"thul":381,"webimage":357,"guidelines":382,"websitejpg_xl":383,"websitewebp_l":384,"websitewebp_m":385,"websitewebp_xl":386},"https://d2csxpduxe849s.cloudfront.net/media/e32629c6-9347-4f84-81feaef7bfa342b3/3501f557-cafa-4218-930c20d1d930c78c/mini-4ebc2476-6efb-4a3e-a669185b307fef72.png","https://d2csxpduxe849s.cloudfront.net/media/e32629c6-9347-4f84-81feaef7bfa342b3/3501f557-cafa-4218-930c20d1d930c78c/thul-78bd9351-8a86-4c7b-874fc1cc5caa92ce.png","https://d2csxpduxe849s.cloudfront.net/media/e32629c6-9347-4f84-81feaef7bfa342b3/3501f557-cafa-4218-930c20d1d930c78c/f6ff788e-26d5-4bc5-8cb92ee85a59ca4a/guidelines-fmed_main visual_purple_website.png","https://d2csxpduxe849s.cloudfront.net/media/e32629c6-9347-4f84-81feaef7bfa342b3/3501f557-cafa-4218-930c20d1d930c78c/f6ff788e-26d5-4bc5-8cb92ee85a59ca4a/websitejpg_xl-fmed_main visual_purple_website.jpg","https://d2csxpduxe849s.cloudfront.net/media/e32629c6-9347-4f84-81feaef7bfa342b3/3501f557-cafa-4218-930c20d1d930c78c/f6ff788e-26d5-4bc5-8cb92ee85a59ca4a/websitewebp_l-fmed_main visual_purple_website.webp","https://d2csxpduxe849s.cloudfront.net/media/e32629c6-9347-4f84-81feaef7bfa342b3/3501f557-cafa-4218-930c20d1d930c78c/f6ff788e-26d5-4bc5-8cb92ee85a59ca4a/websitewebp_m-fmed_main visual_purple_website.webp","https://d2csxpduxe849s.cloudfront.net/media/e32629c6-9347-4f84-81feaef7bfa342b3/3501f557-cafa-4218-930c20d1d930c78c/f6ff788e-26d5-4bc5-8cb92ee85a59ca4a/websitewebp_xl-fmed_main visual_purple_website.webp","2022-06-27t10:00:04z","laboratory assistant putting test tubes into the holder, close-up view focused on the tubes","landscape","caroline sutter","2022-06-27t09:27:09z",[],[394,395,396,397],"414fb2d4-2283-43fd-be14e534eca67928","6c18119b-14bd-4951-b437696f4357bd33","7c692885-db25-4858-b1fb4ff47b241e9b","d88c0047-ec30-4506-a7df28a4d765e1cf",[399],"frontiersin_org",[401],"main_visual",[403],"photography",{"x":405,"y":406},3680,2456,[408],"publishing","a highly cited multidisciplinary journal which advances our medical knowledge. it supports the translation of scientific advances into new therapies and diagnostic tools that will improve patient care.","\u003cp>frontiers in medicine is a broad-scope, multidisciplinary journal covering all established medical disciplines to improve clinical practice and patient care.\u003c/p>\n\n\u003cp>led by field chief editor prof michel goldman (université libre de bruxelles, belgium), frontiers in medicine is indexed in pubmed central (pmc), web of science (scie), and scopus, among others, and welcomes basic and clinical medical research that facilitate the translation of scientific advances into new therapies or diagnostic tools. topics include, but are not limited to:\u003c/p>\n\n\u003cul>\n \u003cli>dermatology\u003c/li>\n \u003cli>family medicine and primary care\u003c/li>\n \u003cli>gastroenterology\u003c/li>\n \u003cli>gene and cell therapy\u003c/li>\n \u003cli>geriatric medicine\u003c/li>\n \u003cli>healthcare professions education\u003c/li>\n \u003cli>hematology\u003c/li>\n \u003cli>hepatobiliary diseases\u003c/li>\n \u003cli>infectious diseases: pathogenesis and therapy\u003c/li>\n \u003cli>intensive care medicine and anesthesiology\u003c/li>\n \u003cli>nephrology\u003c/li>\n \u003cli>nuclear medicine\u003c/li>\n \u003cli>obstetrics and gynecology\u003c/li>\n \u003cli>ophthalmology\u003c/li>\n \u003cli>pathology\u003c/li>\n \u003cli>precision medicine\u003c/li>\n \u003cli>pulmonary medicine\u003c/li>\n \u003cli>regulatory science\u003c/li>\n \u003cli>rheumatology\u003c/li>\n \u003cli>translational medicine.\u003c/li>\n\u003c/ul>\n\n\u003cp>in addition to papers that provide a link between basic research and clinical practice, a particular emphasis is given to studies that are directly relevant to patient care.\u003c/p>\n\n\u003cp>as well as the established medical disciplines, frontiers in medicine aims to publish research that will facilitate:\u003c/p>\n\n\u003cul>\n \u003cli>access to medicinal products and medical devices worldwide\u003c/li>\n \u003cli>addressing the grand health challenges around the world\u003c/li>\n \u003cli>the exploitation of big data and the use of novel information and communication tools in the assessment of new medicines\u003c/li>\n \u003cli>the scientific bases for guidelines and decisions from regulatory authorities\u003c/li>\n \u003cli>the use of patient-reported outcomes under real world conditions.\u003c/li>\n\u003c/ul>\n\n\u003cp>all studies must contribute insights into the field of medicine. papers which do not primarily focus on a medical discipline are not suitable for publication in this journal. manuscripts that focus solely on the molecular or cellular mechanisms of diseases without a foundation in clinical medicine are not suitable for publication in this journal. similarly, studies that are purely descriptive or observational, without a clear hypothesis or mechanistic investigation, are not within the scope of this journal. research that is primarily epidemiological or public health-oriented, without a foundation in the pathophysiology or treatment of disease, is also not appropriate for this journal.\u003c/p>\n\n\u003cp>frontiers’ journals require that manuscripts primarily comprising computational studies of public data, must include appropriate validation. please refer to the \u003ca href=\"https://www.frontiersin.org/guidelines/policies-and-publication-ethics#standards-for-research-methodology:~:text=complaints%20and%20allegations.-,standards%20for%20research%20methodology,-experiments\">frontiers standards for research methodology policy\u003c/a>, for more information. manuscripts not adhering to these standards will not be considered.\u003cp>\n\n\u003cp>frontiers in medicine is committed to advancing developments in the field of medicine by allowing unrestricted access to articles and communicating scientific knowledge to researchers and the public alike, to enable the scientific breakthroughs of the future.\u003c/p>\n\n\u003cp>ethics statement:\u003c/p>\n\n\u003cp>all manuscripts submitted to frontiers in medicine that have been conducted in human subjects must conform with current regulations and the declaration of helsinki. ethics committee approval and informed patient consent are required for studies involving human subjects. ethics committee approval is also needed for studies involving animals. phase i - phase iv clinical trials submitted for publication in frontiers in medicine must have been registered with an appropriate public trials registry at the time or before the first patient enrolment. the information on the clinical trial registration (unique identifier and url) must be included in the abstract. authors are required to disclose all apparent or potential conflicts of interest according to the icmje guidelines and those of frontiers.\u003c/p>\n\n\u003cp>frontiers endeavors to follow the guidelines and best practice recommendations published by the committee on publication ethics (cope). authors should refer to the author guidelines for full details.\u003c/p>","purple","3.9","3.6","176752","@frontmedicine",{"id":115,"name":116,"slug":117,"abbreviation":417,"isonline":13,"isopenforsubmissions":13,"citescore":418,"impactfactor":419},"fmed",6,3,{"displaytitlepilllabels":13,"displayrelatedarticlesbox":13,"showeditors":13,"showreviewers":13,"showloopimpactlink":13,"enablefigshare":351,"usexmlimages":13},{"ispublic":13,"allowcompanyusers":351,"whitelistemails":422,"enablealljournals":13,"whitelistjournals":444},[423,424,425,426,427,428,429,430,431,428,432,433,434,435,436,437,438,439,440,441,442,443],"y2fybg9zlmxvcmnhqgzyb250awvyc2lulm9yzw==","zgfuawvslmx1ekbmcm9udgllcnnpbi5vcmc=","bgf1cmeudgvuyubmcm9udgllcnnpbi5vcmc=","cmfmywvslnjpyw5jag9aznjvbnrpzxjzaw4ub3jn","amftzxmuc21hbgxib25lqgzyb250awvyc2lulm9yzw==","znjhbi5tb3jlbm9aznjvbnrpzxjzaw4ub3jn","c2ftdwvslmzlcm5hbmrlekbmcm9udgllcnnpbi5vcmc=","ymfyymfyys5jyxjjyw5naxvaznjvbnrpzxjzaw4ub3jn","axzhbi5zyw50yw1hcmlhqgzyb250awvyc2lulm9yzw==","ahvllnryyw5aznjvbnrpzxjzaw4ub3jn","z29uy2fsby52yxjnyxnaznjvbnrpzxjzaw4ub3jn","bhvjawuuc2vubkbmcm9udgllcnnpbi5vcmc=","bg9ybi5mcmfzzxjaznjvbnrpzxjzaw4ub3jn","zwxzys5jyxjyb25aznjvbnrpzxjzaw4ub3jn","bwfhcnrlbi52yw5kawpja0bmcm9udgllcnnpbi5vcmc=","ymluzgh1lmtyaxnobmfuqgzyb250awvyc2lulm9yzw==","bwf0dghldy5hdhr3yxrlcnnaznjvbnrpzxjzaw4ub3jn","z2l1bglhlnzhbhnly2noaubmcm9udgllcnnpbi5vcmc=","zmfiawfulmrlbgxhbw9ydgvaznjvbnrpzxjzaw4ub3jn","dmlqyxlhbi5wcebwaxrzb2x1dglvbnmuy29t","z3vpbgxhdw1llnnldxjhdebmcm9udgllcnnpbi5vcmc=",[445,446,447,406,448,449,374,450,115,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478],2232,1729,2357,2176,2333,1843,106,616,310,657,3123,1468,2137,628,1566,2726,2086,1490,451,141,1335,2655,1238,604,698,1547,176,1440,403,1239,755,2136,609,1534,{"spaceid":374,"name":374,"availablejournalpages":480,"announcement":484},[259,264,261,481,482,483],"volumes","about","community-reviewers",{"__typename":485,"sys":486,"preheader":42,"title":488,"description":489,"image":490,"link":512},"announcement",{"id":487},"5ittnttqgazppgh6rx0alm","articles published with frontiers have received 12 million total citations","your research is the real superpower - learn how we maximise its impact through our leading community journals",[491],{"archive":371,"brandid":372,"copyright":28,"datecreated":492,"datemodified":493,"datepublished":494,"description":28,"extension":495,"filesize":497,"height":498,"id":499,"ispublic":371,"limited":371,"name":500,"orientation":389,"original":28,"thumbnails":501,"type":367,"watermarked":371,"width":508,"videopreviewurls":509,"tags":510,"textmetaproperties":511,"src":502},"2025-06-18t12:58:01z","2025-06-18t14:15:34z","2025-06-18t12:57:32z",[496],"png",1365026,920,"7c5269c4-3c83-4591-951a74d15b95daea","impact metrics banner for article pages",{"webimage":502,"thul":503,"mini":504,"websitewebp_l":505,"websitewebp_m":506,"guidelines":507},"https://brand.frontiersin.org/m/59ee6275cb9a849c/webimage-impact-metrics-banner-for-article-pages.png","https://brand.frontiersin.org/m/59ee6275cb9a849c/thul-impact-metrics-banner-for-article-pages.png","https://brand.frontiersin.org/m/59ee6275cb9a849c/mini-impact-metrics-banner-for-article-pages.png","https://brand.frontiersin.org/asset/7c5269c4-3c83-4591-951a-74d15b95daea/websitewebp_l/impact-metrics-banner-for-article-pages.webp","https://brand.frontiersin.org/asset/7c5269c4-3c83-4591-951a-74d15b95daea/websitewebp_m/impact-metrics-banner-for-article-pages.webp","https://brand.frontiersin.org/asset/7c5269c4-3c83-4591-951a-74d15b95daea/guidelines/impact-metrics-banner-for-article-pages.png",1600,[],[],[],{"text":513,"url":43,"target":27,"arialabel":28},"explore our impact metrics",{"loggeduserinfo":-1},{"currentarticle":516,"ispreviewpage":351,"hassupplementaldata":351,"showcrossmarkwidget":13,"articletemplate":646,"currentarticlepagemetainfo":647,"xmlparsedarticlecontent":-1,"xmlparsingerror":-1},{"id":517,"doi":518,"title":519,"acceptancedate":520,"receptiondate":521,"publicationdate":522,"lastmodifieddate":523,"ispublished":13,"abstract":524,"researchtopic":525,"articletype":531,"stage":534,"keywords":536,"authors":543,"editors":584,"reviewers":592,"journal":607,"section":615,"impactmetrics":617,"volume":620,"articlevolume":621,"relatedarticles":622,"ispublishedv2":13,"contents":623,"files":626},1646249,"10.3389/fmed.2025.1646249","diagnosing autism spectrum disorders using a double deep q-network framework based on social media footprints","2025-07-28t08:25:45.000z","2025-06-16t12:25:51.000z","2025-08-20t00:00:00.000z","2025-10-21t02:22:52.270z","introductionsocial media is increasingly used in many contexts within the healthcare sector. the improved prevalence of internet use via computers or mobile devices presents an opportunity for social media to serve as a tool for the rapid and direct distribution of essential health information. autism spectrum disorders (asd) are a comprehensive neurodevelopmental syndrome with enduring effects. twitter has become a platform for the asd community, offering substantial assistance to its members by disseminating information on their beliefs and perspectives via language and emotional expression. adults with asd have considerable social and emotional challenges, while also demonstrating abilities and interests in screen-based technologies.methodsthe novelty of this research lies in its use in the context of twitter to analyze and identify asd. this research used twitter as the primary data source to examine the behavioral traits and immediate emotional expressions of persons with asd. we applied convolutional neural networks with long short-term memory (cnn-lstm), lstm, and double deep q-network (ddqn-inspired) using a standardized dataset including 172 tweets from the asd class and 158 tweets from the non-asd class. the dataset was processed to exclude lowercase text and special characters, followed by a tokenization approach to convert the text into integer word sequences. the encoding was used to transform the classes into binary labels. following preprocessing, the proposed framework was implemented to identify asd.resultsthe findings of the ddqn-inspired model demonstrate a high precision of 87% compared to the proposed model. this finding demonstrates the potential of the proposed approach for identifying asd based on social media content.discussionultimately, the proposed system was compared against the existing system that used the same dataset. the proposed approach is based on variations in the text of social media interactions, which can assist physicians and clinicians in performing symptom studies within digital footprint environments.",{"id":526,"title":527,"articlescount":528,"ismagazinepage":351,"slug":529,"isopenforsubmission":351,"views":530},69516,"ai innovations in neuroimaging: transforming brain analysis",10,"ai-innovations-in-neuroimaging-transforming-brain-analysis",16647,{"id":532,"name":533},24,"original research",{"id":535,"name":19},18,[537,538,539,540,541,542],"artificial intelligence","deep learning","social media","disabilities","autism spectrum disorders","diagnosing",[544,555,564,573],{"id":545,"firstname":546,"middlename":19,"lastname":547,"givennames":548,"iscorresponding":351,"isprofilepublic":13,"userid":545,"email":-1,"affiliations":549},2586659,"nesren s.","farhah","nesren s. ",[550,553],{"organizationname":551,"countryname":552,"cityname":19,"statename":19,"zipcode":19},"department of health informatics, college of health science, saudi electronic university","saudi arabia",{"organizationname":554,"countryname":552,"cityname":19,"statename":19,"zipcode":19},"king salman center for disability research",{"id":556,"firstname":557,"middlename":19,"lastname":558,"givennames":559,"iscorresponding":351,"isprofilepublic":13,"userid":556,"email":-1,"affiliations":560},3164796,"ahmed abdullah","alqarni","ahmed abdullah ",[561,562],{"organizationname":554,"countryname":552,"cityname":19,"statename":19,"zipcode":19},{"organizationname":563,"countryname":552,"cityname":19,"statename":19,"zipcode":19},"department of computer sciences and information technology, al-baha university",{"id":565,"firstname":566,"middlename":19,"lastname":567,"givennames":568,"iscorresponding":351,"isprofilepublic":13,"userid":565,"email":-1,"affiliations":569},3077810,"nadhem","ebrahim","nadhem ",[570],{"organizationname":571,"countryname":572,"cityname":19,"statename":19,"zipcode":19},"department of computer science, college of engineering and polymer science, university of akron","united states",{"id":574,"firstname":575,"middlename":19,"lastname":576,"givennames":577,"iscorresponding":351,"isprofilepublic":13,"userid":574,"email":-1,"affiliations":578},1762668,"sultan","ahmad","sultan ",[579,581],{"organizationname":580,"countryname":552,"cityname":19,"statename":19,"zipcode":19},"department of computer science, college of computer engineering and sciences, prince sattam bin abdulaziz university",{"organizationname":582,"countryname":583,"cityname":19,"statename":19,"zipcode":19},"school of computer science and engineering, lovely professional university","india",[585],{"id":586,"firstname":587,"middlename":19,"lastname":588,"givennames":589,"iscorresponding":351,"isprofilepublic":13,"userid":586,"email":-1,"affiliations":590},2928766,"pardeep","sangwan","pardeep ",[591],{"organizationname":19,"countryname":19,"cityname":19,"statename":19,"zipcode":19},[593,600],{"id":594,"firstname":595,"middlename":19,"lastname":596,"givennames":597,"iscorresponding":351,"isprofilepublic":13,"userid":594,"email":-1,"affiliations":598},1743107,"jia-bao","liu","jia-bao ",[599],{"organizationname":19,"countryname":19,"cityname":19,"statename":19,"zipcode":19},{"id":601,"firstname":602,"middlename":19,"lastname":603,"givennames":604,"iscorresponding":351,"isprofilepublic":13,"userid":601,"email":-1,"affiliations":605},3104897,"muhammad","adnan","muhammad ",[606],{"organizationname":19,"countryname":19,"cityname":19,"statename":19,"zipcode":19},{"id":115,"slug":117,"name":116,"shortname":608,"electronicissn":609,"field":610,"specialtyid":28,"journalsectionpaths":613},"front. med.","2296-858x",{"id":611,"domainid":612},39,2,[614],{"section":615},{"id":180,"name":181,"slug":182,"specialtyid":616},1754,{"views":618,"downloads":619,"citations":371},1193,132,12,"volume 12 - 2025",[],{"titlehtml":519,"fulltexthtml":624,"menuhtml":625},"\u003cdiv class=\"journalabstract\"> \u003ca id=\"h1\" name=\"h1\">\u003c/a>\n \u003cdiv class=\"authors\">\u003cspan class=\"author-wrapper notranslate\">\u003ca href=\"https://loop.frontiersin.org/people/2586659\" class=\"user-id-2586659\">\u003cimg class=\"pr5\" src=\"https://loop.frontiersin.org/images/profile/2586659/74\" onerror=\"this.onerror=null;this.src='https://loop.frontiersin.org/cdn/images/profile/default_32.jpg';\" alt=\"nesren s. farhah,
\">nesren s. farhah\u003c/a>\u003csup>1,2\u003c/sup>\u003csup>*\u003c/sup>\u003c/span>\u003cspan class=\"author-wrapper notranslate\">\u003ca href=\"https://loop.frontiersin.org/people/3164796\" class=\"user-id-3164796\">\u003cimg class=\"pr5\" src=\"https://loop.frontiersin.org/images/profile/3164796/74\" onerror=\"this.onerror=null;this.src='https://loop.frontiersin.org/cdn/images/profile/default_32.jpg';\" alt=\"ahmed abdullah alqarni,\">ahmed abdullah alqarni\u003c/a>\u003csup>2,3\u003c/sup>\u003c/span>\u003cspan class=\"author-wrapper notranslate\">\u003ca href=\"https://loop.frontiersin.org/people/3077810\" class=\"user-id-3077810\">\u003cimg class=\"pr5\" src=\"https://loop.frontiersin.org/images/profile/3077810/74\" onerror=\"this.onerror=null;this.src='https://loop.frontiersin.org/cdn/images/profile/default_32.jpg';\" alt=\"nadhem ebrahim
\">nadhem ebrahim\u003c/a>\u003csup>4\u003c/sup>\u003csup>*\u003c/sup>\u003c/span>\u003cspan class=\"author-wrapper notranslate\">\u003ca href=\"https://loop.frontiersin.org/people/1762668\" class=\"user-id-1762668\">\u003cimg class=\"pr5\" src=\"https://loop.frontiersin.org/images/profile/1762668/74\" onerror=\"this.onerror=null;this.src='https://loop.frontiersin.org/cdn/images/profile/default_32.jpg';\" alt=\"sultan ahmad,
\">sultan ahmad\u003c/a>\u003csup>5,6\u003c/sup>\u003csup>*\u003c/sup>\u003c/span>\u003c/div> \u003cul class=\"notes\"> \u003cli>\u003cspan>\u003csup>1\u003c/sup>\u003c/span>department of health informatics, college of health science, saudi electronic university, riyadh, saudi arabia\u003c/li> \u003cli>\u003cspan>\u003csup>2\u003c/sup>\u003c/span>king salman center for disability research, riyadh, saudi arabia\u003c/li> \u003cli>\u003cspan>\u003csup>3\u003c/sup>\u003c/span>department of computer sciences and information technology, al-baha university, al-baha, saudi arabia\u003c/li> \u003cli>\u003cspan>\u003csup>4\u003c/sup>\u003c/span>department of computer science, college of engineering and polymer science, university of akron, oh, united states\u003c/li> \u003cli>\u003cspan>\u003csup>5\u003c/sup>\u003c/span>department of computer science, college of computer engineering and sciences, prince sattam bin abdulaziz university, al-kharj, saudi arabia\u003c/li> \u003cli>\u003cspan>\u003csup>6\u003c/sup>\u003c/span>school of computer science and engineering, lovely professional university, phagwara, india\u003c/li> \u003c/ul>\n\u003cp class=\"mb15\">\u003cb>introduction:\u003c/b> social media is increasingly used in many contexts within the healthcare sector. the improved prevalence of internet use via computers or mobile devices presents an opportunity for social media to serve as a tool for the rapid and direct distribution of essential health information. autism spectrum disorders (asd) are a comprehensive neurodevelopmental syndrome with enduring effects. twitter has become a platform for the asd community, offering substantial assistance to its members by disseminating information on their beliefs and perspectives via language and emotional expression. adults with asd have considerable social and emotional challenges, while also demonstrating abilities and interests in screen-based technologies.\u003c/p>\n\u003cp class=\"mb15\">\u003cb>methods:\u003c/b> the novelty of this research lies in its use in the context of twitter to analyze and identify asd. this research used twitter as the primary data source to examine the behavioral traits and immediate emotional expressions of persons with asd. we applied convolutional neural networks with long short-term memory (cnn-lstm), lstm, and double deep q-network (ddqn-inspired) using a standardized dataset including 172 tweets from the asd class and 158 tweets from the non-asd class. the dataset was processed to exclude lowercase text and special characters, followed by a tokenization approach to convert the text into integer word sequences. the encoding was used to transform the classes into binary labels. following preprocessing, the proposed framework was implemented to identify asd.\u003c/p>\n\u003cp class=\"mb15\">\u003cb>results:\u003c/b> the findings of the ddqn-inspired model demonstrate a high precision of 87% compared to the proposed model. this finding demonstrates the potential of the proposed approach for identifying asd based on social media content.\u003c/p>\n\u003cp class=\"mb0\">\u003cb>discussion:\u003c/b> ultimately, the proposed system was compared against the existing system that used the same dataset. the proposed approach is based on variations in the text of social media interactions, which can assist physicians and clinicians in performing symptom studies within digital footprint environments.\u003c/p> \u003cdiv class=\"clear\">\u003c/div> \u003c/div> \u003cdiv class=\"journalfulltext\"> \u003ca id=\"h2\" name=\"h2\">\u003c/a>\n\u003ch2>1 introduction\u003c/h2>\n\u003cp class=\"mb0\">asd is among the most prevalent neurodevelopmental disorders. asd is often demonstrated in children by age three and is defined by impairments in social interactions and communication, repetitive sensory-motor activities, and stereotypical behavioral patterns (\u003ca href=\"#ref1\">1\u003c/a>). asd is a congenital neurodevelopmental condition characterized by symptoms that are evident in early infancy. autism, characterized by restricted interests, repetitive behaviors, and significant disparities in social communication and interaction, typically emerges during early developmental stages and presents challenges in various social functioning domains. a child with autism induces significant anxiety within the family due to several factors, including the ambiguity of the diagnosis, the intensity and persistence of the disease, and the child’s nonconformity to social norms. in opposition, social awareness of autism is markedly inadequate, often conflated with intellectual disability and seen as an incurable ailment (\u003ca href=\"#ref2\">2\u003c/a>, \u003ca href=\"#ref3\">3\u003c/a>). the asd concept is displayed in \u003ca href=\"#fig1\">figure 1\u003c/a>.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 1\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g001.jpg\" name=\"figure1\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g001.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g001.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g001.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g001.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g001.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g001.jpg\" alt=\"nine icons representing concepts related to autism and interventions. top row: discrete trial training, pivotal response training, and verbal behavior intervention. middle row: impulsiveness and aggression, preference for solitude, delayed language development. bottom row: prescription drugs during pregnancy, family history of autism, assistive technologies. each icon illustrates its concept with relevant imagery.\" id=\"fig1\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 1\u003c/b>. displays the asd concept.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb15\">content on social media, particularly videos and text disseminated by parents and caregivers, has emerged as a significant resource for facilitating the early identification of asd (\u003ca href=\"#ref4\">4\u003c/a>, \u003ca href=\"#ref5\">5\u003c/a>). social media are technological tools designed for sharing, enabling users to create networks or engage in existing ones. in that order, the pew research center identified the most popular social media sites as youtube, facebook, instagram, pinterest, linkedin, snapchat, twitter, and whatsapp (\u003ca href=\"#ref6\">6\u003c/a>). most consumers use these networks daily. this research utilizes twitter data to assess the stigmatization of autism and associated terminology, picked based on accessibility and popularity, with analysis conducted using artificial intelligence technologies (\u003ca href=\"#ref7\">7\u003c/a>).\u003c/p>\n\u003cp class=\"mb15\">conventional diagnostic methods, which primarily rely on observational and behavioral evaluations, often encounter issues with accessibility, consistency, and timeliness. recent technology breakthroughs, especially in artificial intelligence (ai), and sensor-based techniques, provide novel opportunities for improving asd identification. by developing more objective, accurate, and scalable approaches, these technologies transform diagnostic methodologies for autism spectrum disorder (asd) (\u003ca href=\"#ref8\">8\u003c/a>–\u003ca href=\"#ref10\">10\u003c/a>). one new way to study the motor patterns, attentional processes, and physiological responses linked to asd in real-time is wearable sensors, eye-tracking devices, and multimodal virtual reality settings. these technologies have the potential to give non-invasive, continuous monitoring, which might help with the early diagnosis of asd and shed light on neurological and behavioral traits that have been hard to document reliably.\u003c/p>\n\u003cp class=\"mb15\">nevertheless, advancements in contemporary research are required to substantiate their efficacy. sensor-based techniques may facilitate the identification of stereotyped behaviors and motor patterns linked to asd in realistic environments, potentially yielding data that could guide timely and customized therapies (\u003ca href=\"#ref11\">11\u003c/a>). neuroimaging and microbiome analysis further advance this technical domain by indicating neurological and biological traits specific to asd. ai-enhanced neuroimaging aids in identifying structural and functional brain connection patterns associated with asd, thereby enhancing the understanding of its neuroanatomical foundation (\u003ca href=\"#ref12\">12\u003c/a>).\u003c/p>\n\u003cp class=\"mb15\">the research conducted by neeharika and riyazuddin et al. (\u003ca href=\"#ref13\">13\u003c/a>) aimed to enhance the accuracy of asd screening by using feature selection methods in conjunction with sophisticated machine learning classifiers. their research included several datasets spanning infants, children, adolescents, and adults, enabling a thorough assessment of asd characteristics across different age demographics. authors’ use of mlp model capacity to reliably and rapidly identify asd, indicating a beneficial screening instrument suitable for various age groups, facilitating both clinical evaluations and extensive screenings. wall et al. (\u003ca href=\"#ref14\">14\u003c/a>) investigated machine learning (ml) algorithms for diagnosing asd using a standard dataset. the researchers focused on the alternating decision tree classifier to identify a limited yet efficient set of queries that optimize the diagnostic procedure. alzakari et al. (\u003ca href=\"#ref15\">15\u003c/a>) proposed a novel two-phase methodology to tackle the variability in asd features with ml approaches, including behavioral, linguistic, and physical data. the first step concentrates on identifying asd, using feature engineering methodologies and ml algorithms, including a logistic regression (lr) and support vector machine (svm) ensemble, attaining a classification with high accuracy. eeg assesses brain activity and may identify children predisposed to developing asd, hence facilitating early diagnosis. eeg data is used to compare asd and hc (\u003ca href=\"#ref16\">16\u003c/a>–\u003ca href=\"#ref18\">18\u003c/a>). in (\u003ca href=\"#ref19\">19\u003c/a>), the cnn model was used for classification after transforming the data into a two-dimensional format. while eeg may facilitate the diagnosis of asd, it is constrained by other factors, such as signal noise.\u003c/p>\n\u003cp class=\"mb15\">the research has used social media to investigate asd. however, exploiting these prevalent platforms and innovative online data sources may be feasible to enhance the comprehension of these diseases. previous research has utilized twitter data to investigate discussions on asd-related material, indicating that this subject is frequently addressed on this platform (\u003ca href=\"#ref20\">20\u003c/a>). considering the use of social media for researching asd is particularly significant, as a recent analysis indicated that around 80% of individuals with asd engage with prominent social media platforms (\u003ca href=\"#ref21\">21\u003c/a>). this study aims to build upon previous research and enhance our comprehension of whether publicly accessible social media data from twitter may provide insights into the existence of digital diagnostic indicators for asd (\u003ca href=\"#ref22\">22\u003c/a>). furthermore, we want to assess the viability of establishing a digital phenotype for asd using social media.\u003c/p>\n\u003cp class=\"mb0\">beykikhoshk et al. (\u003ca href=\"#ref20\">20\u003c/a>) examined twitter’s potential as a data-mining tool to comprehend the actions, challenges, and requirements of autistic individuals. the first finding pertained to the attributes of participants inside the autism subgroup of tweets, indicating that these tweets were highly informative and had considerable potential usefulness for public health experts and policymakers. tomeny et al. (\u003ca href=\"#ref23\">23\u003c/a>) examined demographic correlations of autism-related anti-vaccine opinions on twitter from 2009 to 2015. their results indicated that the frequency of autism-related anti-vaccine views online was alarming, with anti-vaccine tweets connecting with news events and demonstrating geographical clustering. from 2015 to 2019, tárraga-mínguez et al. (\u003ca href=\"#ref24\">24\u003c/a>) examined the phrases “autism” and “asperger” in spain in relation to google search peaks. the public view of autism was significantly impacted by how the condition was portrayed in the news and on social media, and the authors found that social marketing campaigns had a significant role in normalizing autism. in this research (\u003ca href=\"#ref25\">25\u003c/a>), looked at how people sought assistance. the results showed a strong correlation in google search interest between the terms “asperger syndrome” and “greta thunberg,” reaching their highest point in 2019. online traffic to the asperger/autism network and autism speaks websites increased steadily from june to december 2019, indicating a correlation between help-seeking behavior and thunberg’s fame, according to the research. according to the results, the stigma associated with asperger’s disorder may have been positively affected by thunberg’s public exposure.\u003c/p>\n\u003ch3>1.1 contribution\u003c/h3>\n\u003cp class=\"mb0\">the use of tweets from twitter for the detection of asd is substantial, since it offers extensive, real-time, user-generated data that facilitates the early identification of asd-related behaviors, particularly via self-reported experiences and parental observations. this methodology promotes the advancement of suggested models, namely lstm, cnn-lstm, and inspired ddqn, for natural language processing to examine linguistic patterns, feelings, and keywords related to asd. it provides insights into popular views, stigma, and misconceptions around autism, guiding awareness initiatives and public health measures. twitter data is a powerful and accessible resource for enhancing early detection and understanding of asd in diverse groups. utilizing social media in this manner may offer more accessible and timely screening, particularly in regions with limited healthcare resources.\u003c/p> \u003ca id=\"h3\" name=\"h3\">\u003c/a>\n\u003ch2>2 materials and methods\u003c/h2>\n\u003cp class=\"mb0\">\u003ca href=\"#fig2\">figure 2\u003c/a> shows the pipeline of the proposed system to provide a broader perspective to researchers and developers. the framework delineates the processing phases for the pipeline that utilizes social media content to diagnose asd. below, we present a comprehensive assessment of each step.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 2\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g002.jpg\" name=\"figure2\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g002.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g002.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g002.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g002.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g002.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g002.jpg\" alt=\"flowchart depicting a process for analyzing twitter data. it starts with social media avatars and a twitter api feeding into a word cloud for asd-related terms. next, preprocessing involves text cleaning, label encoding, and tokenization. this data feeds into deep learning models, including lstm, cnn-lstm, and ddqn. outputs are classified as asd or non-asd, with corresponding graphs indicating training and validation accuracy over epochs.\" id=\"fig2\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 2\u003c/b>. farmwork of asd system.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch3>2.1 dataset\u003c/h3>\n\u003cp class=\"mb0\">to help with the early diagnosis of asd by using proposed systems, the tasd-dataset includes comprehensive textual sequences that depict the everyday lives of children with and without asd. it offers new elements, including noise sensitivity, sharing interest, sign communication, and tiptoe flapping, it combines critical asd assessment aspects like attention response, word repetition, and emotional empathy, as shown in \u003ca href=\"#fig3\">figure 3\u003c/a>. parents may get detailed insights and better identify signs of autism spectrum disorder (asd) due to the deepening of certain behaviors. the dataset contains 172 tweets from the asd class and 158 non-asd tweets. \u003ca href=\"#fig4\">figure 4\u003c/a> shows the class of the dataset.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 3\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g003.jpg\" name=\"figure3\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g003.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g003.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g003.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g003.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g003.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g003.jpg\" alt=\"bar chart titled “feature frequencies” showing the count of various behaviors. “word repetition” has the highest frequency at 2.00. other features like “attention response,” “change reaction,” and “eye contact” have frequencies of 1.00 each.\" id=\"fig3\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 3\u003c/b>. features of the dataset.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline mb15\">\u003c/div>\n\u003cdiv class=\"imageheaders\">figure 4\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g004.jpg\" name=\"figure4\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g004.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g004.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g004.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g004.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g004.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g004.jpg\" alt=\"bar chart titled “number of tweets per class” compares tweet counts for asd and non-asd categories. asd has around 175 tweets, while non-asd has about 160 tweets.\" id=\"fig4\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 4\u003c/b>. label of the dataset.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch3>2.2 preprocessing\u003c/h3>\n\u003cp class=\"mb0\">text preprocessing is an essential step in the text processing process. words, sentences, and paragraphs can all be found in a text, which is defined as a meaningful sequence of characters. preprocessing methods feed text data to a proposed algorithm in a better form than in its natural state. a tweet can contain different viewpoints on the data it represents. tweets that have not been preprocessed are highly unstructured and contain redundant data. to address these issues, several steps are taken to preprocess tweets for detecting asd, as shown in \u003ca href=\"#fig5\">figure 5\u003c/a>.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 5\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g005.jpg\" name=\"figure5\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g005.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g005.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g005.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g005.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g005.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g005.jpg\" alt=\"flowchart depicting a text preprocessing workflow with three stages: text cleaning, label encoding, and tokenization and padding. the tokenization and padding section includes tokenizer, texts_to_sequences, and padding_sequences. arrows indicate process flow from left to right.\" id=\"fig5\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 5\u003c/b>. preprocessing asd text analysis.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch3>2.3 text cleaning\u003c/h3>\n\u003cp class=\"mb0\">the clean text preprocessing method is a significant step in text datasets because the text contains several extra contexts to preprocess and normalize raw text data for analysis. in these steps, the use is transformed to lowercase to guarantee consistency and prevent differentiation between “asd” and “non-asd.” subsequently, any characters that are not letters, numerals, or spaces are eliminated by a regular expression, so punctuation and other symbols that might create extraneous noise are removed. this method is ultimately applied to the ‘text’ column of the data frame, ensuring that all text elements are sanitized and prepared for feature extraction. \u003ca href=\"#fig6\">figure 6\u003c/a> displays the clean text process.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 6\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g006.jpg\" name=\"figure6\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g006.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g006.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g006.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g006.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g006.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g006.jpg\" alt=\"bar chart titled “text cleaning progression - sample 1” showing text length in characters for four stages: original, lowercased, no special chars, and trimmed. each bar’s length is nearly the same, around 150-200 characters.\" id=\"fig6\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 6\u003c/b>. clean text.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch3>2.4 label encoding\u003c/h3>\n\u003cp class=\"mb0\">the labelencoder method converts text class (asd and non-asd) into numbers, designating 0 for asd and 1 for non-asd. this transformation updates the classification effort by enabling the model to see the labels as numerical values instead of text. \u003ca href=\"#eq1\">equations 1\u003c/a>, \u003ca href=\"#eq2\">2\u003c/a> show the label encoding.\u003c/p>\n\u003cdiv id=\"eq1\" class=\"equationimageholder\">\u003cmath id=\"m1\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext mathvariant=\"italic\">yclassification\u003c/mtext>\u003cmo>∈\u003c/mo>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi mathvariant=\"italic\">asd\u003c/mi>\u003cmo>,\u003c/mo>\u003cmtext mathvariant=\"italic\">non\u003c/mtext>\u003cmo>−\u003c/mo>\u003cmi mathvariant=\"italic\">asd\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmtext mathvariant=\"italic\">then\u003c/mtext>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>1\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq19\" class=\"equationimageholder\">\u003cmath id=\"m2\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmi>y\u003c/mi>\u003cmo>=\u003c/mo>\u003cmtext mathvariant=\"italic\">labelencoder\u003c/mtext>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmtext mathvariant=\"italic\">yclassifcation\u003c/mtext>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>→\u003c/mo>\u003cmi>y\u003c/mi>\u003cmo>∈\u003c/mo>\u003cmo stretchy=\"true\">{\u003c/mo>\u003cmn>0\u003c/mn>\u003cmo>,\u003c/mo>\u003cmn>1\u003c/mn>\u003cmo stretchy=\"true\">}\u003c/mo>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>2\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003ch3>2.5 tokenization and padding\u003c/h3>\n\u003cp class=\"mb0\">tokenization and padding are essential nlp preprocessing procedures that transform unprocessed text into a numerical representation appropriate for machine learning models, particularly neural networks. \u003ca href=\"#fig7\">figure 7\u003c/a> shows the tokenization and padding \u003ca href=\"#eq3\">equation 3\u003c/a>.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 7\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g007.jpg\" name=\"figure7\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g007.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g007.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g007.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g007.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g007.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g007.jpg\" alt=\"sample text tokenization and padding process with three horizontal bar graphs. the first graph shows original text words. the second graph illustrates the tokenized sequence using word indexes with varying heights. the third graph shows a padded sequence with a fixed length of twenty, ensuring uniform token index lengths. the indexes used are rearranged with zero padding.\" id=\"fig7\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 7\u003c/b>. sample of text tokenization and padding.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch4>2.5.1 tokenizer\u003c/h4>\n\u003cp class=\"mb0\">tokenizer procedures transform textual data into a numerical representation suitable for input into neural networks. they convert a text corpus into integer sequences, assigning a distinct index to each unique word according to its frequency, as shown in \u003ca href=\"#eq3\">equation 3\u003c/a>. the tokenizer processing is shown in \u003ca href=\"#fig8\">figure 8\u003c/a>.\u003c/p>\n\u003cdiv id=\"eq2\" class=\"equationimageholder\">\u003cmath id=\"m3\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext mathvariant=\"italic\">index\u003c/mtext>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>w\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>=\u003c/mo>\u003cmsub>\u003cmo mathvariant=\"italic\">rank\u003c/mo>\u003cmi>f\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>w\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmtext mathvariant=\"italic\">if\u003c/mtext>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmsub>\u003cmo mathvariant=\"italic\">rank\u003c/mo>\u003cmi>f\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>w\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>≤\u003c/mo>\u003cmi>v\u003c/mi>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>3\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 8\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g008.jpg\" name=\"figure8\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g008.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g008.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g008.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g008.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g008.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g008.jpg\" alt=\"three bar charts illustrate text data analysis. chart a shows the top 20 most frequent words with “to” being the highest. chart b depicts sequence length distribution before padding, peaking at around 20 tokens. chart c displays sequence lengths post-padding, fixed at 200 tokens, appearing as a single line at the 200 mark.\" id=\"fig8\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 8\u003c/b>. tokenizer analysis: word frequencies and sequence lengths.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">where \u003cmath id=\"m4\">\u003cmsub>\u003cmo mathvariant=\"italic\">rank\u003c/mo>\u003cmi>f\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>w\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003c/math>is rank \u003cmath id=\"m5\">\u003cmi>w\u003c/mi>\u003c/math> frequency \u003cmath id=\"m6\">\u003cmi>f\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>w\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/math> and \u003cmath id=\"m7\">\u003cmi>v\u003c/mi>\u003c/math> is the maximum number of words.\u003c/p>\n\u003ch4>2.5.2 fit texts\u003c/h4>\n\u003cp class=\"mb0\">this phase is crucial for transforming unprocessed text into numerical sequences suitable for input into the proposed system.\u003c/p>\n\u003ch4>2.5.3 texts_to_sequences\u003c/h4>\n\u003cp class=\"mb0\">to convert unprocessed text input into sequences of word indices according to the mapping acquired via as shown in \u003ca href=\"#eq4\">equation 4\u003c/a>.\u003c/p>\n\u003cdiv id=\"eq3\" class=\"equationimageholder\">\u003cmath id=\"m8\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext mathvariant=\"italic\">sequence\u003c/mtext>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>t\u003c/mi>\u003cmi>i\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>=\u003c/mo>\u003cmo stretchy=\"true\">[\u003c/mo>\u003cmtext mathvariant=\"italic\">index\u003c/mtext>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmn>1\u003c/mn>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>,\u003c/mo>\u003cmtext mathvariant=\"italic\">index\u003c/mtext>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmn>2\u003c/mn>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>,\u003c/mo>\u003cmo>…\u003c/mo>\u003cmo>…\u003c/mo>\u003cmo>…\u003c/mo>\u003cmo>,\u003c/mo>\u003cmtext mathvariant=\"italic\">index\u003c/mtext>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmi>m\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo stretchy=\"true\">]\u003c/mo>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>4\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cp class=\"mb0\">where is the \u003cmath id=\"m9\">\u003cmsub>\u003cmi>t\u003c/mi>\u003cmi>i\u003c/mi>\u003c/msub>\u003c/math> is the sentence of the text contained, and \u003cmath id=\"m10\">\u003cmi>w\u003c/mi>\u003c/math> is the words of the text, whereas the \u003cmath id=\"m11\">\u003cmtext mathvariant=\"italic\">index\u003c/mtext>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmn>1\u003c/mn>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/math> is an index of the words in the context.\u003c/p>\n\u003ch4>2.5.4 padding_sequences\u003c/h4>\n\u003cp class=\"mb0\">normalize sequence lengths, which may differ post-tokenization, by padding shorter sequences and truncating larger ones to a predetermined length as shown in \u003ca href=\"#eq5\">equation 5\u003c/a>. the padding and truncated b are fixed on the length. \u003cmath id=\"m12\">\u003cmi>l\u003c/mi>\u003cmo>=\u003c/mo>\u003cmn>200\u003c/mn>\u003c/math>. the padding processing is shown in \u003ca href=\"#fig7\">figure 7\u003c/a>.\u003c/p>\n\u003cdiv id=\"eq4\" class=\"equationimageholder\">\u003cmath id=\"m13\">\u003cmi>x\u003c/mi>\u003cmo>=\u003c/mo>\u003cmo>∣\u003c/mo>\u003cmrow>\u003cmtable displaystyle=\"true\">\u003cmtr>\u003cmtd>\u003cmsub>\u003cmi>x\u003c/mi>\u003cmn>1\u003c/mn>\u003c/msub>\u003c/mtd>\u003c/mtr>\u003cmtr>\u003cmtd>\u003cmsub>\u003cmi>x\u003c/mi>\u003cmn>2\u003c/mn>\u003c/msub>\u003c/mtd>\u003c/mtr>\u003cmtr>\u003cmtd>\u003cmtable>\u003cmtr>\u003cmtd>\u003cmo>.\u003c/mo>\u003c/mtd>\u003c/mtr>\u003cmtr>\u003cmtd>\u003cmo>.\u003c/mo>\u003c/mtd>\u003c/mtr>\u003cmtr>\u003cmtd>\u003cmo>.\u003c/mo>\u003c/mtd>\u003c/mtr>\u003cmtr>\u003cmtd>\u003cmo>.\u003c/mo>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/mtd>\u003c/mtr>\u003cmtr>\u003cmtd>\u003cmi>y\u003c/mi>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/mrow>\u003cmo>∣\u003c/mo>\u003cmo>∈\u003c/mo>\u003cmsup>\u003cmi>ℝ\u003c/mi>\u003cmi mathvariant=\"italic\">nxl\u003c/mi>\u003c/msup>\u003cmtext>    (5)\u003c/mtext>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cp class=\"mb0\">where \u003cmath id=\"m14\">\u003cmi>x\u003c/mi>\u003c/math> is features contain padding and are tokenized, \u003cmath id=\"m15\">\u003cmi>l\u003c/mi>\u003c/math> is the length of the vector. the number of texts is indicated \u003cmath id=\"m16\">\u003cmi>n\u003c/mi>\u003c/math>, and \u003cmath id=\"m17\">\u003cmo>∈\u003c/mo>\u003cmsup>\u003cmi>ℝ\u003c/mi>\u003cmi mathvariant=\"italic\">nxl\u003c/mi>\u003c/msup>\u003c/math> is matrix lues.\u003c/p>\n\u003ch3>2.6 proposed systems\u003c/h3>\n\u003ch4>2.6.1 convolutional neural networks\u003c/h4>\n\u003cp class=\"mb0\">the cnn model is at the core of all advanced machine learning and deep learning applications. they can successfully address text classification, image recognition, object identification, and semantic segmentation. using the same method with a task as different as natural language processing is counterintuitive (\u003ca href=\"#ref7\">7\u003c/a>). the structure is presented in \u003ca href=\"#fig9\">figure 9\u003c/a>. \u003ca href=\"#eq6\">equation 6\u003c/a> presents the convolution layer of cnn.\u003c/p>\n\u003cdiv id=\"eq5\" class=\"equationimageholder\">\u003cmath id=\"m18\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmi>o\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo>,\u003c/mo>\u003cmi>y\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>=\u003c/mo>\u003cmunderover>\u003cmo movablelimits=\"false\">∑\u003c/mo>\u003cmrow>\u003cmi>i\u003c/mi>\u003cmo>=\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003cmi>h\u003c/mi>\u003c/munderover>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmunderover>\u003cmo movablelimits=\"false\">∑\u003c/mo>\u003cmrow>\u003cmi>j\u003c/mi>\u003cmo>=\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003cmi>w\u003c/mi>\u003c/munderover>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmi>i\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi>i\u003c/mi>\u003cmo>,\u003c/mo>\u003cmi>y\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi>j\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>∗\u003c/mo>\u003cmi>k\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>i\u003c/mi>\u003cmo>,\u003c/mo>\u003cmi>j\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>+\u003c/mo>\u003cmi>b\u003c/mi>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>6\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 9\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g009.jpg\" name=\"figure9\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g009.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g009.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g009.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g009.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g009.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g009.jpg\" alt=\"flowchart depicting a text classification process using convolutional neural networks. it starts with a sentence matrix representation. colored blocks denote convolution results with filter sizes of two, three, and four. the results undergo one-max pooling, then concatenate into a single vector. finally, the vector classifies into categories: information giving, information seeking, feature request, solution proposal, problem discovery, aspect evaluation, and others.\" id=\"fig9\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 9\u003c/b>. structure cnn.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">where the features of text \u003cmath id=\"m19\">\u003cmi>o\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo>,\u003c/mo>\u003cmi>y\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/math> the feature of the text is mapped by using.\u003cmath id=\"m20\">\u003cmi>i\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi>i\u003c/mi>\u003cmo>,\u003c/mo>\u003cmi>y\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi>j\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/math> is weighted by a neural network and \u003cmath id=\"m21\">\u003cmi>b\u003c/mi>\u003c/math> is biased to adjust the neural. the relu activation function is \u003ca href=\"#eq20\">equation 7\u003c/a>, the max pooling function is presented in \u003ca href=\"#eq6\">equation 8\u003c/a>. the dense layer is given in \u003ca href=\"#eq7\">equation 9\u003c/a>.\u003c/p>\n\u003cdiv id=\"eq20\" class=\"equationimageholder\">\u003cmath id=\"m22\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmi>f\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>=\u003c/mo>\u003cmi>max\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmn>0\u003c/mn>\u003cmo>,\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>7\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq6\" class=\"equationimageholder\">\u003cmath id=\"m23\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmi>o\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo>,\u003c/mo>\u003cmi>y\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>=\u003c/mo>\u003cmunderover>\u003cmo movablelimits=\"false\">∑\u003c/mo>\u003cmrow>\u003cmi>i\u003c/mi>\u003cmo>=\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003cmi>h\u003c/mi>\u003c/munderover>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmunderover>\u003cmo movablelimits=\"false\">∑\u003c/mo>\u003cmrow>\u003cmi>j\u003c/mi>\u003cmo>=\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003cmi>w\u003c/mi>\u003c/munderover>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmi>i\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi>i\u003c/mi>\u003cmo>,\u003c/mo>\u003cmi>y\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi>j\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>∗\u003c/mo>\u003cmi>k\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>i\u003c/mi>\u003cmo>,\u003c/mo>\u003cmi>j\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>+\u003c/mo>\u003cmi>b\u003c/mi>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>8\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq7\" class=\"equationimageholder\">\u003cmath id=\"m24\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmi mathvariant=\"normal\">o\u003c/mi>\u003cmo>=\u003c/mo>\u003cmi>w\u003c/mi>\u003cmo>·\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi>b\u003c/mi>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>9\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003ch4>2.6.2 long short-term memory network\u003c/h4>\n\u003cp class=\"mb0\">an lstm network is an advanced form of a sequential neural network. it fixes the problem of rnn gradients fading over time. rnns often handle long-term storage. at a high level, the operation of an lstm is comparable to that of a single rnn neuron. the inner workings of the lstm network are outlined in this section. the lstm consists of three parts, each performing a particular function, as seen in \u003ca href=\"#fig10\">figure 10\u003c/a> below. in the first step, it is decided whether the information from the previous time stamp is significant enough to be saved or if it is harmless enough to be deleted. in the second step, the cell will try to acquire new information by analyzing the data that has been presented to it. in the third and final step, the cell incorporates the data from the most recent time stamp into the data stored in the next time stamp. these three components constitute what is referred to as a gate for an lstm cell. the “forget” gate comes first, followed by the “input” section, and then the “output” section is used to define the last portion as shown in \u003ca href=\"#eq10\">equations 10\u003c/a>– \u003ca href=\"#eq14\">14\u003c/a>.\u003c/p>\n\u003cdiv id=\"eq8\" class=\"equationimageholder\">\u003cmath id=\"m25\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext>forget gate\u003c/mtext>\u003cmo>:\u003c/mo>\u003cmsub>\u003cmi>f\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>=\u003c/mo>\u003cmi>σ\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmi>f\u003c/mi>\u003c/msub>\u003cmo>.\u003c/mo>\u003cmsub>\u003cmi>x\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmi>f\u003c/mi>\u003c/msub>\u003cmo>.\u003c/mo>\u003cmsub>\u003cmi>h\u003c/mi>\u003cmrow>\u003cmi>t\u003c/mi>\u003cmo>−\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmsub>\u003cmi>b\u003c/mi>\u003cmi>f\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>10\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq9\" class=\"equationimageholder\">\u003cmath id=\"m26\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext>input gate\u003c/mtext>\u003cmo>:\u003c/mo>\u003cmsub>\u003cmi>i\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>=\u003c/mo>\u003cmi>σ\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmi>c\u003c/mi>\u003c/msub>\u003cmo>.\u003c/mo>\u003cmsub>\u003cmi>x\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmi>i\u003c/mi>\u003c/msub>\u003cmo>.\u003c/mo>\u003cmsub>\u003cmi>h\u003c/mi>\u003cmrow>\u003cmi>t\u003c/mi>\u003cmo>−\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmsub>\u003cmi>b\u003c/mi>\u003cmi>i\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>11\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq10\" class=\"equationimageholder\">\u003cmath id=\"m27\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext>cell gate\u003c/mtext>\u003cmo>:\u003c/mo>\u003cmsub>\u003cmi>c\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>=\u003c/mo>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmi>f\u003c/mi>\u003c/msub>\u003cmo>∗\u003c/mo>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmo>.\u003c/mo>\u003cmsub>\u003cmi>h\u003c/mi>\u003cmrow>\u003cmi>t\u003c/mi>\u003cmo>−\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003c/msub>\u003cmo>,\u003c/mo>\u003cmsub>\u003cmi>x\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmsub>\u003cmi>b\u003c/mi>\u003cmi>f\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>12\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq11\" class=\"equationimageholder\">\u003cmath id=\"m28\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext>output gate\u003c/mtext>\u003cmo>:\u003c/mo>\u003cmsub>\u003cmi>o\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>=\u003c/mo>\u003cmi>σ\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmi>o\u003c/mi>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmsub>\u003cmi>x\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmi>o\u003c/mi>\u003c/msub>\u003cmo>.\u003c/mo>\u003cmsub>\u003cmi>h\u003c/mi>\u003cmrow>\u003cmi>t\u003c/mi>\u003cmo>−\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmsub>\u003cmi>v\u003c/mi>\u003cmi>o\u003c/mi>\u003c/msub>\u003cmo>.\u003c/mo>\u003cmsub>\u003cmi>c\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmsub>\u003cmi>b\u003c/mi>\u003cmi>o\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>13\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq12\" class=\"equationimageholder\">\u003cmath id=\"m29\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext>hidden layer\u003c/mtext>\u003cmo>:\u003c/mo>\u003cmsub>\u003cmi>h\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>=\u003c/mo>\u003cmsub>\u003cmi>o\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmi>tanh\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>c\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>14\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 10\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g010.jpg\" name=\"figure10\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g010.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g010.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g010.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g010.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g010.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g010.jpg\" alt=\"flowchart of an lstm neural network model with multiple layers. the input layer feeds into 25 features, which connect to lstm layer 1 with 128 neurons. relu activation leads to lstm layer 2 with 64 neurons, followed by a sigmoid activation for binary classification into class 0 or class 1.\" id=\"fig10\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 10\u003c/b>. lstm model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb15\">in \u003ca href=\"#fig10\">figure 10\u003c/a>, \u003cmath id=\"m30\">\u003cmsub>\u003cmi>c\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003c/math> represent the prior and current states of the cell, respectively. both \u003cmath id=\"m31\">\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmsub>\u003cmi>h\u003c/mi>\u003cmrow>\u003cmi>t\u003c/mi>\u003cmo>−\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003c/msub>\u003c/math> and \u003cmath id=\"m32\">\u003cmi>h\u003c/mi>\u003c/math> represents the cell output that was processed before the one now being processed. it is common practice to disregard \u003cmath id=\"m33\">\u003cmsub>\u003cmi>f\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003c/math> as a gate, even though it is the input gate. the output of a sigmoid gate is symbolized here by \u003cmath id=\"m34\">\u003cmsub>\u003cmi>o\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003c/math>. the cable that connects the cell gates is where all the data collected by the cell gates is sent to and from \u003cmath id=\"m35\">\u003cmi>c\u003c/mi>\u003c/math>. the \u003cmath id=\"m36\">\u003cmsub>\u003cmi>f\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003c/math> layer decides to remember anything, and the\u003cmath id=\"m37\">\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmsub>\u003cmi>f\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmtext mathvariant=\"italic\">the\u003c/mtext>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003c/math>output is multiplied by c to do so (t-1). after that, c (t-1) is multiplied by the product of the sigmoid layer gate and the tanh layer gate, and the output h t is generated by point-wise multiplication of \u003cmath id=\"m38\">\u003cmsub>\u003cmi>o\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003c/math> and tanh.\u003c/p>\n\u003cp class=\"mb0\">the lstm architecture is intended to capture long-term relationships in twitter text data. the preprocessing converts input words that start with an embedding layer into 128-dimensional dense vectors. the lstm layer with 64 units is then used to mitigate overfitting, integrating dropout and recurrent dropout with 0.5. an l2 regularization term is further included in the lstm and output dense layer. \u003ca href=\"#tab1\">table 1\u003c/a> shows parameters of the lstm model.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">table 1\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t001.jpg\" name=\"table1\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t001.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t001.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t001.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t001.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t001.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t001.jpg\" alt=\"www.frontiersin.org\" id=\"tab1\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>table 1\u003c/b>. lstm parameters model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch4>2.6.3 cnn-lstm model\u003c/h4>\n\u003cp class=\"mb0\">the cnn-lstm model is a hybrid architecture that combines convolutional neural networks (cnn) for spatial feature extraction and long short-term memory (lstm) networks for sequential learning, making it highly effective for analyzing text data such as tweets. the model begins with an embedding layer that transforms each word into a 256-dimensional dense vector, capturing the semantic meaning of words. this is followed by a 1d convolutional layer with 64 filters and a kernel size of 5, which scans through the text to detect local patterns and n-gram features such as common word combinations or phrases often associated with asd. a batch normalization layer is applied to stabilize and accelerate training, followed by a max pooling layer that reduces the dimensionality and computational load by selecting the most prominent features. a dropout layer with a rate of 0.5 is then used to prevent overfitting by randomly deactivating some neurons during training. the output is passed into a 64-unit lstm layer that captures the temporal dependencies and contextual relationships across the tweet sequence. finally, a dense layer with sigmoid activation performs binary classification to predict whether the tweet indicates asd-related content. the model is trained using the adam optimizer, binary cross-entropy loss, class weights, and regularization to handle imbalanced data and improve generalization. the critical parameters of the cnn-lstm model are displayed in \u003ca href=\"#tab2\">table 2\u003c/a>.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">table 2\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t002.jpg\" name=\"table2\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t002.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t002.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t002.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t002.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t002.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t002.jpg\" alt=\"www.frontiersin.org\" id=\"tab2\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>table 2\u003c/b>. cnn-lstm parameters.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch4>2.6.4 double deep q-network (ddqn-inspired)\u003c/h4>\n\u003cp class=\"mb15\">the double q-learning model was introduced by h. van hasselt in 2010, addressing the issue of significant overestimations of action value (q-value) inherent in traditional q-learning. in fundamental q-learning, the agent’s optimal strategy is consistently to select the most advantageous action in any specific state. this concept’s premise is that the optimal action corresponds to the highest expected or estimated q-value. initially, the agent lacks any knowledge of the environment; it must first estimate q(s, a) and subsequently update these estimates with each iteration. the q-values exhibit considerable noise, leading to uncertainty about whether the action associated with the highest expected or estimated q-value is genuinely the optimal choice.\u003c/p>\n\u003cp class=\"mb0\">double q-learning employs two distinct action-value functions, q and q’, as estimators. even if q and q’ exhibit noise, this noise can be interpreted as a uniform distribution as shown \u003ca href=\"#fig11\">figure 11\u003c/a> the update procedure exhibits some variations compared to the basic version. the action selection and action evaluation processes are separated into two distinct maximum function estimators. shown in \u003ca href=\"#eq13\">equations 15\u003c/a>, \u003ca href=\"#eq16\">16\u003c/a>.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 11\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g011.jpg\" name=\"figure11\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g011.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g011.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g011.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g011.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g011.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g011.jpg\" alt=\"diagram illustrating the process of reinforcement learning with replay memory and q-networks. the replay memory outputs a mini-batch containing state, action, reward, and next state. this feeds into both the online and target q-networks. the online q-network outputs state-action pairs, which are used alongside the target q-network’s output in the loss function. a feedback loop connects the replay memory to the online q-network.\" id=\"fig11\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 11\u003c/b>. ddqn-inspired model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">let the vector of a neural network’s weights be represented by \u003ci>θ\u003c/i>. we establish two q-networks: the online q-network q (s, a; θ(t)) and the target q-network q (s, a; θ (t)). to be more specific, the training of q (s, a; \u003ci>Χ\u003c/i> (t)) is done by modifying the weights (t) at time slot t in relation to the goal value y(t).\u003c/p>\n\u003cdiv id=\"eq13\" class=\"equationimageholder\">\u003cmath id=\"m39\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmi>y\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>t\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>=\u003c/mo>\u003cmi>g\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>t\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>+\u003c/mo>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>s\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo>,\u003c/mo>\u003cmtext>argmax\u003c/mtext>\u003cmi>q\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>s\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo>,\u003c/mo>\u003cmsup>\u003cmi>a\u003c/mi>\u003cmo>∗\u003c/mo>\u003c/msup>\u003cmo>;\u003c/mo>\u003cmi>θ\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>t\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>;\u003c/mo>\u003cmi>θ\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>t\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>15\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq14\" class=\"equationimageholder\">\u003cmath id=\"m40\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmi>y\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>t\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>=\u003c/mo>\u003cmi>g\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>t\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>+\u003c/mo>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>s\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo>,\u003c/mo>\u003cmtext>argmax\u003c/mtext>\u003cmi>q\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>s\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo>,\u003c/mo>\u003cmsup>\u003cmi>a\u003c/mi>\u003cmo>∗\u003c/mo>\u003c/msup>\u003cmo>;\u003c/mo>\u003cmi>θ\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>;\u003c/mo>\u003cmsub>\u003cmi>θ\u003c/mi>\u003cmrow>\u003cmi>i\u003c/mi>\u003cmo>−\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>16\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cp class=\"mb15\">the reinforcement learning mechanism integrates generative artificial intelligence for decision-making and prediction tasks, as shown in \u003ca href=\"#eq15\">equations 15\u003c/a>, \u003ca href=\"#eq16\">16\u003c/a>. this equation indicates the generative which produces the estimation or hypothesis at a given time \u003cmath id=\"m41\">\u003cmi>t\u003c/mi>\u003c/math>.\u003cmath id=\"m42\">\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmtext mathvariant=\"italic\">double\u003c/mtext>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmi>q\u003c/mi>\u003cmo>−\u003c/mo>\u003cmtext mathvariant=\"italic\">learning\u003c/mtext>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003c/math>used next state, whereas the s’ is exit state and \u003cmath id=\"m43\">\u003cmtext>argmax\u003c/mtext>\u003cmi>q\u003c/mi>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>s\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo>,\u003c/mo>\u003cmsup>\u003cmi>a\u003c/mi>\u003cmo>∗\u003c/mo>\u003c/msup>\u003cmo>;\u003c/mo>\u003cmi>θ\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>t\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/math> defined as the action of \u003cmath id=\"m44\">\u003cmsup>\u003cmi>a\u003c/mi>\u003cmo>∗\u003c/mo>\u003c/msup>\u003c/math> to maximize the predicted q-value based on the current parameters. to estimate the q-value of this selected action in the next state, the outer q-function q’ employs the older parameters. \u003cmath id=\"m45\">\u003cmsub>\u003cmi>θ\u003c/mi>\u003cmrow>\u003cmi>i\u003c/mi>\u003cmo>−\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003c/msub>\u003c/math>1, which helps reduce overestimation bias. this combination makes applications for predicting asd from social media content domains possible.\u003c/p>\n\u003cp class=\"mb0\">the ddqn model is used to classify asd and non-asd cases utilizing text data. the model utilizes a preprocessing step for text processing that encompasses data loading, cleaning (including lowercasing, removal of special characters, and normalization of spaces), and tokenization, constrained by a maximum vocabulary of 10,000 words and a sequence length of 200. the model architecture, drawing from the double deep q-network (ddqn) model comprises an input layer, an embedding layer with 256 dimensions, and two parallel lstm branches, each containing 64 units, a dropout rate of 0.5, and l2 regularization to capture sequential patterns effectively. the model uses the adam optimizer with a learning rate of 1e-4 and employs binary cross-entropy loss. it is trained for 30 epochs, incorporating early stopping and learning rate reduction callbacks to mitigate overfitting. parameters of ddqn-inspired are shown in \u003ca href=\"#tab3\">table 3\u003c/a>.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">table 3\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t003.jpg\" name=\"table3\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t003.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t003.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t003.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t003.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t003.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t003.jpg\" alt=\"www.frontiersin.org\" id=\"tab3\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>table 3\u003c/b>. parameters of ddqn-inspired.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div> \u003ca id=\"h4\" name=\"h4\">\u003c/a>\n\u003ch2>3 performance of the framework\u003c/h2>\n\u003ch3>3.1 performance of lstm\u003c/h3>\n\u003cp class=\"mb0\">\u003ca href=\"#fig12\">figure 12\u003c/a> presents the accuracy and loss metrics used to train and validate an lstm model over 30 epochs. the validation accuracy of the lstm model, displayed in red, begins at a lower value and increases to about 81%. the blue line in the accuracy plot (a) shows the training accuracy of the lstm model; it increases gradually from around 50% to almost 99%, showing that the model learns the training data well over time. the plot (b) shows the loss of the lstm model; the blue line represents the training loss, which drops gradually from around 0.7 to less than 0.2, suggesting that the model is getting a better fit to the training data. meanwhile, the red validation loss line declines from around 0.7 to about 0.3. while the training loss continues to grow, the validation loss reaches a level and exhibits small oscillations, suggesting that the model’s generalizability may stabilize.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 12\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g012.jpg\" name=\"figure12\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g012.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g012.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g012.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g012.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g012.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g012.jpg\" alt=\"two line graphs depict an lstm model’s performance over 30 epochs. the left graph shows accuracy, with training accuracy rising from 0.5 to 0.9, while validation accuracy fluctuates around 0.8. the right graph displays loss, where training loss decreases from 0.7 to 0.1, and validation loss reduces from 0.7 to 0.3. both graphs feature blue lines for training metrics and red lines for validation metrics.\" id=\"fig12\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 12\u003c/b>. performance of the lstm model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">the roc curve illustrated in \u003ca href=\"#fig13\">figure 13\u003c/a> shows the efficacy of the lstm model in differentiating between the classes. the graph illustrates the tp rate (sensitivity) in relation to the fp rate across different threshold levels. the lstm model attains an auc of 0.95, demonstrating exceptional classification capability. the auc of 1.0, but a result of 0.5 indicates random chance.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 13\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g013.jpg\" name=\"figure13\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g013.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g013.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g013.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g013.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g013.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g013.jpg\" alt=\"roc curve for an lstm model showing the trade-off between true positive rate and false positive rate. the curve bends towards the top-left corner, with an area under the curve (auc) of 0.95, indicating high model performance. a diagonal dashed line represents random chance.\" id=\"fig13\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 13\u003c/b>. roc of the lstm model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch3>3.2 performance of the cnn-lstm model\u003c/h3>\n\u003cp class=\"mb0\">\u003ca href=\"#fig14\">figure 14\u003c/a> presents plots illustrating the performance of a cnn-lstm model over 25 epochs, showing its training and validation metrics for accuracy and loss. the accuracy plot (a) illustrates the training accuracy (blue line), which increases progressively from approximately 51.42% to nearly 99.53%, indicating effective learning from the training data. in contrast, the validation accuracy (red line) rises to about 83.02% with some variability, indicating satisfactory but imperfect generalization. the loss plot (b) shows the training loss (blue line) declining steadily from 0.7140 to below 0.0760, indicating enhanced model fit. in contrast, the validation loss (red line) decreases from 0.7130 to approximately 0.3530, with a slight decline toward the conclusion. this notification indicates that the cnn-lstm model demonstrates efficient learning, as evidenced by the difference between the training and validation measures.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 14\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g014.jpg\" name=\"figure14\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g014.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g014.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g014.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g014.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g014.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g014.jpg\" alt=\"two line graphs show cnn-lstm model performance. the left graph displays training and validation accuracy over 25 epochs. training accuracy improves significantly, surpassing validation accuracy, which fluctuates. the right graph depicts training and validation loss over the same epochs. training loss decreases sharply, while validation loss also reduces but stabilizes after an initial drop.\" id=\"fig14\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 14\u003c/b>. performance of the lstm model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">\u003ca href=\"#fig15\">figure 15\u003c/a> illustrates the roc curve for the cnn-lstm model, illustrating its classification performance at various thresholds. the graph illustrates the tp rate (sensitivity) in relation to the fp rate, with the auc recorded at 92%. the elevated auc value indicates the model has robust discriminative capability in differentiating between the asd and non-asd classes. the roc ascends rapidly toward the top-left corner, as seen in the figure, indicating a high tp rate with few false positives.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 15\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g015.jpg\" name=\"figure15\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g015.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g015.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g015.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g015.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g015.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g015.jpg\" alt=\"roc curve for a cnn_lstm model, showing the true positive rate against the false positive rate. the curve is above the diagonal, with an area under the curve (auc) of 0.92, indicating strong model performance.\" id=\"fig15\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 15\u003c/b>. roc of the cnn-lstm model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch3>3.3 performance of ddqn-inspired model\u003c/h3>\n\u003cp class=\"mb0\">graphs 16 illustrate the performance of a ddqn throughout 30 epochs. the accuracy plot (a) demonstrates that the training accuracy increases from around 58.02% to almost 98.58%, indicating the ddqn model successful learning from the training data over time. the validation accuracy of the ddqn is about 87, showing the best performance compared to different models like lstm and cnn-lstm. the plot (b) illustrates that the training loss decreases from about 0.8155 to around 0.1477, indicating a robust fit to the training data. the validation loss begins at 0.3831 with many fluctuations throughout (\u003ca href=\"#fig16\">figure 16\u003c/a>).\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 16\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g016.jpg\" name=\"figure16\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g016.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g016.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g016.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g016.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g016.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g016.jpg\" alt=\"two graphs display the performance of a ddqn_t model over 30 epochs. graph (a) shows training accuracy in blue and validation accuracy in red, both improving over time. graph (b) illustrates training loss in blue and validation loss in red, both decreasing with some fluctuations.\" id=\"fig16\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 16\u003c/b>. performance of the \u003ci>ddqn-inspired\u003c/i> model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">\u003ca href=\"#fig17\">figure 17\u003c/a> shows the roc curve for the ddqn model; it shows a visual representation of its classification capability, with the curve toward the top-left corner, indicating strong predictive power. the auc value of the ddqn model is 96%, demonstrating that the model can distinguish between the positive and negative classes.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 17\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g017.jpg\" name=\"figure17\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g017.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g017.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g017.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g017.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g017.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g017.jpg\" alt=\"receiver operating characteristic (roc) curve illustrating a ddqn-inspired model performance. the curve shows the trade-off between true positive rate and false positive rate with an area under the curve (auc) of 0.96, indicating high accuracy.\" id=\"fig17\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 17\u003c/b>. roc \u003ci>ddqn-inspired model.\u003c/i>\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div> \u003ca id=\"h5\" name=\"h5\">\u003c/a>\n\u003ch2>4 experiment and discussion results\u003c/h2>\n\u003cp class=\"mb0\">both the jupyter deep learning framework and the windows 10 operating system were utilized during the testing process. experiments were conducted using a machine with 16 gigabytes of ram and an intel core i7 central processing unit. the input dimensions of the experiment were a standard text dataset collected from the twitter api related to asd. the test was utilized in our database, while the remaining 20% was used as part of our validation set. the three dl models, namely lstm, cnn-lstm, and ddqn-inspired, were proposed for detecting asd from social media content.\u003c/p>\n\u003ch3>4.1 measuring the model’s performance\u003c/h3>\n\u003cp class=\"mb0\">sensitivity, specificity, accuracy, recall, and f1 scores are assessment measures used to determine how successfully the algorithms identify asd. the related equations from \u003ca href=\"#eq17\">17\u003c/a> to \u003ca href=\"#eq21\">21\u003c/a>:\u003c/p>\n\u003cdiv id=\"eq15\" class=\"equationimageholder\">\u003cmath id=\"m46\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext mathvariant=\"italic\">accuracy\u003c/mtext>\u003cmo>=\u003c/mo>\u003cmfrac>\u003cmrow>\u003cmi mathvariant=\"italic\">tp\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi mathvariant=\"italic\">tn\u003c/mi>\u003c/mrow>\u003cmrow>\u003cmi mathvariant=\"italic\">tp\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi mathvariant=\"italic\">fp\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi mathvariant=\"italic\">fn\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi mathvariant=\"italic\">tn\u003c/mi>\u003c/mrow>\u003c/mfrac>\u003cmo>×\u003c/mo>\u003cmn>100\u003c/mn>\u003cmo>%\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>17\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq16\" class=\"equationimageholder\">\u003cmath id=\"m47\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext mathvariant=\"italic\">sensitivity\u003c/mtext>\u003cmo>=\u003c/mo>\u003cmfrac>\u003cmi mathvariant=\"italic\">tp\u003c/mi>\u003cmrow>\u003cmi mathvariant=\"italic\">tp\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi mathvariant=\"italic\">fn\u003c/mi>\u003c/mrow>\u003c/mfrac>\u003cmo>×\u003c/mo>\u003cmn>100\u003c/mn>\u003cmo>%\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>18\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq17\" class=\"equationimageholder\">\u003cmath id=\"m48\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext mathvariant=\"italic\">precision\u003c/mtext>\u003cmo>=\u003c/mo>\u003cmfrac>\u003cmi mathvariant=\"italic\">tp\u003c/mi>\u003cmrow>\u003cmi mathvariant=\"italic\">tp\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi mathvariant=\"italic\">fp\u003c/mi>\u003c/mrow>\u003c/mfrac>\u003cmo>×\u003c/mo>\u003cmn>100\u003c/mn>\u003cmo>%\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>19\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq21\" class=\"equationimageholder\">\u003cmath id=\"m49\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext mathvariant=\"italic\">specificity\u003c/mtext>\u003cmo>=\u003c/mo>\u003cmfrac>\u003cmi mathvariant=\"italic\">tn\u003c/mi>\u003cmrow>\u003cmi mathvariant=\"italic\">tn\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi mathvariant=\"italic\">fp\u003c/mi>\u003c/mrow>\u003c/mfrac>\u003cmo>×\u003c/mo>\u003cmn>100\u003c/mn>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>20\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq18\" class=\"equationimageholder\">\u003cmath id=\"m50\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmi>f\u003c/mi>\u003cmn>1\u003c/mn>\u003cmo>−\u003c/mo>\u003cmtext mathvariant=\"italic\">score\u003c/mtext>\u003cmo>=\u003c/mo>\u003cmn>2\u003c/mn>\u003cmo>∗\u003c/mo>\u003cmfrac>\u003cmrow>\u003cmtext mathvariant=\"italic\">precision\u003c/mtext>\u003cmo>×\u003c/mo>\u003cmtext mathvariant=\"italic\">sensitivity\u003c/mtext>\u003c/mrow>\u003cmrow>\u003cmtext mathvariant=\"italic\">precision\u003c/mtext>\u003cmo>+\u003c/mo>\u003cmtext mathvariant=\"italic\">sensitivity\u003c/mtext>\u003c/mrow>\u003c/mfrac>\u003cmo>×\u003c/mo>\u003cmn>100\u003c/mn>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>21\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003ch3>4.2 result of the lstm model\u003c/h3>\n\u003cp class=\"mb0\">the classification lstm model, presented in \u003ca href=\"#tab4\">table 4\u003c/a>, summarizes its performance in differentiating between asd and non-asd patients, attaining an overall accuracy of 81%. the lstm model demonstrates in asd class a precision of 91%, indicating a high accuracy in identifying predicted asd cases. the lstm with recall metric scored 77% and an f1-score of 82% for detecting the asd class. the lstm model with non-asd class demonstrates a precision of 71%, a recall of 89%, and an f1-score of 79%, to identify non-asd cases. the macro average of the lstm model for all metrics is (precision: 81%, recall: 82%, f1-score: 81%). lstm model is recognized for its efficiency and scalability as a model for social media content.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">table 4\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t004.jpg\" name=\"table4\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t004.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t004.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t004.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t004.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t004.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t004.jpg\" alt=\"www.frontiersin.org\" id=\"tab4\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>table 4\u003c/b>. lstm results.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">the confusion matrix for the lstm model is provided in \u003ca href=\"#fig18\">figure 18\u003c/a>. it is presented in a clear manner. among the confirmed asd cases, 29 were accurately identified as asd, whereas 10 were incorrectly classified as non-asd, indicating strong performance with minor errors. in the true non-asd cases, 25 were correctly identified, while 3 were misclassified as asd, suggesting a generally effective detection process. the deep blue and light shades produce a tranquil visual, illustrating the model’s balanced approach in classifying the 67 total instances, demonstrating notable strength in identifying non-asd cases, while exhibiting marginally lower accuracy for asd. this matrix effectively illustrates the lstm model’s systematic approach to managing sequential data, such as text or time-series inputs, in a clear and comprehensible manner.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 18\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g018.jpg\" name=\"figure18\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g018.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g018.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g018.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g018.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g018.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g018.jpg\" alt=\"confusion matrix for lstm model showing true labels versus predicted labels. the matrix includes 29 true positives for asd, 25 true negatives for non-asd, 10 false positives, and 3 false negatives. a color gradient represents value intensity.\" id=\"fig18\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 18\u003c/b>. lstm model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch3>4.3 result of the cnn-lstm model\u003c/h3>\n\u003cp class=\"mb0\">\u003ca href=\"#tab5\">table 5\u003c/a> displays the cnn-lstm model’s performance in distinguishing between asd and non-asd classes. the cnn-lstm model attained an overall accuracy of 85% across the dataset. in the asd label, a precision of 91% was achieved, a high percentage for predicting asd cases that were accurately recognized. the recall indicates that the model identified 82% of all genuine asd cases, resulting in an f1 score of 86%, better than the recall metric. the cnn-lstm model attained 78% accuracy, 89% recall, and an 83% f1 score for the non-asd class. the macro average, representing the unweighted mean of precision, recall, and f1 score across both classes, was 85, 86, and 85%, respectively. the findings indicate that the cnn-lstm model performs satisfactorily, exhibiting a marginally superior capacity to identify asd cases relative to non-asd cases accurately.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">table 5\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t005.jpg\" name=\"table5\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t005.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t005.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t005.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t005.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t005.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t005.jpg\" alt=\"www.frontiersin.org\" id=\"tab5\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>table 5\u003c/b>. results of the cnn-lstm model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">the confusion matrix of a cnn-lstm model is presented in \u003ca href=\"#fig19\">figure 19\u003c/a>, for classifying instances into asd and non-asd. the matrix is structured with true labels on the vertical axis and predicted labels on the horizontal axis, providing a clear summary of the model’s classification outcomes. the matrix shows that out of the instances truly labeled as asd, the model correctly predicted 32 as asd tp while 7 were incorrectly classified as non-asd fn. for the instances truly labeled as non-asd, the model accurately identified 25 as non-asd tn but 3 were misclassified as asd fp. this indicates that the model demonstrates a relatively strong ability to correctly identify asd and non-asd cases, with higher accuracy for true positives (32 out of 39 asd cases) and true negatives (25 out of 28 non-asd cases). overall, the model exhibits promising performance with minimal misclassification errors.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 19\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g019.jpg\" name=\"figure19\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g019.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g019.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g019.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g019.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g019.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g019.jpg\" alt=\"confusion matrix for cnn_lstm_model with predicted labels on the x-axis and true labels on the y-axis. it shows 32 true positives, 7 false negatives, 3 false positives, and 25 true negatives. a gradient bar on the right indicates color intensity from light to dark blue, representing increasing values from 0 to 30.\" id=\"fig19\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 19\u003c/b>. results of cnn-lstm model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch3>4.4 results of double deep q-network\u003c/h3>\n\u003cp class=\"mb0\">the findings of the ddqn model are shown in \u003ca href=\"#tab6\">table 6\u003c/a>, achieving a high precision of 87% compared to the other models. this finding demonstrates the potential of the proposed ddqn approach for identifying asd based on social media content. ultimately, the proposed system was compared against the existing one using the same dataset. the proposed approach may assist physicians in detecting asd and conducting symptomology research in a natural environment, attaining an overall accuracy of 87. the model for the asd class shows a precision of 95%, a recall of 79%, and an f1-score of 87%, indicating robust efficacy in accurately identifying asd patients. the non-asd class has a precision of 77%, a recall of 96%, and an f1-score of 86%, indicating somewhat reduced accuracy with robust recall. the macro average measures (precision 87%, recall 88%, f1-score 87%) indicate performance across both classes.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">table 6\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t006.jpg\" name=\"table6\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t006.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t006.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t006.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t006.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t006.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t006.jpg\" alt=\"www.frontiersin.org\" id=\"tab6\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>table 6\u003c/b>. result of ddqn-inspired.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">the confusion matrix of the ddqn model is shown in \u003ca href=\"#fig20\">figure 20\u003c/a> for the classification task between asd and non-asd cases. for correct classification of asd cases, the model correctly classified 31 instances as asd, represented by the top-left quadrant (tp). however, the ddqn model, misclassified 8 instances misclassifying true asd cases as non-asd, shown in the top-right quadrant (fn). on the other hand, the ddqn showed the true non-asd cases, accurately identified 27 instances as non-asd, depicted in the bottom-right quadrant (tn). at the same time, 1 instance was incorrectly labeled as asd, as shown in the bottom-left quadrant (fp). the confusion matrix of ddqn model highlights that it performs well overall, with a strong ability to correctly identify both asd and non-asd cases, as evidenced by the high counts of tp (31) and tn (27).\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 20\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g020.jpg\" name=\"figure20\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g020.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g020.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g020.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g020.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g020.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g020.jpg\" alt=\"confusion matrix title “ddqn-inspired confusion matrix”. the matrix shows actual versus predicted labels for asd and non-asd. true positives: 31, false positives: 8, false negatives: 1, true negatives: 27. a color bar on the right indicates intensity from light to dark blue, corresponding to values from 0 to 30.\" id=\"fig20\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 20\u003c/b>. result of ddqn-inspired model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb15\">in the digital era, people frequently write content on social media to express their feelings, opinions, beliefs, and activities. this makes social media one of the most significant sources of data generation, allowing you to explore its opportunities and challenges. today, social media has become a mediator between people and the healthcare sector, enabling them to search for information about any specific disease and methods for diagnosing it.\u003c/p>\n\u003cp class=\"mb0\">individuals within the mental health community use social media platforms such as twitter to seek information, exchange experiences, and get assistance about asd in an environment that is seen as more approachable and informal than conventional medical contexts. they often seek immediate, relevant information—whether to understand symptoms, identify coping mechanisms, or connect with others facing similar difficulties. \u003ca href=\"#fig21\">figure 21\u003c/a> illustrates that word clouds are visual representations of text that highlight key terms and their frequency of use. we used wordcloud to compare asd and non-asd texts for instances of word repetition.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 21\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g021.jpg\" name=\"figure21\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g021.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g021.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g021.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g021.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g021.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g021.jpg\" alt=\"word cloud with terms related to asd class, including prominent words like “toddler,” “ability,” “might,” “concerned,” “activities,” and “making.” other words such as “engage,” “learning,” “challenging,” “noise,” and “struggle” also appear, reflecting themes in autism education.\" id=\"fig21\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 21\u003c/b>. asd word cloud.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">the deployment model based on the deep q-network (dqn) model for diagnosing asd is shown in \u003ca href=\"#fig22\">figure 22\u003c/a>.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 22\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g022.jpg\" name=\"figure22\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g022.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g022.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g022.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g022.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g022.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g022.jpg\" alt=\"flowchart depicting a data collection and processing model using twitter api for tweet analysis. the process includes filtering tweets, preprocessing, and applying a deep q-network for model development. it involves validating and testing to build an application interface. the deployment phase includes user interaction, real-time monitoring, and cloud storage. health professionals validate predictions, classifying tweets as asd or non-asd.\" id=\"fig22\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 22\u003c/b>. deployment system-based text for detecting asd.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb15\">step 1: data collections, including cleaning, normalization, and tokenization.\u003c/p>\n\u003cp class=\"mb15\">step 2: model development: the preprocessed data is used to train and validate a deep q-network (dqn) model for classifying tweets as indicative of asd or non-asd patterns.\u003c/p>\n\u003cp class=\"mb15\">step 3: application interface: an application interface is developed once the model has been trained. it integrates with users’ twitter accounts and continuously analyzes their tweets.\u003c/p>\n\u003cp class=\"mb15\">step 4: deployment: the proposed system is deployed in the cloud for storing tweets, enabling real-time monitoring of incoming tweets. predictions are flagged for review by healthcare professionals, who validate the model’s output before categorizing individuals as potentially having asd or non-asd.\u003c/p>\n\u003cp class=\"mb0\">this digital imprint may serve as an ancillary resource for mental health practitioners, providing insights into an individual’s emotional state and social behaviors in a natural environment, potentially facilitating early detection or corroborating a diagnosis. this method is a non-invasive means of data collection, particularly beneficial for individuals who lack rapid access to clinical assessments due to financial constraints, stigma, or resource scarcity. however, it should not replace professional diagnoses and must be conducted with ethical consideration to prevent misunderstanding. \u003ca href=\"#tab7\">table 7\u003c/a> shows the findings of the proposed framework on the twitter dataset. it demonstrates that the suggested method outperforms the current systems in terms of accuracy, proving its efficacy and potential for performance improvements.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">table 7\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t007.jpg\" name=\"table7\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t007.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t007.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t007.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t007.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t007.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t007.jpg\" alt=\"www.frontiersin.org\" id=\"tab7\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>table 7\u003c/b>. compared with the proposed asd system.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div> \u003ca id=\"h6\" name=\"h6\">\u003c/a>\n\u003ch2>5 conclusion\u003c/h2>\n\u003cp class=\"mb0\">to assist people in identifying trends in their behavior, such as social challenges or sensory sensitivities, which may encourage them to pursue a formal diagnosis. the main objective of examining tweets for identifying asd is its ability to provide behavioral and emotional indicators associated with the disorder. this research was used to analyze the textual analysis of tweets to detect the behaviors in self-identified autistic individuals relative to others. the suggested framework was evaluated using information from the social media platform “twitter” collected from a public repository. before examining the proposed system, several preprocessing steps must be implemented in the text. the ‘text’ column is cleaned by converting it to lowercase, eliminating non-alphanumeric characters (excluding spaces) through regular expressions, normalizing whitespace to a single space, and removing any leading or trailing spaces. the asd and non-asd labels are converted into a numerical format (0 or 1) with labelencoder to accommodate the binary classification requirement. tokenization of the text data is performed using a tokenizer, restricting the vocabulary to 10,000 words, and then transforming the text into sequences of numbers. the sequences are padded to a standardized length of 200 tokens to maintain consistency for the proposed model input. the proposed data is ultimately divided into an 80% training and 20% testing ratio, and class weights are calculated to resolve any class imbalance. this preparation pipeline efficiently converts raw text data into a structured numerical representation appropriate for the proposed framework, while preserving academic integrity. the output of these preprocessing steps was processed using three dl models, such as short-term memory (cnn-lstm) and a double deep q-network (ddqn). the results of these proposals were proven, revealing that the ddqn model achieved a high accuracy score of 87% with respect to the accuracy measure. the proposed framework, based on real textual data, can be helpful for real-time offering natural, behavioral, and emotional data that might indicate asd-related characteristics. finally, we have observed that social media (twitter) postings include linguistic patterns, emotional expressions, and social interactions that can help official health officials detect asd based on the thorough symptoms of asd that are posted on the platform. this study utilized a conventional dataset sourced only from the twitter network. we will emphasize the necessity of gathering datasets from many platforms to enhance the model’s generalizability in the future.\u003c/p> \u003ca id=\"h7\" name=\"h7\">\u003c/a>\n\u003ch2>data availability statement\u003c/h2>\n\u003cp class=\"mb0\">the original contributions presented in the study are included in the article/supplementary material, further inquiries can be directed to the corresponding author/s. the dataset used in this study can be found at \u003ca href=\"https://data.mendeley.com/datasets/87s2br3ptb/1\">https://data.mendeley.com/datasets/87s2br3ptb/1\u003c/a>.\u003c/p> \u003ca id=\"h8\" name=\"h8\">\u003c/a>\n\u003ch2>ethics statement\u003c/h2>\n\u003cp class=\"mb0\">ethical approval was not required for the study involving human data in accordance with the local legislation and institutional requirements. written informed consent was not required, for either participation in the study or for the publication of potentially/indirectly identifying information, in accordance with the local legislation and institutional requirements. the social media data was accessed and analysed in accordance with the platform’s terms of use and all relevant institutional/national regulations.\u003c/p> \u003ca id=\"h9\" name=\"h9\">\u003c/a>\n\u003ch2>author contributions\u003c/h2>\n\u003cp class=\"mb0\">nf: supervision, conceptualization, software, methodology, writing – original draft, investigation, visualization, formal analysis, validation. aa: data curation, visualization, methodology, conceptualization, validation, software, formal analysis, writing – original draft. ne: investigation, writing – review & editing, validation, formal analysis. sa: visualization, software, formal analysis, writing – review & editing, data curation.\u003c/p> \u003ca id=\"h10\" name=\"h10\">\u003c/a>\n\u003ch2>funding\u003c/h2>\n\u003cp class=\"mb0\">the author(s) declare that financial support was received for the research and/or publication of this article. the authors extend their appreciation to the king salman center for disability research for funding this work through research group no ksrg-2024-288.\u003c/p> \u003ca id=\"h11\" name=\"h11\">\u003c/a>\n\u003ch2>conflict of interest\u003c/h2>\n\u003cp class=\"mb0\">the authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\u003c/p> \u003ca id=\"h12\" name=\"h12\">\u003c/a>\n\u003ch2>generative ai statement\u003c/h2>\n\u003cp class=\"mb15\">the authors declare that no gen ai was used in the creation of this manuscript.\u003c/p>\n\u003cp class=\"mb0\">any alternative text (alt text) provided alongside figures in this article has been generated by frontiers with the support of artificial intelligence and reasonable efforts have been made to ensure accuracy, including review by the authors wherever possible. if you identify any issues, please contact us.\u003c/p> \u003ca id=\"h13\" name=\"h13\">\u003c/a>\n\u003ch2>publisher’s note\u003c/h2>\n\u003cp class=\"mb0\">all claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.\u003c/p> \u003ca id=\"h14\" name=\"h14\">\u003c/a>\n\u003ch2>references\u003c/h2>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref1\" id=\"ref1\">\u003c/a>1. asd. (2023). available online at: \u003ca href=\"https://www.healthline.com/health/signs-of-autism-in-3-year-old\">https://www.healthline.com/health/signs-of-autism-in-3-year-old\u003c/a>.\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"http://scholar.google.com/scholar_lookup?publication_year=2023&\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref2\" id=\"ref2\">\u003c/a>2. matson, jl, and goldin, rl. what is the future of assessment for autism spectrum disorders: short and long term. \u003ci>res autism spectr disord\u003c/i>. (2014) 8:209–13. doi: 10.1016/j.rasd.2013.01.007\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.1016/j.rasd.2013.01.007\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=jl+matson&author=rl+goldin&publication_year=2014&title=what+is+the+future+of+assessment+for+autism+spectrum+disorders:+short+and+long+term&journal=res+autism+spectr+disord&volume=8&pages=209-13\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref3\" id=\"ref3\">\u003c/a>3. srivastava, ak, and schwartz, ce. intellectual disability and autism spectrum disorders: causal genes and molecular mechanisms. \u003ci>neurosci biobehav rev\u003c/i>. (2014) 46:161–74. doi: 10.1016/j.neubiorev.2014.02.015 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/24709068\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.1016/j.neubiorev.2014.02.015\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=ak+srivastava&author=ce+schwartz&publication_year=2014&title=intellectual+disability+and+autism+spectrum+disorders:+causal+genes+and+molecular+mechanisms&journal=neurosci+biobehav+rev&volume=46&pages=161-74\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref4\" id=\"ref4\">\u003c/a>4. alhujaili, n, platt, e, khalid-khan, s, and groll, d. comparison of social media use among adolescents with autism spectrum disorder and non-asd adolescents. \u003ci>adolesc health med ther\u003c/i>. (2022) 13:15–21. doi: 10.2147/ahmt.s344591 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/35136359\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.2147/ahmt.s344591\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=n+alhujaili&author=e+platt&author=s+khalid-khan&author=d+groll&publication_year=2022&title=comparison+of+social+media+use+among+adolescents+with+autism+spectrum+disorder+and+non-asd+adolescents&journal=adolesc+health+med+ther&volume=13&pages=15-21\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref5\" id=\"ref5\">\u003c/a>5. angulo-jiménez, h, and dethorne, l. narratives about autism: an analysis of youtube videos by individuals who self-identify as autistic. \u003ci>am j speech lang pathol\u003c/i>. (2019) 28:569–90. doi: 10.1044/2018_ajslp-18-0045\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.1044/2018_ajslp-18-0045\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=h+angulo-jiménez&author=l+dethorne&publication_year=2019&title=narratives+about+autism:+an+analysis+of+youtube+videos+by+individuals+who+self-identify+as+autistic&journal=am+j+speech+lang+pathol&volume=28&pages=569-90\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref6\" id=\"ref6\">\u003c/a>6. pew research center. (2021). available online at: \u003ca href=\"https://www.pewresearch.org/internet/2021/04/07/social-media-use-in-2021/\">https://www.pewresearch.org/internet/2021/04/07/social-media-use-in-2021/\u003c/a>\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"http://scholar.google.com/scholar_lookup?publication_year=2021&\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref7\" id=\"ref7\">\u003c/a>7. liu, j-b, guan, l, cao, j, and chen, l. coherence analysis for a class of polygon networks with the noise disturbance. \u003ci>ieee trans syst man cybern syst\u003c/i>. (2025) 2025:326. doi: 10.1109/tsmc.2025.3559326\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.1109/tsmc.2025.3559326\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=j-b+liu&author=l+guan&author=j+cao&author=l+chen&publication_year=2025&title=coherence+analysis+for+a+class+of+polygon+networks+with+the+noise+disturbance&journal=ieee+trans+syst+man+cybern+syst&volume=2025&pages=326\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref8\" id=\"ref8\">\u003c/a>8. al-nefaie, ah, aldhyani, th, sultan, ha, and alzahrani eidah, m. application of artificial intelligence in modern healthcare for diagnosis of autism spectrum disorder. \u003ci>front med\u003c/i>. (2025) 12:1569464. doi: 10.3389/fmed.2025.1569464\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.3389/fmed.2025.1569464\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=ah+al-nefaie&author=th+aldhyani&author=ha+sultan&author=m+alzahrani+eidah&publication_year=2025&title=application+of+artificial+intelligence+in+modern+healthcare+for+diagnosis+of+autism+spectrum+disorder&journal=front+med&volume=12&pages=1569464\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref9\" id=\"ref9\">\u003c/a>9. kim, b, jeong, d, kim, jg, hong, h, and han, k. \u003ci>v-dat (virtual reality data analysis tool): supporting self-awareness for autistic people from multimodal vr sensor data\u003c/i>. in: proceedings of the uist 2023—proceedings of the 36th annual acm symposium on user interface software and technology, san francisco, ca, usa, 29 october–1 november 2023. (2023).\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"http://scholar.google.com/scholar_lookup?author=b+kim&author=d+jeong&author=jg+kim&author=h+hong&author=k+han&publication_year=2023&\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref10\" id=\"ref10\">\u003c/a>10. chen, c, chander, a, and uchino, k. \u003ci>guided play: digital sensing and coaching for stereotypical play behavior in children with autism\u003c/i>. in proceedings of the international conference on intelligent user interfaces, proceedings iui, marina del ray, ca, usa, 17–20 march 2019; part f1476. pp. 208–217. (2019).\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"http://scholar.google.com/scholar_lookup?author=c+chen&author=a+chander&author=k+uchino&publication_year=2019&\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref11\" id=\"ref11\">\u003c/a>11. parui, s, samanta, d, chakravorty, n, ghosh, u, and rodrigues, jj. artificial intelligence and sensor-based autism spectrum disorder diagnosis using brain connectivity analysis. \u003ci>comput electr eng\u003c/i>. (2023) 108:108720. doi: 10.1016/j.compeleceng.2023.108720\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.1016/j.compeleceng.2023.108720\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=s+parui&author=d+samanta&author=n+chakravorty&author=u+ghosh&author=jj+rodrigues&publication_year=2023&title=artificial+intelligence+and+sensor-based+autism+spectrum+disorder+diagnosis+using+brain+connectivity+analysis&journal=comput+electr+eng&volume=108&pages=108720\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref12\" id=\"ref12\">\u003c/a>12. golestan, s, soleiman, p, and moradi, h. a comprehensive review of technologies used for screening, assessment, and rehabilitation of autism spectrum disorder. \u003ci>arxiv\u003c/i>. (2018) 2018:10986. doi: 10.48550/arxiv.1807.10986\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.48550/arxiv.1807.10986\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=s+golestan&author=p+soleiman&author=h+moradi&publication_year=2018&title=a+comprehensive+review+of+technologies+used+for+screening+assessment+and+rehabilitation+of+autism+spectrum+disorder&journal=arxiv&volume=2018&pages=10986\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref13\" id=\"ref13\">\u003c/a>13. neeharika, ch, and riyazuddin, ym. developing an artificial intelligence based model for autism spectrum disorder detection in children. \u003ci>j adv res appl sci eng technol\u003c/i>. (2023) 32:57–72. doi: 10.37934/araset.32.1.5772\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.37934/araset.32.1.5772\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=ch+neeharika&author=ym+riyazuddin&publication_year=2023&title=developing+an+artificial+intelligence+based+model+for+autism+spectrum+disorder+detection+in+children&journal=j+adv+res+appl+sci+eng+technol&volume=32&pages=57-72\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref14\" id=\"ref14\">\u003c/a>14. wall, dp, dally, r, luyster, r, jung, j-y, and deluca, tf. use of artificial intelligence to shorten the behavioral diagnosis of autism. \u003ci>plos one\u003c/i>. (2012) 7:e43855. doi: 10.1371/journal.pone.0043855 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/22952789\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.1371/journal.pone.0043855\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=dp+wall&author=r+dally&author=r+luyster&author=j-y+jung&author=tf+deluca&publication_year=2012&title=use+of+artificial+intelligence+to+shorten+the+behavioral+diagnosis+of+autism&journal=plos+one&volume=7&pages=e43855\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref15\" id=\"ref15\">\u003c/a>15. alzakari, sa, allinjawi, a, aldrees, a, zamzami, n, umer, m, innab, n, et al. early detection of autism spectrum disorder using explainable ai and optimized teaching strategies. \u003ci>j neurosci methods\u003c/i>. (2025) 413:110315. doi: 10.1016/j.jneumeth.2024.110315 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/39532186\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.1016/j.jneumeth.2024.110315\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=sa+alzakari&author=a+allinjawi&author=a+aldrees&author=n+zamzami&author=m+umer&author=n+innab&publication_year=2025&title=early+detection+of+autism+spectrum+disorder+using+explainable+ai+and+optimized+teaching+strategies&journal=j+neurosci+methods&volume=413&pages=110315\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref16\" id=\"ref16\">\u003c/a>16. heunis, t, aldrich, c, peters, j, jeste, s, sahin, m, scheffer, c, et al. recurrence quantification analysis of resting state eeg signals in autism spectrum disorder—a systematic methodological exploration of technical and demographic confounders in the search for biomarkers. \u003ci>bmc med\u003c/i>. (2018) 16:101. doi: 10.1186/s12916-018-1086-7\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.1186/s12916-018-1086-7\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=t+heunis&author=c+aldrich&author=j+peters&author=s+jeste&author=m+sahin&author=c+scheffer&publication_year=2018&title=recurrence+quantification+analysis+of+resting+state+eeg+signals+in+autism+spectrum+disorder—a+systematic+methodological+exploration+of+technical+and+demographic+confounders+in+the+search+for+biomarkers&journal=bmc+med&volume=16&pages=101\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref17\" id=\"ref17\">\u003c/a>17. vicnesh, j, wei, jke, oh, sl, arunkumar, n, abdulhay, e, ciaccio, ej, et al. autism spectrum disorder diagnostic system using hos bispectrum with eeg signals. \u003ci>int j environ res public health\u003c/i>. (2020) 17:971. doi: 10.3390/ijerph17030971\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.3390/ijerph17030971\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=j+vicnesh&author=jke+wei&author=sl+oh&author=n+arunkumar&author=e+abdulhay&author=ej+ciaccio&publication_year=2020&title=autism+spectrum+disorder+diagnostic+system+using+hos+bispectrum+with+eeg+signals&journal=int+j+environ+res+public+health&volume=17&pages=971\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref18\" id=\"ref18\">\u003c/a>18. novielli, p, romano, d, magarelli, m, diacono, d, monaco, a, amoroso, n, et al. personalized identification of autism-related bacteria in the gut microbiome using explainable artificial intelligence. \u003ci>iscience\u003c/i>. (2024) 27:110709. doi: 10.1016/j.isci.2024.110709 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/39286497\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.1016/j.isci.2024.110709\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=p+novielli&author=d+romano&author=m+magarelli&author=d+diacono&author=a+monaco&author=n+amoroso&publication_year=2024&title=personalized+identification+of+autism-related+bacteria+in+the+gut+microbiome+using+explainable+artificial+intelligence&journal=iscience&volume=27&pages=110709\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref19\" id=\"ref19\">\u003c/a>19. bosl, wj, tager-flusberg, h, and nelson, ca. eeg analytics for early detection of autism spectrum disorder: a data-driven approach. \u003ci>sci rep\u003c/i>. (2018) 8:1–20. doi: 10.1038/s41598-018-24318-x \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/29717196\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.1038/s41598-018-24318-x\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=wj+bosl&author=h+tager-flusberg&author=ca+nelson&publication_year=2018&title=eeg+analytics+for+early+detection+of+autism+spectrum+disorder:+a+data-driven+approach&journal=sci+rep&volume=8&pages=1-20\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref20\" id=\"ref20\">\u003c/a>20. beykikhoshk, a, arandjelović, o, phung, d, venkatesh, s, and caelli, t. using twitter to learn about the autism community. \u003ci>soc netw anal min\u003c/i>. (2015) 5:261. doi: 10.1007/s13278-015-0261-\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.1007/s13278-015-0261-\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=a+beykikhoshk&author=o+arandjelović&author=d+phung&author=s+venkatesh&author=t+caelli&publication_year=2015&title=using+twitter+to+learn+about+the+autism+community&journal=soc+netw+anal+min&volume=5&pages=261\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref21\" id=\"ref21\">\u003c/a>21. mazurek, mo. social media use among adults with autism spectrum disorders. \u003ci>comput hum behav\u003c/i>. (2013) 29:1709–14. doi: 10.1016/j.chb.2013.02.004\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.1016/j.chb.2013.02.004\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=mo+mazurek&publication_year=2013&title=social+media+use+among+adults+with+autism+spectrum+disorders&journal=comput+hum+behav&volume=29&pages=1709-14\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref22\" id=\"ref22\">\u003c/a>22. onnela, j, and rauch, sl. harnessing smartphone-based digital phenotyping to enhance behavioral and mental health. \u003ci>neuropsychopharmacology\u003c/i>. (2016) 41:1691–6. doi: 10.1038/npp.2016.7.npp20167 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/26818126\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.1038/npp.2016.7.npp20167\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=j+onnela&author=sl+rauch&publication_year=2016&title=harnessing+smartphone-based+digital+phenotyping+to+enhance+behavioral+and+mental+health&journal=neuropsychopharmacology&volume=41&pages=1691-6\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref23\" id=\"ref23\">\u003c/a>23. tomeny, ts, vargo, cj, and el-toukhy, s. geographic and demographic correlates of autism-related anti-vaccine beliefs on twitter, 2009–2015. \u003ci>soc sci med\u003c/i>. (2017) 191:168–75. doi: 10.1016/j.socscimed.2017.08.041 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/28926775\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.1016/j.socscimed.2017.08.041\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=ts+tomeny&author=cj+vargo&author=s+el-toukhy&publication_year=2017&title=geographic+and+demographic+correlates+of+autism-related+anti-vaccine+beliefs+on+twitter+2009–2015&journal=soc+sci+med&volume=191&pages=168-75\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref24\" id=\"ref24\">\u003c/a>24. tárraga-mínguez, r, gómez-marí, i, and sanz-cervera, p. what motivates internet users to search for asperger syndrome and autism on google? \u003ci>int j environ res public health\u003c/i>. (2020) 17:9386. doi: 10.3390/ijerph17249386 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/33333991\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.3390/ijerph17249386\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=r+tárraga-mínguez&author=i+gómez-marí&author=p+sanz-cervera&publication_year=2020&title=what+motivates+internet+users+to+search+for+asperger+syndrome+and+autism+on+google?&journal=int+j+environ+res+public+health&volume=17&pages=9386\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref25\" id=\"ref25\">\u003c/a>25. hartwell, m, keener, a, coffey, s, chesher, t, torgerson, t, and vassar, m. brief report: public awareness of asperger syndrome following greta thunberg appearances. \u003ci>j autism dev disord\u003c/i>. (2020) 51:2104–8. doi: 10.1007/s10803-020-04651-9 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/32812193\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.1007/s10803-020-04651-9\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=m+hartwell&author=a+keener&author=s+coffey&author=t+chesher&author=t+torgerson&author=m+vassar&publication_year=2020&title=brief+report:+public+awareness+of+asperger+syndrome+following+greta+thunberg+appearances&journal=j+autism+dev+disord&volume=51&pages=2104-8\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref26\" id=\"ref26\">\u003c/a>26. rubio-martín, s, garcía-ordás, mt, bayón-gutiérrez, m, prieto-fernández, n, and benítez-andrades, ja. “\u003ci>early detection of autism spectrum disorder through ai-powered analysis of social media texts\u003c/i>,” 2023 ieee 36th international symposium on computer-based medical systems (cbms), l’aquila, italy, pp. 235–240. (2023).\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"http://scholar.google.com/scholar_lookup?author=s+rubio-martín&author=mt+garcía-ordás&author=m+bayón-gutiérrez&author=n+prieto-fernández&author=ja+benítez-andrades&publication_year=2023&\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref27\" id=\"ref27\">\u003c/a>27. jaiswal, a, and washington, p. using #actuallyautistic on twitter for precision diagnosis of autism spectrum disorder: machine learning study. \u003ci>jmir form res\u003c/i>. (2024) 8:e52660. doi: 10.2196/52660\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.2196/52660\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=a+jaiswal&author=p+washington&publication_year=2024&title=using+#actuallyautistic+on+twitter+for+precision+diagnosis+of+autism+spectrum+disorder:+machine+learning+study&journal=jmir+form+res&volume=8&pages=e52660\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003c/div> \u003cdiv class=\"thinlinem20\">\u003c/div> \u003cdiv class=\"abstractsummary\">\n\u003cp>\u003cspan>keywords:\u003c/span> autism spectrum disorders, diagnosing, social media, deep learning, disabilities, artificial intelligence\u003c/p>\n\u003cp>\u003cspan>citation:\u003c/span> farhah ns, alqarni aa, ebrahim n and ahmad s (2025) diagnosing autism spectrum disorders using a double deep q-network framework based on social media footprints. \u003ci>front. med\u003c/i>. 12:1646249. doi: 10.3389/fmed.2025.1646249\u003c/p>\n\u003cp class=\"timestamps\">\u003cspan>received:\u003c/span> 16 june 2025; \u003cspan>accepted:\u003c/span> 28 july 2025;\u003cbr> \u003cspan>published:\u003c/span> 20 august 2025.\u003c/p> \u003cdiv>\n\u003cp>edited by:\u003c/p> \u003ca href=\"https://loop.frontiersin.org/people/2928766/overview\">pardeep sangwan\u003c/a>, maharaja surajmal institute of technology, india\u003c/div> \u003cdiv>\n\u003cp>reviewed by:\u003c/p> \u003ca href=\"https://loop.frontiersin.org/people/1743107/overview\">jia-bao liu\u003c/a>, anhui jianzhu university, china\u003cbr> \u003ca href=\"https://loop.frontiersin.org/people/3104897/overview\">muhammad adnan\u003c/a>, kohat university of science and technology, pakistan\u003c/div>\n\u003cp>\u003cspan>copyright\u003c/span> © 2025 farhah, alqarni, ebrahim and ahmad. this is an open-access article distributed under the terms of the \u003ca rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\" target=\"_blank\">creative commons attribution license (cc by)\u003c/a>. the use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. no use, distribution or reproduction is permitted which does not comply with these terms.\u003c/p>\n\u003cp>\u003cspan>*correspondence:\u003c/span> nesren s. farhah, \u003ca id=\"encmail\">bi5myxjoywhac2v1lmvkds5zyq==\u003c/a>; nadhem ebrahim, \u003ca id=\"encmail\">bmvicmfoaw1adwfrcm9ulmvkdq==\u003c/a>; sultan ahmad, \u003ca id=\"encmail\">cy5hbglzagvyqhbzyxuuzwr1lnnh\u003c/a>\u003c/p> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>","\u003cul class=\"flyoutjournal\"> \u003cli>\u003ca href=\"#h1\">abstract\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h2\">1 introduction\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h3\">2 materials and methods\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h4\">3 performance of the framework\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h5\">4 experiment and discussion results\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h6\">5 conclusion\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h7\">data availability statement\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h8\">ethics statement\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h9\">author contributions\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h10\">funding\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h11\">conflict of interest\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h12\">generative ai statement\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h13\">publisher’s note\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h14\">references\u003c/a>\u003c/li> \u003c/ul>",[627,633,639],{"name":628,"fileserverpackageentryid":19,"fileserverid":629,"fileserverversionnumber":374,"type":630},"epub.epub","1646249/epub",{"code":631,"name":632},"epub","epub",{"name":634,"fileserverpackageentryid":19,"fileserverid":635,"fileserverversionnumber":374,"type":636},"publishers-proof.pdf","1646249/publishers-proof",{"code":637,"name":638},"pdf","pdf",{"name":640,"fileserverpackageentryid":641,"fileserverid":642,"fileserverversionnumber":374,"type":643},"fmed-12-1646249.xml","fmed-12-1646249/fmed-12-1646249.xml","1646249/xml",{"code":644,"name":645},"nlm_xml","xml","v3",{"title":648,"link":649,"meta":653,"script":754},"frontiers | diagnosing autism spectrum disorders using a double deep q-network framework based on social media footprints",[650],{"rel":651,"href":652},"canonical","https://www.frontiersin.org/journals/medicine/articles/10.3389/fmed.2025.1646249/full",[654,657,660,662,665,669,672,676,679,682,685,687,689,691,693,695,698,701,703,706,708,710,713,716,719,722,725,729,733,736,739,742,745,748,751],{"hid":655,"property":655,"name":655,"content":656},"description","introductionsocial media is increasingly used in many contexts within the healthcare sector. the improved prevalence of internet use via computers or mobile ...",{"hid":658,"property":658,"name":659,"content":648},"og:title","title",{"hid":661,"property":661,"name":655,"content":656},"og:description",{"hid":663,"name":663,"content":664},"keywords","artificial intelligence,deep learning,social media,disabilities,autism spectrum disorders,diagnosing",{"hid":666,"property":666,"name":667,"content":668},"og:site_name","site_name","frontiers",{"hid":670,"property":670,"name":367,"content":671},"og:image","https://images-provider.frontiersin.org/api/ipx/w=1200&f=png/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g001.jpg",{"hid":673,"property":673,"name":674,"content":675},"og:type","type","article",{"hid":677,"property":677,"name":678,"content":652},"og:url","url",{"hid":680,"name":680,"content":681},"twitter:card","summary_large_image",{"hid":683,"name":683,"content":684},"citation_volume","12",{"hid":686,"name":686,"content":116},"citation_journal_title",{"hid":688,"name":688,"content":668},"citation_publisher",{"hid":690,"name":690,"content":608},"citation_journal_abbrev",{"hid":692,"name":692,"content":609},"citation_issn",{"hid":694,"name":694,"content":518},"citation_doi",{"hid":696,"name":696,"content":697},"citation_firstpage","1646249",{"hid":699,"name":699,"content":700},"citation_language","english",{"hid":702,"name":702,"content":519},"citation_title",{"hid":704,"name":704,"content":705},"citation_keywords","artificial intelligence; deep learning; social media; disabilities; autism spectrum disorders; diagnosing",{"hid":707,"name":707,"content":524},"citation_abstract",{"hid":709,"name":709,"content":533},"citation_article_type",{"hid":711,"name":711,"content":712},"citation_pdf_url","https://www.frontiersin.org/journals/medicine/articles/10.3389/fmed.2025.1646249/pdf",{"hid":714,"name":714,"content":715},"citation_xml_url","https://www.frontiersin.org/journals/medicine/articles/10.3389/fmed.2025.1646249/xml",{"hid":717,"name":717,"content":718},"citation_fulltext_world_readable","yes",{"hid":720,"name":720,"content":721},"citation_online_date","2025/07/28",{"hid":723,"name":723,"content":724},"citation_publication_date","2025/08/20",{"hid":726,"name":727,"content":728},"citation_author_0","citation_author","farhah, nesren s. ",{"hid":730,"name":731,"content":732},"citation_author_institution_0","citation_author_institution","department of health informatics, college of health science, saudi electronic university, saudi arabia",{"hid":734,"name":727,"content":735},"citation_author_1","alqarni, ahmed abdullah ",{"hid":737,"name":731,"content":738},"citation_author_institution_1","king salman center for disability research, saudi arabia",{"hid":740,"name":727,"content":741},"citation_author_2","ebrahim, nadhem ",{"hid":743,"name":731,"content":744},"citation_author_institution_2","department of computer science, college of engineering and polymer science, university of akron, united states",{"hid":746,"name":727,"content":747},"citation_author_3","ahmad, sultan ",{"hid":749,"name":731,"content":750},"citation_author_institution_3","department of computer science, college of computer engineering and sciences, prince sattam bin abdulaziz university, saudi arabia",{"hid":752,"name":752,"content":753},"dc.identifier","doi:10.3389/fmed.2025.1646249",[755,758,760,762,764],{"src":756,"body":13,"type":757,"async":13},"https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6","text/javascript",{"src":759,"body":13,"type":757,"async":13},"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/mathjax.js?config=tex-mml-am_chtml",{"src":761,"body":13,"type":757,"async":13},"https://d1bxh8uas1mnw7.cloudfront.net/assets/altmetric_badges-f0bc9b243ff5677d05460c1eb71834ca998946d764eb3bc244ab4b18ba50d21e.js",{"src":763,"body":13,"type":757,"async":13},"https://api.altmetric.com/v1/doi/10.3389/fmed.2025.1646249?callback=_altmetric.embed_callback&domain=www.frontiersin.org&key=3c130976ca2b8f2e88f8377633751ba1&cache_until=14-15",{"src":765,"body":13,"type":757,"async":13},"https://crossmark-cdn.crossref.org/widget/v2.0/widget.js",{"articlehubslug":19,"articlehubpage":767,"articlehubarticleslist":768,"canjournalhasarticlehub":351,"articledoilist":769},{},[],[],{"title":19,"image":-1,"breadcrumbs":771,"linkscollection":772,"metricscollection":774},[],{"total":371,"items":773},[],{"total":371,"items":775},[]] window.__nuxt__={};window.__nuxt__.config={public:{isdevmode:false,appname:"article-pages-2024",baseurl:"https://www.frontiersin.org",domain:"frontiersin.org",loopurl:"https://loop.frontiersin.org",ssmaindomain:"frontiersin.org",contentfulurl:"https://graphql.contentful.com/content/v1/spaces",spaceid:1,spacename:"frontiers",livespaceid:1,tenantlogourl:"",frontiersgraphurl:"https://apollo-federation-gateway.frontiersin.org",registrationapiurl:"https://onboarding-ui.frontiersin.org",emaildigestapiurl:"https://api-email-digest.frontiersin.org",journalfilesapiurl:"https://files-journal-api.frontiersin.org",searchapiurl:"https://search-api.frontiersin.org",productionforumapiurl:"https://production-forum-api-v2.frontiersin.org",gtmserverurl:"https://tag-manager.frontiersin.org",gtmid:"gtm-m322fv2",gtmauth:"owvbwxfajr21yqv1fe1caq",gtmpreview:"env-1",figsharepluginurl:"https://widgets.figshare.com/static/figshare.js",figshareapiurl:"https://api.figshare.com/v2/collections/search",figsharetimeout:3000,crossmarkpublisheddate:"2015/08/24",googlerecaptchasitekey:"6ldg3i0uaaaaaoc4quh35ubhgjotehp_stxhgr_v",googlerecaptchakeyname:"frontiersrecaptchav2",faviconsize16:"https://static2.frontiersin.org/static-resources/tenants/frontiers/favicon_16-tenantfavicon-frontiers.png",faviconsize32:"https://static2.frontiersin.org/static-resources/tenants/frontiers/favicon_32-tenantfavicon-frontiers.png",faviconsize180:"https://static2.frontiersin.org/static-resources/tenants/frontiers/favicon_180-tenantfavicon-frontiers.png",faviconsize192:"https://static2.frontiersin.org/static-resources/tenants/frontiers/favicon_192-tenantfavicon-frontiers.png",faviconsize512:"https://static2.frontiersin.org/static-resources/tenants/frontiers/favicon_512-tenantfavicon-frontiers.png",socialmediaimg:"https://brand.frontiersin.org/m/1c8bcb536c789e11/guidelines-frontiers_logo_1200x628_1-91to1.png",linkedarticlecopytext:"'{\"articletypecopytext\":[{\"articletypeid\":0,\"originalarticlecopytext\":\"part of this article's content has been mentioned in:\",\"linkedarticlecopytext\":\"this article mentions parts of:\"},{\"articletypeid\":122,\"originalarticlecopytext\":\"parts of this article's content have been modified or rectified in:\",\"linkedarticlecopytext\":\"this article is an erratum on:\"},{\"articletypeid\":129,\"originalarticlecopytext\":\"parts of this article's content have been modified or rectified in:\",\"linkedarticlecopytext\":\"this article is an addendum to:\"},{\"articletypeid\":128,\"originalarticlecopytext\":\"a correction has been applied to this article in:\",\"linkedarticlecopytext\":\"this article is a correction to:\"},{\"articletypeid\":134,\"originalarticlecopytext\":\"a retraction of this article was approved in:\",\"linkedarticlecopytext\":\"this article is a retraction of:\"},{\"articletypeid\":29,\"originalarticlecopytext\":\"a commentary has been posted on this article:\",\"linkedarticlecopytext\":\"this article is a commentary on:\"},{\"articletypeid\":30,\"originalarticlecopytext\":\"a commentary has been posted on this article:\",\"linkedarticlecopytext\":\"this article is a commentary on:\"}],\"articleidcopytext\":[]}'\n",acceptedarticleexcludedjournalids:"'[2766,979]'\n",articletypeconfigurablelabel:"\u003c\u003carticle-type:uppercase>> article",settingsfeaturesswitchers:"'{\"displaytitlepilllabels\":true,\"displayrelatedarticlesbox\":true,\"showeditors\":true,\"showreviewers\":true,\"showloopimpactlink\":true,\"enablefigshare\":false,\"usexmlimages\":true}'\n",journalswitharticlehub:"'{\"strings\":[\"science\"]}'\n",terminologysettings:"'{\"terms\":[{\"sequencenumber\":1,\"key\":\"frontiers\",\"tenantterm\":\"frontiers\",\"frontiersdefaultterm\":\"frontiers\",\"category\":\"customer\"},{\"sequencenumber\":2,\"key\":\"submission_system\",\"tenantterm\":\"submission system\",\"frontiersdefaultterm\":\"submission system\",\"category\":\"product\"},{\"sequencenumber\":3,\"key\":\"public_pages\",\"tenantterm\":\"public pages\",\"frontiersdefaultterm\":\"public pages\",\"category\":\"product\"},{\"sequencenumber\":4,\"key\":\"my_frontiers\",\"tenantterm\":\"my frontiers\",\"frontiersdefaultterm\":\"my frontiers\",\"category\":\"product\"},{\"sequencenumber\":5,\"key\":\"digital_editorial_office\",\"tenantterm\":\"digital editorial office\",\"frontiersdefaultterm\":\"digital editorial office\",\"category\":\"product\"},{\"sequencenumber\":6,\"key\":\"deo\",\"tenantterm\":\"deo\",\"frontiersdefaultterm\":\"deo\",\"category\":\"product\"},{\"sequencenumber\":7,\"key\":\"digital_editorial_office_for_chiefs\",\"tenantterm\":\"digital editorial office for chiefs\",\"frontiersdefaultterm\":\"digital editorial office for chiefs\",\"category\":\"product\"},{\"sequencenumber\":8,\"key\":\"digital_editorial_office_for_eof\",\"tenantterm\":\"digital editorial office for eof\",\"frontiersdefaultterm\":\"digital editorial office for eof\",\"category\":\"product\"},{\"sequencenumber\":9,\"key\":\"editorial_office\",\"tenantterm\":\"editorial office\",\"frontiersdefaultterm\":\"editorial office\",\"category\":\"product\"},{\"sequencenumber\":10,\"key\":\"eof\",\"tenantterm\":\"eof\",\"frontiersdefaultterm\":\"eof\",\"category\":\"product\"},{\"sequencenumber\":11,\"key\":\"research_topic_management\",\"tenantterm\":\"research topic management\",\"frontiersdefaultterm\":\"research topic management\",\"category\":\"product\"},{\"sequencenumber\":12,\"key\":\"review_forum\",\"tenantterm\":\"review forum\",\"frontiersdefaultterm\":\"review forum\",\"category\":\"product\"},{\"sequencenumber\":13,\"key\":\"accounting_office\",\"tenantterm\":\"accounting office\",\"frontiersdefaultterm\":\"accounting office\",\"category\":\"product\"},{\"sequencenumber\":14,\"key\":\"aof\",\"tenantterm\":\"aof\",\"frontiersdefaultterm\":\"aof\",\"category\":\"product\"},{\"sequencenumber\":15,\"key\":\"publishing_office\",\"tenantterm\":\"publishing office\",\"frontiersdefaultterm\":\"publishing office\",\"category\":\"product\"},{\"sequencenumber\":16,\"key\":\"production_office\",\"tenantterm\":\"production office forum\",\"frontiersdefaultterm\":\"production office forum\",\"category\":\"product\"},{\"sequencenumber\":17,\"key\":\"pof\",\"tenantterm\":\"pof\",\"frontiersdefaultterm\":\"pof\",\"category\":\"product\"},{\"sequencenumber\":18,\"key\":\"book_office_forum\",\"tenantterm\":\"book office forum\",\"frontiersdefaultterm\":\"book office forum\",\"category\":\"product\"},{\"sequencenumber\":19,\"key\":\"bof\",\"tenantterm\":\"bof\",\"frontiersdefaultterm\":\"bof\",\"category\":\"product\"},{\"sequencenumber\":20,\"key\":\"aira\",\"tenantterm\":\"aira\",\"frontiersdefaultterm\":\"aira\",\"category\":\"product\"},{\"sequencenumber\":21,\"key\":\"editorial_board_management\",\"tenantterm\":\"editorial board management\",\"frontiersdefaultterm\":\"editorial board management\",\"category\":\"product\"},{\"sequencenumber\":22,\"key\":\"ebm\",\"tenantterm\":\"ebm\",\"frontiersdefaultterm\":\"ebm\",\"category\":\"product\"},{\"sequencenumber\":23,\"key\":\"domain\",\"tenantterm\":\"domain\",\"frontiersdefaultterm\":\"domain\",\"category\":\"taxonomy\"},{\"sequencenumber\":24,\"key\":\"journal\",\"tenantterm\":\"journal\",\"frontiersdefaultterm\":\"journal\",\"category\":\"taxonomy\"},{\"sequencenumber\":25,\"key\":\"section\",\"tenantterm\":\"section\",\"frontiersdefaultterm\":\"section\",\"category\":\"taxonomy\"},{\"sequencenumber\":26,\"key\":\"domains\",\"tenantterm\":\"domains\",\"frontiersdefaultterm\":\"domains\",\"category\":\"taxonomy\"},{\"sequencenumber\":27,\"key\":\"specialty_section\",\"tenantterm\":\"specialty section\",\"frontiersdefaultterm\":\"specialty section\",\"category\":\"taxonomy\"},{\"sequencenumber\":28,\"key\":\"specialty_journal\",\"tenantterm\":\"specialty journal\",\"frontiersdefaultterm\":\"specialty journal\",\"category\":\"taxonomy\"},{\"sequencenumber\":29,\"key\":\"journals\",\"tenantterm\":\"journals\",\"frontiersdefaultterm\":\"journals\",\"category\":\"taxonomy\"},{\"sequencenumber\":30,\"key\":\"sections\",\"tenantterm\":\"sections\",\"frontiersdefaultterm\":\"sections\",\"category\":\"taxonomy\"},{\"sequencenumber\":31,\"key\":\"specialty_sections\",\"tenantterm\":\"specialty sections\",\"frontiersdefaultterm\":\"specialty sections\",\"category\":\"taxonomy\"},{\"sequencenumber\":32,\"key\":\"specialty_journals\",\"tenantterm\":\"specialty journals\",\"frontiersdefaultterm\":\"specialty journals\",\"category\":\"taxonomy\"},{\"sequencenumber\":33,\"key\":\"manuscript\",\"tenantterm\":\"manuscript\",\"frontiersdefaultterm\":\"manuscript\",\"category\":\"core\"},{\"sequencenumber\":34,\"key\":\"manuscripts\",\"tenantterm\":\"manuscripts\",\"frontiersdefaultterm\":\"manuscripts\",\"category\":\"core\"},{\"sequencenumber\":35,\"key\":\"article\",\"tenantterm\":\"article\",\"frontiersdefaultterm\":\"article\",\"category\":\"core\"},{\"sequencenumber\":36,\"key\":\"articles\",\"tenantterm\":\"articles\",\"frontiersdefaultterm\":\"articles\",\"category\":\"core\"},{\"sequencenumber\":37,\"key\":\"article_type\",\"tenantterm\":\"article type\",\"frontiersdefaultterm\":\"article type\",\"category\":\"core\"},{\"sequencenumber\":38,\"key\":\"article_types\",\"tenantterm\":\"article types\",\"frontiersdefaultterm\":\"article types\",\"category\":\"core\"},{\"sequencenumber\":39,\"key\":\"author\",\"tenantterm\":\"author\",\"frontiersdefaultterm\":\"author\",\"category\":\"label (role)\"},{\"sequencenumber\":40,\"key\":\"authors\",\"tenantterm\":\"authors\",\"frontiersdefaultterm\":\"authors\",\"category\":\"label (role)\"},{\"sequencenumber\":41,\"key\":\"authoring\",\"tenantterm\":\"authoring\",\"frontiersdefaultterm\":\"authoring\",\"category\":\"core\"},{\"sequencenumber\":42,\"key\":\"authored\",\"tenantterm\":\"authored\",\"frontiersdefaultterm\":\"authored\",\"category\":\"core\"},{\"sequencenumber\":43,\"key\":\"accept\",\"tenantterm\":\"accept\",\"frontiersdefaultterm\":\"accept\",\"category\":\"process\"},{\"sequencenumber\":44,\"key\":\"accepted\",\"tenantterm\":\"accepted\",\"frontiersdefaultterm\":\"accepted\",\"category\":\"process\"},{\"sequencenumber\":45,\"key\":\"assistant_field_chief_editor\",\"tenantterm\":\"assistant field chief editor\",\"frontiersdefaultterm\":\"assistant field chief editor\",\"description\":\"an editorial role on a field journal that a registered user may hold. this gives them rights to different functionality and parts of the platform\",\"category\":\"label (role)\"},{\"sequencenumber\":46,\"key\":\"assistant_specialty_chief_editor\",\"tenantterm\":\"assistant specialty chief editor\",\"frontiersdefaultterm\":\"assistant specialty chief editor\",\"description\":\"an editorial role on a specialty that a registered user may hold. this gives them rights to different functionality and parts of the platform\",\"category\":\"label (role)\"},{\"sequencenumber\":47,\"key\":\"assistant_specialty_chief_editors\",\"tenantterm\":\"assistant specialty chief editors\",\"frontiersdefaultterm\":\"assistant specialty chief editors\",\"category\":\"label (role)\"},{\"sequencenumber\":48,\"key\":\"associate_editor\",\"tenantterm\":\"associate editor\",\"frontiersdefaultterm\":\"associate editor\",\"description\":\"an editorial role on a specialty that a registered user may hold. this gives them rights to different functionality and parts of the platform\",\"category\":\"label (role)\"},{\"sequencenumber\":49,\"key\":\"specialty_chief_editor\",\"tenantterm\":\"specialty chief editor\",\"frontiersdefaultterm\":\"specialty chief editor\",\"description\":\"an editorial role on a specialty that a registered user may hold. this gives them rights to different functionality and parts of the platform\",\"category\":\"label (role)\"},{\"sequencenumber\":50,\"key\":\"specialty_chief_editors\",\"tenantterm\":\"specialty chief editors\",\"frontiersdefaultterm\":\"specialty chief editors\",\"category\":\"label (role)\"},{\"sequencenumber\":51,\"key\":\"chief_editor\",\"tenantterm\":\"chief editor\",\"frontiersdefaultterm\":\"chief editor\",\"category\":\"label (role)\"},{\"sequencenumber\":52,\"key\":\"chief_editors\",\"tenantterm\":\"chief editors\",\"frontiersdefaultterm\":\"chief editors\",\"category\":\"label (role)\"},{\"sequencenumber\":53,\"key\":\"call_for_participation\",\"tenantterm\":\"call for participation\",\"frontiersdefaultterm\":\"call for participation\",\"category\":\"process\"},{\"sequencenumber\":54,\"key\":\"citation\",\"tenantterm\":\"citation\",\"frontiersdefaultterm\":\"citation\",\"category\":\"misc.\"},{\"sequencenumber\":55,\"key\":\"citations\",\"tenantterm\":\"citations\",\"frontiersdefaultterm\":\"citations\",\"category\":\"misc.\"},{\"sequencenumber\":56,\"key\":\"contributor\",\"tenantterm\":\"contributor\",\"frontiersdefaultterm\":\"contributor\",\"category\":\"label (role)\"},{\"sequencenumber\":57,\"key\":\"contributors\",\"tenantterm\":\"contributors\",\"frontiersdefaultterm\":\"contributors\",\"category\":\"label (role)\"},{\"sequencenumber\":58,\"key\":\"corresponding_author\",\"tenantterm\":\"corresponding author\",\"frontiersdefaultterm\":\"corresponding author\",\"category\":\"label (role)\"},{\"sequencenumber\":59,\"key\":\"corresponding_authors\",\"tenantterm\":\"corresponding authors\",\"frontiersdefaultterm\":\"corresponding authors\",\"category\":\"label (role)\"},{\"sequencenumber\":60,\"key\":\"decline\",\"tenantterm\":\"decline\",\"frontiersdefaultterm\":\"decline\",\"category\":\"process\"},{\"sequencenumber\":61,\"key\":\"declined\",\"tenantterm\":\"declined\",\"frontiersdefaultterm\":\"declined\",\"category\":\"process\"},{\"sequencenumber\":62,\"key\":\"reject\",\"tenantterm\":\"reject\",\"frontiersdefaultterm\":\"reject\",\"category\":\"process\"},{\"sequencenumber\":63,\"key\":\"rejected\",\"tenantterm\":\"rejected\",\"frontiersdefaultterm\":\"rejected\",\"category\":\"process\"},{\"sequencenumber\":64,\"key\":\"publish\",\"tenantterm\":\"publish\",\"frontiersdefaultterm\":\"publish\",\"category\":\"core\"},{\"sequencenumber\":65,\"key\":\"published\",\"tenantterm\":\"published\",\"frontiersdefaultterm\":\"published\",\"category\":\"core\"},{\"sequencenumber\":66,\"key\":\"publication\",\"tenantterm\":\"publication\",\"frontiersdefaultterm\":\"publication\",\"category\":\"core\"},{\"sequencenumber\":67,\"key\":\"peer_review\",\"tenantterm\":\"peer review\",\"frontiersdefaultterm\":\"peer review\",\"category\":\"peer review process\"},{\"sequencenumber\":68,\"key\":\"peer_reviewed\",\"tenantterm\":\"peer reviewed\",\"frontiersdefaultterm\":\"peer reviewed\",\"category\":\"peer review process\"},{\"sequencenumber\":69,\"key\":\"initial_validation\",\"tenantterm\":\"initial validation\",\"frontiersdefaultterm\":\"initial validation\",\"category\":\"peer review process\"},{\"sequencenumber\":70,\"key\":\"editorial_assignment\",\"tenantterm\":\"editorial assignment\",\"frontiersdefaultterm\":\"editorial assignment\",\"category\":\"peer review process\"},{\"sequencenumber\":71,\"key\":\"independent_review\",\"tenantterm\":\"independent review\",\"frontiersdefaultterm\":\"independent review\",\"category\":\"peer review process\"},{\"sequencenumber\":72,\"key\":\"interactive_review\",\"tenantterm\":\"interactive review\",\"frontiersdefaultterm\":\"interactive review\",\"category\":\"peer review process\"},{\"sequencenumber\":73,\"key\":\"review\",\"tenantterm\":\"review\",\"frontiersdefaultterm\":\"review\",\"category\":\"peer review process\"},{\"sequencenumber\":74,\"key\":\"reviewing\",\"tenantterm\":\"reviewing\",\"frontiersdefaultterm\":\"reviewing\",\"category\":\"peer review process\"},{\"sequencenumber\":75,\"key\":\"reviewer\",\"tenantterm\":\"reviewer\",\"frontiersdefaultterm\":\"reviewer\",\"category\":\"label (role)\"},{\"sequencenumber\":76,\"key\":\"reviewers\",\"tenantterm\":\"reviewers\",\"frontiersdefaultterm\":\"reviewers\",\"category\":\"label (role)\"},{\"sequencenumber\":77,\"key\":\"review_finalized\",\"tenantterm\":\"review finalized\",\"frontiersdefaultterm\":\"review finalized\",\"category\":\"peer review process\"},{\"sequencenumber\":78,\"key\":\"final_decision\",\"tenantterm\":\"final decision\",\"frontiersdefaultterm\":\"final decision\",\"category\":\"peer review process\"},{\"sequencenumber\":79,\"key\":\"final_validation\",\"tenantterm\":\"final validation\",\"frontiersdefaultterm\":\"final validation\",\"category\":\"peer review process\"},{\"sequencenumber\":80,\"key\":\"ae_accept_manuscript\",\"tenantterm\":\"recommend to accept manuscript\",\"frontiersdefaultterm\":\"accept manuscript\",\"category\":\"process\"},{\"sequencenumber\":81,\"key\":\"fee\",\"tenantterm\":\"fee\",\"frontiersdefaultterm\":\"fee\",\"category\":\"accounting\"},{\"sequencenumber\":82,\"key\":\"fees\",\"tenantterm\":\"fees\",\"frontiersdefaultterm\":\"fees\",\"category\":\"accounting\"},{\"sequencenumber\":83,\"key\":\"guest_associate_editor\",\"tenantterm\":\"guest associate editor\",\"frontiersdefaultterm\":\"guest associate editor\",\"category\":\"label (role)\"},{\"sequencenumber\":84,\"key\":\"guest_associate_editors\",\"tenantterm\":\"guest associate editors\",\"frontiersdefaultterm\":\"guest associate editors\",\"category\":\"label (role)\"},{\"sequencenumber\":85,\"key\":\"in_review\",\"tenantterm\":\"in review\",\"frontiersdefaultterm\":\"in review\",\"category\":\"peer review process\"},{\"sequencenumber\":86,\"key\":\"institutional_member\",\"tenantterm\":\"institutional partner\",\"frontiersdefaultterm\":\"institutional partner\",\"category\":\"accounting\"},{\"sequencenumber\":87,\"key\":\"institutional_membership\",\"tenantterm\":\"institutional partnership\",\"frontiersdefaultterm\":\"institutional partnership\",\"category\":\"accounting\"},{\"sequencenumber\":88,\"key\":\"article_processing_charge\",\"tenantterm\":\"article processing charge\",\"frontiersdefaultterm\":\"article processing charge\",\"category\":\"accounting\"},{\"sequencenumber\":89,\"key\":\"article_processing_charges\",\"tenantterm\":\"article processing charges\",\"frontiersdefaultterm\":\"article processing charges\",\"category\":\"accounting\"},{\"sequencenumber\":90,\"key\":\"apcs\",\"tenantterm\":\"apcs\",\"frontiersdefaultterm\":\"apcs\",\"category\":\"accounting\"},{\"sequencenumber\":91,\"key\":\"apc\",\"tenantterm\":\"apc\",\"frontiersdefaultterm\":\"apc\",\"category\":\"accounting\"},{\"sequencenumber\":92,\"key\":\"received\",\"tenantterm\":\"received\",\"frontiersdefaultterm\":\"received\",\"description\":\"date manuscript was received on.\",\"category\":\"core\"},{\"sequencenumber\":93,\"key\":\"transferred\",\"tenantterm\":\"transferred\",\"frontiersdefaultterm\":\"transferred\",\"category\":\"core\"},{\"sequencenumber\":94,\"key\":\"transfer\",\"tenantterm\":\"transfer\",\"frontiersdefaultterm\":\"transfer\",\"category\":\"core\"},{\"sequencenumber\":95,\"key\":\"research_topic\",\"tenantterm\":\"research topic\",\"frontiersdefaultterm\":\"research topic\",\"category\":\"core\"},{\"sequencenumber\":96,\"key\":\"research_topics\",\"tenantterm\":\"research topics\",\"frontiersdefaultterm\":\"research topics\",\"category\":\"core\"},{\"sequencenumber\":97,\"key\":\"topic_editor\",\"tenantterm\":\"topic editor\",\"frontiersdefaultterm\":\"topic editor\",\"category\":\"label (role)\"},{\"sequencenumber\":98,\"key\":\"review_editor\",\"tenantterm\":\"community reviewer\",\"frontiersdefaultterm\":\"review editor\",\"category\":\"label (role)\"},{\"sequencenumber\":99,\"key\":\"title\",\"tenantterm\":\"title\",\"frontiersdefaultterm\":\"title\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":100,\"key\":\"running_title\",\"tenantterm\":\"running title\",\"frontiersdefaultterm\":\"running title\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":101,\"key\":\"submit\",\"tenantterm\":\"submit\",\"frontiersdefaultterm\":\"submit\",\"category\":\"process\"},{\"sequencenumber\":102,\"key\":\"submitted\",\"tenantterm\":\"submitted\",\"frontiersdefaultterm\":\"submitted\",\"category\":\"process\"},{\"sequencenumber\":103,\"key\":\"submitting\",\"tenantterm\":\"submitting\",\"frontiersdefaultterm\":\"submitting\",\"category\":\"process\"},{\"sequencenumber\":104,\"key\":\"t_e\",\"tenantterm\":\"te\",\"frontiersdefaultterm\":\"te\",\"category\":\"label (role)\"},{\"sequencenumber\":105,\"key\":\"topic\",\"tenantterm\":\"topic\",\"frontiersdefaultterm\":\"topic\",\"category\":\"process\"},{\"sequencenumber\":106,\"key\":\"topic_summary\",\"tenantterm\":\"topic summary\",\"frontiersdefaultterm\":\"topic summary\",\"category\":\"process\"},{\"sequencenumber\":107,\"key\":\"figure\",\"tenantterm\":\"figure\",\"frontiersdefaultterm\":\"figure\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":108,\"key\":\"figures\",\"tenantterm\":\"figures\",\"frontiersdefaultterm\":\"figures\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":109,\"key\":\"editorial_file\",\"tenantterm\":\"editorial file\",\"frontiersdefaultterm\":\"editorial file\",\"category\":\"core\"},{\"sequencenumber\":110,\"key\":\"editorial_files\",\"tenantterm\":\"editorial files\",\"frontiersdefaultterm\":\"editorial files\",\"category\":\"core\"},{\"sequencenumber\":111,\"key\":\"e_book\",\"tenantterm\":\"e-book\",\"frontiersdefaultterm\":\"e-book\",\"category\":\"core\"},{\"sequencenumber\":112,\"key\":\"organization\",\"tenantterm\":\"organization\",\"frontiersdefaultterm\":\"organization\",\"category\":\"core\"},{\"sequencenumber\":113,\"key\":\"institution\",\"tenantterm\":\"institution\",\"frontiersdefaultterm\":\"institution\",\"category\":\"core\"},{\"sequencenumber\":114,\"key\":\"reference\",\"tenantterm\":\"reference\",\"frontiersdefaultterm\":\"reference\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":115,\"key\":\"references\",\"tenantterm\":\"references\",\"frontiersdefaultterm\":\"references\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":116,\"key\":\"sce\",\"tenantterm\":\"sce\",\"frontiersdefaultterm\":\"sce\",\"description\":\"abbreviation for specialty chief editor\",\"category\":\"label (role)\"},{\"sequencenumber\":117,\"key\":\"submission\",\"tenantterm\":\"submission\",\"frontiersdefaultterm\":\"submission\",\"category\":\"process\"},{\"sequencenumber\":118,\"key\":\"submissions\",\"tenantterm\":\"submissions\",\"frontiersdefaultterm\":\"submissions\",\"category\":\"process\"},{\"sequencenumber\":119,\"key\":\"editing\",\"tenantterm\":\"editing\",\"frontiersdefaultterm\":\"editing\",\"category\":\"process\"},{\"sequencenumber\":120,\"key\":\"in_preparation\",\"tenantterm\":\"in preparation\",\"frontiersdefaultterm\":\"in preparation\",\"category\":\"process\"},{\"sequencenumber\":121,\"key\":\"country_region\",\"tenantterm\":\"country/region\",\"frontiersdefaultterm\":\"country/region\",\"description\":\"because of political issues, some of the country listings are actually classified as `regions` and we need to include this. however other clients may not want to do this.\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":122,\"key\":\"countries_regions\",\"tenantterm\":\"countries/regions\",\"frontiersdefaultterm\":\"countries/regions\",\"description\":\"because of political issues, some of the country listings are actually classified as `regions` and we need to include this. however other clients may not want to do this.\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":123,\"key\":\"specialty\",\"tenantterm\":\"specialty\",\"frontiersdefaultterm\":\"specialty\",\"category\":\"core\"},{\"sequencenumber\":124,\"key\":\"specialties\",\"tenantterm\":\"specialties\",\"frontiersdefaultterm\":\"specialties\",\"category\":\"core\"},{\"sequencenumber\":125,\"key\":\"associate_editors\",\"tenantterm\":\"associate editors\",\"frontiersdefaultterm\":\"associate editors\",\"description\":\"an editorial role on a specialty that a registered user may hold. this gives them rights to different functionality and parts of the platform\",\"category\":\"label (role)\"},{\"sequencenumber\":126,\"key\":\"reviewed\",\"tenantterm\":\"reviewed\",\"frontiersdefaultterm\":\"reviewed\",\"category\":\"peer review process\"},{\"sequencenumber\":127,\"key\":\"institutional_members\",\"tenantterm\":\"institutional partners\",\"frontiersdefaultterm\":\"institutional partners\",\"category\":\"accounting\"},{\"sequencenumber\":128,\"key\":\"institutional_memberships\",\"tenantterm\":\"institutional partnerships\",\"frontiersdefaultterm\":\"institutional partnerships\",\"category\":\"accounting\"},{\"sequencenumber\":129,\"key\":\"assistant_field_chief_editors\",\"tenantterm\":\"assistant field chief editors\",\"frontiersdefaultterm\":\"assistant field chief editors\",\"category\":\"label (role)\"},{\"sequencenumber\":130,\"key\":\"publications\",\"tenantterm\":\"publications\",\"frontiersdefaultterm\":\"publications\",\"category\":\"process\"},{\"sequencenumber\":131,\"key\":\"ae_accepted\",\"tenantterm\":\"recommended acceptance\",\"frontiersdefaultterm\":\"accepted\",\"category\":\"process\"},{\"sequencenumber\":132,\"key\":\"field_journal\",\"tenantterm\":\"field journal\",\"frontiersdefaultterm\":\"field journal\",\"category\":\"taxonomy\"},{\"sequencenumber\":133,\"key\":\"field_journals\",\"tenantterm\":\"field journals\",\"frontiersdefaultterm\":\"field journals\",\"category\":\"taxonomy\"},{\"sequencenumber\":134,\"key\":\"program_manager\",\"tenantterm\":\"program manager\",\"frontiersdefaultterm\":\"program manager\",\"category\":\"label (role)\"},{\"sequencenumber\":135,\"key\":\"journal_manager\",\"tenantterm\":\"journal manager\",\"frontiersdefaultterm\":\"journal manager\",\"category\":\"label (role)\"},{\"sequencenumber\":136,\"key\":\"journal_specialist\",\"tenantterm\":\"journal specialist\",\"frontiersdefaultterm\":\"journal specialist\",\"category\":\"label (role)\"},{\"sequencenumber\":137,\"key\":\"program_managers\",\"tenantterm\":\"program managers\",\"frontiersdefaultterm\":\"program managers\",\"category\":\"label (role)\"},{\"sequencenumber\":138,\"key\":\"journal_managers\",\"tenantterm\":\"journal managers\",\"frontiersdefaultterm\":\"journal managers\",\"category\":\"label (role)\"},{\"sequencenumber\":139,\"key\":\"journal_specialists\",\"tenantterm\":\"journal specialists\",\"frontiersdefaultterm\":\"journal specialists\",\"category\":\"label (role)\"},{\"sequencenumber\":140,\"key\":\"cover_letter\",\"tenantterm\":\"manuscript contribution to the field\",\"frontiersdefaultterm\":\"manuscript contribution to the field\",\"category\":\"process\"},{\"sequencenumber\":141,\"key\":\"ae_accepted_manuscript\",\"tenantterm\":\"recommended to accept manuscript\",\"frontiersdefaultterm\":\"accepted manuscript\",\"category\":\"process\"},{\"sequencenumber\":142,\"key\":\"recommend_for_rejection\",\"tenantterm\":\"recommend for rejection\",\"frontiersdefaultterm\":\"recommend for rejection\",\"category\":\"process\"},{\"sequencenumber\":143,\"key\":\"recommended_for_rejection\",\"tenantterm\":\"recommended for rejection\",\"frontiersdefaultterm\":\"recommended for rejection\",\"category\":\"process\"},{\"sequencenumber\":144,\"key\":\"ae\",\"tenantterm\":\"ae\",\"frontiersdefaultterm\":\"ae\",\"description\":\"associate editor - board member\",\"category\":\"label (role)\"},{\"sequencenumber\":145,\"key\":\"re\",\"tenantterm\":\"re\",\"frontiersdefaultterm\":\"re\",\"description\":\"review editor\",\"category\":\"label (role)\"},{\"sequencenumber\":146,\"key\":\"rev\",\"tenantterm\":\"rev\",\"frontiersdefaultterm\":\"rev\",\"description\":\"reviewer\",\"category\":\"label (role)\"},{\"sequencenumber\":147,\"key\":\"aut\",\"tenantterm\":\"aut\",\"frontiersdefaultterm\":\"aut\",\"description\":\"author\",\"category\":\"label (role)\"},{\"sequencenumber\":148,\"key\":\"coraut\",\"tenantterm\":\"coraut\",\"frontiersdefaultterm\":\"coraut\",\"description\":\"corresponding author\",\"category\":\"label (role)\"},{\"sequencenumber\":149,\"key\":\"saut\",\"tenantterm\":\"saut\",\"frontiersdefaultterm\":\"saut\",\"description\":\"submitting author\",\"category\":\"label (role)\"},{\"sequencenumber\":150,\"key\":\"coaut\",\"tenantterm\":\"coaut\",\"frontiersdefaultterm\":\"coaut\",\"description\":\"co-author\",\"category\":\"label (role)\"},{\"sequencenumber\":151,\"key\":\"tsof\",\"tenantterm\":\"tsof\",\"frontiersdefaultterm\":\"tsof\",\"description\":\"typesetter\",\"category\":\"label (role)\"},{\"sequencenumber\":152,\"key\":\"typesetting_office\",\"tenantterm\":\"typesetting office\",\"frontiersdefaultterm\":\"typesetting office\",\"category\":\"product\"},{\"sequencenumber\":153,\"key\":\"config\",\"tenantterm\":\"config\",\"frontiersdefaultterm\":\"config\",\"description\":\"configuration office role\",\"category\":\"label (role)\"},{\"sequencenumber\":154,\"key\":\"jm\",\"tenantterm\":\"jm\",\"frontiersdefaultterm\":\"jm\",\"description\":\"journal manager\",\"category\":\"label (role)\"},{\"sequencenumber\":155,\"key\":\"rte\",\"tenantterm\":\"rte\",\"frontiersdefaultterm\":\"rte\",\"description\":\"research topic editor\",\"category\":\"label (role)\"},{\"sequencenumber\":156,\"key\":\"organizations\",\"tenantterm\":\"organizations\",\"frontiersdefaultterm\":\"organizations\",\"category\":\"core\"},{\"sequencenumber\":157,\"key\":\"publishing\",\"tenantterm\":\"publishing\",\"frontiersdefaultterm\":\"publishing\",\"category\":\"core\"},{\"sequencenumber\":158,\"key\":\"acceptance\",\"tenantterm\":\"acceptance\",\"frontiersdefaultterm\":\"acceptance\",\"category\":\"process\"},{\"sequencenumber\":159,\"key\":\"preferred_associate_editor\",\"tenantterm\":\"preferred associate editor\",\"frontiersdefaultterm\":\"preferred associate editor\",\"category\":\"label (role)\"},{\"sequencenumber\":160,\"key\":\"topic_editors\",\"tenantterm\":\"topic editors\",\"frontiersdefaultterm\":\"topic editors\",\"category\":\"label (role)\"},{\"sequencenumber\":161,\"key\":\"institutions\",\"tenantterm\":\"institutions\",\"frontiersdefaultterm\":\"institutions\",\"category\":\"core\"},{\"sequencenumber\":162,\"key\":\"author(s)\",\"tenantterm\":\"author(s)\",\"frontiersdefaultterm\":\"author(s)\",\"category\":\"label (role)\"},{\"sequencenumber\":163,\"key\":\"figure(s)\",\"tenantterm\":\"figure(s)\",\"frontiersdefaultterm\":\"figure(s)\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":164,\"key\":\"co-authors\",\"tenantterm\":\"co-authors\",\"frontiersdefaultterm\":\"co-authors\",\"description\":\"co-authors\",\"category\":\"label (role)\"},{\"sequencenumber\":165,\"key\":\"editorial_board_members\",\"tenantterm\":\"editorial board members\",\"frontiersdefaultterm\":\"editorial board members\",\"description\":\"editorial board members\",\"category\":\"label (role)\"},{\"sequencenumber\":166,\"key\":\"editorial_board\",\"tenantterm\":\"editorial board\",\"frontiersdefaultterm\":\"editorial board\",\"description\":\"editorial board\",\"category\":\"product\"},{\"sequencenumber\":167,\"key\":\"co-authorship\",\"tenantterm\":\"co-authorship\",\"frontiersdefaultterm\":\"co-authorship\",\"description\":\"co-authorship\",\"category\":\"misc.\"},{\"sequencenumber\":168,\"key\":\"role_id_1\",\"tenantterm\":\"registration office\",\"frontiersdefaultterm\":\"registration office\",\"category\":\"user role\"},{\"sequencenumber\":169,\"key\":\"role_id_2\",\"tenantterm\":\"editorial office\",\"frontiersdefaultterm\":\"editorial office\",\"category\":\"user role\"},{\"sequencenumber\":170,\"key\":\"role_id_7\",\"tenantterm\":\"field chief editor\",\"frontiersdefaultterm\":\"field chief editor\",\"category\":\"user role\"},{\"sequencenumber\":171,\"key\":\"role_id_8\",\"tenantterm\":\"assistant field chief editor\",\"frontiersdefaultterm\":\"assistant field chief editor\",\"category\":\"user role\"},{\"sequencenumber\":172,\"key\":\"role_id_9\",\"tenantterm\":\"specialty chief editor\",\"frontiersdefaultterm\":\"specialty chief editor\",\"category\":\"user role\"},{\"sequencenumber\":173,\"key\":\"role_id_10\",\"tenantterm\":\"assistant specialty chief editor\",\"frontiersdefaultterm\":\"assistant specialty chief editor\",\"category\":\"user role\"},{\"sequencenumber\":174,\"key\":\"role_id_11\",\"tenantterm\":\"associate editor\",\"frontiersdefaultterm\":\"associate editor\",\"category\":\"user role\"},{\"sequencenumber\":175,\"key\":\"role_id_12\",\"tenantterm\":\"guest associate editor\",\"frontiersdefaultterm\":\"guest associate editor\",\"category\":\"user role\"},{\"sequencenumber\":176,\"key\":\"role_id_13\",\"tenantterm\":\"review editor\",\"frontiersdefaultterm\":\"review editor\",\"category\":\"user role\"},{\"sequencenumber\":177,\"key\":\"role_id_14\",\"tenantterm\":\"reviewer\",\"frontiersdefaultterm\":\"reviewer\",\"category\":\"user role\"},{\"sequencenumber\":178,\"key\":\"role_id_15\",\"tenantterm\":\"author\",\"frontiersdefaultterm\":\"author\",\"category\":\"user role\"},{\"sequencenumber\":179,\"key\":\"role_id_16\",\"tenantterm\":\"corresponding author\",\"frontiersdefaultterm\":\"corresponding author\",\"category\":\"user role\"},{\"sequencenumber\":180,\"key\":\"role_id_17\",\"tenantterm\":\"submitting author\",\"frontiersdefaultterm\":\"submitting author\",\"category\":\"user role\"},{\"sequencenumber\":181,\"key\":\"role_id_18\",\"tenantterm\":\"co-author\",\"frontiersdefaultterm\":\"co-author\",\"category\":\"user role\"},{\"sequencenumber\":182,\"key\":\"role_id_20\",\"tenantterm\":\"production office\",\"frontiersdefaultterm\":\"production office\",\"category\":\"user role\"},{\"sequencenumber\":183,\"key\":\"role_id_22\",\"tenantterm\":\"typesetting office (typesetter)\",\"frontiersdefaultterm\":\"typesetting office (typesetter)\",\"category\":\"user role\"},{\"sequencenumber\":184,\"key\":\"role_id_24\",\"tenantterm\":\"registered user\",\"frontiersdefaultterm\":\"registered user\",\"category\":\"user role\"},{\"sequencenumber\":185,\"key\":\"role_id_35\",\"tenantterm\":\"job office\",\"frontiersdefaultterm\":\"job office\",\"category\":\"user role\"},{\"sequencenumber\":186,\"key\":\"role_id_41\",\"tenantterm\":\"special event administrator\",\"frontiersdefaultterm\":\"special event administrator\",\"category\":\"user role\"},{\"sequencenumber\":187,\"key\":\"role_id_42\",\"tenantterm\":\"special event reviewer\",\"frontiersdefaultterm\":\"special event reviewer\",\"category\":\"user role\"},{\"sequencenumber\":188,\"key\":\"role_id_43\",\"tenantterm\":\"submit abstract\",\"frontiersdefaultterm\":\"submit abstract\",\"category\":\"user role\"},{\"sequencenumber\":189,\"key\":\"role_id_52\",\"tenantterm\":\"events office\",\"frontiersdefaultterm\":\"events office\",\"category\":\"user role\"},{\"sequencenumber\":190,\"key\":\"role_id_53\",\"tenantterm\":\"event administrator\",\"frontiersdefaultterm\":\"event administrator\",\"category\":\"user role\"},{\"sequencenumber\":191,\"key\":\"role_id_89\",\"tenantterm\":\"content management office\",\"frontiersdefaultterm\":\"content management office\",\"category\":\"user role\"},{\"sequencenumber\":192,\"key\":\"role_id_98\",\"tenantterm\":\"accounting office\",\"frontiersdefaultterm\":\"accounting office\",\"category\":\"user role\"},{\"sequencenumber\":193,\"key\":\"role_id_99\",\"tenantterm\":\"projects\",\"frontiersdefaultterm\":\"projects\",\"category\":\"user role\"},{\"sequencenumber\":194,\"key\":\"role_id_103\",\"tenantterm\":\"configuration office\",\"frontiersdefaultterm\":\"configuration office\",\"category\":\"user role\"},{\"sequencenumber\":195,\"key\":\"role_id_104\",\"tenantterm\":\"beta user\",\"frontiersdefaultterm\":\"beta user\",\"category\":\"user role\"},{\"sequencenumber\":196,\"key\":\"role_id_106\",\"tenantterm\":\"wfconf\",\"frontiersdefaultterm\":\"wfconf\",\"category\":\"user role\"},{\"sequencenumber\":197,\"key\":\"role_id_107\",\"tenantterm\":\"rt management beta user\",\"frontiersdefaultterm\":\"rt management beta user\",\"category\":\"user role\"},{\"sequencenumber\":198,\"key\":\"role_id_108\",\"tenantterm\":\"deo beta user\",\"frontiersdefaultterm\":\"deo beta user\",\"category\":\"user role\"},{\"sequencenumber\":199,\"key\":\"role_id_109\",\"tenantterm\":\"search beta user\",\"frontiersdefaultterm\":\"search beta user\",\"category\":\"user role\"},{\"sequencenumber\":200,\"key\":\"role_id_110\",\"tenantterm\":\"journal manager\",\"frontiersdefaultterm\":\"journal manager\",\"category\":\"user role\"},{\"sequencenumber\":201,\"key\":\"role_id_111\",\"tenantterm\":\"myfrontiers beta user\",\"frontiersdefaultterm\":\"myfrontiers beta user\",\"category\":\"user role\"},{\"sequencenumber\":202,\"key\":\"role_id_21\",\"tenantterm\":\"copy editor\",\"frontiersdefaultterm\":\"copy editor\",\"category\":\"user role\"},{\"sequencenumber\":203,\"key\":\"role_id_1_abr\",\"tenantterm\":\"rof\",\"frontiersdefaultterm\":\"rof\",\"category\":\"user role\"},{\"sequencenumber\":204,\"key\":\"role_id_2_abr\",\"tenantterm\":\"eof\",\"frontiersdefaultterm\":\"eof\",\"category\":\"user role\"},{\"sequencenumber\":205,\"key\":\"role_id_7_abr\",\"tenantterm\":\"fce\",\"frontiersdefaultterm\":\"fce\",\"category\":\"user role\"},{\"sequencenumber\":206,\"key\":\"role_id_8_abr\",\"tenantterm\":\"afce\",\"frontiersdefaultterm\":\"afce\",\"category\":\"user role\"},{\"sequencenumber\":207,\"key\":\"role_id_9_abr\",\"tenantterm\":\"sce\",\"frontiersdefaultterm\":\"sce\",\"category\":\"user role\"},{\"sequencenumber\":208,\"key\":\"role_id_10_abr\",\"tenantterm\":\"asce\",\"frontiersdefaultterm\":\"asce\",\"category\":\"user role\"},{\"sequencenumber\":209,\"key\":\"role_id_11_abr\",\"tenantterm\":\"ae\",\"frontiersdefaultterm\":\"ae\",\"category\":\"user role\"},{\"sequencenumber\":210,\"key\":\"role_id_12_abr\",\"tenantterm\":\"gae\",\"frontiersdefaultterm\":\"gae\",\"category\":\"user role\"},{\"sequencenumber\":211,\"key\":\"role_id_13_abr\",\"tenantterm\":\"re\",\"frontiersdefaultterm\":\"re\",\"category\":\"user role\"},{\"sequencenumber\":212,\"key\":\"role_id_14_abr\",\"tenantterm\":\"rev\",\"frontiersdefaultterm\":\"rev\",\"category\":\"user role\"},{\"sequencenumber\":213,\"key\":\"role_id_15_abr\",\"tenantterm\":\"aut\",\"frontiersdefaultterm\":\"aut\",\"category\":\"user role\"},{\"sequencenumber\":214,\"key\":\"role_id_16_abr\",\"tenantterm\":\"coraut\",\"frontiersdefaultterm\":\"coraut\",\"category\":\"user role\"},{\"sequencenumber\":215,\"key\":\"role_id_17_abr\",\"tenantterm\":\"saut\",\"frontiersdefaultterm\":\"saut\",\"category\":\"user role\"},{\"sequencenumber\":216,\"key\":\"role_id_18_abr\",\"tenantterm\":\"coaut\",\"frontiersdefaultterm\":\"coaut\",\"category\":\"user role\"},{\"sequencenumber\":217,\"key\":\"role_id_20_abr\",\"tenantterm\":\"pof\",\"frontiersdefaultterm\":\"pof\",\"category\":\"user role\"},{\"sequencenumber\":218,\"key\":\"role_id_22_abr\",\"tenantterm\":\"tsof\",\"frontiersdefaultterm\":\"tsof\",\"category\":\"user role\"},{\"sequencenumber\":219,\"key\":\"role_id_24_abr\",\"tenantterm\":\"ru\",\"frontiersdefaultterm\":\"ru\",\"category\":\"user role\"},{\"sequencenumber\":220,\"key\":\"role_id_35_abr\",\"tenantterm\":\"jof\",\"frontiersdefaultterm\":\"jof\",\"category\":\"user role\"},{\"sequencenumber\":221,\"key\":\"role_id_41_abr\",\"tenantterm\":\"se-adm\",\"frontiersdefaultterm\":\"se-adm\",\"category\":\"user role\"},{\"sequencenumber\":222,\"key\":\"role_id_42_abr\",\"tenantterm\":\"se-rev\",\"frontiersdefaultterm\":\"se-rev\",\"category\":\"user role\"},{\"sequencenumber\":223,\"key\":\"role_id_43_abr\",\"tenantterm\":\"se-aut\",\"frontiersdefaultterm\":\"se-aut\",\"category\":\"user role\"},{\"sequencenumber\":224,\"key\":\"role_id_52_abr\",\"tenantterm\":\"evof\",\"frontiersdefaultterm\":\"evof\",\"category\":\"user role\"},{\"sequencenumber\":225,\"key\":\"role_id_53_abr\",\"tenantterm\":\"ev-adm\",\"frontiersdefaultterm\":\"ev-adm\",\"category\":\"user role\"},{\"sequencenumber\":226,\"key\":\"role_id_89_abr\",\"tenantterm\":\"comof\",\"frontiersdefaultterm\":\"comof\",\"category\":\"user role\"},{\"sequencenumber\":227,\"key\":\"role_id_98_abr\",\"tenantterm\":\"aof\",\"frontiersdefaultterm\":\"aof\",\"category\":\"user role\"},{\"sequencenumber\":228,\"key\":\"role_id_99_abr\",\"tenantterm\":\"projects\",\"frontiersdefaultterm\":\"projects\",\"category\":\"user role\"},{\"sequencenumber\":229,\"key\":\"role_id_103_abr\",\"tenantterm\":\"config\",\"frontiersdefaultterm\":\"config\",\"category\":\"user role\"},{\"sequencenumber\":230,\"key\":\"role_id_104_abr\",\"tenantterm\":\"beta\",\"frontiersdefaultterm\":\"beta\",\"category\":\"user role\"},{\"sequencenumber\":231,\"key\":\"role_id_106_abr\",\"tenantterm\":\"wfconf\",\"frontiersdefaultterm\":\"wfconf\",\"category\":\"user role\"},{\"sequencenumber\":232,\"key\":\"role_id_107_abr\",\"tenantterm\":\"rtbeta\",\"frontiersdefaultterm\":\"rtbeta\",\"category\":\"user role\"},{\"sequencenumber\":233,\"key\":\"role_id_108_abr\",\"tenantterm\":\"deobeta\",\"frontiersdefaultterm\":\"deobeta\",\"category\":\"user role\"},{\"sequencenumber\":234,\"key\":\"role_id_109_abr\",\"tenantterm\":\"searchbeta\",\"frontiersdefaultterm\":\"searchbeta\",\"category\":\"user role\"},{\"sequencenumber\":235,\"key\":\"role_id_110_abr\",\"tenantterm\":\"jm\",\"frontiersdefaultterm\":\"jm\",\"category\":\"user role\"},{\"sequencenumber\":236,\"key\":\"role_id_111_abr\",\"tenantterm\":\"mfbeta\",\"frontiersdefaultterm\":\"mfbeta\",\"category\":\"user role\"},{\"sequencenumber\":237,\"key\":\"role_id_21_abr\",\"tenantterm\":\"coped\",\"frontiersdefaultterm\":\"coped\",\"category\":\"user role\"},{\"sequencenumber\":238,\"key\":\"reviewer_editorial_board\",\"tenantterm\":\"editorial board\",\"frontiersdefaultterm\":\"editorial board\",\"description\":\"this is the label for the review editorial board\",\"category\":\"label\"},{\"sequencenumber\":239,\"key\":\"field_chief_editor\",\"tenantterm\":\"field chief editor\",\"frontiersdefaultterm\":\"field chief editor\",\"category\":\"label (role)\"},{\"sequencenumber\":240,\"key\":\"field_chief_editors\",\"tenantterm\":\"field chief editors\",\"frontiersdefaultterm\":\"field chief editors\",\"category\":\"label (role)\"},{\"sequencenumber\":241,\"key\":\"editor\",\"tenantterm\":\"editor\",\"frontiersdefaultterm\":\"editor\",\"category\":\"label (role)\"},{\"sequencenumber\":242,\"key\":\"editors\",\"tenantterm\":\"editors\",\"frontiersdefaultterm\":\"editors\",\"category\":\"label (role)\"},{\"sequencenumber\":243,\"key\":\"board\",\"tenantterm\":\"board\",\"frontiersdefaultterm\":\"board\",\"category\":\"label\"},{\"sequencenumber\":244,\"key\":\"boards\",\"tenantterm\":\"boards\",\"frontiersdefaultterm\":\"boards\",\"category\":\"label\"},{\"sequencenumber\":245,\"key\":\"article_collection\",\"tenantterm\":\"article collection\",\"frontiersdefaultterm\":\"article collection\",\"category\":\"label\"},{\"sequencenumber\":246,\"key\":\"article_collections\",\"tenantterm\":\"article collections\",\"frontiersdefaultterm\":\"article collections\",\"category\":\"label\"},{\"sequencenumber\":247,\"key\":\"handling_editor\",\"tenantterm\":\"handling editor\",\"frontiersdefaultterm\":\"associate editor\",\"description\":\"this terminology key is for the person assigned to edit a manuscript. it is a label for the temporary handling editor assignment.\",\"category\":\"label (role)\"},{\"sequencenumber\":248,\"key\":\"handling_editors\",\"tenantterm\":\"handling editors\",\"frontiersdefaultterm\":\"associate editors\",\"description\":\"this terminology key is for the person assigned to edit a manuscript. it is a label for the temporary handling editor assignment.\",\"category\":\"label (role)\"},{\"sequencenumber\":249,\"key\":\"ae_accept\",\"tenantterm\":\"recommend acceptance\",\"frontiersdefaultterm\":\"accept\",\"category\":\"process\"},{\"sequencenumber\":250,\"key\":\"rtm\",\"tenantterm\":\"rtm\",\"frontiersdefaultterm\":\"rtm\",\"category\":\"product\"},{\"sequencenumber\":251,\"key\":\"frontiers_media_sa\",\"tenantterm\":\"frontiers media s.a\",\"frontiersdefaultterm\":\"frontiers media s.a\",\"category\":\"customer\"},{\"sequencenumber\":252,\"key\":\"review_editors\",\"tenantterm\":\"community reviewers\",\"frontiersdefaultterm\":\"review editors\",\"category\":\"label (role)\"},{\"sequencenumber\":253,\"key\":\"journal_card_chief_editor\",\"tenantterm\":\"chief editor\",\"frontiersdefaultterm\":\"chief editor\",\"category\":\"label (role)\"},{\"sequencenumber\":254,\"key\":\"journal_card_chief_editors\",\"tenantterm\":\"chief editors\",\"frontiersdefaultterm\":\"chief editors\",\"category\":\"label (role)\"},{\"sequencenumber\":255,\"key\":\"call_for_papers\",\"tenantterm\":\"call for papers\",\"frontiersdefaultterm\":\"call for papers\",\"category\":\"label\"},{\"sequencenumber\":256,\"key\":\"calls_for_papers\",\"tenantterm\":\"calls for papers\",\"frontiersdefaultterm\":\"calls for papers\",\"category\":\"label\"},{\"sequencenumber\":257,\"key\":\"supervising_editor\",\"tenantterm\":\"supervising editor\",\"frontiersdefaultterm\":\"supervising editor\",\"description\":\"a chief or assistant chief editor who is assigned to a manuscript to supervise.\",\"category\":\"role\",\"externalkey\":\"supervising_editor\"},{\"sequencenumber\":258,\"key\":\"supervising_editors\",\"tenantterm\":\"supervising editors\",\"frontiersdefaultterm\":\"supervising editors\",\"description\":\"a chief or assistant chief editor who is assigned to a manuscript to supervise.\",\"category\":\"role\",\"externalkey\":\"supervising_editors\"},{\"sequencenumber\":259,\"key\":\"reviewer_endorse\",\"tenantterm\":\"endorse\",\"frontiersdefaultterm\":\"endorse\",\"category\":\"label\"},{\"sequencenumber\":260,\"key\":\"reviewer_endorsed\",\"tenantterm\":\"endorsed\",\"frontiersdefaultterm\":\"endorsed\",\"category\":\"label\"},{\"sequencenumber\":261,\"key\":\"reviewer_endorse_publication\",\"tenantterm\":\"endorse publication\",\"frontiersdefaultterm\":\"endorse publication\",\"category\":\"label\"},{\"sequencenumber\":262,\"key\":\"reviewer_endorsed_publication\",\"tenantterm\":\"endorsed publication\",\"frontiersdefaultterm\":\"endorsed publication\",\"category\":\"label\"},{\"sequencenumber\":263,\"key\":\"editor_role\",\"tenantterm\":\"editor role\",\"frontiersdefaultterm\":\"editor role\",\"category\":\"label\"},{\"sequencenumber\":264,\"key\":\"editor_roles\",\"tenantterm\":\"editor roles\",\"frontiersdefaultterm\":\"editor roles\",\"category\":\"label\"},{\"sequencenumber\":265,\"key\":\"editorial_role\",\"tenantterm\":\"editorial role\",\"frontiersdefaultterm\":\"editorial role\",\"category\":\"label\"},{\"sequencenumber\":266,\"key\":\"editorial_roles\",\"tenantterm\":\"editorial roles\",\"frontiersdefaultterm\":\"editorial roles\",\"category\":\"label\"},{\"sequencenumber\":267,\"key\":\"call_for_paper\",\"tenantterm\":\"call for paper\",\"frontiersdefaultterm\":\"call for paper\",\"category\":\"label\"},{\"sequencenumber\":268,\"key\":\"research_topic_abstract\",\"tenantterm\":\"manuscript summary\",\"frontiersdefaultterm\":\"manuscript summary\",\"category\":\"process\"},{\"sequencenumber\":269,\"key\":\"research_topic_abstracts\",\"tenantterm\":\"manuscript summaries\",\"frontiersdefaultterm\":\"manuscript summaries\",\"category\":\"process\"},{\"sequencenumber\":270,\"key\":\"submissions_team_manager\",\"tenantterm\":\"journal manager\",\"frontiersdefaultterm\":\"content manager\",\"category\":\"process\"},{\"sequencenumber\":271,\"key\":\"submissions_team\",\"tenantterm\":\"journal team\",\"frontiersdefaultterm\":\"content team\",\"category\":\"process\"},{\"sequencenumber\":272,\"key\":\"topic_coordinator\",\"tenantterm\":\"topic coordinator\",\"frontiersdefaultterm\":\"topic coordinator\",\"category\":\"process\"},{\"sequencenumber\":273,\"key\":\"topic_coordinators\",\"tenantterm\":\"topic coordinators\",\"frontiersdefaultterm\":\"topic coordinators\",\"category\":\"process\"},{\"sequencenumber\":274,\"key\":\"frontiers_journal_team\",\"tenantterm\":\"frontiers journal team\",\"frontiersdefaultterm\":\"frontiers journal team\",\"category\":\"label (role)\"},{\"sequencenumber\":275,\"key\":\"research_topic_ic_submission\",\"tenantterm\":\"rt:ic submission\",\"frontiersdefaultterm\":\"rt:ic submission\",\"category\":\"label (role)\"},{\"sequencenumber\":276,\"key\":\"research_topic_ic_submission_participant\",\"tenantterm\":\"rt:ic submission participant\",\"frontiersdefaultterm\":\"rt:ic submission participant\",\"category\":\"label (role)\"}]}'\n",impactgtmid:"gtm-njf2ml9b",impactgtmauth:"fyo-7nodm9w37qgfms03sa",impactgtmpreview:"env-1",impactgooglemapsapikey:"aizasyctehx2eu8pwfi86gw9fi00ftcykk6ifr8",qualtricsv4tov3:"'{\"enabled\":true,\"interceptid\":\"si_er0e2ze69oz8yn4\",\"projectid\":\"zn_cloy77jhkpc8gai\",\"brandid\":\"frontiersin\"}'\n",qualtricsumux:"'{\"enabled\":false,\"interceptid\":\"si_89fphy3etxqbwtu\",\"projectid\":\"zn_cloy77jhkpc8gai\",\"brandid\":\"frontiersin\"}'\n",qualtricscontinuousbrand:"'{\"enabled\":true,\"interceptid\":\"si_9zut94ut81fcrh4\",\"projectid\":\"zn_cloy77jhkpc8gai\",\"brandid\":\"frontiersin\"}'\n",defaultarticletemplate:"v3"},app:{baseurl:"/",buildid:"f2d5b6d8-d01c-4534-90b9-d659f10f17ca",buildassetsdir:"ap-2024/_nuxt",cdnurl:""}}## Introduction
social media is increasingly used in many contexts within the healthcare sector. the improved prevalence of internet use via computers or mobile devices presents an opportunity for social media to serve as a tool for the rapid and direct distribution of essential health information. autism spectrum disorders (asd) are a comprehensive neurodevelopmental syndrome with enduring effects. twitter has become a platform for the asd community, offering substantial assistance to its members by disseminating information on their beliefs and perspectives via language and emotional expression. adults with asd have considerable social and emotional challenges, while also demonstrating abilities and interests in screen-based technologies. methods: the novelty of this research lies in its use in the context of twitter to analyze and identify asd. this research used twitter as the primary data source to examine the behavioral traits and immediate emotional expressions of persons with asd. we applied convolutional neural networks with long short-term memory (cnn-lstm), lstm, and double deep q-network (ddqn-inspired) using a standardized dataset including 172 tweets from the asd class and 158 tweets from the non-asd class. the dataset was processed to exclude lowercase text and special characters, followed by a tokenization approach to convert the text into integer word sequences. the encoding was used to transform the classes into binary labels. following preprocessing, the proposed framework was implemented to identify asd. results: the findings of the ddqn-inspired model demonstrate a high precision of 87% compared to the proposed model. this finding demonstrates the potential of the proposed approach for identifying asd based on social media content. discussion: ultimately, the proposed system was compared against the existing system that used the same dataset. the proposed approach is based on variations in the text of social media interactions, which can assist physicians and clinicians in performing symptom studies within digital footprint environments. 1 introduction asd is among the most prevalent neurodevelopmental disorders. asd is often demonstrated in children by age three and is defined by impairments in social interactions and communication, repetitive sensory-motor activities, and stereotypical behavioral patterns ( 1 ). asd is a congenital neurodevelopmental condition characterized by symptoms that are evident in early infancy. autism, characterized by restricted interests, repetitive behaviors, and significant disparities in social communication and interaction, typically emerges during early developmental stages and presents challenges in various social functioning domains. a child with autism induces significant anxiety within the family due to several factors, including the ambiguity of the diagnosis, the intensity and persistence of the disease, and the child’s nonconformity to social norms. in opposition, social awareness of autism is markedly inadequate, often conflated with intellectual disability and seen as an incurable ailment ( 2 , 3 ). the asd concept is displayed in figure 1 . figure 1 figure 1 . displays the asd concept. content on social media, particularly videos and text disseminated by parents and caregivers, has emerged as a significant resource for facilitating the early identification of asd ( 4 , 5 ). social media are technological tools designed for sharing, enabling users to create networks or engage in existing ones. in that order, the pew research center identified the most popular social media sites as youtube, facebook, instagram, pinterest, linkedin, snapchat, twitter, and whatsapp ( 6 ). most consumers use these networks daily. this research utilizes twitter data to assess the stigmatization of autism and associated terminology, picked based on accessibility and popularity, with analysis conducted using artificial intelligence technologies ( 7 ). conventional diagnostic methods, which primarily rely on observational and behavioral evaluations, often encounter issues with accessibility, consistency, and timeliness. recent technology breakthroughs, especially in artificial intelligence (ai), and sensor-based techniques, provide novel opportunities for improving asd identification. by developing more objective, accurate, and scalable approaches, these technologies transform diagnostic methodologies for autism spectrum disorder (asd) ( 8 – 10 ). one new way to study the motor patterns, attentional processes, and physiological responses linked to asd in real-time is wearable sensors, eye-tracking devices, and multimodal virtual reality settings. these technologies have the potential to give non-invasive, continuous monitoring, which might help with the early diagnosis of asd and shed light on neurological and behavioral traits that have been hard to document reliably. nevertheless, advancements in contemporary research are required to substantiate their efficacy. sensor-based techniques may facilitate the identification of stereotyped behaviors and motor patterns linked to asd in realistic environments, potentially yielding data that could guide timely and customized therapies ( 11 ). neuroimaging and microbiome analysis further advance this technical domain by indicating neurological and biological traits specific to asd. ai-enhanced neuroimaging aids in identifying structural and functional brain connection patterns associated with asd, thereby enhancing the understanding of its neuroanatomical foundation ( 12 ). the research conducted by neeharika and riyazuddin et al. ( 13 ) aimed to enhance the accuracy of asd screening by using feature selection methods in conjunction with sophisticated machine learning classifiers. their research included several datasets spanning infants, children, adolescents, and adults, enabling a thorough assessment of asd characteristics across different age demographics. authors’ use of mlp model capacity to reliably and rapidly identify asd, indicating a beneficial screening instrument suitable for various age groups, facilitating both clinical evaluations and extensive screenings. wall et al. ( 14 ) investigated machine learning (ml) algorithms for diagnosing asd using a standard dataset. the researchers focused on the alternating decision tree classifier to identify a limited yet efficient set of queries that optimize the diagnostic procedure. alzakari et al. ( 15 ) proposed a novel two-phase methodology to tackle the variability in asd features with ml approaches, including behavioral, linguistic, and physical data. the first step concentrates on identifying asd, using feature engineering methodologies and ml algorithms, including a logistic regression (lr) and support vector machine (svm) ensemble, attaining a classification with high accuracy. eeg assesses brain activity and may identify children predisposed to developing asd, hence facilitating early diagnosis. eeg data is used to compare asd and hc ( 16 – 18 ). in ( 19 ), the cnn model was used for classification after transforming the data into a two-dimensional format. while eeg may facilitate the diagnosis of asd, it is constrained by other factors, such as signal noise. the research has used social media to investigate asd. however, exploiting these prevalent platforms and innovative online data sources may be feasible to enhance the comprehension of these diseases. previous research has utilized twitter data to investigate discussions on asd-related material, indicating that this subject is frequently addressed on this platform ( 20 ). considering the use of social media for researching asd is particularly significant, as a recent analysis indicated that around 80% of individuals with asd engage with prominent social media platforms ( 21 ). this study aims to build upon previous research and enhance our comprehension of whether publicly accessible social media data from twitter may provide insights into the existence of digital diagnostic indicators for asd ( 22 ). furthermore, we want to assess the viability of establishing a digital phenotype for asd using social media. beykikhoshk et al. ( 20 ) examined twitter’s potential as a data-mining tool to comprehend the actions, challenges, and requirements of autistic individuals. the first finding pertained to the attributes of participants inside the autism subgroup of tweets, indicating that these tweets were highly informative and had considerable potential usefulness for public health experts and policymakers. tomeny et al. ( 23 ) examined demographic correlations of autism-related anti-vaccine opinions on twitter from 2009 to 2015. their results indicated that the frequency of autism-related anti-vaccine views online was alarming, with anti-vaccine tweets connecting with news events and demonstrating geographical clustering. from 2015 to 2019, tárraga-mínguez et al. ( 24 ) examined the phrases “autism” and “asperger” in spain in relation to google search peaks. the public view of autism was significantly impacted by how the condition was portrayed in the news and on social media, and the authors found that social marketing campaigns had a significant role in normalizing autism. in this research ( 25 ), looked at how people sought assistance. the results showed a strong correlation in google search interest between the terms “asperger syndrome” and “greta thunberg,” reaching their highest point in 2019. online traffic to the asperger/autism network and autism speaks websites increased steadily from june to december 2019, indicating a correlation between help-seeking behavior and thunberg’s fame, according to the research. according to the results, the stigma associated with asperger’s disorder may have been positively affected by thunberg’s public exposure. 1.1 contribution the use of tweets from twitter for the detection of asd is substantial, since it offers extensive, real-time, user-generated data that facilitates the early identification of asd-related behaviors, particularly via self-reported experiences and parental observations. this methodology promotes the advancement of suggested models, namely lstm, cnn-lstm, and inspired ddqn, for natural language processing to examine linguistic patterns, feelings, and keywords related to asd. it provides insights into popular views, stigma, and misconceptions around autism, guiding awareness initiatives and public health measures. twitter data is a powerful and accessible resource for enhancing early detection and understanding of asd in diverse groups. utilizing social media in this manner may offer more accessible and timely screening, particularly in regions with limited healthcare resources. 2 materials and methods figure 2 shows the pipeline of the proposed system to provide a broader perspective to researchers and developers. the framework delineates the processing phases for the pipeline that utilizes social media content to diagnose asd. below, we present a comprehensive assessment of each step. figure 2 figure 2 . farmwork of asd system. 2.1 dataset to help with the early diagnosis of asd by using proposed systems, the tasd-dataset includes comprehensive textual sequences that depict the everyday lives of children with and without asd. it offers new elements, including noise sensitivity, sharing interest, sign communication, and tiptoe flapping, it combines critical asd assessment aspects like attention response, word repetition, and emotional empathy, as shown in figure 3 . parents may get detailed insights and better identify signs of autism spectrum disorder (asd) due to the deepening of certain behaviors. the dataset contains 172 tweets from the asd class and 158 non-asd tweets. figure 4 shows the class of the dataset. figure 3 figure 3 . features of the dataset. figure 4 figure 4 . label of the dataset. 2.2 preprocessing text preprocessing is an essential step in the text processing process. words, sentences, and paragraphs can all be found in a text, which is defined as a meaningful sequence of characters. preprocessing methods feed text data to a proposed algorithm in a better form than in its natural state. a tweet can contain different viewpoints on the data it represents. tweets that have not been preprocessed are highly unstructured and contain redundant data. to address these issues, several steps are taken to preprocess tweets for detecting asd, as shown in figure 5 . figure 5 figure 5 . preprocessing asd text analysis. 2.3 text cleaning the clean text preprocessing method is a significant step in text datasets because the text contains several extra contexts to preprocess and normalize raw text data for analysis. in these steps, the use is transformed to lowercase to guarantee consistency and prevent differentiation between “asd” and “non-asd.” subsequently, any characters that are not letters, numerals, or spaces are eliminated by a regular expression, so punctuation and other symbols that might create extraneous noise are removed. this method is ultimately applied to the ‘text’ column of the data frame, ensuring that all text elements are sanitized and prepared for feature extraction. figure 6 displays the clean text process. figure 6 figure 6 . clean text. 2.4 label encoding the labelencoder method converts text class (asd and non-asd) into numbers, designating 0 for asd and 1 for non-asd. this transformation updates the classification effort by enabling the model to see the labels as numerical values instead of text. equations 1 , 2 show the label encoding. yclassification ∈ ( asd , non − asd ) then      ( 1 ) y = labelencoder ( yclassifcation ) → y ∈ { 0 , 1 }      ( 2 ) 2.5 tokenization and padding tokenization and padding are essential nlp preprocessing procedures that transform unprocessed text into a numerical representation appropriate for machine learning models, particularly neural networks. figure 7 shows the tokenization and padding equation 3 . figure 7 figure 7 . sample of text tokenization and padding. 2.5.1 tokenizer tokenizer procedures transform textual data into a numerical representation suitable for input into neural networks. they convert a text corpus into integer sequences, assigning a distinct index to each unique word according to its frequency, as shown in equation 3 . the tokenizer processing is shown in figure 8 . index ( w ) = rank f ( w ) if rank f ( w ) ≤ v      ( 3 ) figure 8 figure 8 . tokenizer analysis: word frequencies and sequence lengths. where rank f ( w ) is rank w frequency f ( w ) and v is the maximum number of words. 2.5.2 fit texts this phase is crucial for transforming unprocessed text into numerical sequences suitable for input into the proposed system. 2.5.3 texts_to_sequences to convert unprocessed text input into sequences of word indices according to the mapping acquired via as shown in equation 4 . sequence ( t i ) = [ index ( w 1 ) , index ( w 2 ) , … … … , index ( w m ) ]      ( 4 ) where is the t i is the sentence of the text contained, and w is the words of the text, whereas the index ( w 1 ) is an index of the words in the context. 2.5.4 padding_sequences normalize sequence lengths, which may differ post-tokenization, by padding shorter sequences and truncating larger ones to a predetermined length as shown in equation 5 . the padding and truncated b are fixed on the length. l = 200 . the padding processing is shown in figure 7 . x = ∣ x 1 x 2 . . . . y ∣ ∈ ℝ nxl     (5) where x is features contain padding and are tokenized, l is the length of the vector. the number of texts is indicated n , and ∈ ℝ nxl is matrix lues. 2.6 proposed systems 2.6.1 convolutional neural networks the cnn model is at the core of all advanced machine learning and deep learning applications. they can successfully address text classification, image recognition, object identification, and semantic segmentation. using the same method with a task as different as natural language processing is counterintuitive ( 7 ). the structure is presented in figure 9 . equation 6 presents the convolution layer of cnn. o ( x , y ) = ∑ i = 1 h ∑ j = 1 w i ( x + i , y + j ) ∗ k ( i , j ) + b      ( 6 ) figure 9 figure 9 . structure cnn. where the features of text o ( x , y ) the feature of the text is mapped by using. i ( x + i , y + j ) is weighted by a neural network and b is biased to adjust the neural. the relu activation function is equation 7 , the max pooling function is presented in equation 8 . the dense layer is given in equation 9 . f ( x ) = max ( 0 , x )      ( 7 ) o ( x , y ) = ∑ i = 1 h ∑ j = 1 w i ( x + i , y + j ) ∗ k ( i , j ) + b      ( 8 ) o = w · x + b      ( 9 ) 2.6.2 long short-term memory network an lstm network is an advanced form of a sequential neural network. it fixes the problem of rnn gradients fading over time. rnns often handle long-term storage. at a high level, the operation of an lstm is comparable to that of a single rnn neuron. the inner workings of the lstm network are outlined in this section. the lstm consists of three parts, each performing a particular function, as seen in figure 10 below. in the first step, it is decided whether the information from the previous time stamp is significant enough to be saved or if it is harmless enough to be deleted. in the second step, the cell will try to acquire new information by analyzing the data that has been presented to it. in the third and final step, the cell incorporates the data from the most recent time stamp into the data stored in the next time stamp. these three components constitute what is referred to as a gate for an lstm cell. the “forget” gate comes first, followed by the “input” section, and then the “output” section is used to define the last portion as shown in equations 10 – 14 . forget gate : f t = σ ( w f . x t + w f . h t − 1 + b f )      ( 10 ) input gate : i t = σ ( w c . x t + w i . h t − 1 + b i )      ( 11 ) cell gate : c t = ( w f ∗ ( . h t − 1 , x t ) b f )      ( 12 ) output gate : o t = σ ( w o + x t + w o . h t − 1 + v o . c t + b o )      ( 13 ) hidden layer : h t = o t + tanh ( c t )      ( 14 ) figure 10 figure 10 . lstm model. in figure 10 , c t represent the prior and current states of the cell, respectively. both h t − 1 and h represents the cell output that was processed before the one now being processed. it is common practice to disregard f t as a gate, even though it is the input gate. the output of a sigmoid gate is symbolized here by o t . the cable that connects the cell gates is where all the data collected by the cell gates is sent to and from c . the f t layer decides to remember anything, and the f t the output is multiplied by c to do so (t-1). after that, c (t-1) is multiplied by the product of the sigmoid layer gate and the tanh layer gate, and the output h t is generated by point-wise multiplication of o t and tanh. the lstm architecture is intended to capture long-term relationships in twitter text data. the preprocessing converts input words that start with an embedding layer into 128-dimensional dense vectors. the lstm layer with 64 units is then used to mitigate overfitting, integrating dropout and recurrent dropout with 0.5. an l2 regularization term is further included in the lstm and output dense layer. table 1 shows parameters of the lstm model. table 1 table 1 . lstm parameters model. 2.6.3 cnn-lstm model the cnn-lstm model is a hybrid architecture that combines convolutional neural networks (cnn) for spatial feature extraction and long short-term memory (lstm) networks for sequential learning, making it highly effective for analyzing text data such as tweets. the model begins with an embedding layer that transforms each word into a 256-dimensional dense vector, capturing the semantic meaning of words. this is followed by a 1d convolutional layer with 64 filters and a kernel size of 5, which scans through the text to detect local patterns and n-gram features such as common word combinations or phrases often associated with asd. a batch normalization layer is applied to stabilize and accelerate training, followed by a max pooling layer that reduces the dimensionality and computational load by selecting the most prominent features. a dropout layer with a rate of 0.5 is then used to prevent overfitting by randomly deactivating some neurons during training. the output is passed into a 64-unit lstm layer that captures the temporal dependencies and contextual relationships across the tweet sequence. finally, a dense layer with sigmoid activation performs binary classification to predict whether the tweet indicates asd-related content. the model is trained using the adam optimizer, binary cross-entropy loss, class weights, and regularization to handle imbalanced data and improve generalization. the critical parameters of the cnn-lstm model are displayed in table 2 . table 2 table 2 . cnn-lstm parameters. 2.6.4 double deep q-network (ddqn-inspired) the double q-learning model was introduced by h. van hasselt in 2010, addressing the issue of significant overestimations of action value (q-value) inherent in traditional q-learning. in fundamental q-learning, the agent’s optimal strategy is consistently to select the most advantageous action in any specific state. this concept’s premise is that the optimal action corresponds to the highest expected or estimated q-value. initially, the agent lacks any knowledge of the environment; it must first estimate q(s, a) and subsequently update these estimates with each iteration. the q-values exhibit considerable noise, leading to uncertainty about whether the action associated with the highest expected or estimated q-value is genuinely the optimal choice. double q-learning employs two distinct action-value functions, q and q’, as estimators. even if q and q’ exhibit noise, this noise can be interpreted as a uniform distribution as shown figure 11 the update procedure exhibits some variations compared to the basic version. the action selection and action evaluation processes are separated into two distinct maximum function estimators. shown in equations 15 , 16 . figure 11 figure 11 . ddqn-inspired model. let the vector of a neural network’s weights be represented by θ . we establish two q-networks: the online q-network q (s, a; θ(t)) and the target q-network q (s, a; θ (t)). to be more specific, the training of q (s, a; Χ (t)) is done by modifying the weights (t) at time slot t in relation to the goal value y(t). y ( t ) = g ( t ) + ( s ′ , argmax q ( s ′ , a ∗ ; θ ′ ( t ) ) ; θ ′ ( t ) )      ( 15 ) y ( t ) = g ( t ) + ( s ′ , argmax q ( s ′ , a ∗ ; θ ′ ) ; θ i − 1 )      ( 16 ) the reinforcement learning mechanism integrates generative artificial intelligence for decision-making and prediction tasks, as shown in equations 15 , 16 . this equation indicates the generative which produces the estimation or hypothesis at a given time t . double q − learning used next state, whereas the s’ is exit state and argmax q ( s ′ , a ∗ ; θ ′ ( t ) ) defined as the action of a ∗ to maximize the predicted q-value based on the current parameters. to estimate the q-value of this selected action in the next state, the outer q-function q’ employs the older parameters. θ i − 1 1, which helps reduce overestimation bias. this combination makes applications for predicting asd from social media content domains possible. the ddqn model is used to classify asd and non-asd cases utilizing text data. the model utilizes a preprocessing step for text processing that encompasses data loading, cleaning (including lowercasing, removal of special characters, and normalization of spaces), and tokenization, constrained by a maximum vocabulary of 10,000 words and a sequence length of 200. the model architecture, drawing from the double deep q-network (ddqn) model comprises an input layer, an embedding layer with 256 dimensions, and two parallel lstm branches, each containing 64 units, a dropout rate of 0.5, and l2 regularization to capture sequential patterns effectively. the model uses the adam optimizer with a learning rate of 1e-4 and employs binary cross-entropy loss. it is trained for 30 epochs, incorporating early stopping and learning rate reduction callbacks to mitigate overfitting. parameters of ddqn-inspired are shown in table 3 . table 3 table 3 . parameters of ddqn-inspired. 3 performance of the framework 3.1 performance of lstm figure 12 presents the accuracy and loss metrics used to train and validate an lstm model over 30 epochs. the validation accuracy of the lstm model, displayed in red, begins at a lower value and increases to about 81%. the blue line in the accuracy plot (a) shows the training accuracy of the lstm model; it increases gradually from around 50% to almost 99%, showing that the model learns the training data well over time. the plot (b) shows the loss of the lstm model; the blue line represents the training loss, which drops gradually from around 0.7 to less than 0.2, suggesting that the model is getting a better fit to the training data. meanwhile, the red validation loss line declines from around 0.7 to about 0.3. while the training loss continues to grow, the validation loss reaches a level and exhibits small oscillations, suggesting that the model’s generalizability may stabilize. figure 12 figure 12 . performance of the lstm model. the roc curve illustrated in figure 13 shows the efficacy of the lstm model in differentiating between the classes. the graph illustrates the tp rate (sensitivity) in relation to the fp rate across different threshold levels. the lstm model attains an auc of 0.95, demonstrating exceptional classification capability. the auc of 1.0, but a result of 0.5 indicates random chance. figure 13 figure 13 . roc of the lstm model. 3.2 performance of the cnn-lstm model figure 14 presents plots illustrating the performance of a cnn-lstm model over 25 epochs, showing its training and validation metrics for accuracy and loss. the accuracy plot (a) illustrates the training accuracy (blue line), which increases progressively from approximately 51.42% to nearly 99.53%, indicating effective learning from the training data. in contrast, the validation accuracy (red line) rises to about 83.02% with some variability, indicating satisfactory but imperfect generalization. the loss plot (b) shows the training loss (blue line) declining steadily from 0.7140 to below 0.0760, indicating enhanced model fit. in contrast, the validation loss (red line) decreases from 0.7130 to approximately 0.3530, with a slight decline toward the conclusion. this notification indicates that the cnn-lstm model demonstrates efficient learning, as evidenced by the difference between the training and validation measures. figure 14 figure 14 . performance of the lstm model. figure 15 illustrates the roc curve for the cnn-lstm model, illustrating its classification performance at various thresholds. the graph illustrates the tp rate (sensitivity) in relation to the fp rate, with the auc recorded at 92%. the elevated auc value indicates the model has robust discriminative capability in differentiating between the asd and non-asd classes. the roc ascends rapidly toward the top-left corner, as seen in the figure, indicating a high tp rate with few false positives. figure 15 figure 15 . roc of the cnn-lstm model. 3.3 performance of ddqn-inspired model graphs 16 illustrate the performance of a ddqn throughout 30 epochs. the accuracy plot (a) demonstrates that the training accuracy increases from around 58.02% to almost 98.58%, indicating the ddqn model successful learning from the training data over time. the validation accuracy of the ddqn is about 87, showing the best performance compared to different models like lstm and cnn-lstm. the plot (b) illustrates that the training loss decreases from about 0.8155 to around 0.1477, indicating a robust fit to the training data. the validation loss begins at 0.3831 with many fluctuations throughout ( figure 16 ). figure 16 figure 16 . performance of the ddqn-inspired model. figure 17 shows the roc curve for the ddqn model; it shows a visual representation of its classification capability, with the curve toward the top-left corner, indicating strong predictive power. the auc value of the ddqn model is 96%, demonstrating that the model can distinguish between the positive and negative classes. figure 17 figure 17 . roc ddqn-inspired model. 4 experiment and discussion results both the jupyter deep learning framework and the windows 10 operating system were utilized during the testing process. experiments were conducted using a machine with 16 gigabytes of ram and an intel core i7 central processing unit. the input dimensions of the experiment were a standard text dataset collected from the twitter api related to asd. the test was utilized in our database, while the remaining 20% was used as part of our validation set. the three dl models, namely lstm, cnn-lstm, and ddqn-inspired, were proposed for detecting asd from social media content. 4.1 measuring the model’s performance sensitivity, specificity, accuracy, recall, and f1 scores are assessment measures used to determine how successfully the algorithms identify asd. the related equations from 17 to 21 : accuracy = tp + tn tp + fp + fn + tn × 100 %      ( 17 ) sensitivity = tp tp + fn × 100 %      ( 18 ) precision = tp tp + fp × 100 %      ( 19 ) specificity = tn tn + fp × 100      ( 20 ) f 1 − score = 2 ∗ precision × sensitivity precision + sensitivity × 100      ( 21 ) 4.2 result of the lstm model the classification lstm model, presented in table 4 , summarizes its performance in differentiating between asd and non-asd patients, attaining an overall accuracy of 81%. the lstm model demonstrates in asd class a precision of 91%, indicating a high accuracy in identifying predicted asd cases. the lstm with recall metric scored 77% and an f1-score of 82% for detecting the asd class. the lstm model with non-asd class demonstrates a precision of 71%, a recall of 89%, and an f1-score of 79%, to identify non-asd cases. the macro average of the lstm model for all metrics is (precision: 81%, recall: 82%, f1-score: 81%). lstm model is recognized for its efficiency and scalability as a model for social media content. table 4 table 4 . lstm results. the confusion matrix for the lstm model is provided in figure 18 . it is presented in a clear manner. among the confirmed asd cases, 29 were accurately identified as asd, whereas 10 were incorrectly classified as non-asd, indicating strong performance with minor errors. in the true non-asd cases, 25 were correctly identified, while 3 were misclassified as asd, suggesting a generally effective detection process. the deep blue and light shades produce a tranquil visual, illustrating the model’s balanced approach in classifying the 67 total instances, demonstrating notable strength in identifying non-asd cases, while exhibiting marginally lower accuracy for asd. this matrix effectively illustrates the lstm model’s systematic approach to managing sequential data, such as text or time-series inputs, in a clear and comprehensible manner. figure 18 figure 18 . lstm model. 4.3 result of the cnn-lstm model table 5 displays the cnn-lstm model’s performance in distinguishing between asd and non-asd classes. the cnn-lstm model attained an overall accuracy of 85% across the dataset. in the asd label, a precision of 91% was achieved, a high percentage for predicting asd cases that were accurately recognized. the recall indicates that the model identified 82% of all genuine asd cases, resulting in an f1 score of 86%, better than the recall metric. the cnn-lstm model attained 78% accuracy, 89% recall, and an 83% f1 score for the non-asd class. the macro average, representing the unweighted mean of precision, recall, and f1 score across both classes, was 85, 86, and 85%, respectively. the findings indicate that the cnn-lstm model performs satisfactorily, exhibiting a marginally superior capacity to identify asd cases relative to non-asd cases accurately. table 5 table 5 . results of the cnn-lstm model. the confusion matrix of a cnn-lstm model is presented in figure 19 , for classifying instances into asd and non-asd. the matrix is structured with true labels on the vertical axis and predicted labels on the horizontal axis, providing a clear summary of the model’s classification outcomes. the matrix shows that out of the instances truly labeled as asd, the model correctly predicted 32 as asd tp while 7 were incorrectly classified as non-asd fn. for the instances truly labeled as non-asd, the model accurately identified 25 as non-asd tn but 3 were misclassified as asd fp. this indicates that the model demonstrates a relatively strong ability to correctly identify asd and non-asd cases, with higher accuracy for true positives (32 out of 39 asd cases) and true negatives (25 out of 28 non-asd cases). overall, the model exhibits promising performance with minimal misclassification errors. figure 19 figure 19 . results of cnn-lstm model. 4.4 results of double deep q-network the findings of the ddqn model are shown in table 6 , achieving a high precision of 87% compared to the other models. this finding demonstrates the potential of the proposed ddqn approach for identifying asd based on social media content. ultimately, the proposed system was compared against the existing one using the same dataset. the proposed approach may assist physicians in detecting asd and conducting symptomology research in a natural environment, attaining an overall accuracy of 87. the model for the asd class shows a precision of 95%, a recall of 79%, and an f1-score of 87%, indicating robust efficacy in accurately identifying asd patients. the non-asd class has a precision of 77%, a recall of 96%, and an f1-score of 86%, indicating somewhat reduced accuracy with robust recall. the macro average measures (precision 87%, recall 88%, f1-score 87%) indicate performance across both classes. table 6 table 6 . result of ddqn-inspired. the confusion matrix of the ddqn model is shown in figure 20 for the classification task between asd and non-asd cases. for correct classification of asd cases, the model correctly classified 31 instances as asd, represented by the top-left quadrant (tp). however, the ddqn model, misclassified 8 instances misclassifying true asd cases as non-asd, shown in the top-right quadrant (fn). on the other hand, the ddqn showed the true non-asd cases, accurately identified 27 instances as non-asd, depicted in the bottom-right quadrant (tn). at the same time, 1 instance was incorrectly labeled as asd, as shown in the bottom-left quadrant (fp). the confusion matrix of ddqn model highlights that it performs well overall, with a strong ability to correctly identify both asd and non-asd cases, as evidenced by the high counts of tp (31) and tn (27). figure 20 figure 20 . result of ddqn-inspired model. in the digital era, people frequently write content on social media to express their feelings, opinions, beliefs, and activities. this makes social media one of the most significant sources of data generation, allowing you to explore its opportunities and challenges. today, social media has become a mediator between people and the healthcare sector, enabling them to search for information about any specific disease and methods for diagnosing it. individuals within the mental health community use social media platforms such as twitter to seek information, exchange experiences, and get assistance about asd in an environment that is seen as more approachable and informal than conventional medical contexts. they often seek immediate, relevant information—whether to understand symptoms, identify coping mechanisms, or connect with others facing similar difficulties. figure 21 illustrates that word clouds are visual representations of text that highlight key terms and their frequency of use. we used wordcloud to compare asd and non-asd texts for instances of word repetition. figure 21 figure 21 . asd word cloud. the deployment model based on the deep q-network (dqn) model for diagnosing asd is shown in figure 22 . figure 22 figure 22 . deployment system-based text for detecting asd. step 1: data collections, including cleaning, normalization, and tokenization. step 2: model development: the preprocessed data is used to train and validate a deep q-network (dqn) model for classifying tweets as indicative of asd or non-asd patterns. step 3: application interface: an application interface is developed once the model has been trained. it integrates with users’ twitter accounts and continuously analyzes their tweets. step 4: deployment: the proposed system is deployed in the cloud for storing tweets, enabling real-time monitoring of incoming tweets. predictions are flagged for review by healthcare professionals, who validate the model’s output before categorizing individuals as potentially having asd or non-asd. this digital imprint may serve as an ancillary resource for mental health practitioners, providing insights into an individual’s emotional state and social behaviors in a natural environment, potentially facilitating early detection or corroborating a diagnosis. this method is a non-invasive means of data collection, particularly beneficial for individuals who lack rapid access to clinical assessments due to financial constraints, stigma, or resource scarcity. however, it should not replace professional diagnoses and must be conducted with ethical consideration to prevent misunderstanding. table 7 shows the findings of the proposed framework on the twitter dataset. it demonstrates that the suggested method outperforms the current systems in terms of accuracy, proving its efficacy and potential for performance improvements. table 7 table 7 . compared with the proposed asd system. 5 conclusion to assist people in identifying trends in their behavior, such as social challenges or sensory sensitivities, which may encourage them to pursue a formal diagnosis. the main objective of examining tweets for identifying asd is its ability to provide behavioral and emotional indicators associated with the disorder. this research was used to analyze the textual analysis of tweets to detect the behaviors in self-identified autistic individuals relative to others. the suggested framework was evaluated using information from the social media platform “twitter” collected from a public repository. before examining the proposed system, several preprocessing steps must be implemented in the text. the ‘text’ column is cleaned by converting it to lowercase, eliminating non-alphanumeric characters (excluding spaces) through regular expressions, normalizing whitespace to a single space, and removing any leading or trailing spaces. the asd and non-asd labels are converted into a numerical format (0 or 1) with labelencoder to accommodate the binary classification requirement. tokenization of the text data is performed using a tokenizer, restricting the vocabulary to 10,000 words, and then transforming the text into sequences of numbers. the sequences are padded to a standardized length of 200 tokens to maintain consistency for the proposed model input. the proposed data is ultimately divided into an 80% training and 20% testing ratio, and class weights are calculated to resolve any class imbalance. this preparation pipeline efficiently converts raw text data into a structured numerical representation appropriate for the proposed framework, while preserving academic integrity. the output of these preprocessing steps was processed using three dl models, such as short-term memory (cnn-lstm) and a double deep q-network (ddqn). the results of these proposals were proven, revealing that the ddqn model achieved a high accuracy score of 87% with respect to the accuracy measure. the proposed framework, based on real textual data, can be helpful for real-time offering natural, behavioral, and emotional data that might indicate asd-related characteristics. finally, we have observed that social media (twitter) postings include linguistic patterns, emotional expressions, and social interactions that can help official health officials detect asd based on the thorough symptoms of asd that are posted on the platform. this study utilized a conventional dataset sourced only from the twitter network. we will emphasize the necessity of gathering datasets from many platforms to enhance the model’s generalizability in the future. data availability statement the original contributions presented in the study are included in the article/supplementary material, further inquiries can be directed to the corresponding author/s. the dataset used in this study can be found at https://data.mendeley.com/datasets/87s2br3ptb/1 . ethics statement ethical approval was not required for the study involving human data in accordance with the local legislation and institutional requirements. written informed consent was not required, for either participation in the study or for the publication of potentially/indirectly identifying information, in accordance with the local legislation and institutional requirements. the social media data was accessed and analysed in accordance with the platform’s terms of use and all relevant institutional/national regulations. author contributions nf: supervision, conceptualization, software, methodology, writing – original draft, investigation, visualization, formal analysis, validation. aa: data curation, visualization, methodology, conceptualization, validation, software, formal analysis, writing – original draft. ne: investigation, writing – review & editing, validation, formal analysis. sa: visualization, software, formal analysis, writing – review & editing, data curation. funding the author(s) declare that financial support was received for the research and/or publication of this article. the authors extend their appreciation to the king salman center for disability research for funding this work through research group no ksrg-2024-288. conflict of interest the authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest. generative ai statement the authors declare that no gen ai was used in the creation of this manuscript. any alternative text (alt text) provided alongside figures in this article has been generated by frontiers with the support of artificial intelligence and reasonable efforts have been made to ensure accuracy, including review by the authors wherever possible. if you identify any issues, please contact us. publisher’s note all claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher. references 1. asd. (2023). available online at: https://www.healthline.com/health/signs-of-autism-in-3-year-old . google scholar 2. matson, jl, and goldin, rl. what is the future of assessment for autism spectrum disorders: short and long term. res autism spectr disord . (2014) 8:209–13. doi: 10.1016/j.rasd.2013.01.007 crossref full text | google scholar 3. srivastava, ak, and schwartz, ce. intellectual disability and autism spectrum disorders: causal genes and molecular mechanisms. neurosci biobehav rev . (2014) 46:161–74. doi: 10.1016/j.neubiorev.2014.02.015 pubmed abstract | crossref full text | google scholar 4. alhujaili, n, platt, e, khalid-khan, s, and groll, d. comparison of social media use among adolescents with autism spectrum disorder and non-asd adolescents. adolesc health med ther . (2022) 13:15–21. doi: 10.2147/ahmt.s344591 pubmed abstract | crossref full text | google scholar 5. angulo-jiménez, h, and dethorne, l. narratives about autism: an analysis of youtube videos by individuals who self-identify as autistic. am j speech lang pathol . (2019) 28:569–90. doi: 10.1044/2018_ajslp-18-0045 crossref full text | google scholar 6. pew research center. (2021). available online at: https://www.pewresearch.org/internet/2021/04/07/social-media-use-in-2021/ google scholar 7. liu, j-b, guan, l, cao, j, and chen, l. coherence analysis for a class of polygon networks with the noise disturbance. ieee trans syst man cybern syst . (2025) 2025:326. doi: 10.1109/tsmc.2025.3559326 crossref full text | google scholar 8. al-nefaie, ah, aldhyani, th, sultan, ha, and alzahrani eidah, m. application of artificial intelligence in modern healthcare for diagnosis of autism spectrum disorder. front med . (2025) 12:1569464. doi: 10.3389/fmed.2025.1569464 crossref full text | google scholar 9. kim, b, jeong, d, kim, jg, hong, h, and han, k. v-dat (virtual reality data analysis tool): supporting self-awareness for autistic people from multimodal vr sensor data . in: proceedings of the uist 2023—proceedings of the 36th annual acm symposium on user interface software and technology, san francisco, ca, usa, 29 october–1 november 2023. (2023). google scholar 10. chen, c, chander, a, and uchino, k. guided play: digital sensing and coaching for stereotypical play behavior in children with autism . in proceedings of the international conference on intelligent user interfaces, proceedings iui, marina del ray, ca, usa, 17–20 march 2019; part f1476. pp. 208–217. (2019). google scholar 11. parui, s, samanta, d, chakravorty, n, ghosh, u, and rodrigues, jj. artificial intelligence and sensor-based autism spectrum disorder diagnosis using brain connectivity analysis. comput electr eng . (2023) 108:108720. doi: 10.1016/j.compeleceng.2023.108720 crossref full text | google scholar 12. golestan, s, soleiman, p, and moradi, h. a comprehensive review of technologies used for screening, assessment, and rehabilitation of autism spectrum disorder. arxiv . (2018) 2018:10986. doi: 10.48550/arxiv.1807.10986 crossref full text | google scholar 13. neeharika, ch, and riyazuddin, ym. developing an artificial intelligence based model for autism spectrum disorder detection in children. j adv res appl sci eng technol . (2023) 32:57–72. doi: 10.37934/araset.32.1.5772 crossref full text | google scholar 14. wall, dp, dally, r, luyster, r, jung, j-y, and deluca, tf. use of artificial intelligence to shorten the behavioral diagnosis of autism. plos one . (2012) 7:e43855. doi: 10.1371/journal.pone.0043855 pubmed abstract | crossref full text | google scholar 15. alzakari, sa, allinjawi, a, aldrees, a, zamzami, n, umer, m, innab, n, et al. early detection of autism spectrum disorder using explainable ai and optimized teaching strategies. j neurosci methods . (2025) 413:110315. doi: 10.1016/j.jneumeth.2024.110315 pubmed abstract | crossref full text | google scholar 16. heunis, t, aldrich, c, peters, j, jeste, s, sahin, m, scheffer, c, et al. recurrence quantification analysis of resting state eeg signals in autism spectrum disorder—a systematic methodological exploration of technical and demographic confounders in the search for biomarkers. bmc med . (2018) 16:101. doi: 10.1186/s12916-018-1086-7 crossref full text | google scholar 17. vicnesh, j, wei, jke, oh, sl, arunkumar, n, abdulhay, e, ciaccio, ej, et al. autism spectrum disorder diagnostic system using hos bispectrum with eeg signals. int j environ res public health . (2020) 17:971. doi: 10.3390/ijerph17030971 crossref full text | google scholar 18. novielli, p, romano, d, magarelli, m, diacono, d, monaco, a, amoroso, n, et al. personalized identification of autism-related bacteria in the gut microbiome using explainable artificial intelligence. iscience . (2024) 27:110709. doi: 10.1016/j.isci.2024.110709 pubmed abstract | crossref full text | google scholar 19. bosl, wj, tager-flusberg, h, and nelson, ca. eeg analytics for early detection of autism spectrum disorder: a data-driven approach. sci rep . (2018) 8:1–20. doi: 10.1038/s41598-018-24318-x pubmed abstract | crossref full text | google scholar 20. beykikhoshk, a, arandjelović, o, phung, d, venkatesh, s, and caelli, t. using twitter to learn about the autism community. soc netw anal min . (2015) 5:261. doi: 10.1007/s13278-015-0261- crossref full text | google scholar 21. mazurek, mo. social media use among adults with autism spectrum disorders. comput hum behav . (2013) 29:1709–14. doi: 10.1016/j.chb.2013.02.004 crossref full text | google scholar 22. onnela, j, and rauch, sl. harnessing smartphone-based digital phenotyping to enhance behavioral and mental health. neuropsychopharmacology . (2016) 41:1691–6. doi: 10.1038/npp.2016.7.npp20167 pubmed abstract | crossref full text | google scholar 23. tomeny, ts, vargo, cj, and el-toukhy, s. geographic and demographic correlates of autism-related anti-vaccine beliefs on twitter, 2009–2015. soc sci med . (2017) 191:168–75. doi: 10.1016/j.socscimed.2017.08.041 pubmed abstract | crossref full text | google scholar 24. tárraga-mínguez, r, gómez-marí, i, and sanz-cervera, p. what motivates internet users to search for asperger syndrome and autism on google? int j environ res public health . (2020) 17:9386. doi: 10.3390/ijerph17249386 pubmed abstract | crossref full text | google scholar 25. hartwell, m, keener, a, coffey, s, chesher, t, torgerson, t, and vassar, m. brief report: public awareness of asperger syndrome following greta thunberg appearances. j autism dev disord . (2020) 51:2104–8. doi: 10.1007/s10803-020-04651-9 pubmed abstract | crossref full text | google scholar 26. rubio-martín, s, garcía-ordás, mt, bayón-gutiérrez, m, prieto-fernández, n, and benítez-andrades, ja. “ early detection of autism spectrum disorder through ai-powered analysis of social media texts ,” 2023 ieee 36th international symposium on computer-based medical systems (cbms), l’aquila, italy, pp. 235–240. (2023). google scholar 27. jaiswal, a, and washington, p. using #actuallyautistic on twitter for precision diagnosis of autism spectrum disorder: machine learning study. jmir form res . (2024) 8:e52660. doi: 10.2196/52660 crossref full text | google scholar keywords: autism spectrum disorders, diagnosing, social media, deep learning, disabilities, artificial intelligence citation: farhah ns, alqarni aa, ebrahim n and ahmad s (2025) diagnosing autism spectrum disorders using a double deep q-network framework based on social media footprints. front. med . 12:1646249. doi: 10.3389/fmed.2025.1646249 received: 16 june 2025; accepted: 28 july 2025; published: 20 august 2025. edited by: pardeep sangwan , maharaja surajmal institute of technology, india reviewed by: jia-bao liu , anhui jianzhu university, china muhammad adnan , kohat university of science and technology, pakistan copyright © 2025 farhah, alqarni, ebrahim and ahmad. this is an open-access article distributed under the terms of the creative commons attribution license (cc by) . the use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. no use, distribution or reproduction is permitted which does not comply with these terms. *correspondence: nesren s. farhah, bi5myxjoywhac2v1lmvkds5zyq== ; nadhem ebrahim, bmvicmfoaw1adwfrcm9ulmvkdq== ; sultan ahmad, cy5hbglzagvyqhbzyxuuzwr1lnnh disclaimer: all claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. any product that may be evaluated in this article or claim that may be made by its manufacturer is not guaranteed or endorsed by the publisher. download article download pdf readcube epub xml share on export citation endnote reference manager simple text file bibtex 1,193 total views 132 downloads citation numbers are available from dimensions view article impact view altmetric score share on edited by p s pardeep sangwan reviewed by j l jia-bao liu m a muhammad adnan table of contents abstract 1 introduction 2 materials and methods 3 performance of the framework 4 experiment and discussion results 5 conclusion data availability statement ethics statement author contributions funding conflict of interest generative ai statement publisher’s note references export citation endnote reference manager simple text file bibtex check for updates frontiers' impact articles published with frontiers have received 12 million total citations your research is the real superpower - learn how we maximise its impact through our leading community journals explore our impact metrics supplementary material download article download download pdf readcube epub xml guidelines author guidelines services for authors policies and publication ethics editor guidelines fee policy explore articles research topics journals how we publish outreach frontiers forum frontiers policy labs frontiers for young minds frontiers planet prize connect help center emails and alerts contact us submit career opportunities follow us © 2025 frontiers media s.a. all rights reserved privacy policy | terms and conditions [["shallowreactive",1],{"data":2,"state":4,"once":10,"_errors":11,"serverrendered":13,"path":14,"pinia":15},["shallowreactive",3],{},["reactive",5],{"$ssite-config":6},{"env":7,"name":8,"url":9},"production","frontiers articles","https://article-pages-2024.frontiersin.org/",["set"],["shallowreactive",12],{},true,"/journals/medicine/articles/10.3389/fmed.2025.1646249/full",["reactive",16],{"main":17,"user":514,"article":515,"articlehub":766,"mainheader":770},{"ibar":18,"footer":268,"newslettercomponent":-1,"snackbaritem":350,"toggleshowsnackbar":351,"contentfuljournal":352,"graphjournal":416,"settingsfeaturesswitchers":420,"templatetogglebanner":421,"tenantconfig":479},{"tenantlogo":19,"journallogo":19,"aboutus":20,"submiturl":113,"showsubmitbutton":13,"journal":114,"sectionterm":199,"aboutjournal":200,"mainlinks":249,"journallinks":256,"helpcenterlink":265},"",[21,38,47,71,87],{"title":22,"links":23},"who we are",[24,29,32,35],{"text":25,"url":26,"target":27,"arialabel":28},"mission and values","https://www.frontiersin.org/about/mission","_self",null,{"text":30,"url":31,"target":27,"arialabel":28},"history","https://www.frontiersin.org/about/history",{"text":33,"url":34,"target":27,"arialabel":28},"leadership","https://www.frontiersin.org/about/leadership",{"text":36,"url":37,"target":27,"arialabel":28},"awards","https://www.frontiersin.org/about/awards",{"title":39,"links":40},"impact and progress",[41,44],{"text":42,"url":43,"target":27,"arialabel":28},"frontiers' impact","https://www.frontiersin.org/about/impact",{"text":45,"url":46,"target":27,"arialabel":28},"our annual reports","https://www.frontiersin.org/about/annual-reports",{"title":48,"links":49},"publishing model",[50,53,56,59,62,65,68],{"text":51,"url":52,"target":27,"arialabel":28},"how we publish","https://www.frontiersin.org/about/how-we-publish",{"text":54,"url":55,"target":27,"arialabel":28},"open access","https://www.frontiersin.org/about/open-access",{"text":57,"url":58,"target":27,"arialabel":28},"peer review","https://www.frontiersin.org/about/peer-review",{"text":60,"url":61,"target":27,"arialabel":28},"research integrity","https://www.frontiersin.org/about/research-integrity",{"text":63,"url":64,"target":27,"arialabel":28},"research topics","https://www.frontiersin.org/about/research-topics",{"text":66,"url":67,"target":27,"arialabel":28},"fair² data management","https://www.frontiersin.org/about/fair-data-management",{"text":69,"url":70,"target":27,"arialabel":28},"fee policy","https://www.frontiersin.org/about/fee-policy",{"title":72,"links":73},"services",[74,78,81,84],{"text":75,"url":76,"target":77,"arialabel":28},"societies","https://publishingpartnerships.frontiersin.org/","_blank",{"text":79,"url":80,"target":27,"arialabel":28},"national consortia","https://www.frontiersin.org/open-access-agreements/consortia",{"text":82,"url":83,"target":27,"arialabel":28},"institutional partnerships","https://www.frontiersin.org/about/open-access-agreements",{"text":85,"url":86,"target":27,"arialabel":28},"collaborators","https://www.frontiersin.org/about/collaborators",{"title":88,"links":89},"more from frontiers",[90,94,97,101,105,109],{"text":91,"url":92,"target":77,"arialabel":93},"frontiers forum","https://forum.frontiersin.org/","this link will take you to the frontiers forum website",{"text":95,"url":96,"target":27,"arialabel":28},"frontiers planet prize","https://www.frontiersin.org/about/frontiers-planet-prize",{"text":98,"url":99,"target":77,"arialabel":100},"press office","https://pressoffice.frontiersin.org/","this link will take you to the frontiers press office website",{"text":102,"url":103,"target":27,"arialabel":104},"sustainability","https://www.frontiersin.org/about/sustainability","link to information about frontiers' sustainability",{"text":106,"url":107,"target":77,"arialabel":108},"career opportunities","https://careers.frontiersin.org/","this link will take you to the frontiers careers website",{"text":110,"url":111,"target":27,"arialabel":112},"contact us","https://www.frontiersin.org/about/contact","this link will take you to the help pages to contact our support team","https://www.frontiersin.org/submission/submit?domainid=2&fieldid=39&specialtyid=0&entitytype=2&entityid=602",{"id":115,"name":116,"slug":117,"sections":118},602,"frontiers in medicine","medicine",[119,123,127,131,135,139,143,147,151,155,159,163,167,171,175,179,183,187,191,195],{"id":120,"name":121,"slug":122},797,"dermatology","dermatology",{"id":124,"name":125,"slug":126},842,"family medicine and primary care","family-medicine-and-primary-care",{"id":128,"name":129,"slug":130},681,"gastroenterology","gastroenterology",{"id":132,"name":133,"slug":134},1321,"gene and cell therapy","gene-and-cell-therapy",{"id":136,"name":137,"slug":138},790,"geriatric medicine","geriatric-medicine",{"id":140,"name":141,"slug":142},1969,"healthcare professions education","healthcare-professions-education",{"id":144,"name":145,"slug":146},752,"hematology","hematology",{"id":148,"name":149,"slug":150},3648,"hepatobiliary diseases","hepatobiliary-diseases",{"id":152,"name":153,"slug":154},3379,"infectious diseases: pathogenesis and therapy","infectious-diseases-pathogenesis-and-therapy",{"id":156,"name":157,"slug":158},1139,"intensive care medicine and anesthesiology","intensive-care-medicine-and-anesthesiology",{"id":160,"name":161,"slug":162},768,"nephrology","nephrology",{"id":164,"name":165,"slug":166},815,"nuclear medicine","nuclear-medicine",{"id":168,"name":169,"slug":170},2526,"obstetrics and gynecology","obstetrics-and-gynecology",{"id":172,"name":173,"slug":174},1635,"ophthalmology","ophthalmology",{"id":176,"name":177,"slug":178},618,"pathology","pathology",{"id":180,"name":181,"slug":182},1307,"precision medicine","precision-medicine",{"id":184,"name":185,"slug":186},678,"pulmonary medicine","pulmonary-medicine",{"id":188,"name":189,"slug":190},1306,"regulatory science","regulatory-science",{"id":192,"name":193,"slug":194},662,"rheumatology","rheumatology",{"id":196,"name":197,"slug":198},1318,"translational medicine","translational-medicine","sections",[201,225],{"title":202,"links":203},"scope",[204,207,210,213,216,219,222],{"text":205,"url":206,"target":27,"arialabel":28},"field chief editors","https://www.frontiersin.org/journals/medicine/about#about-editors",{"text":208,"url":209,"target":27,"arialabel":28},"mission & scope","https://www.frontiersin.org/journals/medicine/about#about-scope",{"text":211,"url":212,"target":27,"arialabel":28},"facts","https://www.frontiersin.org/journals/medicine/about#about-facts",{"text":214,"url":215,"target":27,"arialabel":28},"journal sections","https://www.frontiersin.org/journals/medicine/about#about-submission",{"text":217,"url":218,"target":27,"arialabel":28},"open access statement","https://www.frontiersin.org/journals/medicine/about#about-open",{"text":220,"url":221,"target":27,"arialabel":28},"copyright statement","https://www.frontiersin.org/journals/medicine/about#copyright-statement",{"text":223,"url":224,"target":27,"arialabel":28},"quality","https://www.frontiersin.org/journals/medicine/about#about-quality",{"title":226,"links":227},"for authors",[228,231,234,237,240,243,246],{"text":229,"url":230,"target":27,"arialabel":28},"why submit?","https://www.frontiersin.org/journals/medicine/for-authors/why-submit",{"text":232,"url":233,"target":27,"arialabel":28},"article types","https://www.frontiersin.org/journals/medicine/for-authors/article-types",{"text":235,"url":236,"target":27,"arialabel":28},"author guidelines","https://www.frontiersin.org/journals/medicine/for-authors/author-guidelines",{"text":238,"url":239,"target":27,"arialabel":28},"editor guidelines","https://www.frontiersin.org/journals/medicine/for-authors/editor-guidelines",{"text":241,"url":242,"target":27,"arialabel":28},"publishing fees","https://www.frontiersin.org/journals/medicine/for-authors/publishing-fees",{"text":244,"url":245,"target":27,"arialabel":28},"submission checklist","https://www.frontiersin.org/journals/medicine/for-authors/submission-checklist",{"text":247,"url":248,"target":27,"arialabel":28},"contact editorial office","https://www.frontiersin.org/journals/medicine/for-authors/contact-editorial-office",[250,253],{"text":251,"url":252,"target":27,"arialabel":28},"all journals","https://www.frontiersin.org/journals",{"text":254,"url":255,"target":27,"arialabel":28},"all articles","https://www.frontiersin.org/articles",[257,260,262],{"text":258,"url":259,"target":27,"arialabel":28},"articles","articles",{"text":63,"url":261,"target":27,"arialabel":28},"research-topics",{"text":263,"url":264,"target":27,"arialabel":28},"editorial board","editors",{"text":266,"url":267,"target":77,"arialabel":266},"help center","https://helpcenter.frontiersin.org",{"blocks":269,"sociallinks":323,"copyright":347,"termsandconditionsurl":348,"privacypolicyurl":349},[270,284,294,308],{"title":271,"links":272},"guidelines",[273,275,278,281,283],{"text":235,"url":274,"target":27,"arialabel":28},"https://www.frontiersin.org/guidelines/author-guidelines",{"text":276,"url":277,"target":27,"arialabel":28},"services for authors","https://www.frontiersin.org/for-authors/author-services",{"text":279,"url":280,"target":27,"arialabel":28},"policies and publication ethics","https://www.frontiersin.org/guidelines/policies-and-publication-ethics",{"text":238,"url":282,"target":27,"arialabel":28},"https://www.frontiersin.org/guidelines/editor-guidelines",{"text":69,"url":70,"target":27,"arialabel":28},{"title":285,"links":286},"explore",[287,288,291,293],{"text":258,"url":255,"target":27,"arialabel":28},{"text":289,"url":290,"target":27,"arialabel":28},"research topics ","https://www.frontiersin.org/research-topics",{"text":292,"url":252,"target":27,"arialabel":28},"journals",{"text":51,"url":52,"target":27,"arialabel":28},{"title":295,"links":296},"outreach",[297,300,303,307],{"text":298,"url":92,"target":77,"arialabel":299},"frontiers forum ","frontiers forum website",{"text":301,"url":302,"target":77,"arialabel":28},"frontiers policy labs ","https://policylabs.frontiersin.org/",{"text":304,"url":305,"target":77,"arialabel":306},"frontiers for young minds","https://kids.frontiersin.org/","frontiers for young minds journal",{"text":95,"url":96,"target":27,"arialabel":28},{"title":309,"links":310},"connect",[311,312,316,319,322],{"text":266,"url":267,"target":77,"arialabel":266},{"text":313,"url":314,"target":77,"arialabel":315},"emails and alerts ","https://subscription-management.frontiersin.org/emails/preferences#block0","subscribe to frontiers emails",{"text":317,"url":111,"target":27,"arialabel":318},"contact us ","subscribe to newsletter",{"text":320,"url":321,"target":27,"arialabel":28},"submit","https://www.frontiersin.org/submission/submit",{"text":106,"url":107,"target":77,"arialabel":28},[324,332,337,342],{"link":325,"type":328,"color":329,"icon":330,"size":331,"hiddentext":13},{"text":326,"url":327,"target":77,"arialabel":326},"frontiers facebook","https://www.facebook.com/frontiersin","link","grey","facebook","medium",{"link":333,"type":328,"color":329,"icon":336,"size":331,"hiddentext":13},{"text":334,"url":335,"target":77,"arialabel":28},"frontiers twitter","https://twitter.com/frontiersin","twitter",{"link":338,"type":328,"color":329,"icon":341,"size":331,"hiddentext":13},{"text":339,"url":340,"target":77,"arialabel":28},"frontiers linkedin","https://www.linkedin.com/company/frontiers","linkedin",{"link":343,"type":328,"color":329,"icon":346,"size":331,"hiddentext":13},{"text":344,"url":345,"target":77,"arialabel":28},"frontiers instagram","https://www.instagram.com/frontiersin_","instagram","frontiers media s.a. all rights reserved","https://www.frontiersin.org/legal/terms-and-conditions","https://www.frontiersin.org/legal/privacy-policy",{},false,{"__typename":353,"identifier":115,"name":116,"slug":117,"banner":354,"description":409,"mission":410,"palette":411,"impactfactor":412,"citescore":413,"citations":414,"showtagline":28,"twitter":415},"journal",[355],{"id":356,"src":357,"name":358,"tags":359,"type":367,"width":368,"height":369,"idhash":370,"archive":371,"brandid":372,"limited":371,"filesize":373,"ispublic":374,"original":375,"copyright":376,"extension":377,"thumbnails":379,"datecreated":387,"description":388,"orientation":389,"usercreated":390,"watermarked":371,"datemodified":387,"datepublished":391,"ecsarchivefiles":392,"propertyoptions":393,"property_channel":398,"property_sub-type":400,"property_asset_type":402,"activeoriginalfocuspoint":404,"property_office_department":407},"3501f557-cafa-4218-930c20d1d930c78c","https://d2csxpduxe849s.cloudfront.net/media/e32629c6-9347-4f84-81feaef7bfa342b3/3501f557-cafa-4218-930c20d1d930c78c/webimage-5988957c-0534-4338-984381d67214c0af.png","fmed_main visual_purple_website",[360,361,362,363,364,365,366],"professional","medical","research","biotechnology","scientific","analy","lab","image",7360,4912,"67388dad93685635",0,"22c10171-81b3-4da6-99342f272a32e8bb",13595017,1,"https://brand.frontiersin.org/m/67388dad93685635/original/fmed_main-visual_purple_website.jpg","copyright (c) 2018 rosshelen/shutterstock. no use without permission.",[378],"jpg",{"mini":380,"thul":381,"webimage":357,"guidelines":382,"websitejpg_xl":383,"websitewebp_l":384,"websitewebp_m":385,"websitewebp_xl":386},"https://d2csxpduxe849s.cloudfront.net/media/e32629c6-9347-4f84-81feaef7bfa342b3/3501f557-cafa-4218-930c20d1d930c78c/mini-4ebc2476-6efb-4a3e-a669185b307fef72.png","https://d2csxpduxe849s.cloudfront.net/media/e32629c6-9347-4f84-81feaef7bfa342b3/3501f557-cafa-4218-930c20d1d930c78c/thul-78bd9351-8a86-4c7b-874fc1cc5caa92ce.png","https://d2csxpduxe849s.cloudfront.net/media/e32629c6-9347-4f84-81feaef7bfa342b3/3501f557-cafa-4218-930c20d1d930c78c/f6ff788e-26d5-4bc5-8cb92ee85a59ca4a/guidelines-fmed_main visual_purple_website.png","https://d2csxpduxe849s.cloudfront.net/media/e32629c6-9347-4f84-81feaef7bfa342b3/3501f557-cafa-4218-930c20d1d930c78c/f6ff788e-26d5-4bc5-8cb92ee85a59ca4a/websitejpg_xl-fmed_main visual_purple_website.jpg","https://d2csxpduxe849s.cloudfront.net/media/e32629c6-9347-4f84-81feaef7bfa342b3/3501f557-cafa-4218-930c20d1d930c78c/f6ff788e-26d5-4bc5-8cb92ee85a59ca4a/websitewebp_l-fmed_main visual_purple_website.webp","https://d2csxpduxe849s.cloudfront.net/media/e32629c6-9347-4f84-81feaef7bfa342b3/3501f557-cafa-4218-930c20d1d930c78c/f6ff788e-26d5-4bc5-8cb92ee85a59ca4a/websitewebp_m-fmed_main visual_purple_website.webp","https://d2csxpduxe849s.cloudfront.net/media/e32629c6-9347-4f84-81feaef7bfa342b3/3501f557-cafa-4218-930c20d1d930c78c/f6ff788e-26d5-4bc5-8cb92ee85a59ca4a/websitewebp_xl-fmed_main visual_purple_website.webp","2022-06-27t10:00:04z","laboratory assistant putting test tubes into the holder, close-up view focused on the tubes","landscape","caroline sutter","2022-06-27t09:27:09z",[],[394,395,396,397],"414fb2d4-2283-43fd-be14e534eca67928","6c18119b-14bd-4951-b437696f4357bd33","7c692885-db25-4858-b1fb4ff47b241e9b","d88c0047-ec30-4506-a7df28a4d765e1cf",[399],"frontiersin_org",[401],"main_visual",[403],"photography",{"x":405,"y":406},3680,2456,[408],"publishing","a highly cited multidisciplinary journal which advances our medical knowledge. it supports the translation of scientific advances into new therapies and diagnostic tools that will improve patient care.","\u003cp>frontiers in medicine is a broad-scope, multidisciplinary journal covering all established medical disciplines to improve clinical practice and patient care.\u003c/p>\n\n\u003cp>led by field chief editor prof michel goldman (université libre de bruxelles, belgium), frontiers in medicine is indexed in pubmed central (pmc), web of science (scie), and scopus, among others, and welcomes basic and clinical medical research that facilitate the translation of scientific advances into new therapies or diagnostic tools. topics include, but are not limited to:\u003c/p>\n\n\u003cul>\n \u003cli>dermatology\u003c/li>\n \u003cli>family medicine and primary care\u003c/li>\n \u003cli>gastroenterology\u003c/li>\n \u003cli>gene and cell therapy\u003c/li>\n \u003cli>geriatric medicine\u003c/li>\n \u003cli>healthcare professions education\u003c/li>\n \u003cli>hematology\u003c/li>\n \u003cli>hepatobiliary diseases\u003c/li>\n \u003cli>infectious diseases: pathogenesis and therapy\u003c/li>\n \u003cli>intensive care medicine and anesthesiology\u003c/li>\n \u003cli>nephrology\u003c/li>\n \u003cli>nuclear medicine\u003c/li>\n \u003cli>obstetrics and gynecology\u003c/li>\n \u003cli>ophthalmology\u003c/li>\n \u003cli>pathology\u003c/li>\n \u003cli>precision medicine\u003c/li>\n \u003cli>pulmonary medicine\u003c/li>\n \u003cli>regulatory science\u003c/li>\n \u003cli>rheumatology\u003c/li>\n \u003cli>translational medicine.\u003c/li>\n\u003c/ul>\n\n\u003cp>in addition to papers that provide a link between basic research and clinical practice, a particular emphasis is given to studies that are directly relevant to patient care.\u003c/p>\n\n\u003cp>as well as the established medical disciplines, frontiers in medicine aims to publish research that will facilitate:\u003c/p>\n\n\u003cul>\n \u003cli>access to medicinal products and medical devices worldwide\u003c/li>\n \u003cli>addressing the grand health challenges around the world\u003c/li>\n \u003cli>the exploitation of big data and the use of novel information and communication tools in the assessment of new medicines\u003c/li>\n \u003cli>the scientific bases for guidelines and decisions from regulatory authorities\u003c/li>\n \u003cli>the use of patient-reported outcomes under real world conditions.\u003c/li>\n\u003c/ul>\n\n\u003cp>all studies must contribute insights into the field of medicine. papers which do not primarily focus on a medical discipline are not suitable for publication in this journal. manuscripts that focus solely on the molecular or cellular mechanisms of diseases without a foundation in clinical medicine are not suitable for publication in this journal. similarly, studies that are purely descriptive or observational, without a clear hypothesis or mechanistic investigation, are not within the scope of this journal. research that is primarily epidemiological or public health-oriented, without a foundation in the pathophysiology or treatment of disease, is also not appropriate for this journal.\u003c/p>\n\n\u003cp>frontiers’ journals require that manuscripts primarily comprising computational studies of public data, must include appropriate validation. please refer to the \u003ca href=\"https://www.frontiersin.org/guidelines/policies-and-publication-ethics#standards-for-research-methodology:~:text=complaints%20and%20allegations.-,standards%20for%20research%20methodology,-experiments\">frontiers standards for research methodology policy\u003c/a>, for more information. manuscripts not adhering to these standards will not be considered.\u003cp>\n\n\u003cp>frontiers in medicine is committed to advancing developments in the field of medicine by allowing unrestricted access to articles and communicating scientific knowledge to researchers and the public alike, to enable the scientific breakthroughs of the future.\u003c/p>\n\n\u003cp>ethics statement:\u003c/p>\n\n\u003cp>all manuscripts submitted to frontiers in medicine that have been conducted in human subjects must conform with current regulations and the declaration of helsinki. ethics committee approval and informed patient consent are required for studies involving human subjects. ethics committee approval is also needed for studies involving animals. phase i - phase iv clinical trials submitted for publication in frontiers in medicine must have been registered with an appropriate public trials registry at the time or before the first patient enrolment. the information on the clinical trial registration (unique identifier and url) must be included in the abstract. authors are required to disclose all apparent or potential conflicts of interest according to the icmje guidelines and those of frontiers.\u003c/p>\n\n\u003cp>frontiers endeavors to follow the guidelines and best practice recommendations published by the committee on publication ethics (cope). authors should refer to the author guidelines for full details.\u003c/p>","purple","3.9","3.6","176752","@frontmedicine",{"id":115,"name":116,"slug":117,"abbreviation":417,"isonline":13,"isopenforsubmissions":13,"citescore":418,"impactfactor":419},"fmed",6,3,{"displaytitlepilllabels":13,"displayrelatedarticlesbox":13,"showeditors":13,"showreviewers":13,"showloopimpactlink":13,"enablefigshare":351,"usexmlimages":13},{"ispublic":13,"allowcompanyusers":351,"whitelistemails":422,"enablealljournals":13,"whitelistjournals":444},[423,424,425,426,427,428,429,430,431,428,432,433,434,435,436,437,438,439,440,441,442,443],"y2fybg9zlmxvcmnhqgzyb250awvyc2lulm9yzw==","zgfuawvslmx1ekbmcm9udgllcnnpbi5vcmc=","bgf1cmeudgvuyubmcm9udgllcnnpbi5vcmc=","cmfmywvslnjpyw5jag9aznjvbnrpzxjzaw4ub3jn","amftzxmuc21hbgxib25lqgzyb250awvyc2lulm9yzw==","znjhbi5tb3jlbm9aznjvbnrpzxjzaw4ub3jn","c2ftdwvslmzlcm5hbmrlekbmcm9udgllcnnpbi5vcmc=","ymfyymfyys5jyxjjyw5naxvaznjvbnrpzxjzaw4ub3jn","axzhbi5zyw50yw1hcmlhqgzyb250awvyc2lulm9yzw==","ahvllnryyw5aznjvbnrpzxjzaw4ub3jn","z29uy2fsby52yxjnyxnaznjvbnrpzxjzaw4ub3jn","bhvjawuuc2vubkbmcm9udgllcnnpbi5vcmc=","bg9ybi5mcmfzzxjaznjvbnrpzxjzaw4ub3jn","zwxzys5jyxjyb25aznjvbnrpzxjzaw4ub3jn","bwfhcnrlbi52yw5kawpja0bmcm9udgllcnnpbi5vcmc=","ymluzgh1lmtyaxnobmfuqgzyb250awvyc2lulm9yzw==","bwf0dghldy5hdhr3yxrlcnnaznjvbnrpzxjzaw4ub3jn","z2l1bglhlnzhbhnly2noaubmcm9udgllcnnpbi5vcmc=","zmfiawfulmrlbgxhbw9ydgvaznjvbnrpzxjzaw4ub3jn","dmlqyxlhbi5wcebwaxrzb2x1dglvbnmuy29t","z3vpbgxhdw1llnnldxjhdebmcm9udgllcnnpbi5vcmc=",[445,446,447,406,448,449,374,450,115,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478],2232,1729,2357,2176,2333,1843,106,616,310,657,3123,1468,2137,628,1566,2726,2086,1490,451,141,1335,2655,1238,604,698,1547,176,1440,403,1239,755,2136,609,1534,{"spaceid":374,"name":374,"availablejournalpages":480,"announcement":484},[259,264,261,481,482,483],"volumes","about","community-reviewers",{"__typename":485,"sys":486,"preheader":42,"title":488,"description":489,"image":490,"link":512},"announcement",{"id":487},"5ittnttqgazppgh6rx0alm","articles published with frontiers have received 12 million total citations","your research is the real superpower - learn how we maximise its impact through our leading community journals",[491],{"archive":371,"brandid":372,"copyright":28,"datecreated":492,"datemodified":493,"datepublished":494,"description":28,"extension":495,"filesize":497,"height":498,"id":499,"ispublic":371,"limited":371,"name":500,"orientation":389,"original":28,"thumbnails":501,"type":367,"watermarked":371,"width":508,"videopreviewurls":509,"tags":510,"textmetaproperties":511,"src":502},"2025-06-18t12:58:01z","2025-06-18t14:15:34z","2025-06-18t12:57:32z",[496],"png",1365026,920,"7c5269c4-3c83-4591-951a74d15b95daea","impact metrics banner for article pages",{"webimage":502,"thul":503,"mini":504,"websitewebp_l":505,"websitewebp_m":506,"guidelines":507},"https://brand.frontiersin.org/m/59ee6275cb9a849c/webimage-impact-metrics-banner-for-article-pages.png","https://brand.frontiersin.org/m/59ee6275cb9a849c/thul-impact-metrics-banner-for-article-pages.png","https://brand.frontiersin.org/m/59ee6275cb9a849c/mini-impact-metrics-banner-for-article-pages.png","https://brand.frontiersin.org/asset/7c5269c4-3c83-4591-951a-74d15b95daea/websitewebp_l/impact-metrics-banner-for-article-pages.webp","https://brand.frontiersin.org/asset/7c5269c4-3c83-4591-951a-74d15b95daea/websitewebp_m/impact-metrics-banner-for-article-pages.webp","https://brand.frontiersin.org/asset/7c5269c4-3c83-4591-951a-74d15b95daea/guidelines/impact-metrics-banner-for-article-pages.png",1600,[],[],[],{"text":513,"url":43,"target":27,"arialabel":28},"explore our impact metrics",{"loggeduserinfo":-1},{"currentarticle":516,"ispreviewpage":351,"hassupplementaldata":351,"showcrossmarkwidget":13,"articletemplate":646,"currentarticlepagemetainfo":647,"xmlparsedarticlecontent":-1,"xmlparsingerror":-1},{"id":517,"doi":518,"title":519,"acceptancedate":520,"receptiondate":521,"publicationdate":522,"lastmodifieddate":523,"ispublished":13,"abstract":524,"researchtopic":525,"articletype":531,"stage":534,"keywords":536,"authors":543,"editors":584,"reviewers":592,"journal":607,"section":615,"impactmetrics":617,"volume":620,"articlevolume":621,"relatedarticles":622,"ispublishedv2":13,"contents":623,"files":626},1646249,"10.3389/fmed.2025.1646249","diagnosing autism spectrum disorders using a double deep q-network framework based on social media footprints","2025-07-28t08:25:45.000z","2025-06-16t12:25:51.000z","2025-08-20t00:00:00.000z","2025-10-21t02:22:52.270z","introductionsocial media is increasingly used in many contexts within the healthcare sector. the improved prevalence of internet use via computers or mobile devices presents an opportunity for social media to serve as a tool for the rapid and direct distribution of essential health information. autism spectrum disorders (asd) are a comprehensive neurodevelopmental syndrome with enduring effects. twitter has become a platform for the asd community, offering substantial assistance to its members by disseminating information on their beliefs and perspectives via language and emotional expression. adults with asd have considerable social and emotional challenges, while also demonstrating abilities and interests in screen-based technologies.methodsthe novelty of this research lies in its use in the context of twitter to analyze and identify asd. this research used twitter as the primary data source to examine the behavioral traits and immediate emotional expressions of persons with asd. we applied convolutional neural networks with long short-term memory (cnn-lstm), lstm, and double deep q-network (ddqn-inspired) using a standardized dataset including 172 tweets from the asd class and 158 tweets from the non-asd class. the dataset was processed to exclude lowercase text and special characters, followed by a tokenization approach to convert the text into integer word sequences. the encoding was used to transform the classes into binary labels. following preprocessing, the proposed framework was implemented to identify asd.resultsthe findings of the ddqn-inspired model demonstrate a high precision of 87% compared to the proposed model. this finding demonstrates the potential of the proposed approach for identifying asd based on social media content.discussionultimately, the proposed system was compared against the existing system that used the same dataset. the proposed approach is based on variations in the text of social media interactions, which can assist physicians and clinicians in performing symptom studies within digital footprint environments.",{"id":526,"title":527,"articlescount":528,"ismagazinepage":351,"slug":529,"isopenforsubmission":351,"views":530},69516,"ai innovations in neuroimaging: transforming brain analysis",10,"ai-innovations-in-neuroimaging-transforming-brain-analysis",16647,{"id":532,"name":533},24,"original research",{"id":535,"name":19},18,[537,538,539,540,541,542],"artificial intelligence","deep learning","social media","disabilities","autism spectrum disorders","diagnosing",[544,555,564,573],{"id":545,"firstname":546,"middlename":19,"lastname":547,"givennames":548,"iscorresponding":351,"isprofilepublic":13,"userid":545,"email":-1,"affiliations":549},2586659,"nesren s.","farhah","nesren s. ",[550,553],{"organizationname":551,"countryname":552,"cityname":19,"statename":19,"zipcode":19},"department of health informatics, college of health science, saudi electronic university","saudi arabia",{"organizationname":554,"countryname":552,"cityname":19,"statename":19,"zipcode":19},"king salman center for disability research",{"id":556,"firstname":557,"middlename":19,"lastname":558,"givennames":559,"iscorresponding":351,"isprofilepublic":13,"userid":556,"email":-1,"affiliations":560},3164796,"ahmed abdullah","alqarni","ahmed abdullah ",[561,562],{"organizationname":554,"countryname":552,"cityname":19,"statename":19,"zipcode":19},{"organizationname":563,"countryname":552,"cityname":19,"statename":19,"zipcode":19},"department of computer sciences and information technology, al-baha university",{"id":565,"firstname":566,"middlename":19,"lastname":567,"givennames":568,"iscorresponding":351,"isprofilepublic":13,"userid":565,"email":-1,"affiliations":569},3077810,"nadhem","ebrahim","nadhem ",[570],{"organizationname":571,"countryname":572,"cityname":19,"statename":19,"zipcode":19},"department of computer science, college of engineering and polymer science, university of akron","united states",{"id":574,"firstname":575,"middlename":19,"lastname":576,"givennames":577,"iscorresponding":351,"isprofilepublic":13,"userid":574,"email":-1,"affiliations":578},1762668,"sultan","ahmad","sultan ",[579,581],{"organizationname":580,"countryname":552,"cityname":19,"statename":19,"zipcode":19},"department of computer science, college of computer engineering and sciences, prince sattam bin abdulaziz university",{"organizationname":582,"countryname":583,"cityname":19,"statename":19,"zipcode":19},"school of computer science and engineering, lovely professional university","india",[585],{"id":586,"firstname":587,"middlename":19,"lastname":588,"givennames":589,"iscorresponding":351,"isprofilepublic":13,"userid":586,"email":-1,"affiliations":590},2928766,"pardeep","sangwan","pardeep ",[591],{"organizationname":19,"countryname":19,"cityname":19,"statename":19,"zipcode":19},[593,600],{"id":594,"firstname":595,"middlename":19,"lastname":596,"givennames":597,"iscorresponding":351,"isprofilepublic":13,"userid":594,"email":-1,"affiliations":598},1743107,"jia-bao","liu","jia-bao ",[599],{"organizationname":19,"countryname":19,"cityname":19,"statename":19,"zipcode":19},{"id":601,"firstname":602,"middlename":19,"lastname":603,"givennames":604,"iscorresponding":351,"isprofilepublic":13,"userid":601,"email":-1,"affiliations":605},3104897,"muhammad","adnan","muhammad ",[606],{"organizationname":19,"countryname":19,"cityname":19,"statename":19,"zipcode":19},{"id":115,"slug":117,"name":116,"shortname":608,"electronicissn":609,"field":610,"specialtyid":28,"journalsectionpaths":613},"front. med.","2296-858x",{"id":611,"domainid":612},39,2,[614],{"section":615},{"id":180,"name":181,"slug":182,"specialtyid":616},1754,{"views":618,"downloads":619,"citations":371},1193,132,12,"volume 12 - 2025",[],{"titlehtml":519,"fulltexthtml":624,"menuhtml":625},"\u003cdiv class=\"journalabstract\"> \u003ca id=\"h1\" name=\"h1\">\u003c/a>\n \u003cdiv class=\"authors\">\u003cspan class=\"author-wrapper notranslate\">\u003ca href=\"https://loop.frontiersin.org/people/2586659\" class=\"user-id-2586659\">\u003cimg class=\"pr5\" src=\"https://loop.frontiersin.org/images/profile/2586659/74\" onerror=\"this.onerror=null;this.src='https://loop.frontiersin.org/cdn/images/profile/default_32.jpg';\" alt=\"nesren s. farhah,
\">nesren s. farhah\u003c/a>\u003csup>1,2\u003c/sup>\u003csup>*\u003c/sup>\u003c/span>\u003cspan class=\"author-wrapper notranslate\">\u003ca href=\"https://loop.frontiersin.org/people/3164796\" class=\"user-id-3164796\">\u003cimg class=\"pr5\" src=\"https://loop.frontiersin.org/images/profile/3164796/74\" onerror=\"this.onerror=null;this.src='https://loop.frontiersin.org/cdn/images/profile/default_32.jpg';\" alt=\"ahmed abdullah alqarni,\">ahmed abdullah alqarni\u003c/a>\u003csup>2,3\u003c/sup>\u003c/span>\u003cspan class=\"author-wrapper notranslate\">\u003ca href=\"https://loop.frontiersin.org/people/3077810\" class=\"user-id-3077810\">\u003cimg class=\"pr5\" src=\"https://loop.frontiersin.org/images/profile/3077810/74\" onerror=\"this.onerror=null;this.src='https://loop.frontiersin.org/cdn/images/profile/default_32.jpg';\" alt=\"nadhem ebrahim
\">nadhem ebrahim\u003c/a>\u003csup>4\u003c/sup>\u003csup>*\u003c/sup>\u003c/span>\u003cspan class=\"author-wrapper notranslate\">\u003ca href=\"https://loop.frontiersin.org/people/1762668\" class=\"user-id-1762668\">\u003cimg class=\"pr5\" src=\"https://loop.frontiersin.org/images/profile/1762668/74\" onerror=\"this.onerror=null;this.src='https://loop.frontiersin.org/cdn/images/profile/default_32.jpg';\" alt=\"sultan ahmad,
\">sultan ahmad\u003c/a>\u003csup>5,6\u003c/sup>\u003csup>*\u003c/sup>\u003c/span>\u003c/div> \u003cul class=\"notes\"> \u003cli>\u003cspan>\u003csup>1\u003c/sup>\u003c/span>department of health informatics, college of health science, saudi electronic university, riyadh, saudi arabia\u003c/li> \u003cli>\u003cspan>\u003csup>2\u003c/sup>\u003c/span>king salman center for disability research, riyadh, saudi arabia\u003c/li> \u003cli>\u003cspan>\u003csup>3\u003c/sup>\u003c/span>department of computer sciences and information technology, al-baha university, al-baha, saudi arabia\u003c/li> \u003cli>\u003cspan>\u003csup>4\u003c/sup>\u003c/span>department of computer science, college of engineering and polymer science, university of akron, oh, united states\u003c/li> \u003cli>\u003cspan>\u003csup>5\u003c/sup>\u003c/span>department of computer science, college of computer engineering and sciences, prince sattam bin abdulaziz university, al-kharj, saudi arabia\u003c/li> \u003cli>\u003cspan>\u003csup>6\u003c/sup>\u003c/span>school of computer science and engineering, lovely professional university, phagwara, india\u003c/li> \u003c/ul>\n\u003cp class=\"mb15\">\u003cb>introduction:\u003c/b> social media is increasingly used in many contexts within the healthcare sector. the improved prevalence of internet use via computers or mobile devices presents an opportunity for social media to serve as a tool for the rapid and direct distribution of essential health information. autism spectrum disorders (asd) are a comprehensive neurodevelopmental syndrome with enduring effects. twitter has become a platform for the asd community, offering substantial assistance to its members by disseminating information on their beliefs and perspectives via language and emotional expression. adults with asd have considerable social and emotional challenges, while also demonstrating abilities and interests in screen-based technologies.\u003c/p>\n\u003cp class=\"mb15\">\u003cb>methods:\u003c/b> the novelty of this research lies in its use in the context of twitter to analyze and identify asd. this research used twitter as the primary data source to examine the behavioral traits and immediate emotional expressions of persons with asd. we applied convolutional neural networks with long short-term memory (cnn-lstm), lstm, and double deep q-network (ddqn-inspired) using a standardized dataset including 172 tweets from the asd class and 158 tweets from the non-asd class. the dataset was processed to exclude lowercase text and special characters, followed by a tokenization approach to convert the text into integer word sequences. the encoding was used to transform the classes into binary labels. following preprocessing, the proposed framework was implemented to identify asd.\u003c/p>\n\u003cp class=\"mb15\">\u003cb>results:\u003c/b> the findings of the ddqn-inspired model demonstrate a high precision of 87% compared to the proposed model. this finding demonstrates the potential of the proposed approach for identifying asd based on social media content.\u003c/p>\n\u003cp class=\"mb0\">\u003cb>discussion:\u003c/b> ultimately, the proposed system was compared against the existing system that used the same dataset. the proposed approach is based on variations in the text of social media interactions, which can assist physicians and clinicians in performing symptom studies within digital footprint environments.\u003c/p> \u003cdiv class=\"clear\">\u003c/div> \u003c/div> \u003cdiv class=\"journalfulltext\"> \u003ca id=\"h2\" name=\"h2\">\u003c/a>\n\u003ch2>1 introduction\u003c/h2>\n\u003cp class=\"mb0\">asd is among the most prevalent neurodevelopmental disorders. asd is often demonstrated in children by age three and is defined by impairments in social interactions and communication, repetitive sensory-motor activities, and stereotypical behavioral patterns (\u003ca href=\"#ref1\">1\u003c/a>). asd is a congenital neurodevelopmental condition characterized by symptoms that are evident in early infancy. autism, characterized by restricted interests, repetitive behaviors, and significant disparities in social communication and interaction, typically emerges during early developmental stages and presents challenges in various social functioning domains. a child with autism induces significant anxiety within the family due to several factors, including the ambiguity of the diagnosis, the intensity and persistence of the disease, and the child’s nonconformity to social norms. in opposition, social awareness of autism is markedly inadequate, often conflated with intellectual disability and seen as an incurable ailment (\u003ca href=\"#ref2\">2\u003c/a>, \u003ca href=\"#ref3\">3\u003c/a>). the asd concept is displayed in \u003ca href=\"#fig1\">figure 1\u003c/a>.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 1\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g001.jpg\" name=\"figure1\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g001.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g001.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g001.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g001.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g001.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g001.jpg\" alt=\"nine icons representing concepts related to autism and interventions. top row: discrete trial training, pivotal response training, and verbal behavior intervention. middle row: impulsiveness and aggression, preference for solitude, delayed language development. bottom row: prescription drugs during pregnancy, family history of autism, assistive technologies. each icon illustrates its concept with relevant imagery.\" id=\"fig1\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 1\u003c/b>. displays the asd concept.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb15\">content on social media, particularly videos and text disseminated by parents and caregivers, has emerged as a significant resource for facilitating the early identification of asd (\u003ca href=\"#ref4\">4\u003c/a>, \u003ca href=\"#ref5\">5\u003c/a>). social media are technological tools designed for sharing, enabling users to create networks or engage in existing ones. in that order, the pew research center identified the most popular social media sites as youtube, facebook, instagram, pinterest, linkedin, snapchat, twitter, and whatsapp (\u003ca href=\"#ref6\">6\u003c/a>). most consumers use these networks daily. this research utilizes twitter data to assess the stigmatization of autism and associated terminology, picked based on accessibility and popularity, with analysis conducted using artificial intelligence technologies (\u003ca href=\"#ref7\">7\u003c/a>).\u003c/p>\n\u003cp class=\"mb15\">conventional diagnostic methods, which primarily rely on observational and behavioral evaluations, often encounter issues with accessibility, consistency, and timeliness. recent technology breakthroughs, especially in artificial intelligence (ai), and sensor-based techniques, provide novel opportunities for improving asd identification. by developing more objective, accurate, and scalable approaches, these technologies transform diagnostic methodologies for autism spectrum disorder (asd) (\u003ca href=\"#ref8\">8\u003c/a>–\u003ca href=\"#ref10\">10\u003c/a>). one new way to study the motor patterns, attentional processes, and physiological responses linked to asd in real-time is wearable sensors, eye-tracking devices, and multimodal virtual reality settings. these technologies have the potential to give non-invasive, continuous monitoring, which might help with the early diagnosis of asd and shed light on neurological and behavioral traits that have been hard to document reliably.\u003c/p>\n\u003cp class=\"mb15\">nevertheless, advancements in contemporary research are required to substantiate their efficacy. sensor-based techniques may facilitate the identification of stereotyped behaviors and motor patterns linked to asd in realistic environments, potentially yielding data that could guide timely and customized therapies (\u003ca href=\"#ref11\">11\u003c/a>). neuroimaging and microbiome analysis further advance this technical domain by indicating neurological and biological traits specific to asd. ai-enhanced neuroimaging aids in identifying structural and functional brain connection patterns associated with asd, thereby enhancing the understanding of its neuroanatomical foundation (\u003ca href=\"#ref12\">12\u003c/a>).\u003c/p>\n\u003cp class=\"mb15\">the research conducted by neeharika and riyazuddin et al. (\u003ca href=\"#ref13\">13\u003c/a>) aimed to enhance the accuracy of asd screening by using feature selection methods in conjunction with sophisticated machine learning classifiers. their research included several datasets spanning infants, children, adolescents, and adults, enabling a thorough assessment of asd characteristics across different age demographics. authors’ use of mlp model capacity to reliably and rapidly identify asd, indicating a beneficial screening instrument suitable for various age groups, facilitating both clinical evaluations and extensive screenings. wall et al. (\u003ca href=\"#ref14\">14\u003c/a>) investigated machine learning (ml) algorithms for diagnosing asd using a standard dataset. the researchers focused on the alternating decision tree classifier to identify a limited yet efficient set of queries that optimize the diagnostic procedure. alzakari et al. (\u003ca href=\"#ref15\">15\u003c/a>) proposed a novel two-phase methodology to tackle the variability in asd features with ml approaches, including behavioral, linguistic, and physical data. the first step concentrates on identifying asd, using feature engineering methodologies and ml algorithms, including a logistic regression (lr) and support vector machine (svm) ensemble, attaining a classification with high accuracy. eeg assesses brain activity and may identify children predisposed to developing asd, hence facilitating early diagnosis. eeg data is used to compare asd and hc (\u003ca href=\"#ref16\">16\u003c/a>–\u003ca href=\"#ref18\">18\u003c/a>). in (\u003ca href=\"#ref19\">19\u003c/a>), the cnn model was used for classification after transforming the data into a two-dimensional format. while eeg may facilitate the diagnosis of asd, it is constrained by other factors, such as signal noise.\u003c/p>\n\u003cp class=\"mb15\">the research has used social media to investigate asd. however, exploiting these prevalent platforms and innovative online data sources may be feasible to enhance the comprehension of these diseases. previous research has utilized twitter data to investigate discussions on asd-related material, indicating that this subject is frequently addressed on this platform (\u003ca href=\"#ref20\">20\u003c/a>). considering the use of social media for researching asd is particularly significant, as a recent analysis indicated that around 80% of individuals with asd engage with prominent social media platforms (\u003ca href=\"#ref21\">21\u003c/a>). this study aims to build upon previous research and enhance our comprehension of whether publicly accessible social media data from twitter may provide insights into the existence of digital diagnostic indicators for asd (\u003ca href=\"#ref22\">22\u003c/a>). furthermore, we want to assess the viability of establishing a digital phenotype for asd using social media.\u003c/p>\n\u003cp class=\"mb0\">beykikhoshk et al. (\u003ca href=\"#ref20\">20\u003c/a>) examined twitter’s potential as a data-mining tool to comprehend the actions, challenges, and requirements of autistic individuals. the first finding pertained to the attributes of participants inside the autism subgroup of tweets, indicating that these tweets were highly informative and had considerable potential usefulness for public health experts and policymakers. tomeny et al. (\u003ca href=\"#ref23\">23\u003c/a>) examined demographic correlations of autism-related anti-vaccine opinions on twitter from 2009 to 2015. their results indicated that the frequency of autism-related anti-vaccine views online was alarming, with anti-vaccine tweets connecting with news events and demonstrating geographical clustering. from 2015 to 2019, tárraga-mínguez et al. (\u003ca href=\"#ref24\">24\u003c/a>) examined the phrases “autism” and “asperger” in spain in relation to google search peaks. the public view of autism was significantly impacted by how the condition was portrayed in the news and on social media, and the authors found that social marketing campaigns had a significant role in normalizing autism. in this research (\u003ca href=\"#ref25\">25\u003c/a>), looked at how people sought assistance. the results showed a strong correlation in google search interest between the terms “asperger syndrome” and “greta thunberg,” reaching their highest point in 2019. online traffic to the asperger/autism network and autism speaks websites increased steadily from june to december 2019, indicating a correlation between help-seeking behavior and thunberg’s fame, according to the research. according to the results, the stigma associated with asperger’s disorder may have been positively affected by thunberg’s public exposure.\u003c/p>\n\u003ch3>1.1 contribution\u003c/h3>\n\u003cp class=\"mb0\">the use of tweets from twitter for the detection of asd is substantial, since it offers extensive, real-time, user-generated data that facilitates the early identification of asd-related behaviors, particularly via self-reported experiences and parental observations. this methodology promotes the advancement of suggested models, namely lstm, cnn-lstm, and inspired ddqn, for natural language processing to examine linguistic patterns, feelings, and keywords related to asd. it provides insights into popular views, stigma, and misconceptions around autism, guiding awareness initiatives and public health measures. twitter data is a powerful and accessible resource for enhancing early detection and understanding of asd in diverse groups. utilizing social media in this manner may offer more accessible and timely screening, particularly in regions with limited healthcare resources.\u003c/p> \u003ca id=\"h3\" name=\"h3\">\u003c/a>\n\u003ch2>2 materials and methods\u003c/h2>\n\u003cp class=\"mb0\">\u003ca href=\"#fig2\">figure 2\u003c/a> shows the pipeline of the proposed system to provide a broader perspective to researchers and developers. the framework delineates the processing phases for the pipeline that utilizes social media content to diagnose asd. below, we present a comprehensive assessment of each step.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 2\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g002.jpg\" name=\"figure2\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g002.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g002.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g002.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g002.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g002.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g002.jpg\" alt=\"flowchart depicting a process for analyzing twitter data. it starts with social media avatars and a twitter api feeding into a word cloud for asd-related terms. next, preprocessing involves text cleaning, label encoding, and tokenization. this data feeds into deep learning models, including lstm, cnn-lstm, and ddqn. outputs are classified as asd or non-asd, with corresponding graphs indicating training and validation accuracy over epochs.\" id=\"fig2\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 2\u003c/b>. farmwork of asd system.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch3>2.1 dataset\u003c/h3>\n\u003cp class=\"mb0\">to help with the early diagnosis of asd by using proposed systems, the tasd-dataset includes comprehensive textual sequences that depict the everyday lives of children with and without asd. it offers new elements, including noise sensitivity, sharing interest, sign communication, and tiptoe flapping, it combines critical asd assessment aspects like attention response, word repetition, and emotional empathy, as shown in \u003ca href=\"#fig3\">figure 3\u003c/a>. parents may get detailed insights and better identify signs of autism spectrum disorder (asd) due to the deepening of certain behaviors. the dataset contains 172 tweets from the asd class and 158 non-asd tweets. \u003ca href=\"#fig4\">figure 4\u003c/a> shows the class of the dataset.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 3\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g003.jpg\" name=\"figure3\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g003.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g003.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g003.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g003.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g003.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g003.jpg\" alt=\"bar chart titled “feature frequencies” showing the count of various behaviors. “word repetition” has the highest frequency at 2.00. other features like “attention response,” “change reaction,” and “eye contact” have frequencies of 1.00 each.\" id=\"fig3\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 3\u003c/b>. features of the dataset.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline mb15\">\u003c/div>\n\u003cdiv class=\"imageheaders\">figure 4\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g004.jpg\" name=\"figure4\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g004.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g004.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g004.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g004.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g004.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g004.jpg\" alt=\"bar chart titled “number of tweets per class” compares tweet counts for asd and non-asd categories. asd has around 175 tweets, while non-asd has about 160 tweets.\" id=\"fig4\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 4\u003c/b>. label of the dataset.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch3>2.2 preprocessing\u003c/h3>\n\u003cp class=\"mb0\">text preprocessing is an essential step in the text processing process. words, sentences, and paragraphs can all be found in a text, which is defined as a meaningful sequence of characters. preprocessing methods feed text data to a proposed algorithm in a better form than in its natural state. a tweet can contain different viewpoints on the data it represents. tweets that have not been preprocessed are highly unstructured and contain redundant data. to address these issues, several steps are taken to preprocess tweets for detecting asd, as shown in \u003ca href=\"#fig5\">figure 5\u003c/a>.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 5\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g005.jpg\" name=\"figure5\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g005.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g005.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g005.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g005.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g005.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g005.jpg\" alt=\"flowchart depicting a text preprocessing workflow with three stages: text cleaning, label encoding, and tokenization and padding. the tokenization and padding section includes tokenizer, texts_to_sequences, and padding_sequences. arrows indicate process flow from left to right.\" id=\"fig5\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 5\u003c/b>. preprocessing asd text analysis.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch3>2.3 text cleaning\u003c/h3>\n\u003cp class=\"mb0\">the clean text preprocessing method is a significant step in text datasets because the text contains several extra contexts to preprocess and normalize raw text data for analysis. in these steps, the use is transformed to lowercase to guarantee consistency and prevent differentiation between “asd” and “non-asd.” subsequently, any characters that are not letters, numerals, or spaces are eliminated by a regular expression, so punctuation and other symbols that might create extraneous noise are removed. this method is ultimately applied to the ‘text’ column of the data frame, ensuring that all text elements are sanitized and prepared for feature extraction. \u003ca href=\"#fig6\">figure 6\u003c/a> displays the clean text process.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 6\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g006.jpg\" name=\"figure6\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g006.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g006.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g006.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g006.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g006.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g006.jpg\" alt=\"bar chart titled “text cleaning progression - sample 1” showing text length in characters for four stages: original, lowercased, no special chars, and trimmed. each bar’s length is nearly the same, around 150-200 characters.\" id=\"fig6\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 6\u003c/b>. clean text.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch3>2.4 label encoding\u003c/h3>\n\u003cp class=\"mb0\">the labelencoder method converts text class (asd and non-asd) into numbers, designating 0 for asd and 1 for non-asd. this transformation updates the classification effort by enabling the model to see the labels as numerical values instead of text. \u003ca href=\"#eq1\">equations 1\u003c/a>, \u003ca href=\"#eq2\">2\u003c/a> show the label encoding.\u003c/p>\n\u003cdiv id=\"eq1\" class=\"equationimageholder\">\u003cmath id=\"m1\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext mathvariant=\"italic\">yclassification\u003c/mtext>\u003cmo>∈\u003c/mo>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi mathvariant=\"italic\">asd\u003c/mi>\u003cmo>,\u003c/mo>\u003cmtext mathvariant=\"italic\">non\u003c/mtext>\u003cmo>−\u003c/mo>\u003cmi mathvariant=\"italic\">asd\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmtext mathvariant=\"italic\">then\u003c/mtext>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>1\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq19\" class=\"equationimageholder\">\u003cmath id=\"m2\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmi>y\u003c/mi>\u003cmo>=\u003c/mo>\u003cmtext mathvariant=\"italic\">labelencoder\u003c/mtext>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmtext mathvariant=\"italic\">yclassifcation\u003c/mtext>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>→\u003c/mo>\u003cmi>y\u003c/mi>\u003cmo>∈\u003c/mo>\u003cmo stretchy=\"true\">{\u003c/mo>\u003cmn>0\u003c/mn>\u003cmo>,\u003c/mo>\u003cmn>1\u003c/mn>\u003cmo stretchy=\"true\">}\u003c/mo>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>2\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003ch3>2.5 tokenization and padding\u003c/h3>\n\u003cp class=\"mb0\">tokenization and padding are essential nlp preprocessing procedures that transform unprocessed text into a numerical representation appropriate for machine learning models, particularly neural networks. \u003ca href=\"#fig7\">figure 7\u003c/a> shows the tokenization and padding \u003ca href=\"#eq3\">equation 3\u003c/a>.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 7\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g007.jpg\" name=\"figure7\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g007.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g007.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g007.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g007.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g007.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g007.jpg\" alt=\"sample text tokenization and padding process with three horizontal bar graphs. the first graph shows original text words. the second graph illustrates the tokenized sequence using word indexes with varying heights. the third graph shows a padded sequence with a fixed length of twenty, ensuring uniform token index lengths. the indexes used are rearranged with zero padding.\" id=\"fig7\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 7\u003c/b>. sample of text tokenization and padding.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch4>2.5.1 tokenizer\u003c/h4>\n\u003cp class=\"mb0\">tokenizer procedures transform textual data into a numerical representation suitable for input into neural networks. they convert a text corpus into integer sequences, assigning a distinct index to each unique word according to its frequency, as shown in \u003ca href=\"#eq3\">equation 3\u003c/a>. the tokenizer processing is shown in \u003ca href=\"#fig8\">figure 8\u003c/a>.\u003c/p>\n\u003cdiv id=\"eq2\" class=\"equationimageholder\">\u003cmath id=\"m3\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext mathvariant=\"italic\">index\u003c/mtext>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>w\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>=\u003c/mo>\u003cmsub>\u003cmo mathvariant=\"italic\">rank\u003c/mo>\u003cmi>f\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>w\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmtext mathvariant=\"italic\">if\u003c/mtext>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmsub>\u003cmo mathvariant=\"italic\">rank\u003c/mo>\u003cmi>f\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>w\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>≤\u003c/mo>\u003cmi>v\u003c/mi>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>3\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 8\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g008.jpg\" name=\"figure8\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g008.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g008.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g008.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g008.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g008.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g008.jpg\" alt=\"three bar charts illustrate text data analysis. chart a shows the top 20 most frequent words with “to” being the highest. chart b depicts sequence length distribution before padding, peaking at around 20 tokens. chart c displays sequence lengths post-padding, fixed at 200 tokens, appearing as a single line at the 200 mark.\" id=\"fig8\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 8\u003c/b>. tokenizer analysis: word frequencies and sequence lengths.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">where \u003cmath id=\"m4\">\u003cmsub>\u003cmo mathvariant=\"italic\">rank\u003c/mo>\u003cmi>f\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>w\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003c/math>is rank \u003cmath id=\"m5\">\u003cmi>w\u003c/mi>\u003c/math> frequency \u003cmath id=\"m6\">\u003cmi>f\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>w\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/math> and \u003cmath id=\"m7\">\u003cmi>v\u003c/mi>\u003c/math> is the maximum number of words.\u003c/p>\n\u003ch4>2.5.2 fit texts\u003c/h4>\n\u003cp class=\"mb0\">this phase is crucial for transforming unprocessed text into numerical sequences suitable for input into the proposed system.\u003c/p>\n\u003ch4>2.5.3 texts_to_sequences\u003c/h4>\n\u003cp class=\"mb0\">to convert unprocessed text input into sequences of word indices according to the mapping acquired via as shown in \u003ca href=\"#eq4\">equation 4\u003c/a>.\u003c/p>\n\u003cdiv id=\"eq3\" class=\"equationimageholder\">\u003cmath id=\"m8\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext mathvariant=\"italic\">sequence\u003c/mtext>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>t\u003c/mi>\u003cmi>i\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>=\u003c/mo>\u003cmo stretchy=\"true\">[\u003c/mo>\u003cmtext mathvariant=\"italic\">index\u003c/mtext>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmn>1\u003c/mn>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>,\u003c/mo>\u003cmtext mathvariant=\"italic\">index\u003c/mtext>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmn>2\u003c/mn>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>,\u003c/mo>\u003cmo>…\u003c/mo>\u003cmo>…\u003c/mo>\u003cmo>…\u003c/mo>\u003cmo>,\u003c/mo>\u003cmtext mathvariant=\"italic\">index\u003c/mtext>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmi>m\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo stretchy=\"true\">]\u003c/mo>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>4\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cp class=\"mb0\">where is the \u003cmath id=\"m9\">\u003cmsub>\u003cmi>t\u003c/mi>\u003cmi>i\u003c/mi>\u003c/msub>\u003c/math> is the sentence of the text contained, and \u003cmath id=\"m10\">\u003cmi>w\u003c/mi>\u003c/math> is the words of the text, whereas the \u003cmath id=\"m11\">\u003cmtext mathvariant=\"italic\">index\u003c/mtext>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmn>1\u003c/mn>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/math> is an index of the words in the context.\u003c/p>\n\u003ch4>2.5.4 padding_sequences\u003c/h4>\n\u003cp class=\"mb0\">normalize sequence lengths, which may differ post-tokenization, by padding shorter sequences and truncating larger ones to a predetermined length as shown in \u003ca href=\"#eq5\">equation 5\u003c/a>. the padding and truncated b are fixed on the length. \u003cmath id=\"m12\">\u003cmi>l\u003c/mi>\u003cmo>=\u003c/mo>\u003cmn>200\u003c/mn>\u003c/math>. the padding processing is shown in \u003ca href=\"#fig7\">figure 7\u003c/a>.\u003c/p>\n\u003cdiv id=\"eq4\" class=\"equationimageholder\">\u003cmath id=\"m13\">\u003cmi>x\u003c/mi>\u003cmo>=\u003c/mo>\u003cmo>∣\u003c/mo>\u003cmrow>\u003cmtable displaystyle=\"true\">\u003cmtr>\u003cmtd>\u003cmsub>\u003cmi>x\u003c/mi>\u003cmn>1\u003c/mn>\u003c/msub>\u003c/mtd>\u003c/mtr>\u003cmtr>\u003cmtd>\u003cmsub>\u003cmi>x\u003c/mi>\u003cmn>2\u003c/mn>\u003c/msub>\u003c/mtd>\u003c/mtr>\u003cmtr>\u003cmtd>\u003cmtable>\u003cmtr>\u003cmtd>\u003cmo>.\u003c/mo>\u003c/mtd>\u003c/mtr>\u003cmtr>\u003cmtd>\u003cmo>.\u003c/mo>\u003c/mtd>\u003c/mtr>\u003cmtr>\u003cmtd>\u003cmo>.\u003c/mo>\u003c/mtd>\u003c/mtr>\u003cmtr>\u003cmtd>\u003cmo>.\u003c/mo>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/mtd>\u003c/mtr>\u003cmtr>\u003cmtd>\u003cmi>y\u003c/mi>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/mrow>\u003cmo>∣\u003c/mo>\u003cmo>∈\u003c/mo>\u003cmsup>\u003cmi>ℝ\u003c/mi>\u003cmi mathvariant=\"italic\">nxl\u003c/mi>\u003c/msup>\u003cmtext>    (5)\u003c/mtext>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cp class=\"mb0\">where \u003cmath id=\"m14\">\u003cmi>x\u003c/mi>\u003c/math> is features contain padding and are tokenized, \u003cmath id=\"m15\">\u003cmi>l\u003c/mi>\u003c/math> is the length of the vector. the number of texts is indicated \u003cmath id=\"m16\">\u003cmi>n\u003c/mi>\u003c/math>, and \u003cmath id=\"m17\">\u003cmo>∈\u003c/mo>\u003cmsup>\u003cmi>ℝ\u003c/mi>\u003cmi mathvariant=\"italic\">nxl\u003c/mi>\u003c/msup>\u003c/math> is matrix lues.\u003c/p>\n\u003ch3>2.6 proposed systems\u003c/h3>\n\u003ch4>2.6.1 convolutional neural networks\u003c/h4>\n\u003cp class=\"mb0\">the cnn model is at the core of all advanced machine learning and deep learning applications. they can successfully address text classification, image recognition, object identification, and semantic segmentation. using the same method with a task as different as natural language processing is counterintuitive (\u003ca href=\"#ref7\">7\u003c/a>). the structure is presented in \u003ca href=\"#fig9\">figure 9\u003c/a>. \u003ca href=\"#eq6\">equation 6\u003c/a> presents the convolution layer of cnn.\u003c/p>\n\u003cdiv id=\"eq5\" class=\"equationimageholder\">\u003cmath id=\"m18\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmi>o\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo>,\u003c/mo>\u003cmi>y\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>=\u003c/mo>\u003cmunderover>\u003cmo movablelimits=\"false\">∑\u003c/mo>\u003cmrow>\u003cmi>i\u003c/mi>\u003cmo>=\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003cmi>h\u003c/mi>\u003c/munderover>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmunderover>\u003cmo movablelimits=\"false\">∑\u003c/mo>\u003cmrow>\u003cmi>j\u003c/mi>\u003cmo>=\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003cmi>w\u003c/mi>\u003c/munderover>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmi>i\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi>i\u003c/mi>\u003cmo>,\u003c/mo>\u003cmi>y\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi>j\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>∗\u003c/mo>\u003cmi>k\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>i\u003c/mi>\u003cmo>,\u003c/mo>\u003cmi>j\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>+\u003c/mo>\u003cmi>b\u003c/mi>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>6\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 9\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g009.jpg\" name=\"figure9\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g009.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g009.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g009.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g009.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g009.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g009.jpg\" alt=\"flowchart depicting a text classification process using convolutional neural networks. it starts with a sentence matrix representation. colored blocks denote convolution results with filter sizes of two, three, and four. the results undergo one-max pooling, then concatenate into a single vector. finally, the vector classifies into categories: information giving, information seeking, feature request, solution proposal, problem discovery, aspect evaluation, and others.\" id=\"fig9\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 9\u003c/b>. structure cnn.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">where the features of text \u003cmath id=\"m19\">\u003cmi>o\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo>,\u003c/mo>\u003cmi>y\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/math> the feature of the text is mapped by using.\u003cmath id=\"m20\">\u003cmi>i\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi>i\u003c/mi>\u003cmo>,\u003c/mo>\u003cmi>y\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi>j\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/math> is weighted by a neural network and \u003cmath id=\"m21\">\u003cmi>b\u003c/mi>\u003c/math> is biased to adjust the neural. the relu activation function is \u003ca href=\"#eq20\">equation 7\u003c/a>, the max pooling function is presented in \u003ca href=\"#eq6\">equation 8\u003c/a>. the dense layer is given in \u003ca href=\"#eq7\">equation 9\u003c/a>.\u003c/p>\n\u003cdiv id=\"eq20\" class=\"equationimageholder\">\u003cmath id=\"m22\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmi>f\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>=\u003c/mo>\u003cmi>max\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmn>0\u003c/mn>\u003cmo>,\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>7\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq6\" class=\"equationimageholder\">\u003cmath id=\"m23\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmi>o\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo>,\u003c/mo>\u003cmi>y\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>=\u003c/mo>\u003cmunderover>\u003cmo movablelimits=\"false\">∑\u003c/mo>\u003cmrow>\u003cmi>i\u003c/mi>\u003cmo>=\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003cmi>h\u003c/mi>\u003c/munderover>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmunderover>\u003cmo movablelimits=\"false\">∑\u003c/mo>\u003cmrow>\u003cmi>j\u003c/mi>\u003cmo>=\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003cmi>w\u003c/mi>\u003c/munderover>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmi>i\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi>i\u003c/mi>\u003cmo>,\u003c/mo>\u003cmi>y\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi>j\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>∗\u003c/mo>\u003cmi>k\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>i\u003c/mi>\u003cmo>,\u003c/mo>\u003cmi>j\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>+\u003c/mo>\u003cmi>b\u003c/mi>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>8\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq7\" class=\"equationimageholder\">\u003cmath id=\"m24\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmi mathvariant=\"normal\">o\u003c/mi>\u003cmo>=\u003c/mo>\u003cmi>w\u003c/mi>\u003cmo>·\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi>b\u003c/mi>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>9\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003ch4>2.6.2 long short-term memory network\u003c/h4>\n\u003cp class=\"mb0\">an lstm network is an advanced form of a sequential neural network. it fixes the problem of rnn gradients fading over time. rnns often handle long-term storage. at a high level, the operation of an lstm is comparable to that of a single rnn neuron. the inner workings of the lstm network are outlined in this section. the lstm consists of three parts, each performing a particular function, as seen in \u003ca href=\"#fig10\">figure 10\u003c/a> below. in the first step, it is decided whether the information from the previous time stamp is significant enough to be saved or if it is harmless enough to be deleted. in the second step, the cell will try to acquire new information by analyzing the data that has been presented to it. in the third and final step, the cell incorporates the data from the most recent time stamp into the data stored in the next time stamp. these three components constitute what is referred to as a gate for an lstm cell. the “forget” gate comes first, followed by the “input” section, and then the “output” section is used to define the last portion as shown in \u003ca href=\"#eq10\">equations 10\u003c/a>– \u003ca href=\"#eq14\">14\u003c/a>.\u003c/p>\n\u003cdiv id=\"eq8\" class=\"equationimageholder\">\u003cmath id=\"m25\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext>forget gate\u003c/mtext>\u003cmo>:\u003c/mo>\u003cmsub>\u003cmi>f\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>=\u003c/mo>\u003cmi>σ\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmi>f\u003c/mi>\u003c/msub>\u003cmo>.\u003c/mo>\u003cmsub>\u003cmi>x\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmi>f\u003c/mi>\u003c/msub>\u003cmo>.\u003c/mo>\u003cmsub>\u003cmi>h\u003c/mi>\u003cmrow>\u003cmi>t\u003c/mi>\u003cmo>−\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmsub>\u003cmi>b\u003c/mi>\u003cmi>f\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>10\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq9\" class=\"equationimageholder\">\u003cmath id=\"m26\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext>input gate\u003c/mtext>\u003cmo>:\u003c/mo>\u003cmsub>\u003cmi>i\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>=\u003c/mo>\u003cmi>σ\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmi>c\u003c/mi>\u003c/msub>\u003cmo>.\u003c/mo>\u003cmsub>\u003cmi>x\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmi>i\u003c/mi>\u003c/msub>\u003cmo>.\u003c/mo>\u003cmsub>\u003cmi>h\u003c/mi>\u003cmrow>\u003cmi>t\u003c/mi>\u003cmo>−\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmsub>\u003cmi>b\u003c/mi>\u003cmi>i\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>11\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq10\" class=\"equationimageholder\">\u003cmath id=\"m27\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext>cell gate\u003c/mtext>\u003cmo>:\u003c/mo>\u003cmsub>\u003cmi>c\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>=\u003c/mo>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmi>f\u003c/mi>\u003c/msub>\u003cmo>∗\u003c/mo>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmo>.\u003c/mo>\u003cmsub>\u003cmi>h\u003c/mi>\u003cmrow>\u003cmi>t\u003c/mi>\u003cmo>−\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003c/msub>\u003cmo>,\u003c/mo>\u003cmsub>\u003cmi>x\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmsub>\u003cmi>b\u003c/mi>\u003cmi>f\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>12\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq11\" class=\"equationimageholder\">\u003cmath id=\"m28\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext>output gate\u003c/mtext>\u003cmo>:\u003c/mo>\u003cmsub>\u003cmi>o\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>=\u003c/mo>\u003cmi>σ\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmi>o\u003c/mi>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmsub>\u003cmi>x\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmi>o\u003c/mi>\u003c/msub>\u003cmo>.\u003c/mo>\u003cmsub>\u003cmi>h\u003c/mi>\u003cmrow>\u003cmi>t\u003c/mi>\u003cmo>−\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmsub>\u003cmi>v\u003c/mi>\u003cmi>o\u003c/mi>\u003c/msub>\u003cmo>.\u003c/mo>\u003cmsub>\u003cmi>c\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmsub>\u003cmi>b\u003c/mi>\u003cmi>o\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>13\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq12\" class=\"equationimageholder\">\u003cmath id=\"m29\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext>hidden layer\u003c/mtext>\u003cmo>:\u003c/mo>\u003cmsub>\u003cmi>h\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>=\u003c/mo>\u003cmsub>\u003cmi>o\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmi>tanh\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>c\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>14\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 10\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g010.jpg\" name=\"figure10\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g010.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g010.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g010.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g010.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g010.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g010.jpg\" alt=\"flowchart of an lstm neural network model with multiple layers. the input layer feeds into 25 features, which connect to lstm layer 1 with 128 neurons. relu activation leads to lstm layer 2 with 64 neurons, followed by a sigmoid activation for binary classification into class 0 or class 1.\" id=\"fig10\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 10\u003c/b>. lstm model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb15\">in \u003ca href=\"#fig10\">figure 10\u003c/a>, \u003cmath id=\"m30\">\u003cmsub>\u003cmi>c\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003c/math> represent the prior and current states of the cell, respectively. both \u003cmath id=\"m31\">\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmsub>\u003cmi>h\u003c/mi>\u003cmrow>\u003cmi>t\u003c/mi>\u003cmo>−\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003c/msub>\u003c/math> and \u003cmath id=\"m32\">\u003cmi>h\u003c/mi>\u003c/math> represents the cell output that was processed before the one now being processed. it is common practice to disregard \u003cmath id=\"m33\">\u003cmsub>\u003cmi>f\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003c/math> as a gate, even though it is the input gate. the output of a sigmoid gate is symbolized here by \u003cmath id=\"m34\">\u003cmsub>\u003cmi>o\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003c/math>. the cable that connects the cell gates is where all the data collected by the cell gates is sent to and from \u003cmath id=\"m35\">\u003cmi>c\u003c/mi>\u003c/math>. the \u003cmath id=\"m36\">\u003cmsub>\u003cmi>f\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003c/math> layer decides to remember anything, and the\u003cmath id=\"m37\">\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmsub>\u003cmi>f\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmtext mathvariant=\"italic\">the\u003c/mtext>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003c/math>output is multiplied by c to do so (t-1). after that, c (t-1) is multiplied by the product of the sigmoid layer gate and the tanh layer gate, and the output h t is generated by point-wise multiplication of \u003cmath id=\"m38\">\u003cmsub>\u003cmi>o\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003c/math> and tanh.\u003c/p>\n\u003cp class=\"mb0\">the lstm architecture is intended to capture long-term relationships in twitter text data. the preprocessing converts input words that start with an embedding layer into 128-dimensional dense vectors. the lstm layer with 64 units is then used to mitigate overfitting, integrating dropout and recurrent dropout with 0.5. an l2 regularization term is further included in the lstm and output dense layer. \u003ca href=\"#tab1\">table 1\u003c/a> shows parameters of the lstm model.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">table 1\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t001.jpg\" name=\"table1\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t001.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t001.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t001.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t001.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t001.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t001.jpg\" alt=\"www.frontiersin.org\" id=\"tab1\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>table 1\u003c/b>. lstm parameters model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch4>2.6.3 cnn-lstm model\u003c/h4>\n\u003cp class=\"mb0\">the cnn-lstm model is a hybrid architecture that combines convolutional neural networks (cnn) for spatial feature extraction and long short-term memory (lstm) networks for sequential learning, making it highly effective for analyzing text data such as tweets. the model begins with an embedding layer that transforms each word into a 256-dimensional dense vector, capturing the semantic meaning of words. this is followed by a 1d convolutional layer with 64 filters and a kernel size of 5, which scans through the text to detect local patterns and n-gram features such as common word combinations or phrases often associated with asd. a batch normalization layer is applied to stabilize and accelerate training, followed by a max pooling layer that reduces the dimensionality and computational load by selecting the most prominent features. a dropout layer with a rate of 0.5 is then used to prevent overfitting by randomly deactivating some neurons during training. the output is passed into a 64-unit lstm layer that captures the temporal dependencies and contextual relationships across the tweet sequence. finally, a dense layer with sigmoid activation performs binary classification to predict whether the tweet indicates asd-related content. the model is trained using the adam optimizer, binary cross-entropy loss, class weights, and regularization to handle imbalanced data and improve generalization. the critical parameters of the cnn-lstm model are displayed in \u003ca href=\"#tab2\">table 2\u003c/a>.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">table 2\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t002.jpg\" name=\"table2\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t002.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t002.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t002.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t002.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t002.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t002.jpg\" alt=\"www.frontiersin.org\" id=\"tab2\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>table 2\u003c/b>. cnn-lstm parameters.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch4>2.6.4 double deep q-network (ddqn-inspired)\u003c/h4>\n\u003cp class=\"mb15\">the double q-learning model was introduced by h. van hasselt in 2010, addressing the issue of significant overestimations of action value (q-value) inherent in traditional q-learning. in fundamental q-learning, the agent’s optimal strategy is consistently to select the most advantageous action in any specific state. this concept’s premise is that the optimal action corresponds to the highest expected or estimated q-value. initially, the agent lacks any knowledge of the environment; it must first estimate q(s, a) and subsequently update these estimates with each iteration. the q-values exhibit considerable noise, leading to uncertainty about whether the action associated with the highest expected or estimated q-value is genuinely the optimal choice.\u003c/p>\n\u003cp class=\"mb0\">double q-learning employs two distinct action-value functions, q and q’, as estimators. even if q and q’ exhibit noise, this noise can be interpreted as a uniform distribution as shown \u003ca href=\"#fig11\">figure 11\u003c/a> the update procedure exhibits some variations compared to the basic version. the action selection and action evaluation processes are separated into two distinct maximum function estimators. shown in \u003ca href=\"#eq13\">equations 15\u003c/a>, \u003ca href=\"#eq16\">16\u003c/a>.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 11\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g011.jpg\" name=\"figure11\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g011.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g011.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g011.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g011.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g011.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g011.jpg\" alt=\"diagram illustrating the process of reinforcement learning with replay memory and q-networks. the replay memory outputs a mini-batch containing state, action, reward, and next state. this feeds into both the online and target q-networks. the online q-network outputs state-action pairs, which are used alongside the target q-network’s output in the loss function. a feedback loop connects the replay memory to the online q-network.\" id=\"fig11\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 11\u003c/b>. ddqn-inspired model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">let the vector of a neural network’s weights be represented by \u003ci>θ\u003c/i>. we establish two q-networks: the online q-network q (s, a; θ(t)) and the target q-network q (s, a; θ (t)). to be more specific, the training of q (s, a; \u003ci>Χ\u003c/i> (t)) is done by modifying the weights (t) at time slot t in relation to the goal value y(t).\u003c/p>\n\u003cdiv id=\"eq13\" class=\"equationimageholder\">\u003cmath id=\"m39\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmi>y\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>t\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>=\u003c/mo>\u003cmi>g\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>t\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>+\u003c/mo>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>s\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo>,\u003c/mo>\u003cmtext>argmax\u003c/mtext>\u003cmi>q\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>s\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo>,\u003c/mo>\u003cmsup>\u003cmi>a\u003c/mi>\u003cmo>∗\u003c/mo>\u003c/msup>\u003cmo>;\u003c/mo>\u003cmi>θ\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>t\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>;\u003c/mo>\u003cmi>θ\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>t\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>15\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq14\" class=\"equationimageholder\">\u003cmath id=\"m40\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmi>y\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>t\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>=\u003c/mo>\u003cmi>g\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>t\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>+\u003c/mo>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>s\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo>,\u003c/mo>\u003cmtext>argmax\u003c/mtext>\u003cmi>q\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>s\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo>,\u003c/mo>\u003cmsup>\u003cmi>a\u003c/mi>\u003cmo>∗\u003c/mo>\u003c/msup>\u003cmo>;\u003c/mo>\u003cmi>θ\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>;\u003c/mo>\u003cmsub>\u003cmi>θ\u003c/mi>\u003cmrow>\u003cmi>i\u003c/mi>\u003cmo>−\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>16\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cp class=\"mb15\">the reinforcement learning mechanism integrates generative artificial intelligence for decision-making and prediction tasks, as shown in \u003ca href=\"#eq15\">equations 15\u003c/a>, \u003ca href=\"#eq16\">16\u003c/a>. this equation indicates the generative which produces the estimation or hypothesis at a given time \u003cmath id=\"m41\">\u003cmi>t\u003c/mi>\u003c/math>.\u003cmath id=\"m42\">\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmtext mathvariant=\"italic\">double\u003c/mtext>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmi>q\u003c/mi>\u003cmo>−\u003c/mo>\u003cmtext mathvariant=\"italic\">learning\u003c/mtext>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003c/math>used next state, whereas the s’ is exit state and \u003cmath id=\"m43\">\u003cmtext>argmax\u003c/mtext>\u003cmi>q\u003c/mi>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>s\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo>,\u003c/mo>\u003cmsup>\u003cmi>a\u003c/mi>\u003cmo>∗\u003c/mo>\u003c/msup>\u003cmo>;\u003c/mo>\u003cmi>θ\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>t\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/math> defined as the action of \u003cmath id=\"m44\">\u003cmsup>\u003cmi>a\u003c/mi>\u003cmo>∗\u003c/mo>\u003c/msup>\u003c/math> to maximize the predicted q-value based on the current parameters. to estimate the q-value of this selected action in the next state, the outer q-function q’ employs the older parameters. \u003cmath id=\"m45\">\u003cmsub>\u003cmi>θ\u003c/mi>\u003cmrow>\u003cmi>i\u003c/mi>\u003cmo>−\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003c/msub>\u003c/math>1, which helps reduce overestimation bias. this combination makes applications for predicting asd from social media content domains possible.\u003c/p>\n\u003cp class=\"mb0\">the ddqn model is used to classify asd and non-asd cases utilizing text data. the model utilizes a preprocessing step for text processing that encompasses data loading, cleaning (including lowercasing, removal of special characters, and normalization of spaces), and tokenization, constrained by a maximum vocabulary of 10,000 words and a sequence length of 200. the model architecture, drawing from the double deep q-network (ddqn) model comprises an input layer, an embedding layer with 256 dimensions, and two parallel lstm branches, each containing 64 units, a dropout rate of 0.5, and l2 regularization to capture sequential patterns effectively. the model uses the adam optimizer with a learning rate of 1e-4 and employs binary cross-entropy loss. it is trained for 30 epochs, incorporating early stopping and learning rate reduction callbacks to mitigate overfitting. parameters of ddqn-inspired are shown in \u003ca href=\"#tab3\">table 3\u003c/a>.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">table 3\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t003.jpg\" name=\"table3\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t003.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t003.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t003.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t003.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t003.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t003.jpg\" alt=\"www.frontiersin.org\" id=\"tab3\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>table 3\u003c/b>. parameters of ddqn-inspired.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div> \u003ca id=\"h4\" name=\"h4\">\u003c/a>\n\u003ch2>3 performance of the framework\u003c/h2>\n\u003ch3>3.1 performance of lstm\u003c/h3>\n\u003cp class=\"mb0\">\u003ca href=\"#fig12\">figure 12\u003c/a> presents the accuracy and loss metrics used to train and validate an lstm model over 30 epochs. the validation accuracy of the lstm model, displayed in red, begins at a lower value and increases to about 81%. the blue line in the accuracy plot (a) shows the training accuracy of the lstm model; it increases gradually from around 50% to almost 99%, showing that the model learns the training data well over time. the plot (b) shows the loss of the lstm model; the blue line represents the training loss, which drops gradually from around 0.7 to less than 0.2, suggesting that the model is getting a better fit to the training data. meanwhile, the red validation loss line declines from around 0.7 to about 0.3. while the training loss continues to grow, the validation loss reaches a level and exhibits small oscillations, suggesting that the model’s generalizability may stabilize.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 12\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g012.jpg\" name=\"figure12\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g012.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g012.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g012.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g012.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g012.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g012.jpg\" alt=\"two line graphs depict an lstm model’s performance over 30 epochs. the left graph shows accuracy, with training accuracy rising from 0.5 to 0.9, while validation accuracy fluctuates around 0.8. the right graph displays loss, where training loss decreases from 0.7 to 0.1, and validation loss reduces from 0.7 to 0.3. both graphs feature blue lines for training metrics and red lines for validation metrics.\" id=\"fig12\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 12\u003c/b>. performance of the lstm model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">the roc curve illustrated in \u003ca href=\"#fig13\">figure 13\u003c/a> shows the efficacy of the lstm model in differentiating between the classes. the graph illustrates the tp rate (sensitivity) in relation to the fp rate across different threshold levels. the lstm model attains an auc of 0.95, demonstrating exceptional classification capability. the auc of 1.0, but a result of 0.5 indicates random chance.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 13\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g013.jpg\" name=\"figure13\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g013.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g013.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g013.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g013.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g013.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g013.jpg\" alt=\"roc curve for an lstm model showing the trade-off between true positive rate and false positive rate. the curve bends towards the top-left corner, with an area under the curve (auc) of 0.95, indicating high model performance. a diagonal dashed line represents random chance.\" id=\"fig13\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 13\u003c/b>. roc of the lstm model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch3>3.2 performance of the cnn-lstm model\u003c/h3>\n\u003cp class=\"mb0\">\u003ca href=\"#fig14\">figure 14\u003c/a> presents plots illustrating the performance of a cnn-lstm model over 25 epochs, showing its training and validation metrics for accuracy and loss. the accuracy plot (a) illustrates the training accuracy (blue line), which increases progressively from approximately 51.42% to nearly 99.53%, indicating effective learning from the training data. in contrast, the validation accuracy (red line) rises to about 83.02% with some variability, indicating satisfactory but imperfect generalization. the loss plot (b) shows the training loss (blue line) declining steadily from 0.7140 to below 0.0760, indicating enhanced model fit. in contrast, the validation loss (red line) decreases from 0.7130 to approximately 0.3530, with a slight decline toward the conclusion. this notification indicates that the cnn-lstm model demonstrates efficient learning, as evidenced by the difference between the training and validation measures.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 14\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g014.jpg\" name=\"figure14\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g014.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g014.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g014.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g014.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g014.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g014.jpg\" alt=\"two line graphs show cnn-lstm model performance. the left graph displays training and validation accuracy over 25 epochs. training accuracy improves significantly, surpassing validation accuracy, which fluctuates. the right graph depicts training and validation loss over the same epochs. training loss decreases sharply, while validation loss also reduces but stabilizes after an initial drop.\" id=\"fig14\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 14\u003c/b>. performance of the lstm model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">\u003ca href=\"#fig15\">figure 15\u003c/a> illustrates the roc curve for the cnn-lstm model, illustrating its classification performance at various thresholds. the graph illustrates the tp rate (sensitivity) in relation to the fp rate, with the auc recorded at 92%. the elevated auc value indicates the model has robust discriminative capability in differentiating between the asd and non-asd classes. the roc ascends rapidly toward the top-left corner, as seen in the figure, indicating a high tp rate with few false positives.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 15\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g015.jpg\" name=\"figure15\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g015.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g015.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g015.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g015.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g015.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g015.jpg\" alt=\"roc curve for a cnn_lstm model, showing the true positive rate against the false positive rate. the curve is above the diagonal, with an area under the curve (auc) of 0.92, indicating strong model performance.\" id=\"fig15\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 15\u003c/b>. roc of the cnn-lstm model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch3>3.3 performance of ddqn-inspired model\u003c/h3>\n\u003cp class=\"mb0\">graphs 16 illustrate the performance of a ddqn throughout 30 epochs. the accuracy plot (a) demonstrates that the training accuracy increases from around 58.02% to almost 98.58%, indicating the ddqn model successful learning from the training data over time. the validation accuracy of the ddqn is about 87, showing the best performance compared to different models like lstm and cnn-lstm. the plot (b) illustrates that the training loss decreases from about 0.8155 to around 0.1477, indicating a robust fit to the training data. the validation loss begins at 0.3831 with many fluctuations throughout (\u003ca href=\"#fig16\">figure 16\u003c/a>).\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 16\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g016.jpg\" name=\"figure16\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g016.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g016.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g016.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g016.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g016.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g016.jpg\" alt=\"two graphs display the performance of a ddqn_t model over 30 epochs. graph (a) shows training accuracy in blue and validation accuracy in red, both improving over time. graph (b) illustrates training loss in blue and validation loss in red, both decreasing with some fluctuations.\" id=\"fig16\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 16\u003c/b>. performance of the \u003ci>ddqn-inspired\u003c/i> model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">\u003ca href=\"#fig17\">figure 17\u003c/a> shows the roc curve for the ddqn model; it shows a visual representation of its classification capability, with the curve toward the top-left corner, indicating strong predictive power. the auc value of the ddqn model is 96%, demonstrating that the model can distinguish between the positive and negative classes.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 17\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g017.jpg\" name=\"figure17\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g017.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g017.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g017.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g017.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g017.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g017.jpg\" alt=\"receiver operating characteristic (roc) curve illustrating a ddqn-inspired model performance. the curve shows the trade-off between true positive rate and false positive rate with an area under the curve (auc) of 0.96, indicating high accuracy.\" id=\"fig17\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 17\u003c/b>. roc \u003ci>ddqn-inspired model.\u003c/i>\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div> \u003ca id=\"h5\" name=\"h5\">\u003c/a>\n\u003ch2>4 experiment and discussion results\u003c/h2>\n\u003cp class=\"mb0\">both the jupyter deep learning framework and the windows 10 operating system were utilized during the testing process. experiments were conducted using a machine with 16 gigabytes of ram and an intel core i7 central processing unit. the input dimensions of the experiment were a standard text dataset collected from the twitter api related to asd. the test was utilized in our database, while the remaining 20% was used as part of our validation set. the three dl models, namely lstm, cnn-lstm, and ddqn-inspired, were proposed for detecting asd from social media content.\u003c/p>\n\u003ch3>4.1 measuring the model’s performance\u003c/h3>\n\u003cp class=\"mb0\">sensitivity, specificity, accuracy, recall, and f1 scores are assessment measures used to determine how successfully the algorithms identify asd. the related equations from \u003ca href=\"#eq17\">17\u003c/a> to \u003ca href=\"#eq21\">21\u003c/a>:\u003c/p>\n\u003cdiv id=\"eq15\" class=\"equationimageholder\">\u003cmath id=\"m46\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext mathvariant=\"italic\">accuracy\u003c/mtext>\u003cmo>=\u003c/mo>\u003cmfrac>\u003cmrow>\u003cmi mathvariant=\"italic\">tp\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi mathvariant=\"italic\">tn\u003c/mi>\u003c/mrow>\u003cmrow>\u003cmi mathvariant=\"italic\">tp\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi mathvariant=\"italic\">fp\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi mathvariant=\"italic\">fn\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi mathvariant=\"italic\">tn\u003c/mi>\u003c/mrow>\u003c/mfrac>\u003cmo>×\u003c/mo>\u003cmn>100\u003c/mn>\u003cmo>%\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>17\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq16\" class=\"equationimageholder\">\u003cmath id=\"m47\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext mathvariant=\"italic\">sensitivity\u003c/mtext>\u003cmo>=\u003c/mo>\u003cmfrac>\u003cmi mathvariant=\"italic\">tp\u003c/mi>\u003cmrow>\u003cmi mathvariant=\"italic\">tp\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi mathvariant=\"italic\">fn\u003c/mi>\u003c/mrow>\u003c/mfrac>\u003cmo>×\u003c/mo>\u003cmn>100\u003c/mn>\u003cmo>%\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>18\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq17\" class=\"equationimageholder\">\u003cmath id=\"m48\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext mathvariant=\"italic\">precision\u003c/mtext>\u003cmo>=\u003c/mo>\u003cmfrac>\u003cmi mathvariant=\"italic\">tp\u003c/mi>\u003cmrow>\u003cmi mathvariant=\"italic\">tp\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi mathvariant=\"italic\">fp\u003c/mi>\u003c/mrow>\u003c/mfrac>\u003cmo>×\u003c/mo>\u003cmn>100\u003c/mn>\u003cmo>%\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>19\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq21\" class=\"equationimageholder\">\u003cmath id=\"m49\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext mathvariant=\"italic\">specificity\u003c/mtext>\u003cmo>=\u003c/mo>\u003cmfrac>\u003cmi mathvariant=\"italic\">tn\u003c/mi>\u003cmrow>\u003cmi mathvariant=\"italic\">tn\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi mathvariant=\"italic\">fp\u003c/mi>\u003c/mrow>\u003c/mfrac>\u003cmo>×\u003c/mo>\u003cmn>100\u003c/mn>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>20\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq18\" class=\"equationimageholder\">\u003cmath id=\"m50\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmi>f\u003c/mi>\u003cmn>1\u003c/mn>\u003cmo>−\u003c/mo>\u003cmtext mathvariant=\"italic\">score\u003c/mtext>\u003cmo>=\u003c/mo>\u003cmn>2\u003c/mn>\u003cmo>∗\u003c/mo>\u003cmfrac>\u003cmrow>\u003cmtext mathvariant=\"italic\">precision\u003c/mtext>\u003cmo>×\u003c/mo>\u003cmtext mathvariant=\"italic\">sensitivity\u003c/mtext>\u003c/mrow>\u003cmrow>\u003cmtext mathvariant=\"italic\">precision\u003c/mtext>\u003cmo>+\u003c/mo>\u003cmtext mathvariant=\"italic\">sensitivity\u003c/mtext>\u003c/mrow>\u003c/mfrac>\u003cmo>×\u003c/mo>\u003cmn>100\u003c/mn>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>21\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003ch3>4.2 result of the lstm model\u003c/h3>\n\u003cp class=\"mb0\">the classification lstm model, presented in \u003ca href=\"#tab4\">table 4\u003c/a>, summarizes its performance in differentiating between asd and non-asd patients, attaining an overall accuracy of 81%. the lstm model demonstrates in asd class a precision of 91%, indicating a high accuracy in identifying predicted asd cases. the lstm with recall metric scored 77% and an f1-score of 82% for detecting the asd class. the lstm model with non-asd class demonstrates a precision of 71%, a recall of 89%, and an f1-score of 79%, to identify non-asd cases. the macro average of the lstm model for all metrics is (precision: 81%, recall: 82%, f1-score: 81%). lstm model is recognized for its efficiency and scalability as a model for social media content.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">table 4\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t004.jpg\" name=\"table4\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t004.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t004.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t004.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t004.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t004.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t004.jpg\" alt=\"www.frontiersin.org\" id=\"tab4\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>table 4\u003c/b>. lstm results.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">the confusion matrix for the lstm model is provided in \u003ca href=\"#fig18\">figure 18\u003c/a>. it is presented in a clear manner. among the confirmed asd cases, 29 were accurately identified as asd, whereas 10 were incorrectly classified as non-asd, indicating strong performance with minor errors. in the true non-asd cases, 25 were correctly identified, while 3 were misclassified as asd, suggesting a generally effective detection process. the deep blue and light shades produce a tranquil visual, illustrating the model’s balanced approach in classifying the 67 total instances, demonstrating notable strength in identifying non-asd cases, while exhibiting marginally lower accuracy for asd. this matrix effectively illustrates the lstm model’s systematic approach to managing sequential data, such as text or time-series inputs, in a clear and comprehensible manner.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 18\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g018.jpg\" name=\"figure18\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g018.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g018.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g018.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g018.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g018.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g018.jpg\" alt=\"confusion matrix for lstm model showing true labels versus predicted labels. the matrix includes 29 true positives for asd, 25 true negatives for non-asd, 10 false positives, and 3 false negatives. a color gradient represents value intensity.\" id=\"fig18\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 18\u003c/b>. lstm model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch3>4.3 result of the cnn-lstm model\u003c/h3>\n\u003cp class=\"mb0\">\u003ca href=\"#tab5\">table 5\u003c/a> displays the cnn-lstm model’s performance in distinguishing between asd and non-asd classes. the cnn-lstm model attained an overall accuracy of 85% across the dataset. in the asd label, a precision of 91% was achieved, a high percentage for predicting asd cases that were accurately recognized. the recall indicates that the model identified 82% of all genuine asd cases, resulting in an f1 score of 86%, better than the recall metric. the cnn-lstm model attained 78% accuracy, 89% recall, and an 83% f1 score for the non-asd class. the macro average, representing the unweighted mean of precision, recall, and f1 score across both classes, was 85, 86, and 85%, respectively. the findings indicate that the cnn-lstm model performs satisfactorily, exhibiting a marginally superior capacity to identify asd cases relative to non-asd cases accurately.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">table 5\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t005.jpg\" name=\"table5\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t005.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t005.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t005.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t005.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t005.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t005.jpg\" alt=\"www.frontiersin.org\" id=\"tab5\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>table 5\u003c/b>. results of the cnn-lstm model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">the confusion matrix of a cnn-lstm model is presented in \u003ca href=\"#fig19\">figure 19\u003c/a>, for classifying instances into asd and non-asd. the matrix is structured with true labels on the vertical axis and predicted labels on the horizontal axis, providing a clear summary of the model’s classification outcomes. the matrix shows that out of the instances truly labeled as asd, the model correctly predicted 32 as asd tp while 7 were incorrectly classified as non-asd fn. for the instances truly labeled as non-asd, the model accurately identified 25 as non-asd tn but 3 were misclassified as asd fp. this indicates that the model demonstrates a relatively strong ability to correctly identify asd and non-asd cases, with higher accuracy for true positives (32 out of 39 asd cases) and true negatives (25 out of 28 non-asd cases). overall, the model exhibits promising performance with minimal misclassification errors.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 19\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g019.jpg\" name=\"figure19\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g019.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g019.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g019.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g019.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g019.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g019.jpg\" alt=\"confusion matrix for cnn_lstm_model with predicted labels on the x-axis and true labels on the y-axis. it shows 32 true positives, 7 false negatives, 3 false positives, and 25 true negatives. a gradient bar on the right indicates color intensity from light to dark blue, representing increasing values from 0 to 30.\" id=\"fig19\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 19\u003c/b>. results of cnn-lstm model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch3>4.4 results of double deep q-network\u003c/h3>\n\u003cp class=\"mb0\">the findings of the ddqn model are shown in \u003ca href=\"#tab6\">table 6\u003c/a>, achieving a high precision of 87% compared to the other models. this finding demonstrates the potential of the proposed ddqn approach for identifying asd based on social media content. ultimately, the proposed system was compared against the existing one using the same dataset. the proposed approach may assist physicians in detecting asd and conducting symptomology research in a natural environment, attaining an overall accuracy of 87. the model for the asd class shows a precision of 95%, a recall of 79%, and an f1-score of 87%, indicating robust efficacy in accurately identifying asd patients. the non-asd class has a precision of 77%, a recall of 96%, and an f1-score of 86%, indicating somewhat reduced accuracy with robust recall. the macro average measures (precision 87%, recall 88%, f1-score 87%) indicate performance across both classes.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">table 6\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t006.jpg\" name=\"table6\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t006.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t006.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t006.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t006.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t006.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t006.jpg\" alt=\"www.frontiersin.org\" id=\"tab6\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>table 6\u003c/b>. result of ddqn-inspired.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">the confusion matrix of the ddqn model is shown in \u003ca href=\"#fig20\">figure 20\u003c/a> for the classification task between asd and non-asd cases. for correct classification of asd cases, the model correctly classified 31 instances as asd, represented by the top-left quadrant (tp). however, the ddqn model, misclassified 8 instances misclassifying true asd cases as non-asd, shown in the top-right quadrant (fn). on the other hand, the ddqn showed the true non-asd cases, accurately identified 27 instances as non-asd, depicted in the bottom-right quadrant (tn). at the same time, 1 instance was incorrectly labeled as asd, as shown in the bottom-left quadrant (fp). the confusion matrix of ddqn model highlights that it performs well overall, with a strong ability to correctly identify both asd and non-asd cases, as evidenced by the high counts of tp (31) and tn (27).\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 20\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g020.jpg\" name=\"figure20\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g020.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g020.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g020.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g020.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g020.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g020.jpg\" alt=\"confusion matrix title “ddqn-inspired confusion matrix”. the matrix shows actual versus predicted labels for asd and non-asd. true positives: 31, false positives: 8, false negatives: 1, true negatives: 27. a color bar on the right indicates intensity from light to dark blue, corresponding to values from 0 to 30.\" id=\"fig20\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 20\u003c/b>. result of ddqn-inspired model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb15\">in the digital era, people frequently write content on social media to express their feelings, opinions, beliefs, and activities. this makes social media one of the most significant sources of data generation, allowing you to explore its opportunities and challenges. today, social media has become a mediator between people and the healthcare sector, enabling them to search for information about any specific disease and methods for diagnosing it.\u003c/p>\n\u003cp class=\"mb0\">individuals within the mental health community use social media platforms such as twitter to seek information, exchange experiences, and get assistance about asd in an environment that is seen as more approachable and informal than conventional medical contexts. they often seek immediate, relevant information—whether to understand symptoms, identify coping mechanisms, or connect with others facing similar difficulties. \u003ca href=\"#fig21\">figure 21\u003c/a> illustrates that word clouds are visual representations of text that highlight key terms and their frequency of use. we used wordcloud to compare asd and non-asd texts for instances of word repetition.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 21\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g021.jpg\" name=\"figure21\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g021.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g021.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g021.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g021.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g021.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g021.jpg\" alt=\"word cloud with terms related to asd class, including prominent words like “toddler,” “ability,” “might,” “concerned,” “activities,” and “making.” other words such as “engage,” “learning,” “challenging,” “noise,” and “struggle” also appear, reflecting themes in autism education.\" id=\"fig21\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 21\u003c/b>. asd word cloud.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">the deployment model based on the deep q-network (dqn) model for diagnosing asd is shown in \u003ca href=\"#fig22\">figure 22\u003c/a>.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 22\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g022.jpg\" name=\"figure22\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g022.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g022.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g022.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g022.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g022.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g022.jpg\" alt=\"flowchart depicting a data collection and processing model using twitter api for tweet analysis. the process includes filtering tweets, preprocessing, and applying a deep q-network for model development. it involves validating and testing to build an application interface. the deployment phase includes user interaction, real-time monitoring, and cloud storage. health professionals validate predictions, classifying tweets as asd or non-asd.\" id=\"fig22\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 22\u003c/b>. deployment system-based text for detecting asd.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb15\">step 1: data collections, including cleaning, normalization, and tokenization.\u003c/p>\n\u003cp class=\"mb15\">step 2: model development: the preprocessed data is used to train and validate a deep q-network (dqn) model for classifying tweets as indicative of asd or non-asd patterns.\u003c/p>\n\u003cp class=\"mb15\">step 3: application interface: an application interface is developed once the model has been trained. it integrates with users’ twitter accounts and continuously analyzes their tweets.\u003c/p>\n\u003cp class=\"mb15\">step 4: deployment: the proposed system is deployed in the cloud for storing tweets, enabling real-time monitoring of incoming tweets. predictions are flagged for review by healthcare professionals, who validate the model’s output before categorizing individuals as potentially having asd or non-asd.\u003c/p>\n\u003cp class=\"mb0\">this digital imprint may serve as an ancillary resource for mental health practitioners, providing insights into an individual’s emotional state and social behaviors in a natural environment, potentially facilitating early detection or corroborating a diagnosis. this method is a non-invasive means of data collection, particularly beneficial for individuals who lack rapid access to clinical assessments due to financial constraints, stigma, or resource scarcity. however, it should not replace professional diagnoses and must be conducted with ethical consideration to prevent misunderstanding. \u003ca href=\"#tab7\">table 7\u003c/a> shows the findings of the proposed framework on the twitter dataset. it demonstrates that the suggested method outperforms the current systems in terms of accuracy, proving its efficacy and potential for performance improvements.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">table 7\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t007.jpg\" name=\"table7\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t007.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t007.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t007.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t007.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t007.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t007.jpg\" alt=\"www.frontiersin.org\" id=\"tab7\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>table 7\u003c/b>. compared with the proposed asd system.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div> \u003ca id=\"h6\" name=\"h6\">\u003c/a>\n\u003ch2>5 conclusion\u003c/h2>\n\u003cp class=\"mb0\">to assist people in identifying trends in their behavior, such as social challenges or sensory sensitivities, which may encourage them to pursue a formal diagnosis. the main objective of examining tweets for identifying asd is its ability to provide behavioral and emotional indicators associated with the disorder. this research was used to analyze the textual analysis of tweets to detect the behaviors in self-identified autistic individuals relative to others. the suggested framework was evaluated using information from the social media platform “twitter” collected from a public repository. before examining the proposed system, several preprocessing steps must be implemented in the text. the ‘text’ column is cleaned by converting it to lowercase, eliminating non-alphanumeric characters (excluding spaces) through regular expressions, normalizing whitespace to a single space, and removing any leading or trailing spaces. the asd and non-asd labels are converted into a numerical format (0 or 1) with labelencoder to accommodate the binary classification requirement. tokenization of the text data is performed using a tokenizer, restricting the vocabulary to 10,000 words, and then transforming the text into sequences of numbers. the sequences are padded to a standardized length of 200 tokens to maintain consistency for the proposed model input. the proposed data is ultimately divided into an 80% training and 20% testing ratio, and class weights are calculated to resolve any class imbalance. this preparation pipeline efficiently converts raw text data into a structured numerical representation appropriate for the proposed framework, while preserving academic integrity. the output of these preprocessing steps was processed using three dl models, such as short-term memory (cnn-lstm) and a double deep q-network (ddqn). the results of these proposals were proven, revealing that the ddqn model achieved a high accuracy score of 87% with respect to the accuracy measure. the proposed framework, based on real textual data, can be helpful for real-time offering natural, behavioral, and emotional data that might indicate asd-related characteristics. finally, we have observed that social media (twitter) postings include linguistic patterns, emotional expressions, and social interactions that can help official health officials detect asd based on the thorough symptoms of asd that are posted on the platform. this study utilized a conventional dataset sourced only from the twitter network. we will emphasize the necessity of gathering datasets from many platforms to enhance the model’s generalizability in the future.\u003c/p> \u003ca id=\"h7\" name=\"h7\">\u003c/a>\n\u003ch2>data availability statement\u003c/h2>\n\u003cp class=\"mb0\">the original contributions presented in the study are included in the article/supplementary material, further inquiries can be directed to the corresponding author/s. the dataset used in this study can be found at \u003ca href=\"https://data.mendeley.com/datasets/87s2br3ptb/1\">https://data.mendeley.com/datasets/87s2br3ptb/1\u003c/a>.\u003c/p> \u003ca id=\"h8\" name=\"h8\">\u003c/a>\n\u003ch2>ethics statement\u003c/h2>\n\u003cp class=\"mb0\">ethical approval was not required for the study involving human data in accordance with the local legislation and institutional requirements. written informed consent was not required, for either participation in the study or for the publication of potentially/indirectly identifying information, in accordance with the local legislation and institutional requirements. the social media data was accessed and analysed in accordance with the platform’s terms of use and all relevant institutional/national regulations.\u003c/p> \u003ca id=\"h9\" name=\"h9\">\u003c/a>\n\u003ch2>author contributions\u003c/h2>\n\u003cp class=\"mb0\">nf: supervision, conceptualization, software, methodology, writing – original draft, investigation, visualization, formal analysis, validation. aa: data curation, visualization, methodology, conceptualization, validation, software, formal analysis, writing – original draft. ne: investigation, writing – review & editing, validation, formal analysis. sa: visualization, software, formal analysis, writing – review & editing, data curation.\u003c/p> \u003ca id=\"h10\" name=\"h10\">\u003c/a>\n\u003ch2>funding\u003c/h2>\n\u003cp class=\"mb0\">the author(s) declare that financial support was received for the research and/or publication of this article. the authors extend their appreciation to the king salman center for disability research for funding this work through research group no ksrg-2024-288.\u003c/p> \u003ca id=\"h11\" name=\"h11\">\u003c/a>\n\u003ch2>conflict of interest\u003c/h2>\n\u003cp class=\"mb0\">the authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\u003c/p> \u003ca id=\"h12\" name=\"h12\">\u003c/a>\n\u003ch2>generative ai statement\u003c/h2>\n\u003cp class=\"mb15\">the authors declare that no gen ai was used in the creation of this manuscript.\u003c/p>\n\u003cp class=\"mb0\">any alternative text (alt text) provided alongside figures in this article has been generated by frontiers with the support of artificial intelligence and reasonable efforts have been made to ensure accuracy, including review by the authors wherever possible. if you identify any issues, please contact us.\u003c/p> \u003ca id=\"h13\" name=\"h13\">\u003c/a>\n\u003ch2>publisher’s note\u003c/h2>\n\u003cp class=\"mb0\">all claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.\u003c/p> \u003ca id=\"h14\" name=\"h14\">\u003c/a>\n\u003ch2>references\u003c/h2>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref1\" id=\"ref1\">\u003c/a>1. asd. (2023). available online at: \u003ca href=\"https://www.healthline.com/health/signs-of-autism-in-3-year-old\">https://www.healthline.com/health/signs-of-autism-in-3-year-old\u003c/a>.\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"http://scholar.google.com/scholar_lookup?publication_year=2023&\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref2\" id=\"ref2\">\u003c/a>2. matson, jl, and goldin, rl. what is the future of assessment for autism spectrum disorders: short and long term. \u003ci>res autism spectr disord\u003c/i>. (2014) 8:209–13. doi: 10.1016/j.rasd.2013.01.007\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.1016/j.rasd.2013.01.007\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=jl+matson&author=rl+goldin&publication_year=2014&title=what+is+the+future+of+assessment+for+autism+spectrum+disorders:+short+and+long+term&journal=res+autism+spectr+disord&volume=8&pages=209-13\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref3\" id=\"ref3\">\u003c/a>3. srivastava, ak, and schwartz, ce. intellectual disability and autism spectrum disorders: causal genes and molecular mechanisms. \u003ci>neurosci biobehav rev\u003c/i>. (2014) 46:161–74. doi: 10.1016/j.neubiorev.2014.02.015 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/24709068\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.1016/j.neubiorev.2014.02.015\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=ak+srivastava&author=ce+schwartz&publication_year=2014&title=intellectual+disability+and+autism+spectrum+disorders:+causal+genes+and+molecular+mechanisms&journal=neurosci+biobehav+rev&volume=46&pages=161-74\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref4\" id=\"ref4\">\u003c/a>4. alhujaili, n, platt, e, khalid-khan, s, and groll, d. comparison of social media use among adolescents with autism spectrum disorder and non-asd adolescents. \u003ci>adolesc health med ther\u003c/i>. (2022) 13:15–21. doi: 10.2147/ahmt.s344591 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/35136359\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.2147/ahmt.s344591\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=n+alhujaili&author=e+platt&author=s+khalid-khan&author=d+groll&publication_year=2022&title=comparison+of+social+media+use+among+adolescents+with+autism+spectrum+disorder+and+non-asd+adolescents&journal=adolesc+health+med+ther&volume=13&pages=15-21\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref5\" id=\"ref5\">\u003c/a>5. angulo-jiménez, h, and dethorne, l. narratives about autism: an analysis of youtube videos by individuals who self-identify as autistic. \u003ci>am j speech lang pathol\u003c/i>. (2019) 28:569–90. doi: 10.1044/2018_ajslp-18-0045\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.1044/2018_ajslp-18-0045\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=h+angulo-jiménez&author=l+dethorne&publication_year=2019&title=narratives+about+autism:+an+analysis+of+youtube+videos+by+individuals+who+self-identify+as+autistic&journal=am+j+speech+lang+pathol&volume=28&pages=569-90\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref6\" id=\"ref6\">\u003c/a>6. pew research center. (2021). available online at: \u003ca href=\"https://www.pewresearch.org/internet/2021/04/07/social-media-use-in-2021/\">https://www.pewresearch.org/internet/2021/04/07/social-media-use-in-2021/\u003c/a>\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"http://scholar.google.com/scholar_lookup?publication_year=2021&\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref7\" id=\"ref7\">\u003c/a>7. liu, j-b, guan, l, cao, j, and chen, l. coherence analysis for a class of polygon networks with the noise disturbance. \u003ci>ieee trans syst man cybern syst\u003c/i>. (2025) 2025:326. doi: 10.1109/tsmc.2025.3559326\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.1109/tsmc.2025.3559326\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=j-b+liu&author=l+guan&author=j+cao&author=l+chen&publication_year=2025&title=coherence+analysis+for+a+class+of+polygon+networks+with+the+noise+disturbance&journal=ieee+trans+syst+man+cybern+syst&volume=2025&pages=326\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref8\" id=\"ref8\">\u003c/a>8. al-nefaie, ah, aldhyani, th, sultan, ha, and alzahrani eidah, m. application of artificial intelligence in modern healthcare for diagnosis of autism spectrum disorder. \u003ci>front med\u003c/i>. (2025) 12:1569464. doi: 10.3389/fmed.2025.1569464\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.3389/fmed.2025.1569464\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=ah+al-nefaie&author=th+aldhyani&author=ha+sultan&author=m+alzahrani+eidah&publication_year=2025&title=application+of+artificial+intelligence+in+modern+healthcare+for+diagnosis+of+autism+spectrum+disorder&journal=front+med&volume=12&pages=1569464\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref9\" id=\"ref9\">\u003c/a>9. kim, b, jeong, d, kim, jg, hong, h, and han, k. \u003ci>v-dat (virtual reality data analysis tool): supporting self-awareness for autistic people from multimodal vr sensor data\u003c/i>. in: proceedings of the uist 2023—proceedings of the 36th annual acm symposium on user interface software and technology, san francisco, ca, usa, 29 october–1 november 2023. (2023).\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"http://scholar.google.com/scholar_lookup?author=b+kim&author=d+jeong&author=jg+kim&author=h+hong&author=k+han&publication_year=2023&\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref10\" id=\"ref10\">\u003c/a>10. chen, c, chander, a, and uchino, k. \u003ci>guided play: digital sensing and coaching for stereotypical play behavior in children with autism\u003c/i>. in proceedings of the international conference on intelligent user interfaces, proceedings iui, marina del ray, ca, usa, 17–20 march 2019; part f1476. pp. 208–217. (2019).\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"http://scholar.google.com/scholar_lookup?author=c+chen&author=a+chander&author=k+uchino&publication_year=2019&\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref11\" id=\"ref11\">\u003c/a>11. parui, s, samanta, d, chakravorty, n, ghosh, u, and rodrigues, jj. artificial intelligence and sensor-based autism spectrum disorder diagnosis using brain connectivity analysis. \u003ci>comput electr eng\u003c/i>. (2023) 108:108720. doi: 10.1016/j.compeleceng.2023.108720\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.1016/j.compeleceng.2023.108720\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=s+parui&author=d+samanta&author=n+chakravorty&author=u+ghosh&author=jj+rodrigues&publication_year=2023&title=artificial+intelligence+and+sensor-based+autism+spectrum+disorder+diagnosis+using+brain+connectivity+analysis&journal=comput+electr+eng&volume=108&pages=108720\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref12\" id=\"ref12\">\u003c/a>12. golestan, s, soleiman, p, and moradi, h. a comprehensive review of technologies used for screening, assessment, and rehabilitation of autism spectrum disorder. \u003ci>arxiv\u003c/i>. (2018) 2018:10986. doi: 10.48550/arxiv.1807.10986\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.48550/arxiv.1807.10986\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=s+golestan&author=p+soleiman&author=h+moradi&publication_year=2018&title=a+comprehensive+review+of+technologies+used+for+screening+assessment+and+rehabilitation+of+autism+spectrum+disorder&journal=arxiv&volume=2018&pages=10986\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref13\" id=\"ref13\">\u003c/a>13. neeharika, ch, and riyazuddin, ym. developing an artificial intelligence based model for autism spectrum disorder detection in children. \u003ci>j adv res appl sci eng technol\u003c/i>. (2023) 32:57–72. doi: 10.37934/araset.32.1.5772\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.37934/araset.32.1.5772\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=ch+neeharika&author=ym+riyazuddin&publication_year=2023&title=developing+an+artificial+intelligence+based+model+for+autism+spectrum+disorder+detection+in+children&journal=j+adv+res+appl+sci+eng+technol&volume=32&pages=57-72\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref14\" id=\"ref14\">\u003c/a>14. wall, dp, dally, r, luyster, r, jung, j-y, and deluca, tf. use of artificial intelligence to shorten the behavioral diagnosis of autism. \u003ci>plos one\u003c/i>. (2012) 7:e43855. doi: 10.1371/journal.pone.0043855 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/22952789\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.1371/journal.pone.0043855\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=dp+wall&author=r+dally&author=r+luyster&author=j-y+jung&author=tf+deluca&publication_year=2012&title=use+of+artificial+intelligence+to+shorten+the+behavioral+diagnosis+of+autism&journal=plos+one&volume=7&pages=e43855\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref15\" id=\"ref15\">\u003c/a>15. alzakari, sa, allinjawi, a, aldrees, a, zamzami, n, umer, m, innab, n, et al. early detection of autism spectrum disorder using explainable ai and optimized teaching strategies. \u003ci>j neurosci methods\u003c/i>. (2025) 413:110315. doi: 10.1016/j.jneumeth.2024.110315 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/39532186\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.1016/j.jneumeth.2024.110315\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=sa+alzakari&author=a+allinjawi&author=a+aldrees&author=n+zamzami&author=m+umer&author=n+innab&publication_year=2025&title=early+detection+of+autism+spectrum+disorder+using+explainable+ai+and+optimized+teaching+strategies&journal=j+neurosci+methods&volume=413&pages=110315\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref16\" id=\"ref16\">\u003c/a>16. heunis, t, aldrich, c, peters, j, jeste, s, sahin, m, scheffer, c, et al. recurrence quantification analysis of resting state eeg signals in autism spectrum disorder—a systematic methodological exploration of technical and demographic confounders in the search for biomarkers. \u003ci>bmc med\u003c/i>. (2018) 16:101. doi: 10.1186/s12916-018-1086-7\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.1186/s12916-018-1086-7\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=t+heunis&author=c+aldrich&author=j+peters&author=s+jeste&author=m+sahin&author=c+scheffer&publication_year=2018&title=recurrence+quantification+analysis+of+resting+state+eeg+signals+in+autism+spectrum+disorder—a+systematic+methodological+exploration+of+technical+and+demographic+confounders+in+the+search+for+biomarkers&journal=bmc+med&volume=16&pages=101\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref17\" id=\"ref17\">\u003c/a>17. vicnesh, j, wei, jke, oh, sl, arunkumar, n, abdulhay, e, ciaccio, ej, et al. autism spectrum disorder diagnostic system using hos bispectrum with eeg signals. \u003ci>int j environ res public health\u003c/i>. (2020) 17:971. doi: 10.3390/ijerph17030971\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.3390/ijerph17030971\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=j+vicnesh&author=jke+wei&author=sl+oh&author=n+arunkumar&author=e+abdulhay&author=ej+ciaccio&publication_year=2020&title=autism+spectrum+disorder+diagnostic+system+using+hos+bispectrum+with+eeg+signals&journal=int+j+environ+res+public+health&volume=17&pages=971\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref18\" id=\"ref18\">\u003c/a>18. novielli, p, romano, d, magarelli, m, diacono, d, monaco, a, amoroso, n, et al. personalized identification of autism-related bacteria in the gut microbiome using explainable artificial intelligence. \u003ci>iscience\u003c/i>. (2024) 27:110709. doi: 10.1016/j.isci.2024.110709 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/39286497\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.1016/j.isci.2024.110709\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=p+novielli&author=d+romano&author=m+magarelli&author=d+diacono&author=a+monaco&author=n+amoroso&publication_year=2024&title=personalized+identification+of+autism-related+bacteria+in+the+gut+microbiome+using+explainable+artificial+intelligence&journal=iscience&volume=27&pages=110709\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref19\" id=\"ref19\">\u003c/a>19. bosl, wj, tager-flusberg, h, and nelson, ca. eeg analytics for early detection of autism spectrum disorder: a data-driven approach. \u003ci>sci rep\u003c/i>. (2018) 8:1–20. doi: 10.1038/s41598-018-24318-x \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/29717196\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.1038/s41598-018-24318-x\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=wj+bosl&author=h+tager-flusberg&author=ca+nelson&publication_year=2018&title=eeg+analytics+for+early+detection+of+autism+spectrum+disorder:+a+data-driven+approach&journal=sci+rep&volume=8&pages=1-20\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref20\" id=\"ref20\">\u003c/a>20. beykikhoshk, a, arandjelović, o, phung, d, venkatesh, s, and caelli, t. using twitter to learn about the autism community. \u003ci>soc netw anal min\u003c/i>. (2015) 5:261. doi: 10.1007/s13278-015-0261-\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.1007/s13278-015-0261-\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=a+beykikhoshk&author=o+arandjelović&author=d+phung&author=s+venkatesh&author=t+caelli&publication_year=2015&title=using+twitter+to+learn+about+the+autism+community&journal=soc+netw+anal+min&volume=5&pages=261\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref21\" id=\"ref21\">\u003c/a>21. mazurek, mo. social media use among adults with autism spectrum disorders. \u003ci>comput hum behav\u003c/i>. (2013) 29:1709–14. doi: 10.1016/j.chb.2013.02.004\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.1016/j.chb.2013.02.004\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=mo+mazurek&publication_year=2013&title=social+media+use+among+adults+with+autism+spectrum+disorders&journal=comput+hum+behav&volume=29&pages=1709-14\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref22\" id=\"ref22\">\u003c/a>22. onnela, j, and rauch, sl. harnessing smartphone-based digital phenotyping to enhance behavioral and mental health. \u003ci>neuropsychopharmacology\u003c/i>. (2016) 41:1691–6. doi: 10.1038/npp.2016.7.npp20167 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/26818126\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.1038/npp.2016.7.npp20167\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=j+onnela&author=sl+rauch&publication_year=2016&title=harnessing+smartphone-based+digital+phenotyping+to+enhance+behavioral+and+mental+health&journal=neuropsychopharmacology&volume=41&pages=1691-6\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref23\" id=\"ref23\">\u003c/a>23. tomeny, ts, vargo, cj, and el-toukhy, s. geographic and demographic correlates of autism-related anti-vaccine beliefs on twitter, 2009–2015. \u003ci>soc sci med\u003c/i>. (2017) 191:168–75. doi: 10.1016/j.socscimed.2017.08.041 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/28926775\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.1016/j.socscimed.2017.08.041\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=ts+tomeny&author=cj+vargo&author=s+el-toukhy&publication_year=2017&title=geographic+and+demographic+correlates+of+autism-related+anti-vaccine+beliefs+on+twitter+2009–2015&journal=soc+sci+med&volume=191&pages=168-75\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref24\" id=\"ref24\">\u003c/a>24. tárraga-mínguez, r, gómez-marí, i, and sanz-cervera, p. what motivates internet users to search for asperger syndrome and autism on google? \u003ci>int j environ res public health\u003c/i>. (2020) 17:9386. doi: 10.3390/ijerph17249386 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/33333991\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.3390/ijerph17249386\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=r+tárraga-mínguez&author=i+gómez-marí&author=p+sanz-cervera&publication_year=2020&title=what+motivates+internet+users+to+search+for+asperger+syndrome+and+autism+on+google?&journal=int+j+environ+res+public+health&volume=17&pages=9386\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref25\" id=\"ref25\">\u003c/a>25. hartwell, m, keener, a, coffey, s, chesher, t, torgerson, t, and vassar, m. brief report: public awareness of asperger syndrome following greta thunberg appearances. \u003ci>j autism dev disord\u003c/i>. (2020) 51:2104–8. doi: 10.1007/s10803-020-04651-9 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/32812193\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.1007/s10803-020-04651-9\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=m+hartwell&author=a+keener&author=s+coffey&author=t+chesher&author=t+torgerson&author=m+vassar&publication_year=2020&title=brief+report:+public+awareness+of+asperger+syndrome+following+greta+thunberg+appearances&journal=j+autism+dev+disord&volume=51&pages=2104-8\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref26\" id=\"ref26\">\u003c/a>26. rubio-martín, s, garcía-ordás, mt, bayón-gutiérrez, m, prieto-fernández, n, and benítez-andrades, ja. “\u003ci>early detection of autism spectrum disorder through ai-powered analysis of social media texts\u003c/i>,” 2023 ieee 36th international symposium on computer-based medical systems (cbms), l’aquila, italy, pp. 235–240. (2023).\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"http://scholar.google.com/scholar_lookup?author=s+rubio-martín&author=mt+garcía-ordás&author=m+bayón-gutiérrez&author=n+prieto-fernández&author=ja+benítez-andrades&publication_year=2023&\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref27\" id=\"ref27\">\u003c/a>27. jaiswal, a, and washington, p. using #actuallyautistic on twitter for precision diagnosis of autism spectrum disorder: machine learning study. \u003ci>jmir form res\u003c/i>. (2024) 8:e52660. doi: 10.2196/52660\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.2196/52660\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=a+jaiswal&author=p+washington&publication_year=2024&title=using+#actuallyautistic+on+twitter+for+precision+diagnosis+of+autism+spectrum+disorder:+machine+learning+study&journal=jmir+form+res&volume=8&pages=e52660\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003c/div> \u003cdiv class=\"thinlinem20\">\u003c/div> \u003cdiv class=\"abstractsummary\">\n\u003cp>\u003cspan>keywords:\u003c/span> autism spectrum disorders, diagnosing, social media, deep learning, disabilities, artificial intelligence\u003c/p>\n\u003cp>\u003cspan>citation:\u003c/span> farhah ns, alqarni aa, ebrahim n and ahmad s (2025) diagnosing autism spectrum disorders using a double deep q-network framework based on social media footprints. \u003ci>front. med\u003c/i>. 12:1646249. doi: 10.3389/fmed.2025.1646249\u003c/p>\n\u003cp class=\"timestamps\">\u003cspan>received:\u003c/span> 16 june 2025; \u003cspan>accepted:\u003c/span> 28 july 2025;\u003cbr> \u003cspan>published:\u003c/span> 20 august 2025.\u003c/p> \u003cdiv>\n\u003cp>edited by:\u003c/p> \u003ca href=\"https://loop.frontiersin.org/people/2928766/overview\">pardeep sangwan\u003c/a>, maharaja surajmal institute of technology, india\u003c/div> \u003cdiv>\n\u003cp>reviewed by:\u003c/p> \u003ca href=\"https://loop.frontiersin.org/people/1743107/overview\">jia-bao liu\u003c/a>, anhui jianzhu university, china\u003cbr> \u003ca href=\"https://loop.frontiersin.org/people/3104897/overview\">muhammad adnan\u003c/a>, kohat university of science and technology, pakistan\u003c/div>\n\u003cp>\u003cspan>copyright\u003c/span> © 2025 farhah, alqarni, ebrahim and ahmad. this is an open-access article distributed under the terms of the \u003ca rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\" target=\"_blank\">creative commons attribution license (cc by)\u003c/a>. the use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. no use, distribution or reproduction is permitted which does not comply with these terms.\u003c/p>\n\u003cp>\u003cspan>*correspondence:\u003c/span> nesren s. farhah, \u003ca id=\"encmail\">bi5myxjoywhac2v1lmvkds5zyq==\u003c/a>; nadhem ebrahim, \u003ca id=\"encmail\">bmvicmfoaw1adwfrcm9ulmvkdq==\u003c/a>; sultan ahmad, \u003ca id=\"encmail\">cy5hbglzagvyqhbzyxuuzwr1lnnh\u003c/a>\u003c/p> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>","\u003cul class=\"flyoutjournal\"> \u003cli>\u003ca href=\"#h1\">abstract\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h2\">1 introduction\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h3\">2 materials and methods\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h4\">3 performance of the framework\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h5\">4 experiment and discussion results\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h6\">5 conclusion\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h7\">data availability statement\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h8\">ethics statement\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h9\">author contributions\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h10\">funding\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h11\">conflict of interest\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h12\">generative ai statement\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h13\">publisher’s note\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h14\">references\u003c/a>\u003c/li> \u003c/ul>",[627,633,639],{"name":628,"fileserverpackageentryid":19,"fileserverid":629,"fileserverversionnumber":374,"type":630},"epub.epub","1646249/epub",{"code":631,"name":632},"epub","epub",{"name":634,"fileserverpackageentryid":19,"fileserverid":635,"fileserverversionnumber":374,"type":636},"publishers-proof.pdf","1646249/publishers-proof",{"code":637,"name":638},"pdf","pdf",{"name":640,"fileserverpackageentryid":641,"fileserverid":642,"fileserverversionnumber":374,"type":643},"fmed-12-1646249.xml","fmed-12-1646249/fmed-12-1646249.xml","1646249/xml",{"code":644,"name":645},"nlm_xml","xml","v3",{"title":648,"link":649,"meta":653,"script":754},"frontiers | diagnosing autism spectrum disorders using a double deep q-network framework based on social media footprints",[650],{"rel":651,"href":652},"canonical","https://www.frontiersin.org/journals/medicine/articles/10.3389/fmed.2025.1646249/full",[654,657,660,662,665,669,672,676,679,682,685,687,689,691,693,695,698,701,703,706,708,710,713,716,719,722,725,729,733,736,739,742,745,748,751],{"hid":655,"property":655,"name":655,"content":656},"description","introductionsocial media is increasingly used in many contexts within the healthcare sector. the improved prevalence of internet use via computers or mobile ...",{"hid":658,"property":658,"name":659,"content":648},"og:title","title",{"hid":661,"property":661,"name":655,"content":656},"og:description",{"hid":663,"name":663,"content":664},"keywords","artificial intelligence,deep learning,social media,disabilities,autism spectrum disorders,diagnosing",{"hid":666,"property":666,"name":667,"content":668},"og:site_name","site_name","frontiers",{"hid":670,"property":670,"name":367,"content":671},"og:image","https://images-provider.frontiersin.org/api/ipx/w=1200&f=png/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g001.jpg",{"hid":673,"property":673,"name":674,"content":675},"og:type","type","article",{"hid":677,"property":677,"name":678,"content":652},"og:url","url",{"hid":680,"name":680,"content":681},"twitter:card","summary_large_image",{"hid":683,"name":683,"content":684},"citation_volume","12",{"hid":686,"name":686,"content":116},"citation_journal_title",{"hid":688,"name":688,"content":668},"citation_publisher",{"hid":690,"name":690,"content":608},"citation_journal_abbrev",{"hid":692,"name":692,"content":609},"citation_issn",{"hid":694,"name":694,"content":518},"citation_doi",{"hid":696,"name":696,"content":697},"citation_firstpage","1646249",{"hid":699,"name":699,"content":700},"citation_language","english",{"hid":702,"name":702,"content":519},"citation_title",{"hid":704,"name":704,"content":705},"citation_keywords","artificial intelligence; deep learning; social media; disabilities; autism spectrum disorders; diagnosing",{"hid":707,"name":707,"content":524},"citation_abstract",{"hid":709,"name":709,"content":533},"citation_article_type",{"hid":711,"name":711,"content":712},"citation_pdf_url","https://www.frontiersin.org/journals/medicine/articles/10.3389/fmed.2025.1646249/pdf",{"hid":714,"name":714,"content":715},"citation_xml_url","https://www.frontiersin.org/journals/medicine/articles/10.3389/fmed.2025.1646249/xml",{"hid":717,"name":717,"content":718},"citation_fulltext_world_readable","yes",{"hid":720,"name":720,"content":721},"citation_online_date","2025/07/28",{"hid":723,"name":723,"content":724},"citation_publication_date","2025/08/20",{"hid":726,"name":727,"content":728},"citation_author_0","citation_author","farhah, nesren s. ",{"hid":730,"name":731,"content":732},"citation_author_institution_0","citation_author_institution","department of health informatics, college of health science, saudi electronic university, saudi arabia",{"hid":734,"name":727,"content":735},"citation_author_1","alqarni, ahmed abdullah ",{"hid":737,"name":731,"content":738},"citation_author_institution_1","king salman center for disability research, saudi arabia",{"hid":740,"name":727,"content":741},"citation_author_2","ebrahim, nadhem ",{"hid":743,"name":731,"content":744},"citation_author_institution_2","department of computer science, college of engineering and polymer science, university of akron, united states",{"hid":746,"name":727,"content":747},"citation_author_3","ahmad, sultan ",{"hid":749,"name":731,"content":750},"citation_author_institution_3","department of computer science, college of computer engineering and sciences, prince sattam bin abdulaziz university, saudi arabia",{"hid":752,"name":752,"content":753},"dc.identifier","doi:10.3389/fmed.2025.1646249",[755,758,760,762,764],{"src":756,"body":13,"type":757,"async":13},"https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6","text/javascript",{"src":759,"body":13,"type":757,"async":13},"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/mathjax.js?config=tex-mml-am_chtml",{"src":761,"body":13,"type":757,"async":13},"https://d1bxh8uas1mnw7.cloudfront.net/assets/altmetric_badges-f0bc9b243ff5677d05460c1eb71834ca998946d764eb3bc244ab4b18ba50d21e.js",{"src":763,"body":13,"type":757,"async":13},"https://api.altmetric.com/v1/doi/10.3389/fmed.2025.1646249?callback=_altmetric.embed_callback&domain=www.frontiersin.org&key=3c130976ca2b8f2e88f8377633751ba1&cache_until=14-15",{"src":765,"body":13,"type":757,"async":13},"https://crossmark-cdn.crossref.org/widget/v2.0/widget.js",{"articlehubslug":19,"articlehubpage":767,"articlehubarticleslist":768,"canjournalhasarticlehub":351,"articledoilist":769},{},[],[],{"title":19,"image":-1,"breadcrumbs":771,"linkscollection":772,"metricscollection":774},[],{"total":371,"items":773},[],{"total":371,"items":775},[]] window.__nuxt__={};window.__nuxt__.config={public:{isdevmode:false,appname:"article-pages-2024",baseurl:"https://www.frontiersin.org",domain:"frontiersin.org",loopurl:"https://loop.frontiersin.org",ssmaindomain:"frontiersin.org",contentfulurl:"https://graphql.contentful.com/content/v1/spaces",spaceid:1,spacename:"frontiers",livespaceid:1,tenantlogourl:"",frontiersgraphurl:"https://apollo-federation-gateway.frontiersin.org",registrationapiurl:"https://onboarding-ui.frontiersin.org",emaildigestapiurl:"https://api-email-digest.frontiersin.org",journalfilesapiurl:"https://files-journal-api.frontiersin.org",searchapiurl:"https://search-api.frontiersin.org",productionforumapiurl:"https://production-forum-api-v2.frontiersin.org",gtmserverurl:"https://tag-manager.frontiersin.org",gtmid:"gtm-m322fv2",gtmauth:"owvbwxfajr21yqv1fe1caq",gtmpreview:"env-1",figsharepluginurl:"https://widgets.figshare.com/static/figshare.js",figshareapiurl:"https://api.figshare.com/v2/collections/search",figsharetimeout:3000,crossmarkpublisheddate:"2015/08/24",googlerecaptchasitekey:"6ldg3i0uaaaaaoc4quh35ubhgjotehp_stxhgr_v",googlerecaptchakeyname:"frontiersrecaptchav2",faviconsize16:"https://static2.frontiersin.org/static-resources/tenants/frontiers/favicon_16-tenantfavicon-frontiers.png",faviconsize32:"https://static2.frontiersin.org/static-resources/tenants/frontiers/favicon_32-tenantfavicon-frontiers.png",faviconsize180:"https://static2.frontiersin.org/static-resources/tenants/frontiers/favicon_180-tenantfavicon-frontiers.png",faviconsize192:"https://static2.frontiersin.org/static-resources/tenants/frontiers/favicon_192-tenantfavicon-frontiers.png",faviconsize512:"https://static2.frontiersin.org/static-resources/tenants/frontiers/favicon_512-tenantfavicon-frontiers.png",socialmediaimg:"https://brand.frontiersin.org/m/1c8bcb536c789e11/guidelines-frontiers_logo_1200x628_1-91to1.png",linkedarticlecopytext:"'{\"articletypecopytext\":[{\"articletypeid\":0,\"originalarticlecopytext\":\"part of this article's content has been mentioned in:\",\"linkedarticlecopytext\":\"this article mentions parts of:\"},{\"articletypeid\":122,\"originalarticlecopytext\":\"parts of this article's content have been modified or rectified in:\",\"linkedarticlecopytext\":\"this article is an erratum on:\"},{\"articletypeid\":129,\"originalarticlecopytext\":\"parts of this article's content have been modified or rectified in:\",\"linkedarticlecopytext\":\"this article is an addendum to:\"},{\"articletypeid\":128,\"originalarticlecopytext\":\"a correction has been applied to this article in:\",\"linkedarticlecopytext\":\"this article is a correction to:\"},{\"articletypeid\":134,\"originalarticlecopytext\":\"a retraction of this article was approved in:\",\"linkedarticlecopytext\":\"this article is a retraction of:\"},{\"articletypeid\":29,\"originalarticlecopytext\":\"a commentary has been posted on this article:\",\"linkedarticlecopytext\":\"this article is a commentary on:\"},{\"articletypeid\":30,\"originalarticlecopytext\":\"a commentary has been posted on this article:\",\"linkedarticlecopytext\":\"this article is a commentary on:\"}],\"articleidcopytext\":[]}'\n",acceptedarticleexcludedjournalids:"'[2766,979]'\n",articletypeconfigurablelabel:"\u003c\u003carticle-type:uppercase>> article",settingsfeaturesswitchers:"'{\"displaytitlepilllabels\":true,\"displayrelatedarticlesbox\":true,\"showeditors\":true,\"showreviewers\":true,\"showloopimpactlink\":true,\"enablefigshare\":false,\"usexmlimages\":true}'\n",journalswitharticlehub:"'{\"strings\":[\"science\"]}'\n",terminologysettings:"'{\"terms\":[{\"sequencenumber\":1,\"key\":\"frontiers\",\"tenantterm\":\"frontiers\",\"frontiersdefaultterm\":\"frontiers\",\"category\":\"customer\"},{\"sequencenumber\":2,\"key\":\"submission_system\",\"tenantterm\":\"submission system\",\"frontiersdefaultterm\":\"submission system\",\"category\":\"product\"},{\"sequencenumber\":3,\"key\":\"public_pages\",\"tenantterm\":\"public pages\",\"frontiersdefaultterm\":\"public pages\",\"category\":\"product\"},{\"sequencenumber\":4,\"key\":\"my_frontiers\",\"tenantterm\":\"my frontiers\",\"frontiersdefaultterm\":\"my frontiers\",\"category\":\"product\"},{\"sequencenumber\":5,\"key\":\"digital_editorial_office\",\"tenantterm\":\"digital editorial office\",\"frontiersdefaultterm\":\"digital editorial office\",\"category\":\"product\"},{\"sequencenumber\":6,\"key\":\"deo\",\"tenantterm\":\"deo\",\"frontiersdefaultterm\":\"deo\",\"category\":\"product\"},{\"sequencenumber\":7,\"key\":\"digital_editorial_office_for_chiefs\",\"tenantterm\":\"digital editorial office for chiefs\",\"frontiersdefaultterm\":\"digital editorial office for chiefs\",\"category\":\"product\"},{\"sequencenumber\":8,\"key\":\"digital_editorial_office_for_eof\",\"tenantterm\":\"digital editorial office for eof\",\"frontiersdefaultterm\":\"digital editorial office for eof\",\"category\":\"product\"},{\"sequencenumber\":9,\"key\":\"editorial_office\",\"tenantterm\":\"editorial office\",\"frontiersdefaultterm\":\"editorial office\",\"category\":\"product\"},{\"sequencenumber\":10,\"key\":\"eof\",\"tenantterm\":\"eof\",\"frontiersdefaultterm\":\"eof\",\"category\":\"product\"},{\"sequencenumber\":11,\"key\":\"research_topic_management\",\"tenantterm\":\"research topic management\",\"frontiersdefaultterm\":\"research topic management\",\"category\":\"product\"},{\"sequencenumber\":12,\"key\":\"review_forum\",\"tenantterm\":\"review forum\",\"frontiersdefaultterm\":\"review forum\",\"category\":\"product\"},{\"sequencenumber\":13,\"key\":\"accounting_office\",\"tenantterm\":\"accounting office\",\"frontiersdefaultterm\":\"accounting office\",\"category\":\"product\"},{\"sequencenumber\":14,\"key\":\"aof\",\"tenantterm\":\"aof\",\"frontiersdefaultterm\":\"aof\",\"category\":\"product\"},{\"sequencenumber\":15,\"key\":\"publishing_office\",\"tenantterm\":\"publishing office\",\"frontiersdefaultterm\":\"publishing office\",\"category\":\"product\"},{\"sequencenumber\":16,\"key\":\"production_office\",\"tenantterm\":\"production office forum\",\"frontiersdefaultterm\":\"production office forum\",\"category\":\"product\"},{\"sequencenumber\":17,\"key\":\"pof\",\"tenantterm\":\"pof\",\"frontiersdefaultterm\":\"pof\",\"category\":\"product\"},{\"sequencenumber\":18,\"key\":\"book_office_forum\",\"tenantterm\":\"book office forum\",\"frontiersdefaultterm\":\"book office forum\",\"category\":\"product\"},{\"sequencenumber\":19,\"key\":\"bof\",\"tenantterm\":\"bof\",\"frontiersdefaultterm\":\"bof\",\"category\":\"product\"},{\"sequencenumber\":20,\"key\":\"aira\",\"tenantterm\":\"aira\",\"frontiersdefaultterm\":\"aira\",\"category\":\"product\"},{\"sequencenumber\":21,\"key\":\"editorial_board_management\",\"tenantterm\":\"editorial board management\",\"frontiersdefaultterm\":\"editorial board management\",\"category\":\"product\"},{\"sequencenumber\":22,\"key\":\"ebm\",\"tenantterm\":\"ebm\",\"frontiersdefaultterm\":\"ebm\",\"category\":\"product\"},{\"sequencenumber\":23,\"key\":\"domain\",\"tenantterm\":\"domain\",\"frontiersdefaultterm\":\"domain\",\"category\":\"taxonomy\"},{\"sequencenumber\":24,\"key\":\"journal\",\"tenantterm\":\"journal\",\"frontiersdefaultterm\":\"journal\",\"category\":\"taxonomy\"},{\"sequencenumber\":25,\"key\":\"section\",\"tenantterm\":\"section\",\"frontiersdefaultterm\":\"section\",\"category\":\"taxonomy\"},{\"sequencenumber\":26,\"key\":\"domains\",\"tenantterm\":\"domains\",\"frontiersdefaultterm\":\"domains\",\"category\":\"taxonomy\"},{\"sequencenumber\":27,\"key\":\"specialty_section\",\"tenantterm\":\"specialty section\",\"frontiersdefaultterm\":\"specialty section\",\"category\":\"taxonomy\"},{\"sequencenumber\":28,\"key\":\"specialty_journal\",\"tenantterm\":\"specialty journal\",\"frontiersdefaultterm\":\"specialty journal\",\"category\":\"taxonomy\"},{\"sequencenumber\":29,\"key\":\"journals\",\"tenantterm\":\"journals\",\"frontiersdefaultterm\":\"journals\",\"category\":\"taxonomy\"},{\"sequencenumber\":30,\"key\":\"sections\",\"tenantterm\":\"sections\",\"frontiersdefaultterm\":\"sections\",\"category\":\"taxonomy\"},{\"sequencenumber\":31,\"key\":\"specialty_sections\",\"tenantterm\":\"specialty sections\",\"frontiersdefaultterm\":\"specialty sections\",\"category\":\"taxonomy\"},{\"sequencenumber\":32,\"key\":\"specialty_journals\",\"tenantterm\":\"specialty journals\",\"frontiersdefaultterm\":\"specialty journals\",\"category\":\"taxonomy\"},{\"sequencenumber\":33,\"key\":\"manuscript\",\"tenantterm\":\"manuscript\",\"frontiersdefaultterm\":\"manuscript\",\"category\":\"core\"},{\"sequencenumber\":34,\"key\":\"manuscripts\",\"tenantterm\":\"manuscripts\",\"frontiersdefaultterm\":\"manuscripts\",\"category\":\"core\"},{\"sequencenumber\":35,\"key\":\"article\",\"tenantterm\":\"article\",\"frontiersdefaultterm\":\"article\",\"category\":\"core\"},{\"sequencenumber\":36,\"key\":\"articles\",\"tenantterm\":\"articles\",\"frontiersdefaultterm\":\"articles\",\"category\":\"core\"},{\"sequencenumber\":37,\"key\":\"article_type\",\"tenantterm\":\"article type\",\"frontiersdefaultterm\":\"article type\",\"category\":\"core\"},{\"sequencenumber\":38,\"key\":\"article_types\",\"tenantterm\":\"article types\",\"frontiersdefaultterm\":\"article types\",\"category\":\"core\"},{\"sequencenumber\":39,\"key\":\"author\",\"tenantterm\":\"author\",\"frontiersdefaultterm\":\"author\",\"category\":\"label (role)\"},{\"sequencenumber\":40,\"key\":\"authors\",\"tenantterm\":\"authors\",\"frontiersdefaultterm\":\"authors\",\"category\":\"label (role)\"},{\"sequencenumber\":41,\"key\":\"authoring\",\"tenantterm\":\"authoring\",\"frontiersdefaultterm\":\"authoring\",\"category\":\"core\"},{\"sequencenumber\":42,\"key\":\"authored\",\"tenantterm\":\"authored\",\"frontiersdefaultterm\":\"authored\",\"category\":\"core\"},{\"sequencenumber\":43,\"key\":\"accept\",\"tenantterm\":\"accept\",\"frontiersdefaultterm\":\"accept\",\"category\":\"process\"},{\"sequencenumber\":44,\"key\":\"accepted\",\"tenantterm\":\"accepted\",\"frontiersdefaultterm\":\"accepted\",\"category\":\"process\"},{\"sequencenumber\":45,\"key\":\"assistant_field_chief_editor\",\"tenantterm\":\"assistant field chief editor\",\"frontiersdefaultterm\":\"assistant field chief editor\",\"description\":\"an editorial role on a field journal that a registered user may hold. this gives them rights to different functionality and parts of the platform\",\"category\":\"label (role)\"},{\"sequencenumber\":46,\"key\":\"assistant_specialty_chief_editor\",\"tenantterm\":\"assistant specialty chief editor\",\"frontiersdefaultterm\":\"assistant specialty chief editor\",\"description\":\"an editorial role on a specialty that a registered user may hold. this gives them rights to different functionality and parts of the platform\",\"category\":\"label (role)\"},{\"sequencenumber\":47,\"key\":\"assistant_specialty_chief_editors\",\"tenantterm\":\"assistant specialty chief editors\",\"frontiersdefaultterm\":\"assistant specialty chief editors\",\"category\":\"label (role)\"},{\"sequencenumber\":48,\"key\":\"associate_editor\",\"tenantterm\":\"associate editor\",\"frontiersdefaultterm\":\"associate editor\",\"description\":\"an editorial role on a specialty that a registered user may hold. this gives them rights to different functionality and parts of the platform\",\"category\":\"label (role)\"},{\"sequencenumber\":49,\"key\":\"specialty_chief_editor\",\"tenantterm\":\"specialty chief editor\",\"frontiersdefaultterm\":\"specialty chief editor\",\"description\":\"an editorial role on a specialty that a registered user may hold. this gives them rights to different functionality and parts of the platform\",\"category\":\"label (role)\"},{\"sequencenumber\":50,\"key\":\"specialty_chief_editors\",\"tenantterm\":\"specialty chief editors\",\"frontiersdefaultterm\":\"specialty chief editors\",\"category\":\"label (role)\"},{\"sequencenumber\":51,\"key\":\"chief_editor\",\"tenantterm\":\"chief editor\",\"frontiersdefaultterm\":\"chief editor\",\"category\":\"label (role)\"},{\"sequencenumber\":52,\"key\":\"chief_editors\",\"tenantterm\":\"chief editors\",\"frontiersdefaultterm\":\"chief editors\",\"category\":\"label (role)\"},{\"sequencenumber\":53,\"key\":\"call_for_participation\",\"tenantterm\":\"call for participation\",\"frontiersdefaultterm\":\"call for participation\",\"category\":\"process\"},{\"sequencenumber\":54,\"key\":\"citation\",\"tenantterm\":\"citation\",\"frontiersdefaultterm\":\"citation\",\"category\":\"misc.\"},{\"sequencenumber\":55,\"key\":\"citations\",\"tenantterm\":\"citations\",\"frontiersdefaultterm\":\"citations\",\"category\":\"misc.\"},{\"sequencenumber\":56,\"key\":\"contributor\",\"tenantterm\":\"contributor\",\"frontiersdefaultterm\":\"contributor\",\"category\":\"label (role)\"},{\"sequencenumber\":57,\"key\":\"contributors\",\"tenantterm\":\"contributors\",\"frontiersdefaultterm\":\"contributors\",\"category\":\"label (role)\"},{\"sequencenumber\":58,\"key\":\"corresponding_author\",\"tenantterm\":\"corresponding author\",\"frontiersdefaultterm\":\"corresponding author\",\"category\":\"label (role)\"},{\"sequencenumber\":59,\"key\":\"corresponding_authors\",\"tenantterm\":\"corresponding authors\",\"frontiersdefaultterm\":\"corresponding authors\",\"category\":\"label (role)\"},{\"sequencenumber\":60,\"key\":\"decline\",\"tenantterm\":\"decline\",\"frontiersdefaultterm\":\"decline\",\"category\":\"process\"},{\"sequencenumber\":61,\"key\":\"declined\",\"tenantterm\":\"declined\",\"frontiersdefaultterm\":\"declined\",\"category\":\"process\"},{\"sequencenumber\":62,\"key\":\"reject\",\"tenantterm\":\"reject\",\"frontiersdefaultterm\":\"reject\",\"category\":\"process\"},{\"sequencenumber\":63,\"key\":\"rejected\",\"tenantterm\":\"rejected\",\"frontiersdefaultterm\":\"rejected\",\"category\":\"process\"},{\"sequencenumber\":64,\"key\":\"publish\",\"tenantterm\":\"publish\",\"frontiersdefaultterm\":\"publish\",\"category\":\"core\"},{\"sequencenumber\":65,\"key\":\"published\",\"tenantterm\":\"published\",\"frontiersdefaultterm\":\"published\",\"category\":\"core\"},{\"sequencenumber\":66,\"key\":\"publication\",\"tenantterm\":\"publication\",\"frontiersdefaultterm\":\"publication\",\"category\":\"core\"},{\"sequencenumber\":67,\"key\":\"peer_review\",\"tenantterm\":\"peer review\",\"frontiersdefaultterm\":\"peer review\",\"category\":\"peer review process\"},{\"sequencenumber\":68,\"key\":\"peer_reviewed\",\"tenantterm\":\"peer reviewed\",\"frontiersdefaultterm\":\"peer reviewed\",\"category\":\"peer review process\"},{\"sequencenumber\":69,\"key\":\"initial_validation\",\"tenantterm\":\"initial validation\",\"frontiersdefaultterm\":\"initial validation\",\"category\":\"peer review process\"},{\"sequencenumber\":70,\"key\":\"editorial_assignment\",\"tenantterm\":\"editorial assignment\",\"frontiersdefaultterm\":\"editorial assignment\",\"category\":\"peer review process\"},{\"sequencenumber\":71,\"key\":\"independent_review\",\"tenantterm\":\"independent review\",\"frontiersdefaultterm\":\"independent review\",\"category\":\"peer review process\"},{\"sequencenumber\":72,\"key\":\"interactive_review\",\"tenantterm\":\"interactive review\",\"frontiersdefaultterm\":\"interactive review\",\"category\":\"peer review process\"},{\"sequencenumber\":73,\"key\":\"review\",\"tenantterm\":\"review\",\"frontiersdefaultterm\":\"review\",\"category\":\"peer review process\"},{\"sequencenumber\":74,\"key\":\"reviewing\",\"tenantterm\":\"reviewing\",\"frontiersdefaultterm\":\"reviewing\",\"category\":\"peer review process\"},{\"sequencenumber\":75,\"key\":\"reviewer\",\"tenantterm\":\"reviewer\",\"frontiersdefaultterm\":\"reviewer\",\"category\":\"label (role)\"},{\"sequencenumber\":76,\"key\":\"reviewers\",\"tenantterm\":\"reviewers\",\"frontiersdefaultterm\":\"reviewers\",\"category\":\"label (role)\"},{\"sequencenumber\":77,\"key\":\"review_finalized\",\"tenantterm\":\"review finalized\",\"frontiersdefaultterm\":\"review finalized\",\"category\":\"peer review process\"},{\"sequencenumber\":78,\"key\":\"final_decision\",\"tenantterm\":\"final decision\",\"frontiersdefaultterm\":\"final decision\",\"category\":\"peer review process\"},{\"sequencenumber\":79,\"key\":\"final_validation\",\"tenantterm\":\"final validation\",\"frontiersdefaultterm\":\"final validation\",\"category\":\"peer review process\"},{\"sequencenumber\":80,\"key\":\"ae_accept_manuscript\",\"tenantterm\":\"recommend to accept manuscript\",\"frontiersdefaultterm\":\"accept manuscript\",\"category\":\"process\"},{\"sequencenumber\":81,\"key\":\"fee\",\"tenantterm\":\"fee\",\"frontiersdefaultterm\":\"fee\",\"category\":\"accounting\"},{\"sequencenumber\":82,\"key\":\"fees\",\"tenantterm\":\"fees\",\"frontiersdefaultterm\":\"fees\",\"category\":\"accounting\"},{\"sequencenumber\":83,\"key\":\"guest_associate_editor\",\"tenantterm\":\"guest associate editor\",\"frontiersdefaultterm\":\"guest associate editor\",\"category\":\"label (role)\"},{\"sequencenumber\":84,\"key\":\"guest_associate_editors\",\"tenantterm\":\"guest associate editors\",\"frontiersdefaultterm\":\"guest associate editors\",\"category\":\"label (role)\"},{\"sequencenumber\":85,\"key\":\"in_review\",\"tenantterm\":\"in review\",\"frontiersdefaultterm\":\"in review\",\"category\":\"peer review process\"},{\"sequencenumber\":86,\"key\":\"institutional_member\",\"tenantterm\":\"institutional partner\",\"frontiersdefaultterm\":\"institutional partner\",\"category\":\"accounting\"},{\"sequencenumber\":87,\"key\":\"institutional_membership\",\"tenantterm\":\"institutional partnership\",\"frontiersdefaultterm\":\"institutional partnership\",\"category\":\"accounting\"},{\"sequencenumber\":88,\"key\":\"article_processing_charge\",\"tenantterm\":\"article processing charge\",\"frontiersdefaultterm\":\"article processing charge\",\"category\":\"accounting\"},{\"sequencenumber\":89,\"key\":\"article_processing_charges\",\"tenantterm\":\"article processing charges\",\"frontiersdefaultterm\":\"article processing charges\",\"category\":\"accounting\"},{\"sequencenumber\":90,\"key\":\"apcs\",\"tenantterm\":\"apcs\",\"frontiersdefaultterm\":\"apcs\",\"category\":\"accounting\"},{\"sequencenumber\":91,\"key\":\"apc\",\"tenantterm\":\"apc\",\"frontiersdefaultterm\":\"apc\",\"category\":\"accounting\"},{\"sequencenumber\":92,\"key\":\"received\",\"tenantterm\":\"received\",\"frontiersdefaultterm\":\"received\",\"description\":\"date manuscript was received on.\",\"category\":\"core\"},{\"sequencenumber\":93,\"key\":\"transferred\",\"tenantterm\":\"transferred\",\"frontiersdefaultterm\":\"transferred\",\"category\":\"core\"},{\"sequencenumber\":94,\"key\":\"transfer\",\"tenantterm\":\"transfer\",\"frontiersdefaultterm\":\"transfer\",\"category\":\"core\"},{\"sequencenumber\":95,\"key\":\"research_topic\",\"tenantterm\":\"research topic\",\"frontiersdefaultterm\":\"research topic\",\"category\":\"core\"},{\"sequencenumber\":96,\"key\":\"research_topics\",\"tenantterm\":\"research topics\",\"frontiersdefaultterm\":\"research topics\",\"category\":\"core\"},{\"sequencenumber\":97,\"key\":\"topic_editor\",\"tenantterm\":\"topic editor\",\"frontiersdefaultterm\":\"topic editor\",\"category\":\"label (role)\"},{\"sequencenumber\":98,\"key\":\"review_editor\",\"tenantterm\":\"community reviewer\",\"frontiersdefaultterm\":\"review editor\",\"category\":\"label (role)\"},{\"sequencenumber\":99,\"key\":\"title\",\"tenantterm\":\"title\",\"frontiersdefaultterm\":\"title\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":100,\"key\":\"running_title\",\"tenantterm\":\"running title\",\"frontiersdefaultterm\":\"running title\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":101,\"key\":\"submit\",\"tenantterm\":\"submit\",\"frontiersdefaultterm\":\"submit\",\"category\":\"process\"},{\"sequencenumber\":102,\"key\":\"submitted\",\"tenantterm\":\"submitted\",\"frontiersdefaultterm\":\"submitted\",\"category\":\"process\"},{\"sequencenumber\":103,\"key\":\"submitting\",\"tenantterm\":\"submitting\",\"frontiersdefaultterm\":\"submitting\",\"category\":\"process\"},{\"sequencenumber\":104,\"key\":\"t_e\",\"tenantterm\":\"te\",\"frontiersdefaultterm\":\"te\",\"category\":\"label (role)\"},{\"sequencenumber\":105,\"key\":\"topic\",\"tenantterm\":\"topic\",\"frontiersdefaultterm\":\"topic\",\"category\":\"process\"},{\"sequencenumber\":106,\"key\":\"topic_summary\",\"tenantterm\":\"topic summary\",\"frontiersdefaultterm\":\"topic summary\",\"category\":\"process\"},{\"sequencenumber\":107,\"key\":\"figure\",\"tenantterm\":\"figure\",\"frontiersdefaultterm\":\"figure\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":108,\"key\":\"figures\",\"tenantterm\":\"figures\",\"frontiersdefaultterm\":\"figures\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":109,\"key\":\"editorial_file\",\"tenantterm\":\"editorial file\",\"frontiersdefaultterm\":\"editorial file\",\"category\":\"core\"},{\"sequencenumber\":110,\"key\":\"editorial_files\",\"tenantterm\":\"editorial files\",\"frontiersdefaultterm\":\"editorial files\",\"category\":\"core\"},{\"sequencenumber\":111,\"key\":\"e_book\",\"tenantterm\":\"e-book\",\"frontiersdefaultterm\":\"e-book\",\"category\":\"core\"},{\"sequencenumber\":112,\"key\":\"organization\",\"tenantterm\":\"organization\",\"frontiersdefaultterm\":\"organization\",\"category\":\"core\"},{\"sequencenumber\":113,\"key\":\"institution\",\"tenantterm\":\"institution\",\"frontiersdefaultterm\":\"institution\",\"category\":\"core\"},{\"sequencenumber\":114,\"key\":\"reference\",\"tenantterm\":\"reference\",\"frontiersdefaultterm\":\"reference\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":115,\"key\":\"references\",\"tenantterm\":\"references\",\"frontiersdefaultterm\":\"references\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":116,\"key\":\"sce\",\"tenantterm\":\"sce\",\"frontiersdefaultterm\":\"sce\",\"description\":\"abbreviation for specialty chief editor\",\"category\":\"label (role)\"},{\"sequencenumber\":117,\"key\":\"submission\",\"tenantterm\":\"submission\",\"frontiersdefaultterm\":\"submission\",\"category\":\"process\"},{\"sequencenumber\":118,\"key\":\"submissions\",\"tenantterm\":\"submissions\",\"frontiersdefaultterm\":\"submissions\",\"category\":\"process\"},{\"sequencenumber\":119,\"key\":\"editing\",\"tenantterm\":\"editing\",\"frontiersdefaultterm\":\"editing\",\"category\":\"process\"},{\"sequencenumber\":120,\"key\":\"in_preparation\",\"tenantterm\":\"in preparation\",\"frontiersdefaultterm\":\"in preparation\",\"category\":\"process\"},{\"sequencenumber\":121,\"key\":\"country_region\",\"tenantterm\":\"country/region\",\"frontiersdefaultterm\":\"country/region\",\"description\":\"because of political issues, some of the country listings are actually classified as `regions` and we need to include this. however other clients may not want to do this.\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":122,\"key\":\"countries_regions\",\"tenantterm\":\"countries/regions\",\"frontiersdefaultterm\":\"countries/regions\",\"description\":\"because of political issues, some of the country listings are actually classified as `regions` and we need to include this. however other clients may not want to do this.\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":123,\"key\":\"specialty\",\"tenantterm\":\"specialty\",\"frontiersdefaultterm\":\"specialty\",\"category\":\"core\"},{\"sequencenumber\":124,\"key\":\"specialties\",\"tenantterm\":\"specialties\",\"frontiersdefaultterm\":\"specialties\",\"category\":\"core\"},{\"sequencenumber\":125,\"key\":\"associate_editors\",\"tenantterm\":\"associate editors\",\"frontiersdefaultterm\":\"associate editors\",\"description\":\"an editorial role on a specialty that a registered user may hold. this gives them rights to different functionality and parts of the platform\",\"category\":\"label (role)\"},{\"sequencenumber\":126,\"key\":\"reviewed\",\"tenantterm\":\"reviewed\",\"frontiersdefaultterm\":\"reviewed\",\"category\":\"peer review process\"},{\"sequencenumber\":127,\"key\":\"institutional_members\",\"tenantterm\":\"institutional partners\",\"frontiersdefaultterm\":\"institutional partners\",\"category\":\"accounting\"},{\"sequencenumber\":128,\"key\":\"institutional_memberships\",\"tenantterm\":\"institutional partnerships\",\"frontiersdefaultterm\":\"institutional partnerships\",\"category\":\"accounting\"},{\"sequencenumber\":129,\"key\":\"assistant_field_chief_editors\",\"tenantterm\":\"assistant field chief editors\",\"frontiersdefaultterm\":\"assistant field chief editors\",\"category\":\"label (role)\"},{\"sequencenumber\":130,\"key\":\"publications\",\"tenantterm\":\"publications\",\"frontiersdefaultterm\":\"publications\",\"category\":\"process\"},{\"sequencenumber\":131,\"key\":\"ae_accepted\",\"tenantterm\":\"recommended acceptance\",\"frontiersdefaultterm\":\"accepted\",\"category\":\"process\"},{\"sequencenumber\":132,\"key\":\"field_journal\",\"tenantterm\":\"field journal\",\"frontiersdefaultterm\":\"field journal\",\"category\":\"taxonomy\"},{\"sequencenumber\":133,\"key\":\"field_journals\",\"tenantterm\":\"field journals\",\"frontiersdefaultterm\":\"field journals\",\"category\":\"taxonomy\"},{\"sequencenumber\":134,\"key\":\"program_manager\",\"tenantterm\":\"program manager\",\"frontiersdefaultterm\":\"program manager\",\"category\":\"label (role)\"},{\"sequencenumber\":135,\"key\":\"journal_manager\",\"tenantterm\":\"journal manager\",\"frontiersdefaultterm\":\"journal manager\",\"category\":\"label (role)\"},{\"sequencenumber\":136,\"key\":\"journal_specialist\",\"tenantterm\":\"journal specialist\",\"frontiersdefaultterm\":\"journal specialist\",\"category\":\"label (role)\"},{\"sequencenumber\":137,\"key\":\"program_managers\",\"tenantterm\":\"program managers\",\"frontiersdefaultterm\":\"program managers\",\"category\":\"label (role)\"},{\"sequencenumber\":138,\"key\":\"journal_managers\",\"tenantterm\":\"journal managers\",\"frontiersdefaultterm\":\"journal managers\",\"category\":\"label (role)\"},{\"sequencenumber\":139,\"key\":\"journal_specialists\",\"tenantterm\":\"journal specialists\",\"frontiersdefaultterm\":\"journal specialists\",\"category\":\"label (role)\"},{\"sequencenumber\":140,\"key\":\"cover_letter\",\"tenantterm\":\"manuscript contribution to the field\",\"frontiersdefaultterm\":\"manuscript contribution to the field\",\"category\":\"process\"},{\"sequencenumber\":141,\"key\":\"ae_accepted_manuscript\",\"tenantterm\":\"recommended to accept manuscript\",\"frontiersdefaultterm\":\"accepted manuscript\",\"category\":\"process\"},{\"sequencenumber\":142,\"key\":\"recommend_for_rejection\",\"tenantterm\":\"recommend for rejection\",\"frontiersdefaultterm\":\"recommend for rejection\",\"category\":\"process\"},{\"sequencenumber\":143,\"key\":\"recommended_for_rejection\",\"tenantterm\":\"recommended for rejection\",\"frontiersdefaultterm\":\"recommended for rejection\",\"category\":\"process\"},{\"sequencenumber\":144,\"key\":\"ae\",\"tenantterm\":\"ae\",\"frontiersdefaultterm\":\"ae\",\"description\":\"associate editor - board member\",\"category\":\"label (role)\"},{\"sequencenumber\":145,\"key\":\"re\",\"tenantterm\":\"re\",\"frontiersdefaultterm\":\"re\",\"description\":\"review editor\",\"category\":\"label (role)\"},{\"sequencenumber\":146,\"key\":\"rev\",\"tenantterm\":\"rev\",\"frontiersdefaultterm\":\"rev\",\"description\":\"reviewer\",\"category\":\"label (role)\"},{\"sequencenumber\":147,\"key\":\"aut\",\"tenantterm\":\"aut\",\"frontiersdefaultterm\":\"aut\",\"description\":\"author\",\"category\":\"label (role)\"},{\"sequencenumber\":148,\"key\":\"coraut\",\"tenantterm\":\"coraut\",\"frontiersdefaultterm\":\"coraut\",\"description\":\"corresponding author\",\"category\":\"label (role)\"},{\"sequencenumber\":149,\"key\":\"saut\",\"tenantterm\":\"saut\",\"frontiersdefaultterm\":\"saut\",\"description\":\"submitting author\",\"category\":\"label (role)\"},{\"sequencenumber\":150,\"key\":\"coaut\",\"tenantterm\":\"coaut\",\"frontiersdefaultterm\":\"coaut\",\"description\":\"co-author\",\"category\":\"label (role)\"},{\"sequencenumber\":151,\"key\":\"tsof\",\"tenantterm\":\"tsof\",\"frontiersdefaultterm\":\"tsof\",\"description\":\"typesetter\",\"category\":\"label (role)\"},{\"sequencenumber\":152,\"key\":\"typesetting_office\",\"tenantterm\":\"typesetting office\",\"frontiersdefaultterm\":\"typesetting office\",\"category\":\"product\"},{\"sequencenumber\":153,\"key\":\"config\",\"tenantterm\":\"config\",\"frontiersdefaultterm\":\"config\",\"description\":\"configuration office role\",\"category\":\"label (role)\"},{\"sequencenumber\":154,\"key\":\"jm\",\"tenantterm\":\"jm\",\"frontiersdefaultterm\":\"jm\",\"description\":\"journal manager\",\"category\":\"label (role)\"},{\"sequencenumber\":155,\"key\":\"rte\",\"tenantterm\":\"rte\",\"frontiersdefaultterm\":\"rte\",\"description\":\"research topic editor\",\"category\":\"label (role)\"},{\"sequencenumber\":156,\"key\":\"organizations\",\"tenantterm\":\"organizations\",\"frontiersdefaultterm\":\"organizations\",\"category\":\"core\"},{\"sequencenumber\":157,\"key\":\"publishing\",\"tenantterm\":\"publishing\",\"frontiersdefaultterm\":\"publishing\",\"category\":\"core\"},{\"sequencenumber\":158,\"key\":\"acceptance\",\"tenantterm\":\"acceptance\",\"frontiersdefaultterm\":\"acceptance\",\"category\":\"process\"},{\"sequencenumber\":159,\"key\":\"preferred_associate_editor\",\"tenantterm\":\"preferred associate editor\",\"frontiersdefaultterm\":\"preferred associate editor\",\"category\":\"label (role)\"},{\"sequencenumber\":160,\"key\":\"topic_editors\",\"tenantterm\":\"topic editors\",\"frontiersdefaultterm\":\"topic editors\",\"category\":\"label (role)\"},{\"sequencenumber\":161,\"key\":\"institutions\",\"tenantterm\":\"institutions\",\"frontiersdefaultterm\":\"institutions\",\"category\":\"core\"},{\"sequencenumber\":162,\"key\":\"author(s)\",\"tenantterm\":\"author(s)\",\"frontiersdefaultterm\":\"author(s)\",\"category\":\"label (role)\"},{\"sequencenumber\":163,\"key\":\"figure(s)\",\"tenantterm\":\"figure(s)\",\"frontiersdefaultterm\":\"figure(s)\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":164,\"key\":\"co-authors\",\"tenantterm\":\"co-authors\",\"frontiersdefaultterm\":\"co-authors\",\"description\":\"co-authors\",\"category\":\"label (role)\"},{\"sequencenumber\":165,\"key\":\"editorial_board_members\",\"tenantterm\":\"editorial board members\",\"frontiersdefaultterm\":\"editorial board members\",\"description\":\"editorial board members\",\"category\":\"label (role)\"},{\"sequencenumber\":166,\"key\":\"editorial_board\",\"tenantterm\":\"editorial board\",\"frontiersdefaultterm\":\"editorial board\",\"description\":\"editorial board\",\"category\":\"product\"},{\"sequencenumber\":167,\"key\":\"co-authorship\",\"tenantterm\":\"co-authorship\",\"frontiersdefaultterm\":\"co-authorship\",\"description\":\"co-authorship\",\"category\":\"misc.\"},{\"sequencenumber\":168,\"key\":\"role_id_1\",\"tenantterm\":\"registration office\",\"frontiersdefaultterm\":\"registration office\",\"category\":\"user role\"},{\"sequencenumber\":169,\"key\":\"role_id_2\",\"tenantterm\":\"editorial office\",\"frontiersdefaultterm\":\"editorial office\",\"category\":\"user role\"},{\"sequencenumber\":170,\"key\":\"role_id_7\",\"tenantterm\":\"field chief editor\",\"frontiersdefaultterm\":\"field chief editor\",\"category\":\"user role\"},{\"sequencenumber\":171,\"key\":\"role_id_8\",\"tenantterm\":\"assistant field chief editor\",\"frontiersdefaultterm\":\"assistant field chief editor\",\"category\":\"user role\"},{\"sequencenumber\":172,\"key\":\"role_id_9\",\"tenantterm\":\"specialty chief editor\",\"frontiersdefaultterm\":\"specialty chief editor\",\"category\":\"user role\"},{\"sequencenumber\":173,\"key\":\"role_id_10\",\"tenantterm\":\"assistant specialty chief editor\",\"frontiersdefaultterm\":\"assistant specialty chief editor\",\"category\":\"user role\"},{\"sequencenumber\":174,\"key\":\"role_id_11\",\"tenantterm\":\"associate editor\",\"frontiersdefaultterm\":\"associate editor\",\"category\":\"user role\"},{\"sequencenumber\":175,\"key\":\"role_id_12\",\"tenantterm\":\"guest associate editor\",\"frontiersdefaultterm\":\"guest associate editor\",\"category\":\"user role\"},{\"sequencenumber\":176,\"key\":\"role_id_13\",\"tenantterm\":\"review editor\",\"frontiersdefaultterm\":\"review editor\",\"category\":\"user role\"},{\"sequencenumber\":177,\"key\":\"role_id_14\",\"tenantterm\":\"reviewer\",\"frontiersdefaultterm\":\"reviewer\",\"category\":\"user role\"},{\"sequencenumber\":178,\"key\":\"role_id_15\",\"tenantterm\":\"author\",\"frontiersdefaultterm\":\"author\",\"category\":\"user role\"},{\"sequencenumber\":179,\"key\":\"role_id_16\",\"tenantterm\":\"corresponding author\",\"frontiersdefaultterm\":\"corresponding author\",\"category\":\"user role\"},{\"sequencenumber\":180,\"key\":\"role_id_17\",\"tenantterm\":\"submitting author\",\"frontiersdefaultterm\":\"submitting author\",\"category\":\"user role\"},{\"sequencenumber\":181,\"key\":\"role_id_18\",\"tenantterm\":\"co-author\",\"frontiersdefaultterm\":\"co-author\",\"category\":\"user role\"},{\"sequencenumber\":182,\"key\":\"role_id_20\",\"tenantterm\":\"production office\",\"frontiersdefaultterm\":\"production office\",\"category\":\"user role\"},{\"sequencenumber\":183,\"key\":\"role_id_22\",\"tenantterm\":\"typesetting office (typesetter)\",\"frontiersdefaultterm\":\"typesetting office (typesetter)\",\"category\":\"user role\"},{\"sequencenumber\":184,\"key\":\"role_id_24\",\"tenantterm\":\"registered user\",\"frontiersdefaultterm\":\"registered user\",\"category\":\"user role\"},{\"sequencenumber\":185,\"key\":\"role_id_35\",\"tenantterm\":\"job office\",\"frontiersdefaultterm\":\"job office\",\"category\":\"user role\"},{\"sequencenumber\":186,\"key\":\"role_id_41\",\"tenantterm\":\"special event administrator\",\"frontiersdefaultterm\":\"special event administrator\",\"category\":\"user role\"},{\"sequencenumber\":187,\"key\":\"role_id_42\",\"tenantterm\":\"special event reviewer\",\"frontiersdefaultterm\":\"special event reviewer\",\"category\":\"user role\"},{\"sequencenumber\":188,\"key\":\"role_id_43\",\"tenantterm\":\"submit abstract\",\"frontiersdefaultterm\":\"submit abstract\",\"category\":\"user role\"},{\"sequencenumber\":189,\"key\":\"role_id_52\",\"tenantterm\":\"events office\",\"frontiersdefaultterm\":\"events office\",\"category\":\"user role\"},{\"sequencenumber\":190,\"key\":\"role_id_53\",\"tenantterm\":\"event administrator\",\"frontiersdefaultterm\":\"event administrator\",\"category\":\"user role\"},{\"sequencenumber\":191,\"key\":\"role_id_89\",\"tenantterm\":\"content management office\",\"frontiersdefaultterm\":\"content management office\",\"category\":\"user role\"},{\"sequencenumber\":192,\"key\":\"role_id_98\",\"tenantterm\":\"accounting office\",\"frontiersdefaultterm\":\"accounting office\",\"category\":\"user role\"},{\"sequencenumber\":193,\"key\":\"role_id_99\",\"tenantterm\":\"projects\",\"frontiersdefaultterm\":\"projects\",\"category\":\"user role\"},{\"sequencenumber\":194,\"key\":\"role_id_103\",\"tenantterm\":\"configuration office\",\"frontiersdefaultterm\":\"configuration office\",\"category\":\"user role\"},{\"sequencenumber\":195,\"key\":\"role_id_104\",\"tenantterm\":\"beta user\",\"frontiersdefaultterm\":\"beta user\",\"category\":\"user role\"},{\"sequencenumber\":196,\"key\":\"role_id_106\",\"tenantterm\":\"wfconf\",\"frontiersdefaultterm\":\"wfconf\",\"category\":\"user role\"},{\"sequencenumber\":197,\"key\":\"role_id_107\",\"tenantterm\":\"rt management beta user\",\"frontiersdefaultterm\":\"rt management beta user\",\"category\":\"user role\"},{\"sequencenumber\":198,\"key\":\"role_id_108\",\"tenantterm\":\"deo beta user\",\"frontiersdefaultterm\":\"deo beta user\",\"category\":\"user role\"},{\"sequencenumber\":199,\"key\":\"role_id_109\",\"tenantterm\":\"search beta user\",\"frontiersdefaultterm\":\"search beta user\",\"category\":\"user role\"},{\"sequencenumber\":200,\"key\":\"role_id_110\",\"tenantterm\":\"journal manager\",\"frontiersdefaultterm\":\"journal manager\",\"category\":\"user role\"},{\"sequencenumber\":201,\"key\":\"role_id_111\",\"tenantterm\":\"myfrontiers beta user\",\"frontiersdefaultterm\":\"myfrontiers beta user\",\"category\":\"user role\"},{\"sequencenumber\":202,\"key\":\"role_id_21\",\"tenantterm\":\"copy editor\",\"frontiersdefaultterm\":\"copy editor\",\"category\":\"user role\"},{\"sequencenumber\":203,\"key\":\"role_id_1_abr\",\"tenantterm\":\"rof\",\"frontiersdefaultterm\":\"rof\",\"category\":\"user role\"},{\"sequencenumber\":204,\"key\":\"role_id_2_abr\",\"tenantterm\":\"eof\",\"frontiersdefaultterm\":\"eof\",\"category\":\"user role\"},{\"sequencenumber\":205,\"key\":\"role_id_7_abr\",\"tenantterm\":\"fce\",\"frontiersdefaultterm\":\"fce\",\"category\":\"user role\"},{\"sequencenumber\":206,\"key\":\"role_id_8_abr\",\"tenantterm\":\"afce\",\"frontiersdefaultterm\":\"afce\",\"category\":\"user role\"},{\"sequencenumber\":207,\"key\":\"role_id_9_abr\",\"tenantterm\":\"sce\",\"frontiersdefaultterm\":\"sce\",\"category\":\"user role\"},{\"sequencenumber\":208,\"key\":\"role_id_10_abr\",\"tenantterm\":\"asce\",\"frontiersdefaultterm\":\"asce\",\"category\":\"user role\"},{\"sequencenumber\":209,\"key\":\"role_id_11_abr\",\"tenantterm\":\"ae\",\"frontiersdefaultterm\":\"ae\",\"category\":\"user role\"},{\"sequencenumber\":210,\"key\":\"role_id_12_abr\",\"tenantterm\":\"gae\",\"frontiersdefaultterm\":\"gae\",\"category\":\"user role\"},{\"sequencenumber\":211,\"key\":\"role_id_13_abr\",\"tenantterm\":\"re\",\"frontiersdefaultterm\":\"re\",\"category\":\"user role\"},{\"sequencenumber\":212,\"key\":\"role_id_14_abr\",\"tenantterm\":\"rev\",\"frontiersdefaultterm\":\"rev\",\"category\":\"user role\"},{\"sequencenumber\":213,\"key\":\"role_id_15_abr\",\"tenantterm\":\"aut\",\"frontiersdefaultterm\":\"aut\",\"category\":\"user role\"},{\"sequencenumber\":214,\"key\":\"role_id_16_abr\",\"tenantterm\":\"coraut\",\"frontiersdefaultterm\":\"coraut\",\"category\":\"user role\"},{\"sequencenumber\":215,\"key\":\"role_id_17_abr\",\"tenantterm\":\"saut\",\"frontiersdefaultterm\":\"saut\",\"category\":\"user role\"},{\"sequencenumber\":216,\"key\":\"role_id_18_abr\",\"tenantterm\":\"coaut\",\"frontiersdefaultterm\":\"coaut\",\"category\":\"user role\"},{\"sequencenumber\":217,\"key\":\"role_id_20_abr\",\"tenantterm\":\"pof\",\"frontiersdefaultterm\":\"pof\",\"category\":\"user role\"},{\"sequencenumber\":218,\"key\":\"role_id_22_abr\",\"tenantterm\":\"tsof\",\"frontiersdefaultterm\":\"tsof\",\"category\":\"user role\"},{\"sequencenumber\":219,\"key\":\"role_id_24_abr\",\"tenantterm\":\"ru\",\"frontiersdefaultterm\":\"ru\",\"category\":\"user role\"},{\"sequencenumber\":220,\"key\":\"role_id_35_abr\",\"tenantterm\":\"jof\",\"frontiersdefaultterm\":\"jof\",\"category\":\"user role\"},{\"sequencenumber\":221,\"key\":\"role_id_41_abr\",\"tenantterm\":\"se-adm\",\"frontiersdefaultterm\":\"se-adm\",\"category\":\"user role\"},{\"sequencenumber\":222,\"key\":\"role_id_42_abr\",\"tenantterm\":\"se-rev\",\"frontiersdefaultterm\":\"se-rev\",\"category\":\"user role\"},{\"sequencenumber\":223,\"key\":\"role_id_43_abr\",\"tenantterm\":\"se-aut\",\"frontiersdefaultterm\":\"se-aut\",\"category\":\"user role\"},{\"sequencenumber\":224,\"key\":\"role_id_52_abr\",\"tenantterm\":\"evof\",\"frontiersdefaultterm\":\"evof\",\"category\":\"user role\"},{\"sequencenumber\":225,\"key\":\"role_id_53_abr\",\"tenantterm\":\"ev-adm\",\"frontiersdefaultterm\":\"ev-adm\",\"category\":\"user role\"},{\"sequencenumber\":226,\"key\":\"role_id_89_abr\",\"tenantterm\":\"comof\",\"frontiersdefaultterm\":\"comof\",\"category\":\"user role\"},{\"sequencenumber\":227,\"key\":\"role_id_98_abr\",\"tenantterm\":\"aof\",\"frontiersdefaultterm\":\"aof\",\"category\":\"user role\"},{\"sequencenumber\":228,\"key\":\"role_id_99_abr\",\"tenantterm\":\"projects\",\"frontiersdefaultterm\":\"projects\",\"category\":\"user role\"},{\"sequencenumber\":229,\"key\":\"role_id_103_abr\",\"tenantterm\":\"config\",\"frontiersdefaultterm\":\"config\",\"category\":\"user role\"},{\"sequencenumber\":230,\"key\":\"role_id_104_abr\",\"tenantterm\":\"beta\",\"frontiersdefaultterm\":\"beta\",\"category\":\"user role\"},{\"sequencenumber\":231,\"key\":\"role_id_106_abr\",\"tenantterm\":\"wfconf\",\"frontiersdefaultterm\":\"wfconf\",\"category\":\"user role\"},{\"sequencenumber\":232,\"key\":\"role_id_107_abr\",\"tenantterm\":\"rtbeta\",\"frontiersdefaultterm\":\"rtbeta\",\"category\":\"user role\"},{\"sequencenumber\":233,\"key\":\"role_id_108_abr\",\"tenantterm\":\"deobeta\",\"frontiersdefaultterm\":\"deobeta\",\"category\":\"user role\"},{\"sequencenumber\":234,\"key\":\"role_id_109_abr\",\"tenantterm\":\"searchbeta\",\"frontiersdefaultterm\":\"searchbeta\",\"category\":\"user role\"},{\"sequencenumber\":235,\"key\":\"role_id_110_abr\",\"tenantterm\":\"jm\",\"frontiersdefaultterm\":\"jm\",\"category\":\"user role\"},{\"sequencenumber\":236,\"key\":\"role_id_111_abr\",\"tenantterm\":\"mfbeta\",\"frontiersdefaultterm\":\"mfbeta\",\"category\":\"user role\"},{\"sequencenumber\":237,\"key\":\"role_id_21_abr\",\"tenantterm\":\"coped\",\"frontiersdefaultterm\":\"coped\",\"category\":\"user role\"},{\"sequencenumber\":238,\"key\":\"reviewer_editorial_board\",\"tenantterm\":\"editorial board\",\"frontiersdefaultterm\":\"editorial board\",\"description\":\"this is the label for the review editorial board\",\"category\":\"label\"},{\"sequencenumber\":239,\"key\":\"field_chief_editor\",\"tenantterm\":\"field chief editor\",\"frontiersdefaultterm\":\"field chief editor\",\"category\":\"label (role)\"},{\"sequencenumber\":240,\"key\":\"field_chief_editors\",\"tenantterm\":\"field chief editors\",\"frontiersdefaultterm\":\"field chief editors\",\"category\":\"label (role)\"},{\"sequencenumber\":241,\"key\":\"editor\",\"tenantterm\":\"editor\",\"frontiersdefaultterm\":\"editor\",\"category\":\"label (role)\"},{\"sequencenumber\":242,\"key\":\"editors\",\"tenantterm\":\"editors\",\"frontiersdefaultterm\":\"editors\",\"category\":\"label (role)\"},{\"sequencenumber\":243,\"key\":\"board\",\"tenantterm\":\"board\",\"frontiersdefaultterm\":\"board\",\"category\":\"label\"},{\"sequencenumber\":244,\"key\":\"boards\",\"tenantterm\":\"boards\",\"frontiersdefaultterm\":\"boards\",\"category\":\"label\"},{\"sequencenumber\":245,\"key\":\"article_collection\",\"tenantterm\":\"article collection\",\"frontiersdefaultterm\":\"article collection\",\"category\":\"label\"},{\"sequencenumber\":246,\"key\":\"article_collections\",\"tenantterm\":\"article collections\",\"frontiersdefaultterm\":\"article collections\",\"category\":\"label\"},{\"sequencenumber\":247,\"key\":\"handling_editor\",\"tenantterm\":\"handling editor\",\"frontiersdefaultterm\":\"associate editor\",\"description\":\"this terminology key is for the person assigned to edit a manuscript. it is a label for the temporary handling editor assignment.\",\"category\":\"label (role)\"},{\"sequencenumber\":248,\"key\":\"handling_editors\",\"tenantterm\":\"handling editors\",\"frontiersdefaultterm\":\"associate editors\",\"description\":\"this terminology key is for the person assigned to edit a manuscript. it is a label for the temporary handling editor assignment.\",\"category\":\"label (role)\"},{\"sequencenumber\":249,\"key\":\"ae_accept\",\"tenantterm\":\"recommend acceptance\",\"frontiersdefaultterm\":\"accept\",\"category\":\"process\"},{\"sequencenumber\":250,\"key\":\"rtm\",\"tenantterm\":\"rtm\",\"frontiersdefaultterm\":\"rtm\",\"category\":\"product\"},{\"sequencenumber\":251,\"key\":\"frontiers_media_sa\",\"tenantterm\":\"frontiers media s.a\",\"frontiersdefaultterm\":\"frontiers media s.a\",\"category\":\"customer\"},{\"sequencenumber\":252,\"key\":\"review_editors\",\"tenantterm\":\"community reviewers\",\"frontiersdefaultterm\":\"review editors\",\"category\":\"label (role)\"},{\"sequencenumber\":253,\"key\":\"journal_card_chief_editor\",\"tenantterm\":\"chief editor\",\"frontiersdefaultterm\":\"chief editor\",\"category\":\"label (role)\"},{\"sequencenumber\":254,\"key\":\"journal_card_chief_editors\",\"tenantterm\":\"chief editors\",\"frontiersdefaultterm\":\"chief editors\",\"category\":\"label (role)\"},{\"sequencenumber\":255,\"key\":\"call_for_papers\",\"tenantterm\":\"call for papers\",\"frontiersdefaultterm\":\"call for papers\",\"category\":\"label\"},{\"sequencenumber\":256,\"key\":\"calls_for_papers\",\"tenantterm\":\"calls for papers\",\"frontiersdefaultterm\":\"calls for papers\",\"category\":\"label\"},{\"sequencenumber\":257,\"key\":\"supervising_editor\",\"tenantterm\":\"supervising editor\",\"frontiersdefaultterm\":\"supervising editor\",\"description\":\"a chief or assistant chief editor who is assigned to a manuscript to supervise.\",\"category\":\"role\",\"externalkey\":\"supervising_editor\"},{\"sequencenumber\":258,\"key\":\"supervising_editors\",\"tenantterm\":\"supervising editors\",\"frontiersdefaultterm\":\"supervising editors\",\"description\":\"a chief or assistant chief editor who is assigned to a manuscript to supervise.\",\"category\":\"role\",\"externalkey\":\"supervising_editors\"},{\"sequencenumber\":259,\"key\":\"reviewer_endorse\",\"tenantterm\":\"endorse\",\"frontiersdefaultterm\":\"endorse\",\"category\":\"label\"},{\"sequencenumber\":260,\"key\":\"reviewer_endorsed\",\"tenantterm\":\"endorsed\",\"frontiersdefaultterm\":\"endorsed\",\"category\":\"label\"},{\"sequencenumber\":261,\"key\":\"reviewer_endorse_publication\",\"tenantterm\":\"endorse publication\",\"frontiersdefaultterm\":\"endorse publication\",\"category\":\"label\"},{\"sequencenumber\":262,\"key\":\"reviewer_endorsed_publication\",\"tenantterm\":\"endorsed publication\",\"frontiersdefaultterm\":\"endorsed publication\",\"category\":\"label\"},{\"sequencenumber\":263,\"key\":\"editor_role\",\"tenantterm\":\"editor role\",\"frontiersdefaultterm\":\"editor role\",\"category\":\"label\"},{\"sequencenumber\":264,\"key\":\"editor_roles\",\"tenantterm\":\"editor roles\",\"frontiersdefaultterm\":\"editor roles\",\"category\":\"label\"},{\"sequencenumber\":265,\"key\":\"editorial_role\",\"tenantterm\":\"editorial role\",\"frontiersdefaultterm\":\"editorial role\",\"category\":\"label\"},{\"sequencenumber\":266,\"key\":\"editorial_roles\",\"tenantterm\":\"editorial roles\",\"frontiersdefaultterm\":\"editorial roles\",\"category\":\"label\"},{\"sequencenumber\":267,\"key\":\"call_for_paper\",\"tenantterm\":\"call for paper\",\"frontiersdefaultterm\":\"call for paper\",\"category\":\"label\"},{\"sequencenumber\":268,\"key\":\"research_topic_abstract\",\"tenantterm\":\"manuscript summary\",\"frontiersdefaultterm\":\"manuscript summary\",\"category\":\"process\"},{\"sequencenumber\":269,\"key\":\"research_topic_abstracts\",\"tenantterm\":\"manuscript summaries\",\"frontiersdefaultterm\":\"manuscript summaries\",\"category\":\"process\"},{\"sequencenumber\":270,\"key\":\"submissions_team_manager\",\"tenantterm\":\"journal manager\",\"frontiersdefaultterm\":\"content manager\",\"category\":\"process\"},{\"sequencenumber\":271,\"key\":\"submissions_team\",\"tenantterm\":\"journal team\",\"frontiersdefaultterm\":\"content team\",\"category\":\"process\"},{\"sequencenumber\":272,\"key\":\"topic_coordinator\",\"tenantterm\":\"topic coordinator\",\"frontiersdefaultterm\":\"topic coordinator\",\"category\":\"process\"},{\"sequencenumber\":273,\"key\":\"topic_coordinators\",\"tenantterm\":\"topic coordinators\",\"frontiersdefaultterm\":\"topic coordinators\",\"category\":\"process\"},{\"sequencenumber\":274,\"key\":\"frontiers_journal_team\",\"tenantterm\":\"frontiers journal team\",\"frontiersdefaultterm\":\"frontiers journal team\",\"category\":\"label (role)\"},{\"sequencenumber\":275,\"key\":\"research_topic_ic_submission\",\"tenantterm\":\"rt:ic submission\",\"frontiersdefaultterm\":\"rt:ic submission\",\"category\":\"label (role)\"},{\"sequencenumber\":276,\"key\":\"research_topic_ic_submission_participant\",\"tenantterm\":\"rt:ic submission participant\",\"frontiersdefaultterm\":\"rt:ic submission participant\",\"category\":\"label (role)\"}]}'\n",impactgtmid:"gtm-njf2ml9b",impactgtmauth:"fyo-7nodm9w37qgfms03sa",impactgtmpreview:"env-1",impactgooglemapsapikey:"aizasyctehx2eu8pwfi86gw9fi00ftcykk6ifr8",qualtricsv4tov3:"'{\"enabled\":true,\"interceptid\":\"si_er0e2ze69oz8yn4\",\"projectid\":\"zn_cloy77jhkpc8gai\",\"brandid\":\"frontiersin\"}'\n",qualtricsumux:"'{\"enabled\":false,\"interceptid\":\"si_89fphy3etxqbwtu\",\"projectid\":\"zn_cloy77jhkpc8gai\",\"brandid\":\"frontiersin\"}'\n",qualtricscontinuousbrand:"'{\"enabled\":true,\"interceptid\":\"si_9zut94ut81fcrh4\",\"projectid\":\"zn_cloy77jhkpc8gai\",\"brandid\":\"frontiersin\"}'\n",defaultarticletemplate:"v3"},app:{baseurl:"/",buildid:"f2d5b6d8-d01c-4534-90b9-d659f10f17ca",buildassetsdir:"ap-2024/_nuxt",cdnurl:""}}## Methods
the novelty of this research lies in its use in the context of twitter to analyze and identify asd. this research used twitter as the primary data source to examine the behavioral traits and immediate emotional expressions of persons with asd. we applied convolutional neural networks with long short-term memory (cnn-lstm), lstm, and double deep q-network (ddqn-inspired) using a standardized dataset including 172 tweets from the asd class and 158 tweets from the non-asd class. the dataset was processed to exclude lowercase text and special characters, followed by a tokenization approach to convert the text into integer word sequences. the encoding was used to transform the classes into binary labels. following preprocessing, the proposed framework was implemented to identify asd. results: the findings of the ddqn-inspired model demonstrate a high precision of 87% compared to the proposed model. this finding demonstrates the potential of the proposed approach for identifying asd based on social media content. discussion: ultimately, the proposed system was compared against the existing system that used the same dataset. the proposed approach is based on variations in the text of social media interactions, which can assist physicians and clinicians in performing symptom studies within digital footprint environments. 1 introduction asd is among the most prevalent neurodevelopmental disorders. asd is often demonstrated in children by age three and is defined by impairments in social interactions and communication, repetitive sensory-motor activities, and stereotypical behavioral patterns ( 1 ). asd is a congenital neurodevelopmental condition characterized by symptoms that are evident in early infancy. autism, characterized by restricted interests, repetitive behaviors, and significant disparities in social communication and interaction, typically emerges during early developmental stages and presents challenges in various social functioning domains. a child with autism induces significant anxiety within the family due to several factors, including the ambiguity of the diagnosis, the intensity and persistence of the disease, and the child’s nonconformity to social norms. in opposition, social awareness of autism is markedly inadequate, often conflated with intellectual disability and seen as an incurable ailment ( 2 , 3 ). the asd concept is displayed in figure 1 . figure 1 figure 1 . displays the asd concept. content on social media, particularly videos and text disseminated by parents and caregivers, has emerged as a significant resource for facilitating the early identification of asd ( 4 , 5 ). social media are technological tools designed for sharing, enabling users to create networks or engage in existing ones. in that order, the pew research center identified the most popular social media sites as youtube, facebook, instagram, pinterest, linkedin, snapchat, twitter, and whatsapp ( 6 ). most consumers use these networks daily. this research utilizes twitter data to assess the stigmatization of autism and associated terminology, picked based on accessibility and popularity, with analysis conducted using artificial intelligence technologies ( 7 ). conventional diagnostic methods, which primarily rely on observational and behavioral evaluations, often encounter issues with accessibility, consistency, and timeliness. recent technology breakthroughs, especially in artificial intelligence (ai), and sensor-based techniques, provide novel opportunities for improving asd identification. by developing more objective, accurate, and scalable approaches, these technologies transform diagnostic methodologies for autism spectrum disorder (asd) ( 8 – 10 ). one new way to study the motor patterns, attentional processes, and physiological responses linked to asd in real-time is wearable sensors, eye-tracking devices, and multimodal virtual reality settings. these technologies have the potential to give non-invasive, continuous monitoring, which might help with the early diagnosis of asd and shed light on neurological and behavioral traits that have been hard to document reliably. nevertheless, advancements in contemporary research are required to substantiate their efficacy. sensor-based techniques may facilitate the identification of stereotyped behaviors and motor patterns linked to asd in realistic environments, potentially yielding data that could guide timely and customized therapies ( 11 ). neuroimaging and microbiome analysis further advance this technical domain by indicating neurological and biological traits specific to asd. ai-enhanced neuroimaging aids in identifying structural and functional brain connection patterns associated with asd, thereby enhancing the understanding of its neuroanatomical foundation ( 12 ). the research conducted by neeharika and riyazuddin et al. ( 13 ) aimed to enhance the accuracy of asd screening by using feature selection methods in conjunction with sophisticated machine learning classifiers. their research included several datasets spanning infants, children, adolescents, and adults, enabling a thorough assessment of asd characteristics across different age demographics. authors’ use of mlp model capacity to reliably and rapidly identify asd, indicating a beneficial screening instrument suitable for various age groups, facilitating both clinical evaluations and extensive screenings. wall et al. ( 14 ) investigated machine learning (ml) algorithms for diagnosing asd using a standard dataset. the researchers focused on the alternating decision tree classifier to identify a limited yet efficient set of queries that optimize the diagnostic procedure. alzakari et al. ( 15 ) proposed a novel two-phase methodology to tackle the variability in asd features with ml approaches, including behavioral, linguistic, and physical data. the first step concentrates on identifying asd, using feature engineering methodologies and ml algorithms, including a logistic regression (lr) and support vector machine (svm) ensemble, attaining a classification with high accuracy. eeg assesses brain activity and may identify children predisposed to developing asd, hence facilitating early diagnosis. eeg data is used to compare asd and hc ( 16 – 18 ). in ( 19 ), the cnn model was used for classification after transforming the data into a two-dimensional format. while eeg may facilitate the diagnosis of asd, it is constrained by other factors, such as signal noise. the research has used social media to investigate asd. however, exploiting these prevalent platforms and innovative online data sources may be feasible to enhance the comprehension of these diseases. previous research has utilized twitter data to investigate discussions on asd-related material, indicating that this subject is frequently addressed on this platform ( 20 ). considering the use of social media for researching asd is particularly significant, as a recent analysis indicated that around 80% of individuals with asd engage with prominent social media platforms ( 21 ). this study aims to build upon previous research and enhance our comprehension of whether publicly accessible social media data from twitter may provide insights into the existence of digital diagnostic indicators for asd ( 22 ). furthermore, we want to assess the viability of establishing a digital phenotype for asd using social media. beykikhoshk et al. ( 20 ) examined twitter’s potential as a data-mining tool to comprehend the actions, challenges, and requirements of autistic individuals. the first finding pertained to the attributes of participants inside the autism subgroup of tweets, indicating that these tweets were highly informative and had considerable potential usefulness for public health experts and policymakers. tomeny et al. ( 23 ) examined demographic correlations of autism-related anti-vaccine opinions on twitter from 2009 to 2015. their results indicated that the frequency of autism-related anti-vaccine views online was alarming, with anti-vaccine tweets connecting with news events and demonstrating geographical clustering. from 2015 to 2019, tárraga-mínguez et al. ( 24 ) examined the phrases “autism” and “asperger” in spain in relation to google search peaks. the public view of autism was significantly impacted by how the condition was portrayed in the news and on social media, and the authors found that social marketing campaigns had a significant role in normalizing autism. in this research ( 25 ), looked at how people sought assistance. the results showed a strong correlation in google search interest between the terms “asperger syndrome” and “greta thunberg,” reaching their highest point in 2019. online traffic to the asperger/autism network and autism speaks websites increased steadily from june to december 2019, indicating a correlation between help-seeking behavior and thunberg’s fame, according to the research. according to the results, the stigma associated with asperger’s disorder may have been positively affected by thunberg’s public exposure. 1.1 contribution the use of tweets from twitter for the detection of asd is substantial, since it offers extensive, real-time, user-generated data that facilitates the early identification of asd-related behaviors, particularly via self-reported experiences and parental observations. this methodology promotes the advancement of suggested models, namely lstm, cnn-lstm, and inspired ddqn, for natural language processing to examine linguistic patterns, feelings, and keywords related to asd. it provides insights into popular views, stigma, and misconceptions around autism, guiding awareness initiatives and public health measures. twitter data is a powerful and accessible resource for enhancing early detection and understanding of asd in diverse groups. utilizing social media in this manner may offer more accessible and timely screening, particularly in regions with limited healthcare resources. 2 materials and methods figure 2 shows the pipeline of the proposed system to provide a broader perspective to researchers and developers. the framework delineates the processing phases for the pipeline that utilizes social media content to diagnose asd. below, we present a comprehensive assessment of each step. figure 2 figure 2 . farmwork of asd system. 2.1 dataset to help with the early diagnosis of asd by using proposed systems, the tasd-dataset includes comprehensive textual sequences that depict the everyday lives of children with and without asd. it offers new elements, including noise sensitivity, sharing interest, sign communication, and tiptoe flapping, it combines critical asd assessment aspects like attention response, word repetition, and emotional empathy, as shown in figure 3 . parents may get detailed insights and better identify signs of autism spectrum disorder (asd) due to the deepening of certain behaviors. the dataset contains 172 tweets from the asd class and 158 non-asd tweets. figure 4 shows the class of the dataset. figure 3 figure 3 . features of the dataset. figure 4 figure 4 . label of the dataset. 2.2 preprocessing text preprocessing is an essential step in the text processing process. words, sentences, and paragraphs can all be found in a text, which is defined as a meaningful sequence of characters. preprocessing methods feed text data to a proposed algorithm in a better form than in its natural state. a tweet can contain different viewpoints on the data it represents. tweets that have not been preprocessed are highly unstructured and contain redundant data. to address these issues, several steps are taken to preprocess tweets for detecting asd, as shown in figure 5 . figure 5 figure 5 . preprocessing asd text analysis. 2.3 text cleaning the clean text preprocessing method is a significant step in text datasets because the text contains several extra contexts to preprocess and normalize raw text data for analysis. in these steps, the use is transformed to lowercase to guarantee consistency and prevent differentiation between “asd” and “non-asd.” subsequently, any characters that are not letters, numerals, or spaces are eliminated by a regular expression, so punctuation and other symbols that might create extraneous noise are removed. this method is ultimately applied to the ‘text’ column of the data frame, ensuring that all text elements are sanitized and prepared for feature extraction. figure 6 displays the clean text process. figure 6 figure 6 . clean text. 2.4 label encoding the labelencoder method converts text class (asd and non-asd) into numbers, designating 0 for asd and 1 for non-asd. this transformation updates the classification effort by enabling the model to see the labels as numerical values instead of text. equations 1 , 2 show the label encoding. yclassification ∈ ( asd , non − asd ) then      ( 1 ) y = labelencoder ( yclassifcation ) → y ∈ { 0 , 1 }      ( 2 ) 2.5 tokenization and padding tokenization and padding are essential nlp preprocessing procedures that transform unprocessed text into a numerical representation appropriate for machine learning models, particularly neural networks. figure 7 shows the tokenization and padding equation 3 . figure 7 figure 7 . sample of text tokenization and padding. 2.5.1 tokenizer tokenizer procedures transform textual data into a numerical representation suitable for input into neural networks. they convert a text corpus into integer sequences, assigning a distinct index to each unique word according to its frequency, as shown in equation 3 . the tokenizer processing is shown in figure 8 . index ( w ) = rank f ( w ) if rank f ( w ) ≤ v      ( 3 ) figure 8 figure 8 . tokenizer analysis: word frequencies and sequence lengths. where rank f ( w ) is rank w frequency f ( w ) and v is the maximum number of words. 2.5.2 fit texts this phase is crucial for transforming unprocessed text into numerical sequences suitable for input into the proposed system. 2.5.3 texts_to_sequences to convert unprocessed text input into sequences of word indices according to the mapping acquired via as shown in equation 4 . sequence ( t i ) = [ index ( w 1 ) , index ( w 2 ) , … … … , index ( w m ) ]      ( 4 ) where is the t i is the sentence of the text contained, and w is the words of the text, whereas the index ( w 1 ) is an index of the words in the context. 2.5.4 padding_sequences normalize sequence lengths, which may differ post-tokenization, by padding shorter sequences and truncating larger ones to a predetermined length as shown in equation 5 . the padding and truncated b are fixed on the length. l = 200 . the padding processing is shown in figure 7 . x = ∣ x 1 x 2 . . . . y ∣ ∈ ℝ nxl     (5) where x is features contain padding and are tokenized, l is the length of the vector. the number of texts is indicated n , and ∈ ℝ nxl is matrix lues. 2.6 proposed systems 2.6.1 convolutional neural networks the cnn model is at the core of all advanced machine learning and deep learning applications. they can successfully address text classification, image recognition, object identification, and semantic segmentation. using the same method with a task as different as natural language processing is counterintuitive ( 7 ). the structure is presented in figure 9 . equation 6 presents the convolution layer of cnn. o ( x , y ) = ∑ i = 1 h ∑ j = 1 w i ( x + i , y + j ) ∗ k ( i , j ) + b      ( 6 ) figure 9 figure 9 . structure cnn. where the features of text o ( x , y ) the feature of the text is mapped by using. i ( x + i , y + j ) is weighted by a neural network and b is biased to adjust the neural. the relu activation function is equation 7 , the max pooling function is presented in equation 8 . the dense layer is given in equation 9 . f ( x ) = max ( 0 , x )      ( 7 ) o ( x , y ) = ∑ i = 1 h ∑ j = 1 w i ( x + i , y + j ) ∗ k ( i , j ) + b      ( 8 ) o = w · x + b      ( 9 ) 2.6.2 long short-term memory network an lstm network is an advanced form of a sequential neural network. it fixes the problem of rnn gradients fading over time. rnns often handle long-term storage. at a high level, the operation of an lstm is comparable to that of a single rnn neuron. the inner workings of the lstm network are outlined in this section. the lstm consists of three parts, each performing a particular function, as seen in figure 10 below. in the first step, it is decided whether the information from the previous time stamp is significant enough to be saved or if it is harmless enough to be deleted. in the second step, the cell will try to acquire new information by analyzing the data that has been presented to it. in the third and final step, the cell incorporates the data from the most recent time stamp into the data stored in the next time stamp. these three components constitute what is referred to as a gate for an lstm cell. the “forget” gate comes first, followed by the “input” section, and then the “output” section is used to define the last portion as shown in equations 10 – 14 . forget gate : f t = σ ( w f . x t + w f . h t − 1 + b f )      ( 10 ) input gate : i t = σ ( w c . x t + w i . h t − 1 + b i )      ( 11 ) cell gate : c t = ( w f ∗ ( . h t − 1 , x t ) b f )      ( 12 ) output gate : o t = σ ( w o + x t + w o . h t − 1 + v o . c t + b o )      ( 13 ) hidden layer : h t = o t + tanh ( c t )      ( 14 ) figure 10 figure 10 . lstm model. in figure 10 , c t represent the prior and current states of the cell, respectively. both h t − 1 and h represents the cell output that was processed before the one now being processed. it is common practice to disregard f t as a gate, even though it is the input gate. the output of a sigmoid gate is symbolized here by o t . the cable that connects the cell gates is where all the data collected by the cell gates is sent to and from c . the f t layer decides to remember anything, and the f t the output is multiplied by c to do so (t-1). after that, c (t-1) is multiplied by the product of the sigmoid layer gate and the tanh layer gate, and the output h t is generated by point-wise multiplication of o t and tanh. the lstm architecture is intended to capture long-term relationships in twitter text data. the preprocessing converts input words that start with an embedding layer into 128-dimensional dense vectors. the lstm layer with 64 units is then used to mitigate overfitting, integrating dropout and recurrent dropout with 0.5. an l2 regularization term is further included in the lstm and output dense layer. table 1 shows parameters of the lstm model. table 1 table 1 . lstm parameters model. 2.6.3 cnn-lstm model the cnn-lstm model is a hybrid architecture that combines convolutional neural networks (cnn) for spatial feature extraction and long short-term memory (lstm) networks for sequential learning, making it highly effective for analyzing text data such as tweets. the model begins with an embedding layer that transforms each word into a 256-dimensional dense vector, capturing the semantic meaning of words. this is followed by a 1d convolutional layer with 64 filters and a kernel size of 5, which scans through the text to detect local patterns and n-gram features such as common word combinations or phrases often associated with asd. a batch normalization layer is applied to stabilize and accelerate training, followed by a max pooling layer that reduces the dimensionality and computational load by selecting the most prominent features. a dropout layer with a rate of 0.5 is then used to prevent overfitting by randomly deactivating some neurons during training. the output is passed into a 64-unit lstm layer that captures the temporal dependencies and contextual relationships across the tweet sequence. finally, a dense layer with sigmoid activation performs binary classification to predict whether the tweet indicates asd-related content. the model is trained using the adam optimizer, binary cross-entropy loss, class weights, and regularization to handle imbalanced data and improve generalization. the critical parameters of the cnn-lstm model are displayed in table 2 . table 2 table 2 . cnn-lstm parameters. 2.6.4 double deep q-network (ddqn-inspired) the double q-learning model was introduced by h. van hasselt in 2010, addressing the issue of significant overestimations of action value (q-value) inherent in traditional q-learning. in fundamental q-learning, the agent’s optimal strategy is consistently to select the most advantageous action in any specific state. this concept’s premise is that the optimal action corresponds to the highest expected or estimated q-value. initially, the agent lacks any knowledge of the environment; it must first estimate q(s, a) and subsequently update these estimates with each iteration. the q-values exhibit considerable noise, leading to uncertainty about whether the action associated with the highest expected or estimated q-value is genuinely the optimal choice. double q-learning employs two distinct action-value functions, q and q’, as estimators. even if q and q’ exhibit noise, this noise can be interpreted as a uniform distribution as shown figure 11 the update procedure exhibits some variations compared to the basic version. the action selection and action evaluation processes are separated into two distinct maximum function estimators. shown in equations 15 , 16 . figure 11 figure 11 . ddqn-inspired model. let the vector of a neural network’s weights be represented by θ . we establish two q-networks: the online q-network q (s, a; θ(t)) and the target q-network q (s, a; θ (t)). to be more specific, the training of q (s, a; Χ (t)) is done by modifying the weights (t) at time slot t in relation to the goal value y(t). y ( t ) = g ( t ) + ( s ′ , argmax q ( s ′ , a ∗ ; θ ′ ( t ) ) ; θ ′ ( t ) )      ( 15 ) y ( t ) = g ( t ) + ( s ′ , argmax q ( s ′ , a ∗ ; θ ′ ) ; θ i − 1 )      ( 16 ) the reinforcement learning mechanism integrates generative artificial intelligence for decision-making and prediction tasks, as shown in equations 15 , 16 . this equation indicates the generative which produces the estimation or hypothesis at a given time t . double q − learning used next state, whereas the s’ is exit state and argmax q ( s ′ , a ∗ ; θ ′ ( t ) ) defined as the action of a ∗ to maximize the predicted q-value based on the current parameters. to estimate the q-value of this selected action in the next state, the outer q-function q’ employs the older parameters. θ i − 1 1, which helps reduce overestimation bias. this combination makes applications for predicting asd from social media content domains possible. the ddqn model is used to classify asd and non-asd cases utilizing text data. the model utilizes a preprocessing step for text processing that encompasses data loading, cleaning (including lowercasing, removal of special characters, and normalization of spaces), and tokenization, constrained by a maximum vocabulary of 10,000 words and a sequence length of 200. the model architecture, drawing from the double deep q-network (ddqn) model comprises an input layer, an embedding layer with 256 dimensions, and two parallel lstm branches, each containing 64 units, a dropout rate of 0.5, and l2 regularization to capture sequential patterns effectively. the model uses the adam optimizer with a learning rate of 1e-4 and employs binary cross-entropy loss. it is trained for 30 epochs, incorporating early stopping and learning rate reduction callbacks to mitigate overfitting. parameters of ddqn-inspired are shown in table 3 . table 3 table 3 . parameters of ddqn-inspired. 3 performance of the framework 3.1 performance of lstm figure 12 presents the accuracy and loss metrics used to train and validate an lstm model over 30 epochs. the validation accuracy of the lstm model, displayed in red, begins at a lower value and increases to about 81%. the blue line in the accuracy plot (a) shows the training accuracy of the lstm model; it increases gradually from around 50% to almost 99%, showing that the model learns the training data well over time. the plot (b) shows the loss of the lstm model; the blue line represents the training loss, which drops gradually from around 0.7 to less than 0.2, suggesting that the model is getting a better fit to the training data. meanwhile, the red validation loss line declines from around 0.7 to about 0.3. while the training loss continues to grow, the validation loss reaches a level and exhibits small oscillations, suggesting that the model’s generalizability may stabilize. figure 12 figure 12 . performance of the lstm model. the roc curve illustrated in figure 13 shows the efficacy of the lstm model in differentiating between the classes. the graph illustrates the tp rate (sensitivity) in relation to the fp rate across different threshold levels. the lstm model attains an auc of 0.95, demonstrating exceptional classification capability. the auc of 1.0, but a result of 0.5 indicates random chance. figure 13 figure 13 . roc of the lstm model. 3.2 performance of the cnn-lstm model figure 14 presents plots illustrating the performance of a cnn-lstm model over 25 epochs, showing its training and validation metrics for accuracy and loss. the accuracy plot (a) illustrates the training accuracy (blue line), which increases progressively from approximately 51.42% to nearly 99.53%, indicating effective learning from the training data. in contrast, the validation accuracy (red line) rises to about 83.02% with some variability, indicating satisfactory but imperfect generalization. the loss plot (b) shows the training loss (blue line) declining steadily from 0.7140 to below 0.0760, indicating enhanced model fit. in contrast, the validation loss (red line) decreases from 0.7130 to approximately 0.3530, with a slight decline toward the conclusion. this notification indicates that the cnn-lstm model demonstrates efficient learning, as evidenced by the difference between the training and validation measures. figure 14 figure 14 . performance of the lstm model. figure 15 illustrates the roc curve for the cnn-lstm model, illustrating its classification performance at various thresholds. the graph illustrates the tp rate (sensitivity) in relation to the fp rate, with the auc recorded at 92%. the elevated auc value indicates the model has robust discriminative capability in differentiating between the asd and non-asd classes. the roc ascends rapidly toward the top-left corner, as seen in the figure, indicating a high tp rate with few false positives. figure 15 figure 15 . roc of the cnn-lstm model. 3.3 performance of ddqn-inspired model graphs 16 illustrate the performance of a ddqn throughout 30 epochs. the accuracy plot (a) demonstrates that the training accuracy increases from around 58.02% to almost 98.58%, indicating the ddqn model successful learning from the training data over time. the validation accuracy of the ddqn is about 87, showing the best performance compared to different models like lstm and cnn-lstm. the plot (b) illustrates that the training loss decreases from about 0.8155 to around 0.1477, indicating a robust fit to the training data. the validation loss begins at 0.3831 with many fluctuations throughout ( figure 16 ). figure 16 figure 16 . performance of the ddqn-inspired model. figure 17 shows the roc curve for the ddqn model; it shows a visual representation of its classification capability, with the curve toward the top-left corner, indicating strong predictive power. the auc value of the ddqn model is 96%, demonstrating that the model can distinguish between the positive and negative classes. figure 17 figure 17 . roc ddqn-inspired model. 4 experiment and discussion results both the jupyter deep learning framework and the windows 10 operating system were utilized during the testing process. experiments were conducted using a machine with 16 gigabytes of ram and an intel core i7 central processing unit. the input dimensions of the experiment were a standard text dataset collected from the twitter api related to asd. the test was utilized in our database, while the remaining 20% was used as part of our validation set. the three dl models, namely lstm, cnn-lstm, and ddqn-inspired, were proposed for detecting asd from social media content. 4.1 measuring the model’s performance sensitivity, specificity, accuracy, recall, and f1 scores are assessment measures used to determine how successfully the algorithms identify asd. the related equations from 17 to 21 : accuracy = tp + tn tp + fp + fn + tn × 100 %      ( 17 ) sensitivity = tp tp + fn × 100 %      ( 18 ) precision = tp tp + fp × 100 %      ( 19 ) specificity = tn tn + fp × 100      ( 20 ) f 1 − score = 2 ∗ precision × sensitivity precision + sensitivity × 100      ( 21 ) 4.2 result of the lstm model the classification lstm model, presented in table 4 , summarizes its performance in differentiating between asd and non-asd patients, attaining an overall accuracy of 81%. the lstm model demonstrates in asd class a precision of 91%, indicating a high accuracy in identifying predicted asd cases. the lstm with recall metric scored 77% and an f1-score of 82% for detecting the asd class. the lstm model with non-asd class demonstrates a precision of 71%, a recall of 89%, and an f1-score of 79%, to identify non-asd cases. the macro average of the lstm model for all metrics is (precision: 81%, recall: 82%, f1-score: 81%). lstm model is recognized for its efficiency and scalability as a model for social media content. table 4 table 4 . lstm results. the confusion matrix for the lstm model is provided in figure 18 . it is presented in a clear manner. among the confirmed asd cases, 29 were accurately identified as asd, whereas 10 were incorrectly classified as non-asd, indicating strong performance with minor errors. in the true non-asd cases, 25 were correctly identified, while 3 were misclassified as asd, suggesting a generally effective detection process. the deep blue and light shades produce a tranquil visual, illustrating the model’s balanced approach in classifying the 67 total instances, demonstrating notable strength in identifying non-asd cases, while exhibiting marginally lower accuracy for asd. this matrix effectively illustrates the lstm model’s systematic approach to managing sequential data, such as text or time-series inputs, in a clear and comprehensible manner. figure 18 figure 18 . lstm model. 4.3 result of the cnn-lstm model table 5 displays the cnn-lstm model’s performance in distinguishing between asd and non-asd classes. the cnn-lstm model attained an overall accuracy of 85% across the dataset. in the asd label, a precision of 91% was achieved, a high percentage for predicting asd cases that were accurately recognized. the recall indicates that the model identified 82% of all genuine asd cases, resulting in an f1 score of 86%, better than the recall metric. the cnn-lstm model attained 78% accuracy, 89% recall, and an 83% f1 score for the non-asd class. the macro average, representing the unweighted mean of precision, recall, and f1 score across both classes, was 85, 86, and 85%, respectively. the findings indicate that the cnn-lstm model performs satisfactorily, exhibiting a marginally superior capacity to identify asd cases relative to non-asd cases accurately. table 5 table 5 . results of the cnn-lstm model. the confusion matrix of a cnn-lstm model is presented in figure 19 , for classifying instances into asd and non-asd. the matrix is structured with true labels on the vertical axis and predicted labels on the horizontal axis, providing a clear summary of the model’s classification outcomes. the matrix shows that out of the instances truly labeled as asd, the model correctly predicted 32 as asd tp while 7 were incorrectly classified as non-asd fn. for the instances truly labeled as non-asd, the model accurately identified 25 as non-asd tn but 3 were misclassified as asd fp. this indicates that the model demonstrates a relatively strong ability to correctly identify asd and non-asd cases, with higher accuracy for true positives (32 out of 39 asd cases) and true negatives (25 out of 28 non-asd cases). overall, the model exhibits promising performance with minimal misclassification errors. figure 19 figure 19 . results of cnn-lstm model. 4.4 results of double deep q-network the findings of the ddqn model are shown in table 6 , achieving a high precision of 87% compared to the other models. this finding demonstrates the potential of the proposed ddqn approach for identifying asd based on social media content. ultimately, the proposed system was compared against the existing one using the same dataset. the proposed approach may assist physicians in detecting asd and conducting symptomology research in a natural environment, attaining an overall accuracy of 87. the model for the asd class shows a precision of 95%, a recall of 79%, and an f1-score of 87%, indicating robust efficacy in accurately identifying asd patients. the non-asd class has a precision of 77%, a recall of 96%, and an f1-score of 86%, indicating somewhat reduced accuracy with robust recall. the macro average measures (precision 87%, recall 88%, f1-score 87%) indicate performance across both classes. table 6 table 6 . result of ddqn-inspired. the confusion matrix of the ddqn model is shown in figure 20 for the classification task between asd and non-asd cases. for correct classification of asd cases, the model correctly classified 31 instances as asd, represented by the top-left quadrant (tp). however, the ddqn model, misclassified 8 instances misclassifying true asd cases as non-asd, shown in the top-right quadrant (fn). on the other hand, the ddqn showed the true non-asd cases, accurately identified 27 instances as non-asd, depicted in the bottom-right quadrant (tn). at the same time, 1 instance was incorrectly labeled as asd, as shown in the bottom-left quadrant (fp). the confusion matrix of ddqn model highlights that it performs well overall, with a strong ability to correctly identify both asd and non-asd cases, as evidenced by the high counts of tp (31) and tn (27). figure 20 figure 20 . result of ddqn-inspired model. in the digital era, people frequently write content on social media to express their feelings, opinions, beliefs, and activities. this makes social media one of the most significant sources of data generation, allowing you to explore its opportunities and challenges. today, social media has become a mediator between people and the healthcare sector, enabling them to search for information about any specific disease and methods for diagnosing it. individuals within the mental health community use social media platforms such as twitter to seek information, exchange experiences, and get assistance about asd in an environment that is seen as more approachable and informal than conventional medical contexts. they often seek immediate, relevant information—whether to understand symptoms, identify coping mechanisms, or connect with others facing similar difficulties. figure 21 illustrates that word clouds are visual representations of text that highlight key terms and their frequency of use. we used wordcloud to compare asd and non-asd texts for instances of word repetition. figure 21 figure 21 . asd word cloud. the deployment model based on the deep q-network (dqn) model for diagnosing asd is shown in figure 22 . figure 22 figure 22 . deployment system-based text for detecting asd. step 1: data collections, including cleaning, normalization, and tokenization. step 2: model development: the preprocessed data is used to train and validate a deep q-network (dqn) model for classifying tweets as indicative of asd or non-asd patterns. step 3: application interface: an application interface is developed once the model has been trained. it integrates with users’ twitter accounts and continuously analyzes their tweets. step 4: deployment: the proposed system is deployed in the cloud for storing tweets, enabling real-time monitoring of incoming tweets. predictions are flagged for review by healthcare professionals, who validate the model’s output before categorizing individuals as potentially having asd or non-asd. this digital imprint may serve as an ancillary resource for mental health practitioners, providing insights into an individual’s emotional state and social behaviors in a natural environment, potentially facilitating early detection or corroborating a diagnosis. this method is a non-invasive means of data collection, particularly beneficial for individuals who lack rapid access to clinical assessments due to financial constraints, stigma, or resource scarcity. however, it should not replace professional diagnoses and must be conducted with ethical consideration to prevent misunderstanding. table 7 shows the findings of the proposed framework on the twitter dataset. it demonstrates that the suggested method outperforms the current systems in terms of accuracy, proving its efficacy and potential for performance improvements. table 7 table 7 . compared with the proposed asd system. 5 conclusion to assist people in identifying trends in their behavior, such as social challenges or sensory sensitivities, which may encourage them to pursue a formal diagnosis. the main objective of examining tweets for identifying asd is its ability to provide behavioral and emotional indicators associated with the disorder. this research was used to analyze the textual analysis of tweets to detect the behaviors in self-identified autistic individuals relative to others. the suggested framework was evaluated using information from the social media platform “twitter” collected from a public repository. before examining the proposed system, several preprocessing steps must be implemented in the text. the ‘text’ column is cleaned by converting it to lowercase, eliminating non-alphanumeric characters (excluding spaces) through regular expressions, normalizing whitespace to a single space, and removing any leading or trailing spaces. the asd and non-asd labels are converted into a numerical format (0 or 1) with labelencoder to accommodate the binary classification requirement. tokenization of the text data is performed using a tokenizer, restricting the vocabulary to 10,000 words, and then transforming the text into sequences of numbers. the sequences are padded to a standardized length of 200 tokens to maintain consistency for the proposed model input. the proposed data is ultimately divided into an 80% training and 20% testing ratio, and class weights are calculated to resolve any class imbalance. this preparation pipeline efficiently converts raw text data into a structured numerical representation appropriate for the proposed framework, while preserving academic integrity. the output of these preprocessing steps was processed using three dl models, such as short-term memory (cnn-lstm) and a double deep q-network (ddqn). the results of these proposals were proven, revealing that the ddqn model achieved a high accuracy score of 87% with respect to the accuracy measure. the proposed framework, based on real textual data, can be helpful for real-time offering natural, behavioral, and emotional data that might indicate asd-related characteristics. finally, we have observed that social media (twitter) postings include linguistic patterns, emotional expressions, and social interactions that can help official health officials detect asd based on the thorough symptoms of asd that are posted on the platform. this study utilized a conventional dataset sourced only from the twitter network. we will emphasize the necessity of gathering datasets from many platforms to enhance the model’s generalizability in the future. data availability statement the original contributions presented in the study are included in the article/supplementary material, further inquiries can be directed to the corresponding author/s. the dataset used in this study can be found at https://data.mendeley.com/datasets/87s2br3ptb/1 . ethics statement ethical approval was not required for the study involving human data in accordance with the local legislation and institutional requirements. written informed consent was not required, for either participation in the study or for the publication of potentially/indirectly identifying information, in accordance with the local legislation and institutional requirements. the social media data was accessed and analysed in accordance with the platform’s terms of use and all relevant institutional/national regulations. author contributions nf: supervision, conceptualization, software, methodology, writing – original draft, investigation, visualization, formal analysis, validation. aa: data curation, visualization, methodology, conceptualization, validation, software, formal analysis, writing – original draft. ne: investigation, writing – review & editing, validation, formal analysis. sa: visualization, software, formal analysis, writing – review & editing, data curation. funding the author(s) declare that financial support was received for the research and/or publication of this article. the authors extend their appreciation to the king salman center for disability research for funding this work through research group no ksrg-2024-288. conflict of interest the authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest. generative ai statement the authors declare that no gen ai was used in the creation of this manuscript. any alternative text (alt text) provided alongside figures in this article has been generated by frontiers with the support of artificial intelligence and reasonable efforts have been made to ensure accuracy, including review by the authors wherever possible. if you identify any issues, please contact us. publisher’s note all claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher. references 1. asd. (2023). available online at: https://www.healthline.com/health/signs-of-autism-in-3-year-old . google scholar 2. matson, jl, and goldin, rl. what is the future of assessment for autism spectrum disorders: short and long term. res autism spectr disord . (2014) 8:209–13. doi: 10.1016/j.rasd.2013.01.007 crossref full text | google scholar 3. srivastava, ak, and schwartz, ce. intellectual disability and autism spectrum disorders: causal genes and molecular mechanisms. neurosci biobehav rev . (2014) 46:161–74. doi: 10.1016/j.neubiorev.2014.02.015 pubmed abstract | crossref full text | google scholar 4. alhujaili, n, platt, e, khalid-khan, s, and groll, d. comparison of social media use among adolescents with autism spectrum disorder and non-asd adolescents. adolesc health med ther . (2022) 13:15–21. doi: 10.2147/ahmt.s344591 pubmed abstract | crossref full text | google scholar 5. angulo-jiménez, h, and dethorne, l. narratives about autism: an analysis of youtube videos by individuals who self-identify as autistic. am j speech lang pathol . (2019) 28:569–90. doi: 10.1044/2018_ajslp-18-0045 crossref full text | google scholar 6. pew research center. (2021). available online at: https://www.pewresearch.org/internet/2021/04/07/social-media-use-in-2021/ google scholar 7. liu, j-b, guan, l, cao, j, and chen, l. coherence analysis for a class of polygon networks with the noise disturbance. ieee trans syst man cybern syst . (2025) 2025:326. doi: 10.1109/tsmc.2025.3559326 crossref full text | google scholar 8. al-nefaie, ah, aldhyani, th, sultan, ha, and alzahrani eidah, m. application of artificial intelligence in modern healthcare for diagnosis of autism spectrum disorder. front med . (2025) 12:1569464. doi: 10.3389/fmed.2025.1569464 crossref full text | google scholar 9. kim, b, jeong, d, kim, jg, hong, h, and han, k. v-dat (virtual reality data analysis tool): supporting self-awareness for autistic people from multimodal vr sensor data . in: proceedings of the uist 2023—proceedings of the 36th annual acm symposium on user interface software and technology, san francisco, ca, usa, 29 october–1 november 2023. (2023). google scholar 10. chen, c, chander, a, and uchino, k. guided play: digital sensing and coaching for stereotypical play behavior in children with autism . in proceedings of the international conference on intelligent user interfaces, proceedings iui, marina del ray, ca, usa, 17–20 march 2019; part f1476. pp. 208–217. (2019). google scholar 11. parui, s, samanta, d, chakravorty, n, ghosh, u, and rodrigues, jj. artificial intelligence and sensor-based autism spectrum disorder diagnosis using brain connectivity analysis. comput electr eng . (2023) 108:108720. doi: 10.1016/j.compeleceng.2023.108720 crossref full text | google scholar 12. golestan, s, soleiman, p, and moradi, h. a comprehensive review of technologies used for screening, assessment, and rehabilitation of autism spectrum disorder. arxiv . (2018) 2018:10986. doi: 10.48550/arxiv.1807.10986 crossref full text | google scholar 13. neeharika, ch, and riyazuddin, ym. developing an artificial intelligence based model for autism spectrum disorder detection in children. j adv res appl sci eng technol . (2023) 32:57–72. doi: 10.37934/araset.32.1.5772 crossref full text | google scholar 14. wall, dp, dally, r, luyster, r, jung, j-y, and deluca, tf. use of artificial intelligence to shorten the behavioral diagnosis of autism. plos one . (2012) 7:e43855. doi: 10.1371/journal.pone.0043855 pubmed abstract | crossref full text | google scholar 15. alzakari, sa, allinjawi, a, aldrees, a, zamzami, n, umer, m, innab, n, et al. early detection of autism spectrum disorder using explainable ai and optimized teaching strategies. j neurosci methods . (2025) 413:110315. doi: 10.1016/j.jneumeth.2024.110315 pubmed abstract | crossref full text | google scholar 16. heunis, t, aldrich, c, peters, j, jeste, s, sahin, m, scheffer, c, et al. recurrence quantification analysis of resting state eeg signals in autism spectrum disorder—a systematic methodological exploration of technical and demographic confounders in the search for biomarkers. bmc med . (2018) 16:101. doi: 10.1186/s12916-018-1086-7 crossref full text | google scholar 17. vicnesh, j, wei, jke, oh, sl, arunkumar, n, abdulhay, e, ciaccio, ej, et al. autism spectrum disorder diagnostic system using hos bispectrum with eeg signals. int j environ res public health . (2020) 17:971. doi: 10.3390/ijerph17030971 crossref full text | google scholar 18. novielli, p, romano, d, magarelli, m, diacono, d, monaco, a, amoroso, n, et al. personalized identification of autism-related bacteria in the gut microbiome using explainable artificial intelligence. iscience . (2024) 27:110709. doi: 10.1016/j.isci.2024.110709 pubmed abstract | crossref full text | google scholar 19. bosl, wj, tager-flusberg, h, and nelson, ca. eeg analytics for early detection of autism spectrum disorder: a data-driven approach. sci rep . (2018) 8:1–20. doi: 10.1038/s41598-018-24318-x pubmed abstract | crossref full text | google scholar 20. beykikhoshk, a, arandjelović, o, phung, d, venkatesh, s, and caelli, t. using twitter to learn about the autism community. soc netw anal min . (2015) 5:261. doi: 10.1007/s13278-015-0261- crossref full text | google scholar 21. mazurek, mo. social media use among adults with autism spectrum disorders. comput hum behav . (2013) 29:1709–14. doi: 10.1016/j.chb.2013.02.004 crossref full text | google scholar 22. onnela, j, and rauch, sl. harnessing smartphone-based digital phenotyping to enhance behavioral and mental health. neuropsychopharmacology . (2016) 41:1691–6. doi: 10.1038/npp.2016.7.npp20167 pubmed abstract | crossref full text | google scholar 23. tomeny, ts, vargo, cj, and el-toukhy, s. geographic and demographic correlates of autism-related anti-vaccine beliefs on twitter, 2009–2015. soc sci med . (2017) 191:168–75. doi: 10.1016/j.socscimed.2017.08.041 pubmed abstract | crossref full text | google scholar 24. tárraga-mínguez, r, gómez-marí, i, and sanz-cervera, p. what motivates internet users to search for asperger syndrome and autism on google? int j environ res public health . (2020) 17:9386. doi: 10.3390/ijerph17249386 pubmed abstract | crossref full text | google scholar 25. hartwell, m, keener, a, coffey, s, chesher, t, torgerson, t, and vassar, m. brief report: public awareness of asperger syndrome following greta thunberg appearances. j autism dev disord . (2020) 51:2104–8. doi: 10.1007/s10803-020-04651-9 pubmed abstract | crossref full text | google scholar 26. rubio-martín, s, garcía-ordás, mt, bayón-gutiérrez, m, prieto-fernández, n, and benítez-andrades, ja. “ early detection of autism spectrum disorder through ai-powered analysis of social media texts ,” 2023 ieee 36th international symposium on computer-based medical systems (cbms), l’aquila, italy, pp. 235–240. (2023). google scholar 27. jaiswal, a, and washington, p. using #actuallyautistic on twitter for precision diagnosis of autism spectrum disorder: machine learning study. jmir form res . (2024) 8:e52660. doi: 10.2196/52660 crossref full text | google scholar keywords: autism spectrum disorders, diagnosing, social media, deep learning, disabilities, artificial intelligence citation: farhah ns, alqarni aa, ebrahim n and ahmad s (2025) diagnosing autism spectrum disorders using a double deep q-network framework based on social media footprints. front. med . 12:1646249. doi: 10.3389/fmed.2025.1646249 received: 16 june 2025; accepted: 28 july 2025; published: 20 august 2025. edited by: pardeep sangwan , maharaja surajmal institute of technology, india reviewed by: jia-bao liu , anhui jianzhu university, china muhammad adnan , kohat university of science and technology, pakistan copyright © 2025 farhah, alqarni, ebrahim and ahmad. this is an open-access article distributed under the terms of the creative commons attribution license (cc by) . the use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. no use, distribution or reproduction is permitted which does not comply with these terms. *correspondence: nesren s. farhah, bi5myxjoywhac2v1lmvkds5zyq== ; nadhem ebrahim, bmvicmfoaw1adwfrcm9ulmvkdq== ; sultan ahmad, cy5hbglzagvyqhbzyxuuzwr1lnnh disclaimer: all claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. any product that may be evaluated in this article or claim that may be made by its manufacturer is not guaranteed or endorsed by the publisher. download article download pdf readcube epub xml share on export citation endnote reference manager simple text file bibtex 1,193 total views 132 downloads citation numbers are available from dimensions view article impact view altmetric score share on edited by p s pardeep sangwan reviewed by j l jia-bao liu m a muhammad adnan table of contents abstract 1 introduction 2 materials and methods 3 performance of the framework 4 experiment and discussion results 5 conclusion data availability statement ethics statement author contributions funding conflict of interest generative ai statement publisher’s note references export citation endnote reference manager simple text file bibtex check for updates frontiers' impact articles published with frontiers have received 12 million total citations your research is the real superpower - learn how we maximise its impact through our leading community journals explore our impact metrics supplementary material download article download download pdf readcube epub xml guidelines author guidelines services for authors policies and publication ethics editor guidelines fee policy explore articles research topics journals how we publish outreach frontiers forum frontiers policy labs frontiers for young minds frontiers planet prize connect help center emails and alerts contact us submit career opportunities follow us © 2025 frontiers media s.a. all rights reserved privacy policy | terms and conditions [["shallowreactive",1],{"data":2,"state":4,"once":10,"_errors":11,"serverrendered":13,"path":14,"pinia":15},["shallowreactive",3],{},["reactive",5],{"$ssite-config":6},{"env":7,"name":8,"url":9},"production","frontiers articles","https://article-pages-2024.frontiersin.org/",["set"],["shallowreactive",12],{},true,"/journals/medicine/articles/10.3389/fmed.2025.1646249/full",["reactive",16],{"main":17,"user":514,"article":515,"articlehub":766,"mainheader":770},{"ibar":18,"footer":268,"newslettercomponent":-1,"snackbaritem":350,"toggleshowsnackbar":351,"contentfuljournal":352,"graphjournal":416,"settingsfeaturesswitchers":420,"templatetogglebanner":421,"tenantconfig":479},{"tenantlogo":19,"journallogo":19,"aboutus":20,"submiturl":113,"showsubmitbutton":13,"journal":114,"sectionterm":199,"aboutjournal":200,"mainlinks":249,"journallinks":256,"helpcenterlink":265},"",[21,38,47,71,87],{"title":22,"links":23},"who we are",[24,29,32,35],{"text":25,"url":26,"target":27,"arialabel":28},"mission and values","https://www.frontiersin.org/about/mission","_self",null,{"text":30,"url":31,"target":27,"arialabel":28},"history","https://www.frontiersin.org/about/history",{"text":33,"url":34,"target":27,"arialabel":28},"leadership","https://www.frontiersin.org/about/leadership",{"text":36,"url":37,"target":27,"arialabel":28},"awards","https://www.frontiersin.org/about/awards",{"title":39,"links":40},"impact and progress",[41,44],{"text":42,"url":43,"target":27,"arialabel":28},"frontiers' impact","https://www.frontiersin.org/about/impact",{"text":45,"url":46,"target":27,"arialabel":28},"our annual reports","https://www.frontiersin.org/about/annual-reports",{"title":48,"links":49},"publishing model",[50,53,56,59,62,65,68],{"text":51,"url":52,"target":27,"arialabel":28},"how we publish","https://www.frontiersin.org/about/how-we-publish",{"text":54,"url":55,"target":27,"arialabel":28},"open access","https://www.frontiersin.org/about/open-access",{"text":57,"url":58,"target":27,"arialabel":28},"peer review","https://www.frontiersin.org/about/peer-review",{"text":60,"url":61,"target":27,"arialabel":28},"research integrity","https://www.frontiersin.org/about/research-integrity",{"text":63,"url":64,"target":27,"arialabel":28},"research topics","https://www.frontiersin.org/about/research-topics",{"text":66,"url":67,"target":27,"arialabel":28},"fair² data management","https://www.frontiersin.org/about/fair-data-management",{"text":69,"url":70,"target":27,"arialabel":28},"fee policy","https://www.frontiersin.org/about/fee-policy",{"title":72,"links":73},"services",[74,78,81,84],{"text":75,"url":76,"target":77,"arialabel":28},"societies","https://publishingpartnerships.frontiersin.org/","_blank",{"text":79,"url":80,"target":27,"arialabel":28},"national consortia","https://www.frontiersin.org/open-access-agreements/consortia",{"text":82,"url":83,"target":27,"arialabel":28},"institutional partnerships","https://www.frontiersin.org/about/open-access-agreements",{"text":85,"url":86,"target":27,"arialabel":28},"collaborators","https://www.frontiersin.org/about/collaborators",{"title":88,"links":89},"more from frontiers",[90,94,97,101,105,109],{"text":91,"url":92,"target":77,"arialabel":93},"frontiers forum","https://forum.frontiersin.org/","this link will take you to the frontiers forum website",{"text":95,"url":96,"target":27,"arialabel":28},"frontiers planet prize","https://www.frontiersin.org/about/frontiers-planet-prize",{"text":98,"url":99,"target":77,"arialabel":100},"press office","https://pressoffice.frontiersin.org/","this link will take you to the frontiers press office website",{"text":102,"url":103,"target":27,"arialabel":104},"sustainability","https://www.frontiersin.org/about/sustainability","link to information about frontiers' sustainability",{"text":106,"url":107,"target":77,"arialabel":108},"career opportunities","https://careers.frontiersin.org/","this link will take you to the frontiers careers website",{"text":110,"url":111,"target":27,"arialabel":112},"contact us","https://www.frontiersin.org/about/contact","this link will take you to the help pages to contact our support team","https://www.frontiersin.org/submission/submit?domainid=2&fieldid=39&specialtyid=0&entitytype=2&entityid=602",{"id":115,"name":116,"slug":117,"sections":118},602,"frontiers in medicine","medicine",[119,123,127,131,135,139,143,147,151,155,159,163,167,171,175,179,183,187,191,195],{"id":120,"name":121,"slug":122},797,"dermatology","dermatology",{"id":124,"name":125,"slug":126},842,"family medicine and primary care","family-medicine-and-primary-care",{"id":128,"name":129,"slug":130},681,"gastroenterology","gastroenterology",{"id":132,"name":133,"slug":134},1321,"gene and cell therapy","gene-and-cell-therapy",{"id":136,"name":137,"slug":138},790,"geriatric medicine","geriatric-medicine",{"id":140,"name":141,"slug":142},1969,"healthcare professions education","healthcare-professions-education",{"id":144,"name":145,"slug":146},752,"hematology","hematology",{"id":148,"name":149,"slug":150},3648,"hepatobiliary diseases","hepatobiliary-diseases",{"id":152,"name":153,"slug":154},3379,"infectious diseases: pathogenesis and therapy","infectious-diseases-pathogenesis-and-therapy",{"id":156,"name":157,"slug":158},1139,"intensive care medicine and anesthesiology","intensive-care-medicine-and-anesthesiology",{"id":160,"name":161,"slug":162},768,"nephrology","nephrology",{"id":164,"name":165,"slug":166},815,"nuclear medicine","nuclear-medicine",{"id":168,"name":169,"slug":170},2526,"obstetrics and gynecology","obstetrics-and-gynecology",{"id":172,"name":173,"slug":174},1635,"ophthalmology","ophthalmology",{"id":176,"name":177,"slug":178},618,"pathology","pathology",{"id":180,"name":181,"slug":182},1307,"precision medicine","precision-medicine",{"id":184,"name":185,"slug":186},678,"pulmonary medicine","pulmonary-medicine",{"id":188,"name":189,"slug":190},1306,"regulatory science","regulatory-science",{"id":192,"name":193,"slug":194},662,"rheumatology","rheumatology",{"id":196,"name":197,"slug":198},1318,"translational medicine","translational-medicine","sections",[201,225],{"title":202,"links":203},"scope",[204,207,210,213,216,219,222],{"text":205,"url":206,"target":27,"arialabel":28},"field chief editors","https://www.frontiersin.org/journals/medicine/about#about-editors",{"text":208,"url":209,"target":27,"arialabel":28},"mission & scope","https://www.frontiersin.org/journals/medicine/about#about-scope",{"text":211,"url":212,"target":27,"arialabel":28},"facts","https://www.frontiersin.org/journals/medicine/about#about-facts",{"text":214,"url":215,"target":27,"arialabel":28},"journal sections","https://www.frontiersin.org/journals/medicine/about#about-submission",{"text":217,"url":218,"target":27,"arialabel":28},"open access statement","https://www.frontiersin.org/journals/medicine/about#about-open",{"text":220,"url":221,"target":27,"arialabel":28},"copyright statement","https://www.frontiersin.org/journals/medicine/about#copyright-statement",{"text":223,"url":224,"target":27,"arialabel":28},"quality","https://www.frontiersin.org/journals/medicine/about#about-quality",{"title":226,"links":227},"for authors",[228,231,234,237,240,243,246],{"text":229,"url":230,"target":27,"arialabel":28},"why submit?","https://www.frontiersin.org/journals/medicine/for-authors/why-submit",{"text":232,"url":233,"target":27,"arialabel":28},"article types","https://www.frontiersin.org/journals/medicine/for-authors/article-types",{"text":235,"url":236,"target":27,"arialabel":28},"author guidelines","https://www.frontiersin.org/journals/medicine/for-authors/author-guidelines",{"text":238,"url":239,"target":27,"arialabel":28},"editor guidelines","https://www.frontiersin.org/journals/medicine/for-authors/editor-guidelines",{"text":241,"url":242,"target":27,"arialabel":28},"publishing fees","https://www.frontiersin.org/journals/medicine/for-authors/publishing-fees",{"text":244,"url":245,"target":27,"arialabel":28},"submission checklist","https://www.frontiersin.org/journals/medicine/for-authors/submission-checklist",{"text":247,"url":248,"target":27,"arialabel":28},"contact editorial office","https://www.frontiersin.org/journals/medicine/for-authors/contact-editorial-office",[250,253],{"text":251,"url":252,"target":27,"arialabel":28},"all journals","https://www.frontiersin.org/journals",{"text":254,"url":255,"target":27,"arialabel":28},"all articles","https://www.frontiersin.org/articles",[257,260,262],{"text":258,"url":259,"target":27,"arialabel":28},"articles","articles",{"text":63,"url":261,"target":27,"arialabel":28},"research-topics",{"text":263,"url":264,"target":27,"arialabel":28},"editorial board","editors",{"text":266,"url":267,"target":77,"arialabel":266},"help center","https://helpcenter.frontiersin.org",{"blocks":269,"sociallinks":323,"copyright":347,"termsandconditionsurl":348,"privacypolicyurl":349},[270,284,294,308],{"title":271,"links":272},"guidelines",[273,275,278,281,283],{"text":235,"url":274,"target":27,"arialabel":28},"https://www.frontiersin.org/guidelines/author-guidelines",{"text":276,"url":277,"target":27,"arialabel":28},"services for authors","https://www.frontiersin.org/for-authors/author-services",{"text":279,"url":280,"target":27,"arialabel":28},"policies and publication ethics","https://www.frontiersin.org/guidelines/policies-and-publication-ethics",{"text":238,"url":282,"target":27,"arialabel":28},"https://www.frontiersin.org/guidelines/editor-guidelines",{"text":69,"url":70,"target":27,"arialabel":28},{"title":285,"links":286},"explore",[287,288,291,293],{"text":258,"url":255,"target":27,"arialabel":28},{"text":289,"url":290,"target":27,"arialabel":28},"research topics ","https://www.frontiersin.org/research-topics",{"text":292,"url":252,"target":27,"arialabel":28},"journals",{"text":51,"url":52,"target":27,"arialabel":28},{"title":295,"links":296},"outreach",[297,300,303,307],{"text":298,"url":92,"target":77,"arialabel":299},"frontiers forum ","frontiers forum website",{"text":301,"url":302,"target":77,"arialabel":28},"frontiers policy labs ","https://policylabs.frontiersin.org/",{"text":304,"url":305,"target":77,"arialabel":306},"frontiers for young minds","https://kids.frontiersin.org/","frontiers for young minds journal",{"text":95,"url":96,"target":27,"arialabel":28},{"title":309,"links":310},"connect",[311,312,316,319,322],{"text":266,"url":267,"target":77,"arialabel":266},{"text":313,"url":314,"target":77,"arialabel":315},"emails and alerts ","https://subscription-management.frontiersin.org/emails/preferences#block0","subscribe to frontiers emails",{"text":317,"url":111,"target":27,"arialabel":318},"contact us ","subscribe to newsletter",{"text":320,"url":321,"target":27,"arialabel":28},"submit","https://www.frontiersin.org/submission/submit",{"text":106,"url":107,"target":77,"arialabel":28},[324,332,337,342],{"link":325,"type":328,"color":329,"icon":330,"size":331,"hiddentext":13},{"text":326,"url":327,"target":77,"arialabel":326},"frontiers facebook","https://www.facebook.com/frontiersin","link","grey","facebook","medium",{"link":333,"type":328,"color":329,"icon":336,"size":331,"hiddentext":13},{"text":334,"url":335,"target":77,"arialabel":28},"frontiers twitter","https://twitter.com/frontiersin","twitter",{"link":338,"type":328,"color":329,"icon":341,"size":331,"hiddentext":13},{"text":339,"url":340,"target":77,"arialabel":28},"frontiers linkedin","https://www.linkedin.com/company/frontiers","linkedin",{"link":343,"type":328,"color":329,"icon":346,"size":331,"hiddentext":13},{"text":344,"url":345,"target":77,"arialabel":28},"frontiers instagram","https://www.instagram.com/frontiersin_","instagram","frontiers media s.a. all rights reserved","https://www.frontiersin.org/legal/terms-and-conditions","https://www.frontiersin.org/legal/privacy-policy",{},false,{"__typename":353,"identifier":115,"name":116,"slug":117,"banner":354,"description":409,"mission":410,"palette":411,"impactfactor":412,"citescore":413,"citations":414,"showtagline":28,"twitter":415},"journal",[355],{"id":356,"src":357,"name":358,"tags":359,"type":367,"width":368,"height":369,"idhash":370,"archive":371,"brandid":372,"limited":371,"filesize":373,"ispublic":374,"original":375,"copyright":376,"extension":377,"thumbnails":379,"datecreated":387,"description":388,"orientation":389,"usercreated":390,"watermarked":371,"datemodified":387,"datepublished":391,"ecsarchivefiles":392,"propertyoptions":393,"property_channel":398,"property_sub-type":400,"property_asset_type":402,"activeoriginalfocuspoint":404,"property_office_department":407},"3501f557-cafa-4218-930c20d1d930c78c","https://d2csxpduxe849s.cloudfront.net/media/e32629c6-9347-4f84-81feaef7bfa342b3/3501f557-cafa-4218-930c20d1d930c78c/webimage-5988957c-0534-4338-984381d67214c0af.png","fmed_main visual_purple_website",[360,361,362,363,364,365,366],"professional","medical","research","biotechnology","scientific","analy","lab","image",7360,4912,"67388dad93685635",0,"22c10171-81b3-4da6-99342f272a32e8bb",13595017,1,"https://brand.frontiersin.org/m/67388dad93685635/original/fmed_main-visual_purple_website.jpg","copyright (c) 2018 rosshelen/shutterstock. no use without permission.",[378],"jpg",{"mini":380,"thul":381,"webimage":357,"guidelines":382,"websitejpg_xl":383,"websitewebp_l":384,"websitewebp_m":385,"websitewebp_xl":386},"https://d2csxpduxe849s.cloudfront.net/media/e32629c6-9347-4f84-81feaef7bfa342b3/3501f557-cafa-4218-930c20d1d930c78c/mini-4ebc2476-6efb-4a3e-a669185b307fef72.png","https://d2csxpduxe849s.cloudfront.net/media/e32629c6-9347-4f84-81feaef7bfa342b3/3501f557-cafa-4218-930c20d1d930c78c/thul-78bd9351-8a86-4c7b-874fc1cc5caa92ce.png","https://d2csxpduxe849s.cloudfront.net/media/e32629c6-9347-4f84-81feaef7bfa342b3/3501f557-cafa-4218-930c20d1d930c78c/f6ff788e-26d5-4bc5-8cb92ee85a59ca4a/guidelines-fmed_main visual_purple_website.png","https://d2csxpduxe849s.cloudfront.net/media/e32629c6-9347-4f84-81feaef7bfa342b3/3501f557-cafa-4218-930c20d1d930c78c/f6ff788e-26d5-4bc5-8cb92ee85a59ca4a/websitejpg_xl-fmed_main visual_purple_website.jpg","https://d2csxpduxe849s.cloudfront.net/media/e32629c6-9347-4f84-81feaef7bfa342b3/3501f557-cafa-4218-930c20d1d930c78c/f6ff788e-26d5-4bc5-8cb92ee85a59ca4a/websitewebp_l-fmed_main visual_purple_website.webp","https://d2csxpduxe849s.cloudfront.net/media/e32629c6-9347-4f84-81feaef7bfa342b3/3501f557-cafa-4218-930c20d1d930c78c/f6ff788e-26d5-4bc5-8cb92ee85a59ca4a/websitewebp_m-fmed_main visual_purple_website.webp","https://d2csxpduxe849s.cloudfront.net/media/e32629c6-9347-4f84-81feaef7bfa342b3/3501f557-cafa-4218-930c20d1d930c78c/f6ff788e-26d5-4bc5-8cb92ee85a59ca4a/websitewebp_xl-fmed_main visual_purple_website.webp","2022-06-27t10:00:04z","laboratory assistant putting test tubes into the holder, close-up view focused on the tubes","landscape","caroline sutter","2022-06-27t09:27:09z",[],[394,395,396,397],"414fb2d4-2283-43fd-be14e534eca67928","6c18119b-14bd-4951-b437696f4357bd33","7c692885-db25-4858-b1fb4ff47b241e9b","d88c0047-ec30-4506-a7df28a4d765e1cf",[399],"frontiersin_org",[401],"main_visual",[403],"photography",{"x":405,"y":406},3680,2456,[408],"publishing","a highly cited multidisciplinary journal which advances our medical knowledge. it supports the translation of scientific advances into new therapies and diagnostic tools that will improve patient care.","\u003cp>frontiers in medicine is a broad-scope, multidisciplinary journal covering all established medical disciplines to improve clinical practice and patient care.\u003c/p>\n\n\u003cp>led by field chief editor prof michel goldman (université libre de bruxelles, belgium), frontiers in medicine is indexed in pubmed central (pmc), web of science (scie), and scopus, among others, and welcomes basic and clinical medical research that facilitate the translation of scientific advances into new therapies or diagnostic tools. topics include, but are not limited to:\u003c/p>\n\n\u003cul>\n \u003cli>dermatology\u003c/li>\n \u003cli>family medicine and primary care\u003c/li>\n \u003cli>gastroenterology\u003c/li>\n \u003cli>gene and cell therapy\u003c/li>\n \u003cli>geriatric medicine\u003c/li>\n \u003cli>healthcare professions education\u003c/li>\n \u003cli>hematology\u003c/li>\n \u003cli>hepatobiliary diseases\u003c/li>\n \u003cli>infectious diseases: pathogenesis and therapy\u003c/li>\n \u003cli>intensive care medicine and anesthesiology\u003c/li>\n \u003cli>nephrology\u003c/li>\n \u003cli>nuclear medicine\u003c/li>\n \u003cli>obstetrics and gynecology\u003c/li>\n \u003cli>ophthalmology\u003c/li>\n \u003cli>pathology\u003c/li>\n \u003cli>precision medicine\u003c/li>\n \u003cli>pulmonary medicine\u003c/li>\n \u003cli>regulatory science\u003c/li>\n \u003cli>rheumatology\u003c/li>\n \u003cli>translational medicine.\u003c/li>\n\u003c/ul>\n\n\u003cp>in addition to papers that provide a link between basic research and clinical practice, a particular emphasis is given to studies that are directly relevant to patient care.\u003c/p>\n\n\u003cp>as well as the established medical disciplines, frontiers in medicine aims to publish research that will facilitate:\u003c/p>\n\n\u003cul>\n \u003cli>access to medicinal products and medical devices worldwide\u003c/li>\n \u003cli>addressing the grand health challenges around the world\u003c/li>\n \u003cli>the exploitation of big data and the use of novel information and communication tools in the assessment of new medicines\u003c/li>\n \u003cli>the scientific bases for guidelines and decisions from regulatory authorities\u003c/li>\n \u003cli>the use of patient-reported outcomes under real world conditions.\u003c/li>\n\u003c/ul>\n\n\u003cp>all studies must contribute insights into the field of medicine. papers which do not primarily focus on a medical discipline are not suitable for publication in this journal. manuscripts that focus solely on the molecular or cellular mechanisms of diseases without a foundation in clinical medicine are not suitable for publication in this journal. similarly, studies that are purely descriptive or observational, without a clear hypothesis or mechanistic investigation, are not within the scope of this journal. research that is primarily epidemiological or public health-oriented, without a foundation in the pathophysiology or treatment of disease, is also not appropriate for this journal.\u003c/p>\n\n\u003cp>frontiers’ journals require that manuscripts primarily comprising computational studies of public data, must include appropriate validation. please refer to the \u003ca href=\"https://www.frontiersin.org/guidelines/policies-and-publication-ethics#standards-for-research-methodology:~:text=complaints%20and%20allegations.-,standards%20for%20research%20methodology,-experiments\">frontiers standards for research methodology policy\u003c/a>, for more information. manuscripts not adhering to these standards will not be considered.\u003cp>\n\n\u003cp>frontiers in medicine is committed to advancing developments in the field of medicine by allowing unrestricted access to articles and communicating scientific knowledge to researchers and the public alike, to enable the scientific breakthroughs of the future.\u003c/p>\n\n\u003cp>ethics statement:\u003c/p>\n\n\u003cp>all manuscripts submitted to frontiers in medicine that have been conducted in human subjects must conform with current regulations and the declaration of helsinki. ethics committee approval and informed patient consent are required for studies involving human subjects. ethics committee approval is also needed for studies involving animals. phase i - phase iv clinical trials submitted for publication in frontiers in medicine must have been registered with an appropriate public trials registry at the time or before the first patient enrolment. the information on the clinical trial registration (unique identifier and url) must be included in the abstract. authors are required to disclose all apparent or potential conflicts of interest according to the icmje guidelines and those of frontiers.\u003c/p>\n\n\u003cp>frontiers endeavors to follow the guidelines and best practice recommendations published by the committee on publication ethics (cope). authors should refer to the author guidelines for full details.\u003c/p>","purple","3.9","3.6","176752","@frontmedicine",{"id":115,"name":116,"slug":117,"abbreviation":417,"isonline":13,"isopenforsubmissions":13,"citescore":418,"impactfactor":419},"fmed",6,3,{"displaytitlepilllabels":13,"displayrelatedarticlesbox":13,"showeditors":13,"showreviewers":13,"showloopimpactlink":13,"enablefigshare":351,"usexmlimages":13},{"ispublic":13,"allowcompanyusers":351,"whitelistemails":422,"enablealljournals":13,"whitelistjournals":444},[423,424,425,426,427,428,429,430,431,428,432,433,434,435,436,437,438,439,440,441,442,443],"y2fybg9zlmxvcmnhqgzyb250awvyc2lulm9yzw==","zgfuawvslmx1ekbmcm9udgllcnnpbi5vcmc=","bgf1cmeudgvuyubmcm9udgllcnnpbi5vcmc=","cmfmywvslnjpyw5jag9aznjvbnrpzxjzaw4ub3jn","amftzxmuc21hbgxib25lqgzyb250awvyc2lulm9yzw==","znjhbi5tb3jlbm9aznjvbnrpzxjzaw4ub3jn","c2ftdwvslmzlcm5hbmrlekbmcm9udgllcnnpbi5vcmc=","ymfyymfyys5jyxjjyw5naxvaznjvbnrpzxjzaw4ub3jn","axzhbi5zyw50yw1hcmlhqgzyb250awvyc2lulm9yzw==","ahvllnryyw5aznjvbnrpzxjzaw4ub3jn","z29uy2fsby52yxjnyxnaznjvbnrpzxjzaw4ub3jn","bhvjawuuc2vubkbmcm9udgllcnnpbi5vcmc=","bg9ybi5mcmfzzxjaznjvbnrpzxjzaw4ub3jn","zwxzys5jyxjyb25aznjvbnrpzxjzaw4ub3jn","bwfhcnrlbi52yw5kawpja0bmcm9udgllcnnpbi5vcmc=","ymluzgh1lmtyaxnobmfuqgzyb250awvyc2lulm9yzw==","bwf0dghldy5hdhr3yxrlcnnaznjvbnrpzxjzaw4ub3jn","z2l1bglhlnzhbhnly2noaubmcm9udgllcnnpbi5vcmc=","zmfiawfulmrlbgxhbw9ydgvaznjvbnrpzxjzaw4ub3jn","dmlqyxlhbi5wcebwaxrzb2x1dglvbnmuy29t","z3vpbgxhdw1llnnldxjhdebmcm9udgllcnnpbi5vcmc=",[445,446,447,406,448,449,374,450,115,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478],2232,1729,2357,2176,2333,1843,106,616,310,657,3123,1468,2137,628,1566,2726,2086,1490,451,141,1335,2655,1238,604,698,1547,176,1440,403,1239,755,2136,609,1534,{"spaceid":374,"name":374,"availablejournalpages":480,"announcement":484},[259,264,261,481,482,483],"volumes","about","community-reviewers",{"__typename":485,"sys":486,"preheader":42,"title":488,"description":489,"image":490,"link":512},"announcement",{"id":487},"5ittnttqgazppgh6rx0alm","articles published with frontiers have received 12 million total citations","your research is the real superpower - learn how we maximise its impact through our leading community journals",[491],{"archive":371,"brandid":372,"copyright":28,"datecreated":492,"datemodified":493,"datepublished":494,"description":28,"extension":495,"filesize":497,"height":498,"id":499,"ispublic":371,"limited":371,"name":500,"orientation":389,"original":28,"thumbnails":501,"type":367,"watermarked":371,"width":508,"videopreviewurls":509,"tags":510,"textmetaproperties":511,"src":502},"2025-06-18t12:58:01z","2025-06-18t14:15:34z","2025-06-18t12:57:32z",[496],"png",1365026,920,"7c5269c4-3c83-4591-951a74d15b95daea","impact metrics banner for article pages",{"webimage":502,"thul":503,"mini":504,"websitewebp_l":505,"websitewebp_m":506,"guidelines":507},"https://brand.frontiersin.org/m/59ee6275cb9a849c/webimage-impact-metrics-banner-for-article-pages.png","https://brand.frontiersin.org/m/59ee6275cb9a849c/thul-impact-metrics-banner-for-article-pages.png","https://brand.frontiersin.org/m/59ee6275cb9a849c/mini-impact-metrics-banner-for-article-pages.png","https://brand.frontiersin.org/asset/7c5269c4-3c83-4591-951a-74d15b95daea/websitewebp_l/impact-metrics-banner-for-article-pages.webp","https://brand.frontiersin.org/asset/7c5269c4-3c83-4591-951a-74d15b95daea/websitewebp_m/impact-metrics-banner-for-article-pages.webp","https://brand.frontiersin.org/asset/7c5269c4-3c83-4591-951a-74d15b95daea/guidelines/impact-metrics-banner-for-article-pages.png",1600,[],[],[],{"text":513,"url":43,"target":27,"arialabel":28},"explore our impact metrics",{"loggeduserinfo":-1},{"currentarticle":516,"ispreviewpage":351,"hassupplementaldata":351,"showcrossmarkwidget":13,"articletemplate":646,"currentarticlepagemetainfo":647,"xmlparsedarticlecontent":-1,"xmlparsingerror":-1},{"id":517,"doi":518,"title":519,"acceptancedate":520,"receptiondate":521,"publicationdate":522,"lastmodifieddate":523,"ispublished":13,"abstract":524,"researchtopic":525,"articletype":531,"stage":534,"keywords":536,"authors":543,"editors":584,"reviewers":592,"journal":607,"section":615,"impactmetrics":617,"volume":620,"articlevolume":621,"relatedarticles":622,"ispublishedv2":13,"contents":623,"files":626},1646249,"10.3389/fmed.2025.1646249","diagnosing autism spectrum disorders using a double deep q-network framework based on social media footprints","2025-07-28t08:25:45.000z","2025-06-16t12:25:51.000z","2025-08-20t00:00:00.000z","2025-10-21t02:22:52.270z","introductionsocial media is increasingly used in many contexts within the healthcare sector. the improved prevalence of internet use via computers or mobile devices presents an opportunity for social media to serve as a tool for the rapid and direct distribution of essential health information. autism spectrum disorders (asd) are a comprehensive neurodevelopmental syndrome with enduring effects. twitter has become a platform for the asd community, offering substantial assistance to its members by disseminating information on their beliefs and perspectives via language and emotional expression. adults with asd have considerable social and emotional challenges, while also demonstrating abilities and interests in screen-based technologies.methodsthe novelty of this research lies in its use in the context of twitter to analyze and identify asd. this research used twitter as the primary data source to examine the behavioral traits and immediate emotional expressions of persons with asd. we applied convolutional neural networks with long short-term memory (cnn-lstm), lstm, and double deep q-network (ddqn-inspired) using a standardized dataset including 172 tweets from the asd class and 158 tweets from the non-asd class. the dataset was processed to exclude lowercase text and special characters, followed by a tokenization approach to convert the text into integer word sequences. the encoding was used to transform the classes into binary labels. following preprocessing, the proposed framework was implemented to identify asd.resultsthe findings of the ddqn-inspired model demonstrate a high precision of 87% compared to the proposed model. this finding demonstrates the potential of the proposed approach for identifying asd based on social media content.discussionultimately, the proposed system was compared against the existing system that used the same dataset. the proposed approach is based on variations in the text of social media interactions, which can assist physicians and clinicians in performing symptom studies within digital footprint environments.",{"id":526,"title":527,"articlescount":528,"ismagazinepage":351,"slug":529,"isopenforsubmission":351,"views":530},69516,"ai innovations in neuroimaging: transforming brain analysis",10,"ai-innovations-in-neuroimaging-transforming-brain-analysis",16647,{"id":532,"name":533},24,"original research",{"id":535,"name":19},18,[537,538,539,540,541,542],"artificial intelligence","deep learning","social media","disabilities","autism spectrum disorders","diagnosing",[544,555,564,573],{"id":545,"firstname":546,"middlename":19,"lastname":547,"givennames":548,"iscorresponding":351,"isprofilepublic":13,"userid":545,"email":-1,"affiliations":549},2586659,"nesren s.","farhah","nesren s. ",[550,553],{"organizationname":551,"countryname":552,"cityname":19,"statename":19,"zipcode":19},"department of health informatics, college of health science, saudi electronic university","saudi arabia",{"organizationname":554,"countryname":552,"cityname":19,"statename":19,"zipcode":19},"king salman center for disability research",{"id":556,"firstname":557,"middlename":19,"lastname":558,"givennames":559,"iscorresponding":351,"isprofilepublic":13,"userid":556,"email":-1,"affiliations":560},3164796,"ahmed abdullah","alqarni","ahmed abdullah ",[561,562],{"organizationname":554,"countryname":552,"cityname":19,"statename":19,"zipcode":19},{"organizationname":563,"countryname":552,"cityname":19,"statename":19,"zipcode":19},"department of computer sciences and information technology, al-baha university",{"id":565,"firstname":566,"middlename":19,"lastname":567,"givennames":568,"iscorresponding":351,"isprofilepublic":13,"userid":565,"email":-1,"affiliations":569},3077810,"nadhem","ebrahim","nadhem ",[570],{"organizationname":571,"countryname":572,"cityname":19,"statename":19,"zipcode":19},"department of computer science, college of engineering and polymer science, university of akron","united states",{"id":574,"firstname":575,"middlename":19,"lastname":576,"givennames":577,"iscorresponding":351,"isprofilepublic":13,"userid":574,"email":-1,"affiliations":578},1762668,"sultan","ahmad","sultan ",[579,581],{"organizationname":580,"countryname":552,"cityname":19,"statename":19,"zipcode":19},"department of computer science, college of computer engineering and sciences, prince sattam bin abdulaziz university",{"organizationname":582,"countryname":583,"cityname":19,"statename":19,"zipcode":19},"school of computer science and engineering, lovely professional university","india",[585],{"id":586,"firstname":587,"middlename":19,"lastname":588,"givennames":589,"iscorresponding":351,"isprofilepublic":13,"userid":586,"email":-1,"affiliations":590},2928766,"pardeep","sangwan","pardeep ",[591],{"organizationname":19,"countryname":19,"cityname":19,"statename":19,"zipcode":19},[593,600],{"id":594,"firstname":595,"middlename":19,"lastname":596,"givennames":597,"iscorresponding":351,"isprofilepublic":13,"userid":594,"email":-1,"affiliations":598},1743107,"jia-bao","liu","jia-bao ",[599],{"organizationname":19,"countryname":19,"cityname":19,"statename":19,"zipcode":19},{"id":601,"firstname":602,"middlename":19,"lastname":603,"givennames":604,"iscorresponding":351,"isprofilepublic":13,"userid":601,"email":-1,"affiliations":605},3104897,"muhammad","adnan","muhammad ",[606],{"organizationname":19,"countryname":19,"cityname":19,"statename":19,"zipcode":19},{"id":115,"slug":117,"name":116,"shortname":608,"electronicissn":609,"field":610,"specialtyid":28,"journalsectionpaths":613},"front. med.","2296-858x",{"id":611,"domainid":612},39,2,[614],{"section":615},{"id":180,"name":181,"slug":182,"specialtyid":616},1754,{"views":618,"downloads":619,"citations":371},1193,132,12,"volume 12 - 2025",[],{"titlehtml":519,"fulltexthtml":624,"menuhtml":625},"\u003cdiv class=\"journalabstract\"> \u003ca id=\"h1\" name=\"h1\">\u003c/a>\n \u003cdiv class=\"authors\">\u003cspan class=\"author-wrapper notranslate\">\u003ca href=\"https://loop.frontiersin.org/people/2586659\" class=\"user-id-2586659\">\u003cimg class=\"pr5\" src=\"https://loop.frontiersin.org/images/profile/2586659/74\" onerror=\"this.onerror=null;this.src='https://loop.frontiersin.org/cdn/images/profile/default_32.jpg';\" alt=\"nesren s. farhah,
\">nesren s. farhah\u003c/a>\u003csup>1,2\u003c/sup>\u003csup>*\u003c/sup>\u003c/span>\u003cspan class=\"author-wrapper notranslate\">\u003ca href=\"https://loop.frontiersin.org/people/3164796\" class=\"user-id-3164796\">\u003cimg class=\"pr5\" src=\"https://loop.frontiersin.org/images/profile/3164796/74\" onerror=\"this.onerror=null;this.src='https://loop.frontiersin.org/cdn/images/profile/default_32.jpg';\" alt=\"ahmed abdullah alqarni,\">ahmed abdullah alqarni\u003c/a>\u003csup>2,3\u003c/sup>\u003c/span>\u003cspan class=\"author-wrapper notranslate\">\u003ca href=\"https://loop.frontiersin.org/people/3077810\" class=\"user-id-3077810\">\u003cimg class=\"pr5\" src=\"https://loop.frontiersin.org/images/profile/3077810/74\" onerror=\"this.onerror=null;this.src='https://loop.frontiersin.org/cdn/images/profile/default_32.jpg';\" alt=\"nadhem ebrahim
\">nadhem ebrahim\u003c/a>\u003csup>4\u003c/sup>\u003csup>*\u003c/sup>\u003c/span>\u003cspan class=\"author-wrapper notranslate\">\u003ca href=\"https://loop.frontiersin.org/people/1762668\" class=\"user-id-1762668\">\u003cimg class=\"pr5\" src=\"https://loop.frontiersin.org/images/profile/1762668/74\" onerror=\"this.onerror=null;this.src='https://loop.frontiersin.org/cdn/images/profile/default_32.jpg';\" alt=\"sultan ahmad,
\">sultan ahmad\u003c/a>\u003csup>5,6\u003c/sup>\u003csup>*\u003c/sup>\u003c/span>\u003c/div> \u003cul class=\"notes\"> \u003cli>\u003cspan>\u003csup>1\u003c/sup>\u003c/span>department of health informatics, college of health science, saudi electronic university, riyadh, saudi arabia\u003c/li> \u003cli>\u003cspan>\u003csup>2\u003c/sup>\u003c/span>king salman center for disability research, riyadh, saudi arabia\u003c/li> \u003cli>\u003cspan>\u003csup>3\u003c/sup>\u003c/span>department of computer sciences and information technology, al-baha university, al-baha, saudi arabia\u003c/li> \u003cli>\u003cspan>\u003csup>4\u003c/sup>\u003c/span>department of computer science, college of engineering and polymer science, university of akron, oh, united states\u003c/li> \u003cli>\u003cspan>\u003csup>5\u003c/sup>\u003c/span>department of computer science, college of computer engineering and sciences, prince sattam bin abdulaziz university, al-kharj, saudi arabia\u003c/li> \u003cli>\u003cspan>\u003csup>6\u003c/sup>\u003c/span>school of computer science and engineering, lovely professional university, phagwara, india\u003c/li> \u003c/ul>\n\u003cp class=\"mb15\">\u003cb>introduction:\u003c/b> social media is increasingly used in many contexts within the healthcare sector. the improved prevalence of internet use via computers or mobile devices presents an opportunity for social media to serve as a tool for the rapid and direct distribution of essential health information. autism spectrum disorders (asd) are a comprehensive neurodevelopmental syndrome with enduring effects. twitter has become a platform for the asd community, offering substantial assistance to its members by disseminating information on their beliefs and perspectives via language and emotional expression. adults with asd have considerable social and emotional challenges, while also demonstrating abilities and interests in screen-based technologies.\u003c/p>\n\u003cp class=\"mb15\">\u003cb>methods:\u003c/b> the novelty of this research lies in its use in the context of twitter to analyze and identify asd. this research used twitter as the primary data source to examine the behavioral traits and immediate emotional expressions of persons with asd. we applied convolutional neural networks with long short-term memory (cnn-lstm), lstm, and double deep q-network (ddqn-inspired) using a standardized dataset including 172 tweets from the asd class and 158 tweets from the non-asd class. the dataset was processed to exclude lowercase text and special characters, followed by a tokenization approach to convert the text into integer word sequences. the encoding was used to transform the classes into binary labels. following preprocessing, the proposed framework was implemented to identify asd.\u003c/p>\n\u003cp class=\"mb15\">\u003cb>results:\u003c/b> the findings of the ddqn-inspired model demonstrate a high precision of 87% compared to the proposed model. this finding demonstrates the potential of the proposed approach for identifying asd based on social media content.\u003c/p>\n\u003cp class=\"mb0\">\u003cb>discussion:\u003c/b> ultimately, the proposed system was compared against the existing system that used the same dataset. the proposed approach is based on variations in the text of social media interactions, which can assist physicians and clinicians in performing symptom studies within digital footprint environments.\u003c/p> \u003cdiv class=\"clear\">\u003c/div> \u003c/div> \u003cdiv class=\"journalfulltext\"> \u003ca id=\"h2\" name=\"h2\">\u003c/a>\n\u003ch2>1 introduction\u003c/h2>\n\u003cp class=\"mb0\">asd is among the most prevalent neurodevelopmental disorders. asd is often demonstrated in children by age three and is defined by impairments in social interactions and communication, repetitive sensory-motor activities, and stereotypical behavioral patterns (\u003ca href=\"#ref1\">1\u003c/a>). asd is a congenital neurodevelopmental condition characterized by symptoms that are evident in early infancy. autism, characterized by restricted interests, repetitive behaviors, and significant disparities in social communication and interaction, typically emerges during early developmental stages and presents challenges in various social functioning domains. a child with autism induces significant anxiety within the family due to several factors, including the ambiguity of the diagnosis, the intensity and persistence of the disease, and the child’s nonconformity to social norms. in opposition, social awareness of autism is markedly inadequate, often conflated with intellectual disability and seen as an incurable ailment (\u003ca href=\"#ref2\">2\u003c/a>, \u003ca href=\"#ref3\">3\u003c/a>). the asd concept is displayed in \u003ca href=\"#fig1\">figure 1\u003c/a>.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 1\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g001.jpg\" name=\"figure1\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g001.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g001.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g001.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g001.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g001.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g001.jpg\" alt=\"nine icons representing concepts related to autism and interventions. top row: discrete trial training, pivotal response training, and verbal behavior intervention. middle row: impulsiveness and aggression, preference for solitude, delayed language development. bottom row: prescription drugs during pregnancy, family history of autism, assistive technologies. each icon illustrates its concept with relevant imagery.\" id=\"fig1\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 1\u003c/b>. displays the asd concept.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb15\">content on social media, particularly videos and text disseminated by parents and caregivers, has emerged as a significant resource for facilitating the early identification of asd (\u003ca href=\"#ref4\">4\u003c/a>, \u003ca href=\"#ref5\">5\u003c/a>). social media are technological tools designed for sharing, enabling users to create networks or engage in existing ones. in that order, the pew research center identified the most popular social media sites as youtube, facebook, instagram, pinterest, linkedin, snapchat, twitter, and whatsapp (\u003ca href=\"#ref6\">6\u003c/a>). most consumers use these networks daily. this research utilizes twitter data to assess the stigmatization of autism and associated terminology, picked based on accessibility and popularity, with analysis conducted using artificial intelligence technologies (\u003ca href=\"#ref7\">7\u003c/a>).\u003c/p>\n\u003cp class=\"mb15\">conventional diagnostic methods, which primarily rely on observational and behavioral evaluations, often encounter issues with accessibility, consistency, and timeliness. recent technology breakthroughs, especially in artificial intelligence (ai), and sensor-based techniques, provide novel opportunities for improving asd identification. by developing more objective, accurate, and scalable approaches, these technologies transform diagnostic methodologies for autism spectrum disorder (asd) (\u003ca href=\"#ref8\">8\u003c/a>–\u003ca href=\"#ref10\">10\u003c/a>). one new way to study the motor patterns, attentional processes, and physiological responses linked to asd in real-time is wearable sensors, eye-tracking devices, and multimodal virtual reality settings. these technologies have the potential to give non-invasive, continuous monitoring, which might help with the early diagnosis of asd and shed light on neurological and behavioral traits that have been hard to document reliably.\u003c/p>\n\u003cp class=\"mb15\">nevertheless, advancements in contemporary research are required to substantiate their efficacy. sensor-based techniques may facilitate the identification of stereotyped behaviors and motor patterns linked to asd in realistic environments, potentially yielding data that could guide timely and customized therapies (\u003ca href=\"#ref11\">11\u003c/a>). neuroimaging and microbiome analysis further advance this technical domain by indicating neurological and biological traits specific to asd. ai-enhanced neuroimaging aids in identifying structural and functional brain connection patterns associated with asd, thereby enhancing the understanding of its neuroanatomical foundation (\u003ca href=\"#ref12\">12\u003c/a>).\u003c/p>\n\u003cp class=\"mb15\">the research conducted by neeharika and riyazuddin et al. (\u003ca href=\"#ref13\">13\u003c/a>) aimed to enhance the accuracy of asd screening by using feature selection methods in conjunction with sophisticated machine learning classifiers. their research included several datasets spanning infants, children, adolescents, and adults, enabling a thorough assessment of asd characteristics across different age demographics. authors’ use of mlp model capacity to reliably and rapidly identify asd, indicating a beneficial screening instrument suitable for various age groups, facilitating both clinical evaluations and extensive screenings. wall et al. (\u003ca href=\"#ref14\">14\u003c/a>) investigated machine learning (ml) algorithms for diagnosing asd using a standard dataset. the researchers focused on the alternating decision tree classifier to identify a limited yet efficient set of queries that optimize the diagnostic procedure. alzakari et al. (\u003ca href=\"#ref15\">15\u003c/a>) proposed a novel two-phase methodology to tackle the variability in asd features with ml approaches, including behavioral, linguistic, and physical data. the first step concentrates on identifying asd, using feature engineering methodologies and ml algorithms, including a logistic regression (lr) and support vector machine (svm) ensemble, attaining a classification with high accuracy. eeg assesses brain activity and may identify children predisposed to developing asd, hence facilitating early diagnosis. eeg data is used to compare asd and hc (\u003ca href=\"#ref16\">16\u003c/a>–\u003ca href=\"#ref18\">18\u003c/a>). in (\u003ca href=\"#ref19\">19\u003c/a>), the cnn model was used for classification after transforming the data into a two-dimensional format. while eeg may facilitate the diagnosis of asd, it is constrained by other factors, such as signal noise.\u003c/p>\n\u003cp class=\"mb15\">the research has used social media to investigate asd. however, exploiting these prevalent platforms and innovative online data sources may be feasible to enhance the comprehension of these diseases. previous research has utilized twitter data to investigate discussions on asd-related material, indicating that this subject is frequently addressed on this platform (\u003ca href=\"#ref20\">20\u003c/a>). considering the use of social media for researching asd is particularly significant, as a recent analysis indicated that around 80% of individuals with asd engage with prominent social media platforms (\u003ca href=\"#ref21\">21\u003c/a>). this study aims to build upon previous research and enhance our comprehension of whether publicly accessible social media data from twitter may provide insights into the existence of digital diagnostic indicators for asd (\u003ca href=\"#ref22\">22\u003c/a>). furthermore, we want to assess the viability of establishing a digital phenotype for asd using social media.\u003c/p>\n\u003cp class=\"mb0\">beykikhoshk et al. (\u003ca href=\"#ref20\">20\u003c/a>) examined twitter’s potential as a data-mining tool to comprehend the actions, challenges, and requirements of autistic individuals. the first finding pertained to the attributes of participants inside the autism subgroup of tweets, indicating that these tweets were highly informative and had considerable potential usefulness for public health experts and policymakers. tomeny et al. (\u003ca href=\"#ref23\">23\u003c/a>) examined demographic correlations of autism-related anti-vaccine opinions on twitter from 2009 to 2015. their results indicated that the frequency of autism-related anti-vaccine views online was alarming, with anti-vaccine tweets connecting with news events and demonstrating geographical clustering. from 2015 to 2019, tárraga-mínguez et al. (\u003ca href=\"#ref24\">24\u003c/a>) examined the phrases “autism” and “asperger” in spain in relation to google search peaks. the public view of autism was significantly impacted by how the condition was portrayed in the news and on social media, and the authors found that social marketing campaigns had a significant role in normalizing autism. in this research (\u003ca href=\"#ref25\">25\u003c/a>), looked at how people sought assistance. the results showed a strong correlation in google search interest between the terms “asperger syndrome” and “greta thunberg,” reaching their highest point in 2019. online traffic to the asperger/autism network and autism speaks websites increased steadily from june to december 2019, indicating a correlation between help-seeking behavior and thunberg’s fame, according to the research. according to the results, the stigma associated with asperger’s disorder may have been positively affected by thunberg’s public exposure.\u003c/p>\n\u003ch3>1.1 contribution\u003c/h3>\n\u003cp class=\"mb0\">the use of tweets from twitter for the detection of asd is substantial, since it offers extensive, real-time, user-generated data that facilitates the early identification of asd-related behaviors, particularly via self-reported experiences and parental observations. this methodology promotes the advancement of suggested models, namely lstm, cnn-lstm, and inspired ddqn, for natural language processing to examine linguistic patterns, feelings, and keywords related to asd. it provides insights into popular views, stigma, and misconceptions around autism, guiding awareness initiatives and public health measures. twitter data is a powerful and accessible resource for enhancing early detection and understanding of asd in diverse groups. utilizing social media in this manner may offer more accessible and timely screening, particularly in regions with limited healthcare resources.\u003c/p> \u003ca id=\"h3\" name=\"h3\">\u003c/a>\n\u003ch2>2 materials and methods\u003c/h2>\n\u003cp class=\"mb0\">\u003ca href=\"#fig2\">figure 2\u003c/a> shows the pipeline of the proposed system to provide a broader perspective to researchers and developers. the framework delineates the processing phases for the pipeline that utilizes social media content to diagnose asd. below, we present a comprehensive assessment of each step.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 2\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g002.jpg\" name=\"figure2\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g002.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g002.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g002.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g002.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g002.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g002.jpg\" alt=\"flowchart depicting a process for analyzing twitter data. it starts with social media avatars and a twitter api feeding into a word cloud for asd-related terms. next, preprocessing involves text cleaning, label encoding, and tokenization. this data feeds into deep learning models, including lstm, cnn-lstm, and ddqn. outputs are classified as asd or non-asd, with corresponding graphs indicating training and validation accuracy over epochs.\" id=\"fig2\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 2\u003c/b>. farmwork of asd system.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch3>2.1 dataset\u003c/h3>\n\u003cp class=\"mb0\">to help with the early diagnosis of asd by using proposed systems, the tasd-dataset includes comprehensive textual sequences that depict the everyday lives of children with and without asd. it offers new elements, including noise sensitivity, sharing interest, sign communication, and tiptoe flapping, it combines critical asd assessment aspects like attention response, word repetition, and emotional empathy, as shown in \u003ca href=\"#fig3\">figure 3\u003c/a>. parents may get detailed insights and better identify signs of autism spectrum disorder (asd) due to the deepening of certain behaviors. the dataset contains 172 tweets from the asd class and 158 non-asd tweets. \u003ca href=\"#fig4\">figure 4\u003c/a> shows the class of the dataset.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 3\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g003.jpg\" name=\"figure3\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g003.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g003.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g003.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g003.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g003.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g003.jpg\" alt=\"bar chart titled “feature frequencies” showing the count of various behaviors. “word repetition” has the highest frequency at 2.00. other features like “attention response,” “change reaction,” and “eye contact” have frequencies of 1.00 each.\" id=\"fig3\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 3\u003c/b>. features of the dataset.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline mb15\">\u003c/div>\n\u003cdiv class=\"imageheaders\">figure 4\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g004.jpg\" name=\"figure4\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g004.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g004.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g004.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g004.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g004.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g004.jpg\" alt=\"bar chart titled “number of tweets per class” compares tweet counts for asd and non-asd categories. asd has around 175 tweets, while non-asd has about 160 tweets.\" id=\"fig4\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 4\u003c/b>. label of the dataset.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch3>2.2 preprocessing\u003c/h3>\n\u003cp class=\"mb0\">text preprocessing is an essential step in the text processing process. words, sentences, and paragraphs can all be found in a text, which is defined as a meaningful sequence of characters. preprocessing methods feed text data to a proposed algorithm in a better form than in its natural state. a tweet can contain different viewpoints on the data it represents. tweets that have not been preprocessed are highly unstructured and contain redundant data. to address these issues, several steps are taken to preprocess tweets for detecting asd, as shown in \u003ca href=\"#fig5\">figure 5\u003c/a>.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 5\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g005.jpg\" name=\"figure5\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g005.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g005.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g005.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g005.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g005.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g005.jpg\" alt=\"flowchart depicting a text preprocessing workflow with three stages: text cleaning, label encoding, and tokenization and padding. the tokenization and padding section includes tokenizer, texts_to_sequences, and padding_sequences. arrows indicate process flow from left to right.\" id=\"fig5\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 5\u003c/b>. preprocessing asd text analysis.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch3>2.3 text cleaning\u003c/h3>\n\u003cp class=\"mb0\">the clean text preprocessing method is a significant step in text datasets because the text contains several extra contexts to preprocess and normalize raw text data for analysis. in these steps, the use is transformed to lowercase to guarantee consistency and prevent differentiation between “asd” and “non-asd.” subsequently, any characters that are not letters, numerals, or spaces are eliminated by a regular expression, so punctuation and other symbols that might create extraneous noise are removed. this method is ultimately applied to the ‘text’ column of the data frame, ensuring that all text elements are sanitized and prepared for feature extraction. \u003ca href=\"#fig6\">figure 6\u003c/a> displays the clean text process.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 6\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g006.jpg\" name=\"figure6\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g006.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g006.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g006.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g006.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g006.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g006.jpg\" alt=\"bar chart titled “text cleaning progression - sample 1” showing text length in characters for four stages: original, lowercased, no special chars, and trimmed. each bar’s length is nearly the same, around 150-200 characters.\" id=\"fig6\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 6\u003c/b>. clean text.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch3>2.4 label encoding\u003c/h3>\n\u003cp class=\"mb0\">the labelencoder method converts text class (asd and non-asd) into numbers, designating 0 for asd and 1 for non-asd. this transformation updates the classification effort by enabling the model to see the labels as numerical values instead of text. \u003ca href=\"#eq1\">equations 1\u003c/a>, \u003ca href=\"#eq2\">2\u003c/a> show the label encoding.\u003c/p>\n\u003cdiv id=\"eq1\" class=\"equationimageholder\">\u003cmath id=\"m1\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext mathvariant=\"italic\">yclassification\u003c/mtext>\u003cmo>∈\u003c/mo>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi mathvariant=\"italic\">asd\u003c/mi>\u003cmo>,\u003c/mo>\u003cmtext mathvariant=\"italic\">non\u003c/mtext>\u003cmo>−\u003c/mo>\u003cmi mathvariant=\"italic\">asd\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmtext mathvariant=\"italic\">then\u003c/mtext>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>1\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq19\" class=\"equationimageholder\">\u003cmath id=\"m2\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmi>y\u003c/mi>\u003cmo>=\u003c/mo>\u003cmtext mathvariant=\"italic\">labelencoder\u003c/mtext>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmtext mathvariant=\"italic\">yclassifcation\u003c/mtext>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>→\u003c/mo>\u003cmi>y\u003c/mi>\u003cmo>∈\u003c/mo>\u003cmo stretchy=\"true\">{\u003c/mo>\u003cmn>0\u003c/mn>\u003cmo>,\u003c/mo>\u003cmn>1\u003c/mn>\u003cmo stretchy=\"true\">}\u003c/mo>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>2\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003ch3>2.5 tokenization and padding\u003c/h3>\n\u003cp class=\"mb0\">tokenization and padding are essential nlp preprocessing procedures that transform unprocessed text into a numerical representation appropriate for machine learning models, particularly neural networks. \u003ca href=\"#fig7\">figure 7\u003c/a> shows the tokenization and padding \u003ca href=\"#eq3\">equation 3\u003c/a>.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 7\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g007.jpg\" name=\"figure7\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g007.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g007.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g007.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g007.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g007.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g007.jpg\" alt=\"sample text tokenization and padding process with three horizontal bar graphs. the first graph shows original text words. the second graph illustrates the tokenized sequence using word indexes with varying heights. the third graph shows a padded sequence with a fixed length of twenty, ensuring uniform token index lengths. the indexes used are rearranged with zero padding.\" id=\"fig7\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 7\u003c/b>. sample of text tokenization and padding.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch4>2.5.1 tokenizer\u003c/h4>\n\u003cp class=\"mb0\">tokenizer procedures transform textual data into a numerical representation suitable for input into neural networks. they convert a text corpus into integer sequences, assigning a distinct index to each unique word according to its frequency, as shown in \u003ca href=\"#eq3\">equation 3\u003c/a>. the tokenizer processing is shown in \u003ca href=\"#fig8\">figure 8\u003c/a>.\u003c/p>\n\u003cdiv id=\"eq2\" class=\"equationimageholder\">\u003cmath id=\"m3\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext mathvariant=\"italic\">index\u003c/mtext>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>w\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>=\u003c/mo>\u003cmsub>\u003cmo mathvariant=\"italic\">rank\u003c/mo>\u003cmi>f\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>w\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmtext mathvariant=\"italic\">if\u003c/mtext>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmsub>\u003cmo mathvariant=\"italic\">rank\u003c/mo>\u003cmi>f\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>w\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>≤\u003c/mo>\u003cmi>v\u003c/mi>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>3\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 8\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g008.jpg\" name=\"figure8\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g008.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g008.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g008.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g008.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g008.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g008.jpg\" alt=\"three bar charts illustrate text data analysis. chart a shows the top 20 most frequent words with “to” being the highest. chart b depicts sequence length distribution before padding, peaking at around 20 tokens. chart c displays sequence lengths post-padding, fixed at 200 tokens, appearing as a single line at the 200 mark.\" id=\"fig8\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 8\u003c/b>. tokenizer analysis: word frequencies and sequence lengths.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">where \u003cmath id=\"m4\">\u003cmsub>\u003cmo mathvariant=\"italic\">rank\u003c/mo>\u003cmi>f\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>w\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003c/math>is rank \u003cmath id=\"m5\">\u003cmi>w\u003c/mi>\u003c/math> frequency \u003cmath id=\"m6\">\u003cmi>f\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>w\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/math> and \u003cmath id=\"m7\">\u003cmi>v\u003c/mi>\u003c/math> is the maximum number of words.\u003c/p>\n\u003ch4>2.5.2 fit texts\u003c/h4>\n\u003cp class=\"mb0\">this phase is crucial for transforming unprocessed text into numerical sequences suitable for input into the proposed system.\u003c/p>\n\u003ch4>2.5.3 texts_to_sequences\u003c/h4>\n\u003cp class=\"mb0\">to convert unprocessed text input into sequences of word indices according to the mapping acquired via as shown in \u003ca href=\"#eq4\">equation 4\u003c/a>.\u003c/p>\n\u003cdiv id=\"eq3\" class=\"equationimageholder\">\u003cmath id=\"m8\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext mathvariant=\"italic\">sequence\u003c/mtext>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>t\u003c/mi>\u003cmi>i\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>=\u003c/mo>\u003cmo stretchy=\"true\">[\u003c/mo>\u003cmtext mathvariant=\"italic\">index\u003c/mtext>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmn>1\u003c/mn>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>,\u003c/mo>\u003cmtext mathvariant=\"italic\">index\u003c/mtext>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmn>2\u003c/mn>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>,\u003c/mo>\u003cmo>…\u003c/mo>\u003cmo>…\u003c/mo>\u003cmo>…\u003c/mo>\u003cmo>,\u003c/mo>\u003cmtext mathvariant=\"italic\">index\u003c/mtext>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmi>m\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo stretchy=\"true\">]\u003c/mo>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>4\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cp class=\"mb0\">where is the \u003cmath id=\"m9\">\u003cmsub>\u003cmi>t\u003c/mi>\u003cmi>i\u003c/mi>\u003c/msub>\u003c/math> is the sentence of the text contained, and \u003cmath id=\"m10\">\u003cmi>w\u003c/mi>\u003c/math> is the words of the text, whereas the \u003cmath id=\"m11\">\u003cmtext mathvariant=\"italic\">index\u003c/mtext>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmn>1\u003c/mn>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/math> is an index of the words in the context.\u003c/p>\n\u003ch4>2.5.4 padding_sequences\u003c/h4>\n\u003cp class=\"mb0\">normalize sequence lengths, which may differ post-tokenization, by padding shorter sequences and truncating larger ones to a predetermined length as shown in \u003ca href=\"#eq5\">equation 5\u003c/a>. the padding and truncated b are fixed on the length. \u003cmath id=\"m12\">\u003cmi>l\u003c/mi>\u003cmo>=\u003c/mo>\u003cmn>200\u003c/mn>\u003c/math>. the padding processing is shown in \u003ca href=\"#fig7\">figure 7\u003c/a>.\u003c/p>\n\u003cdiv id=\"eq4\" class=\"equationimageholder\">\u003cmath id=\"m13\">\u003cmi>x\u003c/mi>\u003cmo>=\u003c/mo>\u003cmo>∣\u003c/mo>\u003cmrow>\u003cmtable displaystyle=\"true\">\u003cmtr>\u003cmtd>\u003cmsub>\u003cmi>x\u003c/mi>\u003cmn>1\u003c/mn>\u003c/msub>\u003c/mtd>\u003c/mtr>\u003cmtr>\u003cmtd>\u003cmsub>\u003cmi>x\u003c/mi>\u003cmn>2\u003c/mn>\u003c/msub>\u003c/mtd>\u003c/mtr>\u003cmtr>\u003cmtd>\u003cmtable>\u003cmtr>\u003cmtd>\u003cmo>.\u003c/mo>\u003c/mtd>\u003c/mtr>\u003cmtr>\u003cmtd>\u003cmo>.\u003c/mo>\u003c/mtd>\u003c/mtr>\u003cmtr>\u003cmtd>\u003cmo>.\u003c/mo>\u003c/mtd>\u003c/mtr>\u003cmtr>\u003cmtd>\u003cmo>.\u003c/mo>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/mtd>\u003c/mtr>\u003cmtr>\u003cmtd>\u003cmi>y\u003c/mi>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/mrow>\u003cmo>∣\u003c/mo>\u003cmo>∈\u003c/mo>\u003cmsup>\u003cmi>ℝ\u003c/mi>\u003cmi mathvariant=\"italic\">nxl\u003c/mi>\u003c/msup>\u003cmtext>    (5)\u003c/mtext>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cp class=\"mb0\">where \u003cmath id=\"m14\">\u003cmi>x\u003c/mi>\u003c/math> is features contain padding and are tokenized, \u003cmath id=\"m15\">\u003cmi>l\u003c/mi>\u003c/math> is the length of the vector. the number of texts is indicated \u003cmath id=\"m16\">\u003cmi>n\u003c/mi>\u003c/math>, and \u003cmath id=\"m17\">\u003cmo>∈\u003c/mo>\u003cmsup>\u003cmi>ℝ\u003c/mi>\u003cmi mathvariant=\"italic\">nxl\u003c/mi>\u003c/msup>\u003c/math> is matrix lues.\u003c/p>\n\u003ch3>2.6 proposed systems\u003c/h3>\n\u003ch4>2.6.1 convolutional neural networks\u003c/h4>\n\u003cp class=\"mb0\">the cnn model is at the core of all advanced machine learning and deep learning applications. they can successfully address text classification, image recognition, object identification, and semantic segmentation. using the same method with a task as different as natural language processing is counterintuitive (\u003ca href=\"#ref7\">7\u003c/a>). the structure is presented in \u003ca href=\"#fig9\">figure 9\u003c/a>. \u003ca href=\"#eq6\">equation 6\u003c/a> presents the convolution layer of cnn.\u003c/p>\n\u003cdiv id=\"eq5\" class=\"equationimageholder\">\u003cmath id=\"m18\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmi>o\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo>,\u003c/mo>\u003cmi>y\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>=\u003c/mo>\u003cmunderover>\u003cmo movablelimits=\"false\">∑\u003c/mo>\u003cmrow>\u003cmi>i\u003c/mi>\u003cmo>=\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003cmi>h\u003c/mi>\u003c/munderover>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmunderover>\u003cmo movablelimits=\"false\">∑\u003c/mo>\u003cmrow>\u003cmi>j\u003c/mi>\u003cmo>=\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003cmi>w\u003c/mi>\u003c/munderover>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmi>i\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi>i\u003c/mi>\u003cmo>,\u003c/mo>\u003cmi>y\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi>j\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>∗\u003c/mo>\u003cmi>k\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>i\u003c/mi>\u003cmo>,\u003c/mo>\u003cmi>j\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>+\u003c/mo>\u003cmi>b\u003c/mi>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>6\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 9\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g009.jpg\" name=\"figure9\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g009.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g009.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g009.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g009.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g009.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g009.jpg\" alt=\"flowchart depicting a text classification process using convolutional neural networks. it starts with a sentence matrix representation. colored blocks denote convolution results with filter sizes of two, three, and four. the results undergo one-max pooling, then concatenate into a single vector. finally, the vector classifies into categories: information giving, information seeking, feature request, solution proposal, problem discovery, aspect evaluation, and others.\" id=\"fig9\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 9\u003c/b>. structure cnn.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">where the features of text \u003cmath id=\"m19\">\u003cmi>o\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo>,\u003c/mo>\u003cmi>y\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/math> the feature of the text is mapped by using.\u003cmath id=\"m20\">\u003cmi>i\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi>i\u003c/mi>\u003cmo>,\u003c/mo>\u003cmi>y\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi>j\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/math> is weighted by a neural network and \u003cmath id=\"m21\">\u003cmi>b\u003c/mi>\u003c/math> is biased to adjust the neural. the relu activation function is \u003ca href=\"#eq20\">equation 7\u003c/a>, the max pooling function is presented in \u003ca href=\"#eq6\">equation 8\u003c/a>. the dense layer is given in \u003ca href=\"#eq7\">equation 9\u003c/a>.\u003c/p>\n\u003cdiv id=\"eq20\" class=\"equationimageholder\">\u003cmath id=\"m22\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmi>f\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>=\u003c/mo>\u003cmi>max\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmn>0\u003c/mn>\u003cmo>,\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>7\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq6\" class=\"equationimageholder\">\u003cmath id=\"m23\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmi>o\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo>,\u003c/mo>\u003cmi>y\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>=\u003c/mo>\u003cmunderover>\u003cmo movablelimits=\"false\">∑\u003c/mo>\u003cmrow>\u003cmi>i\u003c/mi>\u003cmo>=\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003cmi>h\u003c/mi>\u003c/munderover>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmunderover>\u003cmo movablelimits=\"false\">∑\u003c/mo>\u003cmrow>\u003cmi>j\u003c/mi>\u003cmo>=\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003cmi>w\u003c/mi>\u003c/munderover>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmi>i\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi>i\u003c/mi>\u003cmo>,\u003c/mo>\u003cmi>y\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi>j\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>∗\u003c/mo>\u003cmi>k\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>i\u003c/mi>\u003cmo>,\u003c/mo>\u003cmi>j\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>+\u003c/mo>\u003cmi>b\u003c/mi>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>8\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq7\" class=\"equationimageholder\">\u003cmath id=\"m24\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmi mathvariant=\"normal\">o\u003c/mi>\u003cmo>=\u003c/mo>\u003cmi>w\u003c/mi>\u003cmo>·\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi>b\u003c/mi>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>9\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003ch4>2.6.2 long short-term memory network\u003c/h4>\n\u003cp class=\"mb0\">an lstm network is an advanced form of a sequential neural network. it fixes the problem of rnn gradients fading over time. rnns often handle long-term storage. at a high level, the operation of an lstm is comparable to that of a single rnn neuron. the inner workings of the lstm network are outlined in this section. the lstm consists of three parts, each performing a particular function, as seen in \u003ca href=\"#fig10\">figure 10\u003c/a> below. in the first step, it is decided whether the information from the previous time stamp is significant enough to be saved or if it is harmless enough to be deleted. in the second step, the cell will try to acquire new information by analyzing the data that has been presented to it. in the third and final step, the cell incorporates the data from the most recent time stamp into the data stored in the next time stamp. these three components constitute what is referred to as a gate for an lstm cell. the “forget” gate comes first, followed by the “input” section, and then the “output” section is used to define the last portion as shown in \u003ca href=\"#eq10\">equations 10\u003c/a>– \u003ca href=\"#eq14\">14\u003c/a>.\u003c/p>\n\u003cdiv id=\"eq8\" class=\"equationimageholder\">\u003cmath id=\"m25\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext>forget gate\u003c/mtext>\u003cmo>:\u003c/mo>\u003cmsub>\u003cmi>f\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>=\u003c/mo>\u003cmi>σ\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmi>f\u003c/mi>\u003c/msub>\u003cmo>.\u003c/mo>\u003cmsub>\u003cmi>x\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmi>f\u003c/mi>\u003c/msub>\u003cmo>.\u003c/mo>\u003cmsub>\u003cmi>h\u003c/mi>\u003cmrow>\u003cmi>t\u003c/mi>\u003cmo>−\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmsub>\u003cmi>b\u003c/mi>\u003cmi>f\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>10\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq9\" class=\"equationimageholder\">\u003cmath id=\"m26\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext>input gate\u003c/mtext>\u003cmo>:\u003c/mo>\u003cmsub>\u003cmi>i\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>=\u003c/mo>\u003cmi>σ\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmi>c\u003c/mi>\u003c/msub>\u003cmo>.\u003c/mo>\u003cmsub>\u003cmi>x\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmi>i\u003c/mi>\u003c/msub>\u003cmo>.\u003c/mo>\u003cmsub>\u003cmi>h\u003c/mi>\u003cmrow>\u003cmi>t\u003c/mi>\u003cmo>−\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmsub>\u003cmi>b\u003c/mi>\u003cmi>i\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>11\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq10\" class=\"equationimageholder\">\u003cmath id=\"m27\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext>cell gate\u003c/mtext>\u003cmo>:\u003c/mo>\u003cmsub>\u003cmi>c\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>=\u003c/mo>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmi>f\u003c/mi>\u003c/msub>\u003cmo>∗\u003c/mo>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmo>.\u003c/mo>\u003cmsub>\u003cmi>h\u003c/mi>\u003cmrow>\u003cmi>t\u003c/mi>\u003cmo>−\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003c/msub>\u003cmo>,\u003c/mo>\u003cmsub>\u003cmi>x\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmsub>\u003cmi>b\u003c/mi>\u003cmi>f\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>12\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq11\" class=\"equationimageholder\">\u003cmath id=\"m28\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext>output gate\u003c/mtext>\u003cmo>:\u003c/mo>\u003cmsub>\u003cmi>o\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>=\u003c/mo>\u003cmi>σ\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmi>o\u003c/mi>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmsub>\u003cmi>x\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmi>o\u003c/mi>\u003c/msub>\u003cmo>.\u003c/mo>\u003cmsub>\u003cmi>h\u003c/mi>\u003cmrow>\u003cmi>t\u003c/mi>\u003cmo>−\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmsub>\u003cmi>v\u003c/mi>\u003cmi>o\u003c/mi>\u003c/msub>\u003cmo>.\u003c/mo>\u003cmsub>\u003cmi>c\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmsub>\u003cmi>b\u003c/mi>\u003cmi>o\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>13\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq12\" class=\"equationimageholder\">\u003cmath id=\"m29\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext>hidden layer\u003c/mtext>\u003cmo>:\u003c/mo>\u003cmsub>\u003cmi>h\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>=\u003c/mo>\u003cmsub>\u003cmi>o\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmi>tanh\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>c\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>14\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 10\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g010.jpg\" name=\"figure10\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g010.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g010.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g010.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g010.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g010.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g010.jpg\" alt=\"flowchart of an lstm neural network model with multiple layers. the input layer feeds into 25 features, which connect to lstm layer 1 with 128 neurons. relu activation leads to lstm layer 2 with 64 neurons, followed by a sigmoid activation for binary classification into class 0 or class 1.\" id=\"fig10\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 10\u003c/b>. lstm model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb15\">in \u003ca href=\"#fig10\">figure 10\u003c/a>, \u003cmath id=\"m30\">\u003cmsub>\u003cmi>c\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003c/math> represent the prior and current states of the cell, respectively. both \u003cmath id=\"m31\">\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmsub>\u003cmi>h\u003c/mi>\u003cmrow>\u003cmi>t\u003c/mi>\u003cmo>−\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003c/msub>\u003c/math> and \u003cmath id=\"m32\">\u003cmi>h\u003c/mi>\u003c/math> represents the cell output that was processed before the one now being processed. it is common practice to disregard \u003cmath id=\"m33\">\u003cmsub>\u003cmi>f\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003c/math> as a gate, even though it is the input gate. the output of a sigmoid gate is symbolized here by \u003cmath id=\"m34\">\u003cmsub>\u003cmi>o\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003c/math>. the cable that connects the cell gates is where all the data collected by the cell gates is sent to and from \u003cmath id=\"m35\">\u003cmi>c\u003c/mi>\u003c/math>. the \u003cmath id=\"m36\">\u003cmsub>\u003cmi>f\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003c/math> layer decides to remember anything, and the\u003cmath id=\"m37\">\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmsub>\u003cmi>f\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmtext mathvariant=\"italic\">the\u003c/mtext>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003c/math>output is multiplied by c to do so (t-1). after that, c (t-1) is multiplied by the product of the sigmoid layer gate and the tanh layer gate, and the output h t is generated by point-wise multiplication of \u003cmath id=\"m38\">\u003cmsub>\u003cmi>o\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003c/math> and tanh.\u003c/p>\n\u003cp class=\"mb0\">the lstm architecture is intended to capture long-term relationships in twitter text data. the preprocessing converts input words that start with an embedding layer into 128-dimensional dense vectors. the lstm layer with 64 units is then used to mitigate overfitting, integrating dropout and recurrent dropout with 0.5. an l2 regularization term is further included in the lstm and output dense layer. \u003ca href=\"#tab1\">table 1\u003c/a> shows parameters of the lstm model.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">table 1\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t001.jpg\" name=\"table1\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t001.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t001.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t001.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t001.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t001.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t001.jpg\" alt=\"www.frontiersin.org\" id=\"tab1\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>table 1\u003c/b>. lstm parameters model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch4>2.6.3 cnn-lstm model\u003c/h4>\n\u003cp class=\"mb0\">the cnn-lstm model is a hybrid architecture that combines convolutional neural networks (cnn) for spatial feature extraction and long short-term memory (lstm) networks for sequential learning, making it highly effective for analyzing text data such as tweets. the model begins with an embedding layer that transforms each word into a 256-dimensional dense vector, capturing the semantic meaning of words. this is followed by a 1d convolutional layer with 64 filters and a kernel size of 5, which scans through the text to detect local patterns and n-gram features such as common word combinations or phrases often associated with asd. a batch normalization layer is applied to stabilize and accelerate training, followed by a max pooling layer that reduces the dimensionality and computational load by selecting the most prominent features. a dropout layer with a rate of 0.5 is then used to prevent overfitting by randomly deactivating some neurons during training. the output is passed into a 64-unit lstm layer that captures the temporal dependencies and contextual relationships across the tweet sequence. finally, a dense layer with sigmoid activation performs binary classification to predict whether the tweet indicates asd-related content. the model is trained using the adam optimizer, binary cross-entropy loss, class weights, and regularization to handle imbalanced data and improve generalization. the critical parameters of the cnn-lstm model are displayed in \u003ca href=\"#tab2\">table 2\u003c/a>.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">table 2\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t002.jpg\" name=\"table2\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t002.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t002.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t002.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t002.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t002.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t002.jpg\" alt=\"www.frontiersin.org\" id=\"tab2\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>table 2\u003c/b>. cnn-lstm parameters.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch4>2.6.4 double deep q-network (ddqn-inspired)\u003c/h4>\n\u003cp class=\"mb15\">the double q-learning model was introduced by h. van hasselt in 2010, addressing the issue of significant overestimations of action value (q-value) inherent in traditional q-learning. in fundamental q-learning, the agent’s optimal strategy is consistently to select the most advantageous action in any specific state. this concept’s premise is that the optimal action corresponds to the highest expected or estimated q-value. initially, the agent lacks any knowledge of the environment; it must first estimate q(s, a) and subsequently update these estimates with each iteration. the q-values exhibit considerable noise, leading to uncertainty about whether the action associated with the highest expected or estimated q-value is genuinely the optimal choice.\u003c/p>\n\u003cp class=\"mb0\">double q-learning employs two distinct action-value functions, q and q’, as estimators. even if q and q’ exhibit noise, this noise can be interpreted as a uniform distribution as shown \u003ca href=\"#fig11\">figure 11\u003c/a> the update procedure exhibits some variations compared to the basic version. the action selection and action evaluation processes are separated into two distinct maximum function estimators. shown in \u003ca href=\"#eq13\">equations 15\u003c/a>, \u003ca href=\"#eq16\">16\u003c/a>.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 11\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g011.jpg\" name=\"figure11\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g011.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g011.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g011.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g011.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g011.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g011.jpg\" alt=\"diagram illustrating the process of reinforcement learning with replay memory and q-networks. the replay memory outputs a mini-batch containing state, action, reward, and next state. this feeds into both the online and target q-networks. the online q-network outputs state-action pairs, which are used alongside the target q-network’s output in the loss function. a feedback loop connects the replay memory to the online q-network.\" id=\"fig11\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 11\u003c/b>. ddqn-inspired model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">let the vector of a neural network’s weights be represented by \u003ci>θ\u003c/i>. we establish two q-networks: the online q-network q (s, a; θ(t)) and the target q-network q (s, a; θ (t)). to be more specific, the training of q (s, a; \u003ci>Χ\u003c/i> (t)) is done by modifying the weights (t) at time slot t in relation to the goal value y(t).\u003c/p>\n\u003cdiv id=\"eq13\" class=\"equationimageholder\">\u003cmath id=\"m39\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmi>y\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>t\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>=\u003c/mo>\u003cmi>g\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>t\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>+\u003c/mo>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>s\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo>,\u003c/mo>\u003cmtext>argmax\u003c/mtext>\u003cmi>q\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>s\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo>,\u003c/mo>\u003cmsup>\u003cmi>a\u003c/mi>\u003cmo>∗\u003c/mo>\u003c/msup>\u003cmo>;\u003c/mo>\u003cmi>θ\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>t\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>;\u003c/mo>\u003cmi>θ\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>t\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>15\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq14\" class=\"equationimageholder\">\u003cmath id=\"m40\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmi>y\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>t\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>=\u003c/mo>\u003cmi>g\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>t\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>+\u003c/mo>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>s\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo>,\u003c/mo>\u003cmtext>argmax\u003c/mtext>\u003cmi>q\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>s\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo>,\u003c/mo>\u003cmsup>\u003cmi>a\u003c/mi>\u003cmo>∗\u003c/mo>\u003c/msup>\u003cmo>;\u003c/mo>\u003cmi>θ\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>;\u003c/mo>\u003cmsub>\u003cmi>θ\u003c/mi>\u003cmrow>\u003cmi>i\u003c/mi>\u003cmo>−\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>16\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cp class=\"mb15\">the reinforcement learning mechanism integrates generative artificial intelligence for decision-making and prediction tasks, as shown in \u003ca href=\"#eq15\">equations 15\u003c/a>, \u003ca href=\"#eq16\">16\u003c/a>. this equation indicates the generative which produces the estimation or hypothesis at a given time \u003cmath id=\"m41\">\u003cmi>t\u003c/mi>\u003c/math>.\u003cmath id=\"m42\">\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmtext mathvariant=\"italic\">double\u003c/mtext>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmi>q\u003c/mi>\u003cmo>−\u003c/mo>\u003cmtext mathvariant=\"italic\">learning\u003c/mtext>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003c/math>used next state, whereas the s’ is exit state and \u003cmath id=\"m43\">\u003cmtext>argmax\u003c/mtext>\u003cmi>q\u003c/mi>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>s\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo>,\u003c/mo>\u003cmsup>\u003cmi>a\u003c/mi>\u003cmo>∗\u003c/mo>\u003c/msup>\u003cmo>;\u003c/mo>\u003cmi>θ\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>t\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/math> defined as the action of \u003cmath id=\"m44\">\u003cmsup>\u003cmi>a\u003c/mi>\u003cmo>∗\u003c/mo>\u003c/msup>\u003c/math> to maximize the predicted q-value based on the current parameters. to estimate the q-value of this selected action in the next state, the outer q-function q’ employs the older parameters. \u003cmath id=\"m45\">\u003cmsub>\u003cmi>θ\u003c/mi>\u003cmrow>\u003cmi>i\u003c/mi>\u003cmo>−\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003c/msub>\u003c/math>1, which helps reduce overestimation bias. this combination makes applications for predicting asd from social media content domains possible.\u003c/p>\n\u003cp class=\"mb0\">the ddqn model is used to classify asd and non-asd cases utilizing text data. the model utilizes a preprocessing step for text processing that encompasses data loading, cleaning (including lowercasing, removal of special characters, and normalization of spaces), and tokenization, constrained by a maximum vocabulary of 10,000 words and a sequence length of 200. the model architecture, drawing from the double deep q-network (ddqn) model comprises an input layer, an embedding layer with 256 dimensions, and two parallel lstm branches, each containing 64 units, a dropout rate of 0.5, and l2 regularization to capture sequential patterns effectively. the model uses the adam optimizer with a learning rate of 1e-4 and employs binary cross-entropy loss. it is trained for 30 epochs, incorporating early stopping and learning rate reduction callbacks to mitigate overfitting. parameters of ddqn-inspired are shown in \u003ca href=\"#tab3\">table 3\u003c/a>.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">table 3\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t003.jpg\" name=\"table3\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t003.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t003.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t003.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t003.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t003.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t003.jpg\" alt=\"www.frontiersin.org\" id=\"tab3\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>table 3\u003c/b>. parameters of ddqn-inspired.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div> \u003ca id=\"h4\" name=\"h4\">\u003c/a>\n\u003ch2>3 performance of the framework\u003c/h2>\n\u003ch3>3.1 performance of lstm\u003c/h3>\n\u003cp class=\"mb0\">\u003ca href=\"#fig12\">figure 12\u003c/a> presents the accuracy and loss metrics used to train and validate an lstm model over 30 epochs. the validation accuracy of the lstm model, displayed in red, begins at a lower value and increases to about 81%. the blue line in the accuracy plot (a) shows the training accuracy of the lstm model; it increases gradually from around 50% to almost 99%, showing that the model learns the training data well over time. the plot (b) shows the loss of the lstm model; the blue line represents the training loss, which drops gradually from around 0.7 to less than 0.2, suggesting that the model is getting a better fit to the training data. meanwhile, the red validation loss line declines from around 0.7 to about 0.3. while the training loss continues to grow, the validation loss reaches a level and exhibits small oscillations, suggesting that the model’s generalizability may stabilize.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 12\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g012.jpg\" name=\"figure12\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g012.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g012.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g012.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g012.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g012.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g012.jpg\" alt=\"two line graphs depict an lstm model’s performance over 30 epochs. the left graph shows accuracy, with training accuracy rising from 0.5 to 0.9, while validation accuracy fluctuates around 0.8. the right graph displays loss, where training loss decreases from 0.7 to 0.1, and validation loss reduces from 0.7 to 0.3. both graphs feature blue lines for training metrics and red lines for validation metrics.\" id=\"fig12\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 12\u003c/b>. performance of the lstm model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">the roc curve illustrated in \u003ca href=\"#fig13\">figure 13\u003c/a> shows the efficacy of the lstm model in differentiating between the classes. the graph illustrates the tp rate (sensitivity) in relation to the fp rate across different threshold levels. the lstm model attains an auc of 0.95, demonstrating exceptional classification capability. the auc of 1.0, but a result of 0.5 indicates random chance.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 13\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g013.jpg\" name=\"figure13\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g013.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g013.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g013.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g013.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g013.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g013.jpg\" alt=\"roc curve for an lstm model showing the trade-off between true positive rate and false positive rate. the curve bends towards the top-left corner, with an area under the curve (auc) of 0.95, indicating high model performance. a diagonal dashed line represents random chance.\" id=\"fig13\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 13\u003c/b>. roc of the lstm model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch3>3.2 performance of the cnn-lstm model\u003c/h3>\n\u003cp class=\"mb0\">\u003ca href=\"#fig14\">figure 14\u003c/a> presents plots illustrating the performance of a cnn-lstm model over 25 epochs, showing its training and validation metrics for accuracy and loss. the accuracy plot (a) illustrates the training accuracy (blue line), which increases progressively from approximately 51.42% to nearly 99.53%, indicating effective learning from the training data. in contrast, the validation accuracy (red line) rises to about 83.02% with some variability, indicating satisfactory but imperfect generalization. the loss plot (b) shows the training loss (blue line) declining steadily from 0.7140 to below 0.0760, indicating enhanced model fit. in contrast, the validation loss (red line) decreases from 0.7130 to approximately 0.3530, with a slight decline toward the conclusion. this notification indicates that the cnn-lstm model demonstrates efficient learning, as evidenced by the difference between the training and validation measures.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 14\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g014.jpg\" name=\"figure14\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g014.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g014.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g014.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g014.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g014.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g014.jpg\" alt=\"two line graphs show cnn-lstm model performance. the left graph displays training and validation accuracy over 25 epochs. training accuracy improves significantly, surpassing validation accuracy, which fluctuates. the right graph depicts training and validation loss over the same epochs. training loss decreases sharply, while validation loss also reduces but stabilizes after an initial drop.\" id=\"fig14\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 14\u003c/b>. performance of the lstm model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">\u003ca href=\"#fig15\">figure 15\u003c/a> illustrates the roc curve for the cnn-lstm model, illustrating its classification performance at various thresholds. the graph illustrates the tp rate (sensitivity) in relation to the fp rate, with the auc recorded at 92%. the elevated auc value indicates the model has robust discriminative capability in differentiating between the asd and non-asd classes. the roc ascends rapidly toward the top-left corner, as seen in the figure, indicating a high tp rate with few false positives.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 15\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g015.jpg\" name=\"figure15\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g015.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g015.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g015.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g015.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g015.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g015.jpg\" alt=\"roc curve for a cnn_lstm model, showing the true positive rate against the false positive rate. the curve is above the diagonal, with an area under the curve (auc) of 0.92, indicating strong model performance.\" id=\"fig15\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 15\u003c/b>. roc of the cnn-lstm model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch3>3.3 performance of ddqn-inspired model\u003c/h3>\n\u003cp class=\"mb0\">graphs 16 illustrate the performance of a ddqn throughout 30 epochs. the accuracy plot (a) demonstrates that the training accuracy increases from around 58.02% to almost 98.58%, indicating the ddqn model successful learning from the training data over time. the validation accuracy of the ddqn is about 87, showing the best performance compared to different models like lstm and cnn-lstm. the plot (b) illustrates that the training loss decreases from about 0.8155 to around 0.1477, indicating a robust fit to the training data. the validation loss begins at 0.3831 with many fluctuations throughout (\u003ca href=\"#fig16\">figure 16\u003c/a>).\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 16\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g016.jpg\" name=\"figure16\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g016.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g016.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g016.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g016.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g016.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g016.jpg\" alt=\"two graphs display the performance of a ddqn_t model over 30 epochs. graph (a) shows training accuracy in blue and validation accuracy in red, both improving over time. graph (b) illustrates training loss in blue and validation loss in red, both decreasing with some fluctuations.\" id=\"fig16\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 16\u003c/b>. performance of the \u003ci>ddqn-inspired\u003c/i> model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">\u003ca href=\"#fig17\">figure 17\u003c/a> shows the roc curve for the ddqn model; it shows a visual representation of its classification capability, with the curve toward the top-left corner, indicating strong predictive power. the auc value of the ddqn model is 96%, demonstrating that the model can distinguish between the positive and negative classes.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 17\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g017.jpg\" name=\"figure17\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g017.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g017.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g017.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g017.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g017.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g017.jpg\" alt=\"receiver operating characteristic (roc) curve illustrating a ddqn-inspired model performance. the curve shows the trade-off between true positive rate and false positive rate with an area under the curve (auc) of 0.96, indicating high accuracy.\" id=\"fig17\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 17\u003c/b>. roc \u003ci>ddqn-inspired model.\u003c/i>\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div> \u003ca id=\"h5\" name=\"h5\">\u003c/a>\n\u003ch2>4 experiment and discussion results\u003c/h2>\n\u003cp class=\"mb0\">both the jupyter deep learning framework and the windows 10 operating system were utilized during the testing process. experiments were conducted using a machine with 16 gigabytes of ram and an intel core i7 central processing unit. the input dimensions of the experiment were a standard text dataset collected from the twitter api related to asd. the test was utilized in our database, while the remaining 20% was used as part of our validation set. the three dl models, namely lstm, cnn-lstm, and ddqn-inspired, were proposed for detecting asd from social media content.\u003c/p>\n\u003ch3>4.1 measuring the model’s performance\u003c/h3>\n\u003cp class=\"mb0\">sensitivity, specificity, accuracy, recall, and f1 scores are assessment measures used to determine how successfully the algorithms identify asd. the related equations from \u003ca href=\"#eq17\">17\u003c/a> to \u003ca href=\"#eq21\">21\u003c/a>:\u003c/p>\n\u003cdiv id=\"eq15\" class=\"equationimageholder\">\u003cmath id=\"m46\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext mathvariant=\"italic\">accuracy\u003c/mtext>\u003cmo>=\u003c/mo>\u003cmfrac>\u003cmrow>\u003cmi mathvariant=\"italic\">tp\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi mathvariant=\"italic\">tn\u003c/mi>\u003c/mrow>\u003cmrow>\u003cmi mathvariant=\"italic\">tp\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi mathvariant=\"italic\">fp\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi mathvariant=\"italic\">fn\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi mathvariant=\"italic\">tn\u003c/mi>\u003c/mrow>\u003c/mfrac>\u003cmo>×\u003c/mo>\u003cmn>100\u003c/mn>\u003cmo>%\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>17\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq16\" class=\"equationimageholder\">\u003cmath id=\"m47\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext mathvariant=\"italic\">sensitivity\u003c/mtext>\u003cmo>=\u003c/mo>\u003cmfrac>\u003cmi mathvariant=\"italic\">tp\u003c/mi>\u003cmrow>\u003cmi mathvariant=\"italic\">tp\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi mathvariant=\"italic\">fn\u003c/mi>\u003c/mrow>\u003c/mfrac>\u003cmo>×\u003c/mo>\u003cmn>100\u003c/mn>\u003cmo>%\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>18\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq17\" class=\"equationimageholder\">\u003cmath id=\"m48\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext mathvariant=\"italic\">precision\u003c/mtext>\u003cmo>=\u003c/mo>\u003cmfrac>\u003cmi mathvariant=\"italic\">tp\u003c/mi>\u003cmrow>\u003cmi mathvariant=\"italic\">tp\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi mathvariant=\"italic\">fp\u003c/mi>\u003c/mrow>\u003c/mfrac>\u003cmo>×\u003c/mo>\u003cmn>100\u003c/mn>\u003cmo>%\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>19\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq21\" class=\"equationimageholder\">\u003cmath id=\"m49\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext mathvariant=\"italic\">specificity\u003c/mtext>\u003cmo>=\u003c/mo>\u003cmfrac>\u003cmi mathvariant=\"italic\">tn\u003c/mi>\u003cmrow>\u003cmi mathvariant=\"italic\">tn\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi mathvariant=\"italic\">fp\u003c/mi>\u003c/mrow>\u003c/mfrac>\u003cmo>×\u003c/mo>\u003cmn>100\u003c/mn>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>20\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq18\" class=\"equationimageholder\">\u003cmath id=\"m50\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmi>f\u003c/mi>\u003cmn>1\u003c/mn>\u003cmo>−\u003c/mo>\u003cmtext mathvariant=\"italic\">score\u003c/mtext>\u003cmo>=\u003c/mo>\u003cmn>2\u003c/mn>\u003cmo>∗\u003c/mo>\u003cmfrac>\u003cmrow>\u003cmtext mathvariant=\"italic\">precision\u003c/mtext>\u003cmo>×\u003c/mo>\u003cmtext mathvariant=\"italic\">sensitivity\u003c/mtext>\u003c/mrow>\u003cmrow>\u003cmtext mathvariant=\"italic\">precision\u003c/mtext>\u003cmo>+\u003c/mo>\u003cmtext mathvariant=\"italic\">sensitivity\u003c/mtext>\u003c/mrow>\u003c/mfrac>\u003cmo>×\u003c/mo>\u003cmn>100\u003c/mn>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>21\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003ch3>4.2 result of the lstm model\u003c/h3>\n\u003cp class=\"mb0\">the classification lstm model, presented in \u003ca href=\"#tab4\">table 4\u003c/a>, summarizes its performance in differentiating between asd and non-asd patients, attaining an overall accuracy of 81%. the lstm model demonstrates in asd class a precision of 91%, indicating a high accuracy in identifying predicted asd cases. the lstm with recall metric scored 77% and an f1-score of 82% for detecting the asd class. the lstm model with non-asd class demonstrates a precision of 71%, a recall of 89%, and an f1-score of 79%, to identify non-asd cases. the macro average of the lstm model for all metrics is (precision: 81%, recall: 82%, f1-score: 81%). lstm model is recognized for its efficiency and scalability as a model for social media content.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">table 4\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t004.jpg\" name=\"table4\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t004.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t004.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t004.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t004.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t004.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t004.jpg\" alt=\"www.frontiersin.org\" id=\"tab4\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>table 4\u003c/b>. lstm results.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">the confusion matrix for the lstm model is provided in \u003ca href=\"#fig18\">figure 18\u003c/a>. it is presented in a clear manner. among the confirmed asd cases, 29 were accurately identified as asd, whereas 10 were incorrectly classified as non-asd, indicating strong performance with minor errors. in the true non-asd cases, 25 were correctly identified, while 3 were misclassified as asd, suggesting a generally effective detection process. the deep blue and light shades produce a tranquil visual, illustrating the model’s balanced approach in classifying the 67 total instances, demonstrating notable strength in identifying non-asd cases, while exhibiting marginally lower accuracy for asd. this matrix effectively illustrates the lstm model’s systematic approach to managing sequential data, such as text or time-series inputs, in a clear and comprehensible manner.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 18\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g018.jpg\" name=\"figure18\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g018.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g018.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g018.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g018.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g018.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g018.jpg\" alt=\"confusion matrix for lstm model showing true labels versus predicted labels. the matrix includes 29 true positives for asd, 25 true negatives for non-asd, 10 false positives, and 3 false negatives. a color gradient represents value intensity.\" id=\"fig18\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 18\u003c/b>. lstm model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch3>4.3 result of the cnn-lstm model\u003c/h3>\n\u003cp class=\"mb0\">\u003ca href=\"#tab5\">table 5\u003c/a> displays the cnn-lstm model’s performance in distinguishing between asd and non-asd classes. the cnn-lstm model attained an overall accuracy of 85% across the dataset. in the asd label, a precision of 91% was achieved, a high percentage for predicting asd cases that were accurately recognized. the recall indicates that the model identified 82% of all genuine asd cases, resulting in an f1 score of 86%, better than the recall metric. the cnn-lstm model attained 78% accuracy, 89% recall, and an 83% f1 score for the non-asd class. the macro average, representing the unweighted mean of precision, recall, and f1 score across both classes, was 85, 86, and 85%, respectively. the findings indicate that the cnn-lstm model performs satisfactorily, exhibiting a marginally superior capacity to identify asd cases relative to non-asd cases accurately.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">table 5\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t005.jpg\" name=\"table5\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t005.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t005.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t005.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t005.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t005.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t005.jpg\" alt=\"www.frontiersin.org\" id=\"tab5\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>table 5\u003c/b>. results of the cnn-lstm model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">the confusion matrix of a cnn-lstm model is presented in \u003ca href=\"#fig19\">figure 19\u003c/a>, for classifying instances into asd and non-asd. the matrix is structured with true labels on the vertical axis and predicted labels on the horizontal axis, providing a clear summary of the model’s classification outcomes. the matrix shows that out of the instances truly labeled as asd, the model correctly predicted 32 as asd tp while 7 were incorrectly classified as non-asd fn. for the instances truly labeled as non-asd, the model accurately identified 25 as non-asd tn but 3 were misclassified as asd fp. this indicates that the model demonstrates a relatively strong ability to correctly identify asd and non-asd cases, with higher accuracy for true positives (32 out of 39 asd cases) and true negatives (25 out of 28 non-asd cases). overall, the model exhibits promising performance with minimal misclassification errors.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 19\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g019.jpg\" name=\"figure19\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g019.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g019.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g019.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g019.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g019.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g019.jpg\" alt=\"confusion matrix for cnn_lstm_model with predicted labels on the x-axis and true labels on the y-axis. it shows 32 true positives, 7 false negatives, 3 false positives, and 25 true negatives. a gradient bar on the right indicates color intensity from light to dark blue, representing increasing values from 0 to 30.\" id=\"fig19\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 19\u003c/b>. results of cnn-lstm model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch3>4.4 results of double deep q-network\u003c/h3>\n\u003cp class=\"mb0\">the findings of the ddqn model are shown in \u003ca href=\"#tab6\">table 6\u003c/a>, achieving a high precision of 87% compared to the other models. this finding demonstrates the potential of the proposed ddqn approach for identifying asd based on social media content. ultimately, the proposed system was compared against the existing one using the same dataset. the proposed approach may assist physicians in detecting asd and conducting symptomology research in a natural environment, attaining an overall accuracy of 87. the model for the asd class shows a precision of 95%, a recall of 79%, and an f1-score of 87%, indicating robust efficacy in accurately identifying asd patients. the non-asd class has a precision of 77%, a recall of 96%, and an f1-score of 86%, indicating somewhat reduced accuracy with robust recall. the macro average measures (precision 87%, recall 88%, f1-score 87%) indicate performance across both classes.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">table 6\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t006.jpg\" name=\"table6\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t006.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t006.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t006.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t006.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t006.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t006.jpg\" alt=\"www.frontiersin.org\" id=\"tab6\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>table 6\u003c/b>. result of ddqn-inspired.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">the confusion matrix of the ddqn model is shown in \u003ca href=\"#fig20\">figure 20\u003c/a> for the classification task between asd and non-asd cases. for correct classification of asd cases, the model correctly classified 31 instances as asd, represented by the top-left quadrant (tp). however, the ddqn model, misclassified 8 instances misclassifying true asd cases as non-asd, shown in the top-right quadrant (fn). on the other hand, the ddqn showed the true non-asd cases, accurately identified 27 instances as non-asd, depicted in the bottom-right quadrant (tn). at the same time, 1 instance was incorrectly labeled as asd, as shown in the bottom-left quadrant (fp). the confusion matrix of ddqn model highlights that it performs well overall, with a strong ability to correctly identify both asd and non-asd cases, as evidenced by the high counts of tp (31) and tn (27).\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 20\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g020.jpg\" name=\"figure20\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g020.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g020.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g020.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g020.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g020.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g020.jpg\" alt=\"confusion matrix title “ddqn-inspired confusion matrix”. the matrix shows actual versus predicted labels for asd and non-asd. true positives: 31, false positives: 8, false negatives: 1, true negatives: 27. a color bar on the right indicates intensity from light to dark blue, corresponding to values from 0 to 30.\" id=\"fig20\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 20\u003c/b>. result of ddqn-inspired model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb15\">in the digital era, people frequently write content on social media to express their feelings, opinions, beliefs, and activities. this makes social media one of the most significant sources of data generation, allowing you to explore its opportunities and challenges. today, social media has become a mediator between people and the healthcare sector, enabling them to search for information about any specific disease and methods for diagnosing it.\u003c/p>\n\u003cp class=\"mb0\">individuals within the mental health community use social media platforms such as twitter to seek information, exchange experiences, and get assistance about asd in an environment that is seen as more approachable and informal than conventional medical contexts. they often seek immediate, relevant information—whether to understand symptoms, identify coping mechanisms, or connect with others facing similar difficulties. \u003ca href=\"#fig21\">figure 21\u003c/a> illustrates that word clouds are visual representations of text that highlight key terms and their frequency of use. we used wordcloud to compare asd and non-asd texts for instances of word repetition.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 21\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g021.jpg\" name=\"figure21\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g021.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g021.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g021.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g021.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g021.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g021.jpg\" alt=\"word cloud with terms related to asd class, including prominent words like “toddler,” “ability,” “might,” “concerned,” “activities,” and “making.” other words such as “engage,” “learning,” “challenging,” “noise,” and “struggle” also appear, reflecting themes in autism education.\" id=\"fig21\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 21\u003c/b>. asd word cloud.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">the deployment model based on the deep q-network (dqn) model for diagnosing asd is shown in \u003ca href=\"#fig22\">figure 22\u003c/a>.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 22\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g022.jpg\" name=\"figure22\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g022.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g022.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g022.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g022.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g022.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g022.jpg\" alt=\"flowchart depicting a data collection and processing model using twitter api for tweet analysis. the process includes filtering tweets, preprocessing, and applying a deep q-network for model development. it involves validating and testing to build an application interface. the deployment phase includes user interaction, real-time monitoring, and cloud storage. health professionals validate predictions, classifying tweets as asd or non-asd.\" id=\"fig22\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 22\u003c/b>. deployment system-based text for detecting asd.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb15\">step 1: data collections, including cleaning, normalization, and tokenization.\u003c/p>\n\u003cp class=\"mb15\">step 2: model development: the preprocessed data is used to train and validate a deep q-network (dqn) model for classifying tweets as indicative of asd or non-asd patterns.\u003c/p>\n\u003cp class=\"mb15\">step 3: application interface: an application interface is developed once the model has been trained. it integrates with users’ twitter accounts and continuously analyzes their tweets.\u003c/p>\n\u003cp class=\"mb15\">step 4: deployment: the proposed system is deployed in the cloud for storing tweets, enabling real-time monitoring of incoming tweets. predictions are flagged for review by healthcare professionals, who validate the model’s output before categorizing individuals as potentially having asd or non-asd.\u003c/p>\n\u003cp class=\"mb0\">this digital imprint may serve as an ancillary resource for mental health practitioners, providing insights into an individual’s emotional state and social behaviors in a natural environment, potentially facilitating early detection or corroborating a diagnosis. this method is a non-invasive means of data collection, particularly beneficial for individuals who lack rapid access to clinical assessments due to financial constraints, stigma, or resource scarcity. however, it should not replace professional diagnoses and must be conducted with ethical consideration to prevent misunderstanding. \u003ca href=\"#tab7\">table 7\u003c/a> shows the findings of the proposed framework on the twitter dataset. it demonstrates that the suggested method outperforms the current systems in terms of accuracy, proving its efficacy and potential for performance improvements.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">table 7\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t007.jpg\" name=\"table7\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t007.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t007.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t007.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t007.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t007.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t007.jpg\" alt=\"www.frontiersin.org\" id=\"tab7\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>table 7\u003c/b>. compared with the proposed asd system.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div> \u003ca id=\"h6\" name=\"h6\">\u003c/a>\n\u003ch2>5 conclusion\u003c/h2>\n\u003cp class=\"mb0\">to assist people in identifying trends in their behavior, such as social challenges or sensory sensitivities, which may encourage them to pursue a formal diagnosis. the main objective of examining tweets for identifying asd is its ability to provide behavioral and emotional indicators associated with the disorder. this research was used to analyze the textual analysis of tweets to detect the behaviors in self-identified autistic individuals relative to others. the suggested framework was evaluated using information from the social media platform “twitter” collected from a public repository. before examining the proposed system, several preprocessing steps must be implemented in the text. the ‘text’ column is cleaned by converting it to lowercase, eliminating non-alphanumeric characters (excluding spaces) through regular expressions, normalizing whitespace to a single space, and removing any leading or trailing spaces. the asd and non-asd labels are converted into a numerical format (0 or 1) with labelencoder to accommodate the binary classification requirement. tokenization of the text data is performed using a tokenizer, restricting the vocabulary to 10,000 words, and then transforming the text into sequences of numbers. the sequences are padded to a standardized length of 200 tokens to maintain consistency for the proposed model input. the proposed data is ultimately divided into an 80% training and 20% testing ratio, and class weights are calculated to resolve any class imbalance. this preparation pipeline efficiently converts raw text data into a structured numerical representation appropriate for the proposed framework, while preserving academic integrity. the output of these preprocessing steps was processed using three dl models, such as short-term memory (cnn-lstm) and a double deep q-network (ddqn). the results of these proposals were proven, revealing that the ddqn model achieved a high accuracy score of 87% with respect to the accuracy measure. the proposed framework, based on real textual data, can be helpful for real-time offering natural, behavioral, and emotional data that might indicate asd-related characteristics. finally, we have observed that social media (twitter) postings include linguistic patterns, emotional expressions, and social interactions that can help official health officials detect asd based on the thorough symptoms of asd that are posted on the platform. this study utilized a conventional dataset sourced only from the twitter network. we will emphasize the necessity of gathering datasets from many platforms to enhance the model’s generalizability in the future.\u003c/p> \u003ca id=\"h7\" name=\"h7\">\u003c/a>\n\u003ch2>data availability statement\u003c/h2>\n\u003cp class=\"mb0\">the original contributions presented in the study are included in the article/supplementary material, further inquiries can be directed to the corresponding author/s. the dataset used in this study can be found at \u003ca href=\"https://data.mendeley.com/datasets/87s2br3ptb/1\">https://data.mendeley.com/datasets/87s2br3ptb/1\u003c/a>.\u003c/p> \u003ca id=\"h8\" name=\"h8\">\u003c/a>\n\u003ch2>ethics statement\u003c/h2>\n\u003cp class=\"mb0\">ethical approval was not required for the study involving human data in accordance with the local legislation and institutional requirements. written informed consent was not required, for either participation in the study or for the publication of potentially/indirectly identifying information, in accordance with the local legislation and institutional requirements. the social media data was accessed and analysed in accordance with the platform’s terms of use and all relevant institutional/national regulations.\u003c/p> \u003ca id=\"h9\" name=\"h9\">\u003c/a>\n\u003ch2>author contributions\u003c/h2>\n\u003cp class=\"mb0\">nf: supervision, conceptualization, software, methodology, writing – original draft, investigation, visualization, formal analysis, validation. aa: data curation, visualization, methodology, conceptualization, validation, software, formal analysis, writing – original draft. ne: investigation, writing – review & editing, validation, formal analysis. sa: visualization, software, formal analysis, writing – review & editing, data curation.\u003c/p> \u003ca id=\"h10\" name=\"h10\">\u003c/a>\n\u003ch2>funding\u003c/h2>\n\u003cp class=\"mb0\">the author(s) declare that financial support was received for the research and/or publication of this article. the authors extend their appreciation to the king salman center for disability research for funding this work through research group no ksrg-2024-288.\u003c/p> \u003ca id=\"h11\" name=\"h11\">\u003c/a>\n\u003ch2>conflict of interest\u003c/h2>\n\u003cp class=\"mb0\">the authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\u003c/p> \u003ca id=\"h12\" name=\"h12\">\u003c/a>\n\u003ch2>generative ai statement\u003c/h2>\n\u003cp class=\"mb15\">the authors declare that no gen ai was used in the creation of this manuscript.\u003c/p>\n\u003cp class=\"mb0\">any alternative text (alt text) provided alongside figures in this article has been generated by frontiers with the support of artificial intelligence and reasonable efforts have been made to ensure accuracy, including review by the authors wherever possible. if you identify any issues, please contact us.\u003c/p> \u003ca id=\"h13\" name=\"h13\">\u003c/a>\n\u003ch2>publisher’s note\u003c/h2>\n\u003cp class=\"mb0\">all claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.\u003c/p> \u003ca id=\"h14\" name=\"h14\">\u003c/a>\n\u003ch2>references\u003c/h2>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref1\" id=\"ref1\">\u003c/a>1. asd. (2023). available online at: \u003ca href=\"https://www.healthline.com/health/signs-of-autism-in-3-year-old\">https://www.healthline.com/health/signs-of-autism-in-3-year-old\u003c/a>.\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"http://scholar.google.com/scholar_lookup?publication_year=2023&\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref2\" id=\"ref2\">\u003c/a>2. matson, jl, and goldin, rl. what is the future of assessment for autism spectrum disorders: short and long term. \u003ci>res autism spectr disord\u003c/i>. (2014) 8:209–13. doi: 10.1016/j.rasd.2013.01.007\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.1016/j.rasd.2013.01.007\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=jl+matson&author=rl+goldin&publication_year=2014&title=what+is+the+future+of+assessment+for+autism+spectrum+disorders:+short+and+long+term&journal=res+autism+spectr+disord&volume=8&pages=209-13\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref3\" id=\"ref3\">\u003c/a>3. srivastava, ak, and schwartz, ce. intellectual disability and autism spectrum disorders: causal genes and molecular mechanisms. \u003ci>neurosci biobehav rev\u003c/i>. (2014) 46:161–74. doi: 10.1016/j.neubiorev.2014.02.015 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/24709068\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.1016/j.neubiorev.2014.02.015\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=ak+srivastava&author=ce+schwartz&publication_year=2014&title=intellectual+disability+and+autism+spectrum+disorders:+causal+genes+and+molecular+mechanisms&journal=neurosci+biobehav+rev&volume=46&pages=161-74\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref4\" id=\"ref4\">\u003c/a>4. alhujaili, n, platt, e, khalid-khan, s, and groll, d. comparison of social media use among adolescents with autism spectrum disorder and non-asd adolescents. \u003ci>adolesc health med ther\u003c/i>. (2022) 13:15–21. doi: 10.2147/ahmt.s344591 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/35136359\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.2147/ahmt.s344591\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=n+alhujaili&author=e+platt&author=s+khalid-khan&author=d+groll&publication_year=2022&title=comparison+of+social+media+use+among+adolescents+with+autism+spectrum+disorder+and+non-asd+adolescents&journal=adolesc+health+med+ther&volume=13&pages=15-21\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref5\" id=\"ref5\">\u003c/a>5. angulo-jiménez, h, and dethorne, l. narratives about autism: an analysis of youtube videos by individuals who self-identify as autistic. \u003ci>am j speech lang pathol\u003c/i>. (2019) 28:569–90. doi: 10.1044/2018_ajslp-18-0045\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.1044/2018_ajslp-18-0045\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=h+angulo-jiménez&author=l+dethorne&publication_year=2019&title=narratives+about+autism:+an+analysis+of+youtube+videos+by+individuals+who+self-identify+as+autistic&journal=am+j+speech+lang+pathol&volume=28&pages=569-90\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref6\" id=\"ref6\">\u003c/a>6. pew research center. (2021). available online at: \u003ca href=\"https://www.pewresearch.org/internet/2021/04/07/social-media-use-in-2021/\">https://www.pewresearch.org/internet/2021/04/07/social-media-use-in-2021/\u003c/a>\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"http://scholar.google.com/scholar_lookup?publication_year=2021&\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref7\" id=\"ref7\">\u003c/a>7. liu, j-b, guan, l, cao, j, and chen, l. coherence analysis for a class of polygon networks with the noise disturbance. \u003ci>ieee trans syst man cybern syst\u003c/i>. (2025) 2025:326. doi: 10.1109/tsmc.2025.3559326\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.1109/tsmc.2025.3559326\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=j-b+liu&author=l+guan&author=j+cao&author=l+chen&publication_year=2025&title=coherence+analysis+for+a+class+of+polygon+networks+with+the+noise+disturbance&journal=ieee+trans+syst+man+cybern+syst&volume=2025&pages=326\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref8\" id=\"ref8\">\u003c/a>8. al-nefaie, ah, aldhyani, th, sultan, ha, and alzahrani eidah, m. application of artificial intelligence in modern healthcare for diagnosis of autism spectrum disorder. \u003ci>front med\u003c/i>. (2025) 12:1569464. doi: 10.3389/fmed.2025.1569464\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.3389/fmed.2025.1569464\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=ah+al-nefaie&author=th+aldhyani&author=ha+sultan&author=m+alzahrani+eidah&publication_year=2025&title=application+of+artificial+intelligence+in+modern+healthcare+for+diagnosis+of+autism+spectrum+disorder&journal=front+med&volume=12&pages=1569464\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref9\" id=\"ref9\">\u003c/a>9. kim, b, jeong, d, kim, jg, hong, h, and han, k. \u003ci>v-dat (virtual reality data analysis tool): supporting self-awareness for autistic people from multimodal vr sensor data\u003c/i>. in: proceedings of the uist 2023—proceedings of the 36th annual acm symposium on user interface software and technology, san francisco, ca, usa, 29 october–1 november 2023. (2023).\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"http://scholar.google.com/scholar_lookup?author=b+kim&author=d+jeong&author=jg+kim&author=h+hong&author=k+han&publication_year=2023&\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref10\" id=\"ref10\">\u003c/a>10. chen, c, chander, a, and uchino, k. \u003ci>guided play: digital sensing and coaching for stereotypical play behavior in children with autism\u003c/i>. in proceedings of the international conference on intelligent user interfaces, proceedings iui, marina del ray, ca, usa, 17–20 march 2019; part f1476. pp. 208–217. (2019).\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"http://scholar.google.com/scholar_lookup?author=c+chen&author=a+chander&author=k+uchino&publication_year=2019&\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref11\" id=\"ref11\">\u003c/a>11. parui, s, samanta, d, chakravorty, n, ghosh, u, and rodrigues, jj. artificial intelligence and sensor-based autism spectrum disorder diagnosis using brain connectivity analysis. \u003ci>comput electr eng\u003c/i>. (2023) 108:108720. doi: 10.1016/j.compeleceng.2023.108720\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.1016/j.compeleceng.2023.108720\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=s+parui&author=d+samanta&author=n+chakravorty&author=u+ghosh&author=jj+rodrigues&publication_year=2023&title=artificial+intelligence+and+sensor-based+autism+spectrum+disorder+diagnosis+using+brain+connectivity+analysis&journal=comput+electr+eng&volume=108&pages=108720\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref12\" id=\"ref12\">\u003c/a>12. golestan, s, soleiman, p, and moradi, h. a comprehensive review of technologies used for screening, assessment, and rehabilitation of autism spectrum disorder. \u003ci>arxiv\u003c/i>. (2018) 2018:10986. doi: 10.48550/arxiv.1807.10986\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.48550/arxiv.1807.10986\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=s+golestan&author=p+soleiman&author=h+moradi&publication_year=2018&title=a+comprehensive+review+of+technologies+used+for+screening+assessment+and+rehabilitation+of+autism+spectrum+disorder&journal=arxiv&volume=2018&pages=10986\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref13\" id=\"ref13\">\u003c/a>13. neeharika, ch, and riyazuddin, ym. developing an artificial intelligence based model for autism spectrum disorder detection in children. \u003ci>j adv res appl sci eng technol\u003c/i>. (2023) 32:57–72. doi: 10.37934/araset.32.1.5772\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.37934/araset.32.1.5772\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=ch+neeharika&author=ym+riyazuddin&publication_year=2023&title=developing+an+artificial+intelligence+based+model+for+autism+spectrum+disorder+detection+in+children&journal=j+adv+res+appl+sci+eng+technol&volume=32&pages=57-72\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref14\" id=\"ref14\">\u003c/a>14. wall, dp, dally, r, luyster, r, jung, j-y, and deluca, tf. use of artificial intelligence to shorten the behavioral diagnosis of autism. \u003ci>plos one\u003c/i>. (2012) 7:e43855. doi: 10.1371/journal.pone.0043855 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/22952789\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.1371/journal.pone.0043855\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=dp+wall&author=r+dally&author=r+luyster&author=j-y+jung&author=tf+deluca&publication_year=2012&title=use+of+artificial+intelligence+to+shorten+the+behavioral+diagnosis+of+autism&journal=plos+one&volume=7&pages=e43855\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref15\" id=\"ref15\">\u003c/a>15. alzakari, sa, allinjawi, a, aldrees, a, zamzami, n, umer, m, innab, n, et al. early detection of autism spectrum disorder using explainable ai and optimized teaching strategies. \u003ci>j neurosci methods\u003c/i>. (2025) 413:110315. doi: 10.1016/j.jneumeth.2024.110315 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/39532186\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.1016/j.jneumeth.2024.110315\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=sa+alzakari&author=a+allinjawi&author=a+aldrees&author=n+zamzami&author=m+umer&author=n+innab&publication_year=2025&title=early+detection+of+autism+spectrum+disorder+using+explainable+ai+and+optimized+teaching+strategies&journal=j+neurosci+methods&volume=413&pages=110315\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref16\" id=\"ref16\">\u003c/a>16. heunis, t, aldrich, c, peters, j, jeste, s, sahin, m, scheffer, c, et al. recurrence quantification analysis of resting state eeg signals in autism spectrum disorder—a systematic methodological exploration of technical and demographic confounders in the search for biomarkers. \u003ci>bmc med\u003c/i>. (2018) 16:101. doi: 10.1186/s12916-018-1086-7\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.1186/s12916-018-1086-7\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=t+heunis&author=c+aldrich&author=j+peters&author=s+jeste&author=m+sahin&author=c+scheffer&publication_year=2018&title=recurrence+quantification+analysis+of+resting+state+eeg+signals+in+autism+spectrum+disorder—a+systematic+methodological+exploration+of+technical+and+demographic+confounders+in+the+search+for+biomarkers&journal=bmc+med&volume=16&pages=101\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref17\" id=\"ref17\">\u003c/a>17. vicnesh, j, wei, jke, oh, sl, arunkumar, n, abdulhay, e, ciaccio, ej, et al. autism spectrum disorder diagnostic system using hos bispectrum with eeg signals. \u003ci>int j environ res public health\u003c/i>. (2020) 17:971. doi: 10.3390/ijerph17030971\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.3390/ijerph17030971\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=j+vicnesh&author=jke+wei&author=sl+oh&author=n+arunkumar&author=e+abdulhay&author=ej+ciaccio&publication_year=2020&title=autism+spectrum+disorder+diagnostic+system+using+hos+bispectrum+with+eeg+signals&journal=int+j+environ+res+public+health&volume=17&pages=971\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref18\" id=\"ref18\">\u003c/a>18. novielli, p, romano, d, magarelli, m, diacono, d, monaco, a, amoroso, n, et al. personalized identification of autism-related bacteria in the gut microbiome using explainable artificial intelligence. \u003ci>iscience\u003c/i>. (2024) 27:110709. doi: 10.1016/j.isci.2024.110709 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/39286497\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.1016/j.isci.2024.110709\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=p+novielli&author=d+romano&author=m+magarelli&author=d+diacono&author=a+monaco&author=n+amoroso&publication_year=2024&title=personalized+identification+of+autism-related+bacteria+in+the+gut+microbiome+using+explainable+artificial+intelligence&journal=iscience&volume=27&pages=110709\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref19\" id=\"ref19\">\u003c/a>19. bosl, wj, tager-flusberg, h, and nelson, ca. eeg analytics for early detection of autism spectrum disorder: a data-driven approach. \u003ci>sci rep\u003c/i>. (2018) 8:1–20. doi: 10.1038/s41598-018-24318-x \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/29717196\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.1038/s41598-018-24318-x\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=wj+bosl&author=h+tager-flusberg&author=ca+nelson&publication_year=2018&title=eeg+analytics+for+early+detection+of+autism+spectrum+disorder:+a+data-driven+approach&journal=sci+rep&volume=8&pages=1-20\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref20\" id=\"ref20\">\u003c/a>20. beykikhoshk, a, arandjelović, o, phung, d, venkatesh, s, and caelli, t. using twitter to learn about the autism community. \u003ci>soc netw anal min\u003c/i>. (2015) 5:261. doi: 10.1007/s13278-015-0261-\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.1007/s13278-015-0261-\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=a+beykikhoshk&author=o+arandjelović&author=d+phung&author=s+venkatesh&author=t+caelli&publication_year=2015&title=using+twitter+to+learn+about+the+autism+community&journal=soc+netw+anal+min&volume=5&pages=261\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref21\" id=\"ref21\">\u003c/a>21. mazurek, mo. social media use among adults with autism spectrum disorders. \u003ci>comput hum behav\u003c/i>. (2013) 29:1709–14. doi: 10.1016/j.chb.2013.02.004\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.1016/j.chb.2013.02.004\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=mo+mazurek&publication_year=2013&title=social+media+use+among+adults+with+autism+spectrum+disorders&journal=comput+hum+behav&volume=29&pages=1709-14\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref22\" id=\"ref22\">\u003c/a>22. onnela, j, and rauch, sl. harnessing smartphone-based digital phenotyping to enhance behavioral and mental health. \u003ci>neuropsychopharmacology\u003c/i>. (2016) 41:1691–6. doi: 10.1038/npp.2016.7.npp20167 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/26818126\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.1038/npp.2016.7.npp20167\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=j+onnela&author=sl+rauch&publication_year=2016&title=harnessing+smartphone-based+digital+phenotyping+to+enhance+behavioral+and+mental+health&journal=neuropsychopharmacology&volume=41&pages=1691-6\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref23\" id=\"ref23\">\u003c/a>23. tomeny, ts, vargo, cj, and el-toukhy, s. geographic and demographic correlates of autism-related anti-vaccine beliefs on twitter, 2009–2015. \u003ci>soc sci med\u003c/i>. (2017) 191:168–75. doi: 10.1016/j.socscimed.2017.08.041 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/28926775\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.1016/j.socscimed.2017.08.041\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=ts+tomeny&author=cj+vargo&author=s+el-toukhy&publication_year=2017&title=geographic+and+demographic+correlates+of+autism-related+anti-vaccine+beliefs+on+twitter+2009–2015&journal=soc+sci+med&volume=191&pages=168-75\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref24\" id=\"ref24\">\u003c/a>24. tárraga-mínguez, r, gómez-marí, i, and sanz-cervera, p. what motivates internet users to search for asperger syndrome and autism on google? \u003ci>int j environ res public health\u003c/i>. (2020) 17:9386. doi: 10.3390/ijerph17249386 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/33333991\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.3390/ijerph17249386\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=r+tárraga-mínguez&author=i+gómez-marí&author=p+sanz-cervera&publication_year=2020&title=what+motivates+internet+users+to+search+for+asperger+syndrome+and+autism+on+google?&journal=int+j+environ+res+public+health&volume=17&pages=9386\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref25\" id=\"ref25\">\u003c/a>25. hartwell, m, keener, a, coffey, s, chesher, t, torgerson, t, and vassar, m. brief report: public awareness of asperger syndrome following greta thunberg appearances. \u003ci>j autism dev disord\u003c/i>. (2020) 51:2104–8. doi: 10.1007/s10803-020-04651-9 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/32812193\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.1007/s10803-020-04651-9\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=m+hartwell&author=a+keener&author=s+coffey&author=t+chesher&author=t+torgerson&author=m+vassar&publication_year=2020&title=brief+report:+public+awareness+of+asperger+syndrome+following+greta+thunberg+appearances&journal=j+autism+dev+disord&volume=51&pages=2104-8\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref26\" id=\"ref26\">\u003c/a>26. rubio-martín, s, garcía-ordás, mt, bayón-gutiérrez, m, prieto-fernández, n, and benítez-andrades, ja. “\u003ci>early detection of autism spectrum disorder through ai-powered analysis of social media texts\u003c/i>,” 2023 ieee 36th international symposium on computer-based medical systems (cbms), l’aquila, italy, pp. 235–240. (2023).\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"http://scholar.google.com/scholar_lookup?author=s+rubio-martín&author=mt+garcía-ordás&author=m+bayón-gutiérrez&author=n+prieto-fernández&author=ja+benítez-andrades&publication_year=2023&\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref27\" id=\"ref27\">\u003c/a>27. jaiswal, a, and washington, p. using #actuallyautistic on twitter for precision diagnosis of autism spectrum disorder: machine learning study. \u003ci>jmir form res\u003c/i>. (2024) 8:e52660. doi: 10.2196/52660\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.2196/52660\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=a+jaiswal&author=p+washington&publication_year=2024&title=using+#actuallyautistic+on+twitter+for+precision+diagnosis+of+autism+spectrum+disorder:+machine+learning+study&journal=jmir+form+res&volume=8&pages=e52660\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003c/div> \u003cdiv class=\"thinlinem20\">\u003c/div> \u003cdiv class=\"abstractsummary\">\n\u003cp>\u003cspan>keywords:\u003c/span> autism spectrum disorders, diagnosing, social media, deep learning, disabilities, artificial intelligence\u003c/p>\n\u003cp>\u003cspan>citation:\u003c/span> farhah ns, alqarni aa, ebrahim n and ahmad s (2025) diagnosing autism spectrum disorders using a double deep q-network framework based on social media footprints. \u003ci>front. med\u003c/i>. 12:1646249. doi: 10.3389/fmed.2025.1646249\u003c/p>\n\u003cp class=\"timestamps\">\u003cspan>received:\u003c/span> 16 june 2025; \u003cspan>accepted:\u003c/span> 28 july 2025;\u003cbr> \u003cspan>published:\u003c/span> 20 august 2025.\u003c/p> \u003cdiv>\n\u003cp>edited by:\u003c/p> \u003ca href=\"https://loop.frontiersin.org/people/2928766/overview\">pardeep sangwan\u003c/a>, maharaja surajmal institute of technology, india\u003c/div> \u003cdiv>\n\u003cp>reviewed by:\u003c/p> \u003ca href=\"https://loop.frontiersin.org/people/1743107/overview\">jia-bao liu\u003c/a>, anhui jianzhu university, china\u003cbr> \u003ca href=\"https://loop.frontiersin.org/people/3104897/overview\">muhammad adnan\u003c/a>, kohat university of science and technology, pakistan\u003c/div>\n\u003cp>\u003cspan>copyright\u003c/span> © 2025 farhah, alqarni, ebrahim and ahmad. this is an open-access article distributed under the terms of the \u003ca rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\" target=\"_blank\">creative commons attribution license (cc by)\u003c/a>. the use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. no use, distribution or reproduction is permitted which does not comply with these terms.\u003c/p>\n\u003cp>\u003cspan>*correspondence:\u003c/span> nesren s. farhah, \u003ca id=\"encmail\">bi5myxjoywhac2v1lmvkds5zyq==\u003c/a>; nadhem ebrahim, \u003ca id=\"encmail\">bmvicmfoaw1adwfrcm9ulmvkdq==\u003c/a>; sultan ahmad, \u003ca id=\"encmail\">cy5hbglzagvyqhbzyxuuzwr1lnnh\u003c/a>\u003c/p> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>","\u003cul class=\"flyoutjournal\"> \u003cli>\u003ca href=\"#h1\">abstract\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h2\">1 introduction\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h3\">2 materials and methods\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h4\">3 performance of the framework\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h5\">4 experiment and discussion results\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h6\">5 conclusion\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h7\">data availability statement\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h8\">ethics statement\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h9\">author contributions\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h10\">funding\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h11\">conflict of interest\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h12\">generative ai statement\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h13\">publisher’s note\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h14\">references\u003c/a>\u003c/li> \u003c/ul>",[627,633,639],{"name":628,"fileserverpackageentryid":19,"fileserverid":629,"fileserverversionnumber":374,"type":630},"epub.epub","1646249/epub",{"code":631,"name":632},"epub","epub",{"name":634,"fileserverpackageentryid":19,"fileserverid":635,"fileserverversionnumber":374,"type":636},"publishers-proof.pdf","1646249/publishers-proof",{"code":637,"name":638},"pdf","pdf",{"name":640,"fileserverpackageentryid":641,"fileserverid":642,"fileserverversionnumber":374,"type":643},"fmed-12-1646249.xml","fmed-12-1646249/fmed-12-1646249.xml","1646249/xml",{"code":644,"name":645},"nlm_xml","xml","v3",{"title":648,"link":649,"meta":653,"script":754},"frontiers | diagnosing autism spectrum disorders using a double deep q-network framework based on social media footprints",[650],{"rel":651,"href":652},"canonical","https://www.frontiersin.org/journals/medicine/articles/10.3389/fmed.2025.1646249/full",[654,657,660,662,665,669,672,676,679,682,685,687,689,691,693,695,698,701,703,706,708,710,713,716,719,722,725,729,733,736,739,742,745,748,751],{"hid":655,"property":655,"name":655,"content":656},"description","introductionsocial media is increasingly used in many contexts within the healthcare sector. the improved prevalence of internet use via computers or mobile ...",{"hid":658,"property":658,"name":659,"content":648},"og:title","title",{"hid":661,"property":661,"name":655,"content":656},"og:description",{"hid":663,"name":663,"content":664},"keywords","artificial intelligence,deep learning,social media,disabilities,autism spectrum disorders,diagnosing",{"hid":666,"property":666,"name":667,"content":668},"og:site_name","site_name","frontiers",{"hid":670,"property":670,"name":367,"content":671},"og:image","https://images-provider.frontiersin.org/api/ipx/w=1200&f=png/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g001.jpg",{"hid":673,"property":673,"name":674,"content":675},"og:type","type","article",{"hid":677,"property":677,"name":678,"content":652},"og:url","url",{"hid":680,"name":680,"content":681},"twitter:card","summary_large_image",{"hid":683,"name":683,"content":684},"citation_volume","12",{"hid":686,"name":686,"content":116},"citation_journal_title",{"hid":688,"name":688,"content":668},"citation_publisher",{"hid":690,"name":690,"content":608},"citation_journal_abbrev",{"hid":692,"name":692,"content":609},"citation_issn",{"hid":694,"name":694,"content":518},"citation_doi",{"hid":696,"name":696,"content":697},"citation_firstpage","1646249",{"hid":699,"name":699,"content":700},"citation_language","english",{"hid":702,"name":702,"content":519},"citation_title",{"hid":704,"name":704,"content":705},"citation_keywords","artificial intelligence; deep learning; social media; disabilities; autism spectrum disorders; diagnosing",{"hid":707,"name":707,"content":524},"citation_abstract",{"hid":709,"name":709,"content":533},"citation_article_type",{"hid":711,"name":711,"content":712},"citation_pdf_url","https://www.frontiersin.org/journals/medicine/articles/10.3389/fmed.2025.1646249/pdf",{"hid":714,"name":714,"content":715},"citation_xml_url","https://www.frontiersin.org/journals/medicine/articles/10.3389/fmed.2025.1646249/xml",{"hid":717,"name":717,"content":718},"citation_fulltext_world_readable","yes",{"hid":720,"name":720,"content":721},"citation_online_date","2025/07/28",{"hid":723,"name":723,"content":724},"citation_publication_date","2025/08/20",{"hid":726,"name":727,"content":728},"citation_author_0","citation_author","farhah, nesren s. ",{"hid":730,"name":731,"content":732},"citation_author_institution_0","citation_author_institution","department of health informatics, college of health science, saudi electronic university, saudi arabia",{"hid":734,"name":727,"content":735},"citation_author_1","alqarni, ahmed abdullah ",{"hid":737,"name":731,"content":738},"citation_author_institution_1","king salman center for disability research, saudi arabia",{"hid":740,"name":727,"content":741},"citation_author_2","ebrahim, nadhem ",{"hid":743,"name":731,"content":744},"citation_author_institution_2","department of computer science, college of engineering and polymer science, university of akron, united states",{"hid":746,"name":727,"content":747},"citation_author_3","ahmad, sultan ",{"hid":749,"name":731,"content":750},"citation_author_institution_3","department of computer science, college of computer engineering and sciences, prince sattam bin abdulaziz university, saudi arabia",{"hid":752,"name":752,"content":753},"dc.identifier","doi:10.3389/fmed.2025.1646249",[755,758,760,762,764],{"src":756,"body":13,"type":757,"async":13},"https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6","text/javascript",{"src":759,"body":13,"type":757,"async":13},"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/mathjax.js?config=tex-mml-am_chtml",{"src":761,"body":13,"type":757,"async":13},"https://d1bxh8uas1mnw7.cloudfront.net/assets/altmetric_badges-f0bc9b243ff5677d05460c1eb71834ca998946d764eb3bc244ab4b18ba50d21e.js",{"src":763,"body":13,"type":757,"async":13},"https://api.altmetric.com/v1/doi/10.3389/fmed.2025.1646249?callback=_altmetric.embed_callback&domain=www.frontiersin.org&key=3c130976ca2b8f2e88f8377633751ba1&cache_until=14-15",{"src":765,"body":13,"type":757,"async":13},"https://crossmark-cdn.crossref.org/widget/v2.0/widget.js",{"articlehubslug":19,"articlehubpage":767,"articlehubarticleslist":768,"canjournalhasarticlehub":351,"articledoilist":769},{},[],[],{"title":19,"image":-1,"breadcrumbs":771,"linkscollection":772,"metricscollection":774},[],{"total":371,"items":773},[],{"total":371,"items":775},[]] window.__nuxt__={};window.__nuxt__.config={public:{isdevmode:false,appname:"article-pages-2024",baseurl:"https://www.frontiersin.org",domain:"frontiersin.org",loopurl:"https://loop.frontiersin.org",ssmaindomain:"frontiersin.org",contentfulurl:"https://graphql.contentful.com/content/v1/spaces",spaceid:1,spacename:"frontiers",livespaceid:1,tenantlogourl:"",frontiersgraphurl:"https://apollo-federation-gateway.frontiersin.org",registrationapiurl:"https://onboarding-ui.frontiersin.org",emaildigestapiurl:"https://api-email-digest.frontiersin.org",journalfilesapiurl:"https://files-journal-api.frontiersin.org",searchapiurl:"https://search-api.frontiersin.org",productionforumapiurl:"https://production-forum-api-v2.frontiersin.org",gtmserverurl:"https://tag-manager.frontiersin.org",gtmid:"gtm-m322fv2",gtmauth:"owvbwxfajr21yqv1fe1caq",gtmpreview:"env-1",figsharepluginurl:"https://widgets.figshare.com/static/figshare.js",figshareapiurl:"https://api.figshare.com/v2/collections/search",figsharetimeout:3000,crossmarkpublisheddate:"2015/08/24",googlerecaptchasitekey:"6ldg3i0uaaaaaoc4quh35ubhgjotehp_stxhgr_v",googlerecaptchakeyname:"frontiersrecaptchav2",faviconsize16:"https://static2.frontiersin.org/static-resources/tenants/frontiers/favicon_16-tenantfavicon-frontiers.png",faviconsize32:"https://static2.frontiersin.org/static-resources/tenants/frontiers/favicon_32-tenantfavicon-frontiers.png",faviconsize180:"https://static2.frontiersin.org/static-resources/tenants/frontiers/favicon_180-tenantfavicon-frontiers.png",faviconsize192:"https://static2.frontiersin.org/static-resources/tenants/frontiers/favicon_192-tenantfavicon-frontiers.png",faviconsize512:"https://static2.frontiersin.org/static-resources/tenants/frontiers/favicon_512-tenantfavicon-frontiers.png",socialmediaimg:"https://brand.frontiersin.org/m/1c8bcb536c789e11/guidelines-frontiers_logo_1200x628_1-91to1.png",linkedarticlecopytext:"'{\"articletypecopytext\":[{\"articletypeid\":0,\"originalarticlecopytext\":\"part of this article's content has been mentioned in:\",\"linkedarticlecopytext\":\"this article mentions parts of:\"},{\"articletypeid\":122,\"originalarticlecopytext\":\"parts of this article's content have been modified or rectified in:\",\"linkedarticlecopytext\":\"this article is an erratum on:\"},{\"articletypeid\":129,\"originalarticlecopytext\":\"parts of this article's content have been modified or rectified in:\",\"linkedarticlecopytext\":\"this article is an addendum to:\"},{\"articletypeid\":128,\"originalarticlecopytext\":\"a correction has been applied to this article in:\",\"linkedarticlecopytext\":\"this article is a correction to:\"},{\"articletypeid\":134,\"originalarticlecopytext\":\"a retraction of this article was approved in:\",\"linkedarticlecopytext\":\"this article is a retraction of:\"},{\"articletypeid\":29,\"originalarticlecopytext\":\"a commentary has been posted on this article:\",\"linkedarticlecopytext\":\"this article is a commentary on:\"},{\"articletypeid\":30,\"originalarticlecopytext\":\"a commentary has been posted on this article:\",\"linkedarticlecopytext\":\"this article is a commentary on:\"}],\"articleidcopytext\":[]}'\n",acceptedarticleexcludedjournalids:"'[2766,979]'\n",articletypeconfigurablelabel:"\u003c\u003carticle-type:uppercase>> article",settingsfeaturesswitchers:"'{\"displaytitlepilllabels\":true,\"displayrelatedarticlesbox\":true,\"showeditors\":true,\"showreviewers\":true,\"showloopimpactlink\":true,\"enablefigshare\":false,\"usexmlimages\":true}'\n",journalswitharticlehub:"'{\"strings\":[\"science\"]}'\n",terminologysettings:"'{\"terms\":[{\"sequencenumber\":1,\"key\":\"frontiers\",\"tenantterm\":\"frontiers\",\"frontiersdefaultterm\":\"frontiers\",\"category\":\"customer\"},{\"sequencenumber\":2,\"key\":\"submission_system\",\"tenantterm\":\"submission system\",\"frontiersdefaultterm\":\"submission system\",\"category\":\"product\"},{\"sequencenumber\":3,\"key\":\"public_pages\",\"tenantterm\":\"public pages\",\"frontiersdefaultterm\":\"public pages\",\"category\":\"product\"},{\"sequencenumber\":4,\"key\":\"my_frontiers\",\"tenantterm\":\"my frontiers\",\"frontiersdefaultterm\":\"my frontiers\",\"category\":\"product\"},{\"sequencenumber\":5,\"key\":\"digital_editorial_office\",\"tenantterm\":\"digital editorial office\",\"frontiersdefaultterm\":\"digital editorial office\",\"category\":\"product\"},{\"sequencenumber\":6,\"key\":\"deo\",\"tenantterm\":\"deo\",\"frontiersdefaultterm\":\"deo\",\"category\":\"product\"},{\"sequencenumber\":7,\"key\":\"digital_editorial_office_for_chiefs\",\"tenantterm\":\"digital editorial office for chiefs\",\"frontiersdefaultterm\":\"digital editorial office for chiefs\",\"category\":\"product\"},{\"sequencenumber\":8,\"key\":\"digital_editorial_office_for_eof\",\"tenantterm\":\"digital editorial office for eof\",\"frontiersdefaultterm\":\"digital editorial office for eof\",\"category\":\"product\"},{\"sequencenumber\":9,\"key\":\"editorial_office\",\"tenantterm\":\"editorial office\",\"frontiersdefaultterm\":\"editorial office\",\"category\":\"product\"},{\"sequencenumber\":10,\"key\":\"eof\",\"tenantterm\":\"eof\",\"frontiersdefaultterm\":\"eof\",\"category\":\"product\"},{\"sequencenumber\":11,\"key\":\"research_topic_management\",\"tenantterm\":\"research topic management\",\"frontiersdefaultterm\":\"research topic management\",\"category\":\"product\"},{\"sequencenumber\":12,\"key\":\"review_forum\",\"tenantterm\":\"review forum\",\"frontiersdefaultterm\":\"review forum\",\"category\":\"product\"},{\"sequencenumber\":13,\"key\":\"accounting_office\",\"tenantterm\":\"accounting office\",\"frontiersdefaultterm\":\"accounting office\",\"category\":\"product\"},{\"sequencenumber\":14,\"key\":\"aof\",\"tenantterm\":\"aof\",\"frontiersdefaultterm\":\"aof\",\"category\":\"product\"},{\"sequencenumber\":15,\"key\":\"publishing_office\",\"tenantterm\":\"publishing office\",\"frontiersdefaultterm\":\"publishing office\",\"category\":\"product\"},{\"sequencenumber\":16,\"key\":\"production_office\",\"tenantterm\":\"production office forum\",\"frontiersdefaultterm\":\"production office forum\",\"category\":\"product\"},{\"sequencenumber\":17,\"key\":\"pof\",\"tenantterm\":\"pof\",\"frontiersdefaultterm\":\"pof\",\"category\":\"product\"},{\"sequencenumber\":18,\"key\":\"book_office_forum\",\"tenantterm\":\"book office forum\",\"frontiersdefaultterm\":\"book office forum\",\"category\":\"product\"},{\"sequencenumber\":19,\"key\":\"bof\",\"tenantterm\":\"bof\",\"frontiersdefaultterm\":\"bof\",\"category\":\"product\"},{\"sequencenumber\":20,\"key\":\"aira\",\"tenantterm\":\"aira\",\"frontiersdefaultterm\":\"aira\",\"category\":\"product\"},{\"sequencenumber\":21,\"key\":\"editorial_board_management\",\"tenantterm\":\"editorial board management\",\"frontiersdefaultterm\":\"editorial board management\",\"category\":\"product\"},{\"sequencenumber\":22,\"key\":\"ebm\",\"tenantterm\":\"ebm\",\"frontiersdefaultterm\":\"ebm\",\"category\":\"product\"},{\"sequencenumber\":23,\"key\":\"domain\",\"tenantterm\":\"domain\",\"frontiersdefaultterm\":\"domain\",\"category\":\"taxonomy\"},{\"sequencenumber\":24,\"key\":\"journal\",\"tenantterm\":\"journal\",\"frontiersdefaultterm\":\"journal\",\"category\":\"taxonomy\"},{\"sequencenumber\":25,\"key\":\"section\",\"tenantterm\":\"section\",\"frontiersdefaultterm\":\"section\",\"category\":\"taxonomy\"},{\"sequencenumber\":26,\"key\":\"domains\",\"tenantterm\":\"domains\",\"frontiersdefaultterm\":\"domains\",\"category\":\"taxonomy\"},{\"sequencenumber\":27,\"key\":\"specialty_section\",\"tenantterm\":\"specialty section\",\"frontiersdefaultterm\":\"specialty section\",\"category\":\"taxonomy\"},{\"sequencenumber\":28,\"key\":\"specialty_journal\",\"tenantterm\":\"specialty journal\",\"frontiersdefaultterm\":\"specialty journal\",\"category\":\"taxonomy\"},{\"sequencenumber\":29,\"key\":\"journals\",\"tenantterm\":\"journals\",\"frontiersdefaultterm\":\"journals\",\"category\":\"taxonomy\"},{\"sequencenumber\":30,\"key\":\"sections\",\"tenantterm\":\"sections\",\"frontiersdefaultterm\":\"sections\",\"category\":\"taxonomy\"},{\"sequencenumber\":31,\"key\":\"specialty_sections\",\"tenantterm\":\"specialty sections\",\"frontiersdefaultterm\":\"specialty sections\",\"category\":\"taxonomy\"},{\"sequencenumber\":32,\"key\":\"specialty_journals\",\"tenantterm\":\"specialty journals\",\"frontiersdefaultterm\":\"specialty journals\",\"category\":\"taxonomy\"},{\"sequencenumber\":33,\"key\":\"manuscript\",\"tenantterm\":\"manuscript\",\"frontiersdefaultterm\":\"manuscript\",\"category\":\"core\"},{\"sequencenumber\":34,\"key\":\"manuscripts\",\"tenantterm\":\"manuscripts\",\"frontiersdefaultterm\":\"manuscripts\",\"category\":\"core\"},{\"sequencenumber\":35,\"key\":\"article\",\"tenantterm\":\"article\",\"frontiersdefaultterm\":\"article\",\"category\":\"core\"},{\"sequencenumber\":36,\"key\":\"articles\",\"tenantterm\":\"articles\",\"frontiersdefaultterm\":\"articles\",\"category\":\"core\"},{\"sequencenumber\":37,\"key\":\"article_type\",\"tenantterm\":\"article type\",\"frontiersdefaultterm\":\"article type\",\"category\":\"core\"},{\"sequencenumber\":38,\"key\":\"article_types\",\"tenantterm\":\"article types\",\"frontiersdefaultterm\":\"article types\",\"category\":\"core\"},{\"sequencenumber\":39,\"key\":\"author\",\"tenantterm\":\"author\",\"frontiersdefaultterm\":\"author\",\"category\":\"label (role)\"},{\"sequencenumber\":40,\"key\":\"authors\",\"tenantterm\":\"authors\",\"frontiersdefaultterm\":\"authors\",\"category\":\"label (role)\"},{\"sequencenumber\":41,\"key\":\"authoring\",\"tenantterm\":\"authoring\",\"frontiersdefaultterm\":\"authoring\",\"category\":\"core\"},{\"sequencenumber\":42,\"key\":\"authored\",\"tenantterm\":\"authored\",\"frontiersdefaultterm\":\"authored\",\"category\":\"core\"},{\"sequencenumber\":43,\"key\":\"accept\",\"tenantterm\":\"accept\",\"frontiersdefaultterm\":\"accept\",\"category\":\"process\"},{\"sequencenumber\":44,\"key\":\"accepted\",\"tenantterm\":\"accepted\",\"frontiersdefaultterm\":\"accepted\",\"category\":\"process\"},{\"sequencenumber\":45,\"key\":\"assistant_field_chief_editor\",\"tenantterm\":\"assistant field chief editor\",\"frontiersdefaultterm\":\"assistant field chief editor\",\"description\":\"an editorial role on a field journal that a registered user may hold. this gives them rights to different functionality and parts of the platform\",\"category\":\"label (role)\"},{\"sequencenumber\":46,\"key\":\"assistant_specialty_chief_editor\",\"tenantterm\":\"assistant specialty chief editor\",\"frontiersdefaultterm\":\"assistant specialty chief editor\",\"description\":\"an editorial role on a specialty that a registered user may hold. this gives them rights to different functionality and parts of the platform\",\"category\":\"label (role)\"},{\"sequencenumber\":47,\"key\":\"assistant_specialty_chief_editors\",\"tenantterm\":\"assistant specialty chief editors\",\"frontiersdefaultterm\":\"assistant specialty chief editors\",\"category\":\"label (role)\"},{\"sequencenumber\":48,\"key\":\"associate_editor\",\"tenantterm\":\"associate editor\",\"frontiersdefaultterm\":\"associate editor\",\"description\":\"an editorial role on a specialty that a registered user may hold. this gives them rights to different functionality and parts of the platform\",\"category\":\"label (role)\"},{\"sequencenumber\":49,\"key\":\"specialty_chief_editor\",\"tenantterm\":\"specialty chief editor\",\"frontiersdefaultterm\":\"specialty chief editor\",\"description\":\"an editorial role on a specialty that a registered user may hold. this gives them rights to different functionality and parts of the platform\",\"category\":\"label (role)\"},{\"sequencenumber\":50,\"key\":\"specialty_chief_editors\",\"tenantterm\":\"specialty chief editors\",\"frontiersdefaultterm\":\"specialty chief editors\",\"category\":\"label (role)\"},{\"sequencenumber\":51,\"key\":\"chief_editor\",\"tenantterm\":\"chief editor\",\"frontiersdefaultterm\":\"chief editor\",\"category\":\"label (role)\"},{\"sequencenumber\":52,\"key\":\"chief_editors\",\"tenantterm\":\"chief editors\",\"frontiersdefaultterm\":\"chief editors\",\"category\":\"label (role)\"},{\"sequencenumber\":53,\"key\":\"call_for_participation\",\"tenantterm\":\"call for participation\",\"frontiersdefaultterm\":\"call for participation\",\"category\":\"process\"},{\"sequencenumber\":54,\"key\":\"citation\",\"tenantterm\":\"citation\",\"frontiersdefaultterm\":\"citation\",\"category\":\"misc.\"},{\"sequencenumber\":55,\"key\":\"citations\",\"tenantterm\":\"citations\",\"frontiersdefaultterm\":\"citations\",\"category\":\"misc.\"},{\"sequencenumber\":56,\"key\":\"contributor\",\"tenantterm\":\"contributor\",\"frontiersdefaultterm\":\"contributor\",\"category\":\"label (role)\"},{\"sequencenumber\":57,\"key\":\"contributors\",\"tenantterm\":\"contributors\",\"frontiersdefaultterm\":\"contributors\",\"category\":\"label (role)\"},{\"sequencenumber\":58,\"key\":\"corresponding_author\",\"tenantterm\":\"corresponding author\",\"frontiersdefaultterm\":\"corresponding author\",\"category\":\"label (role)\"},{\"sequencenumber\":59,\"key\":\"corresponding_authors\",\"tenantterm\":\"corresponding authors\",\"frontiersdefaultterm\":\"corresponding authors\",\"category\":\"label (role)\"},{\"sequencenumber\":60,\"key\":\"decline\",\"tenantterm\":\"decline\",\"frontiersdefaultterm\":\"decline\",\"category\":\"process\"},{\"sequencenumber\":61,\"key\":\"declined\",\"tenantterm\":\"declined\",\"frontiersdefaultterm\":\"declined\",\"category\":\"process\"},{\"sequencenumber\":62,\"key\":\"reject\",\"tenantterm\":\"reject\",\"frontiersdefaultterm\":\"reject\",\"category\":\"process\"},{\"sequencenumber\":63,\"key\":\"rejected\",\"tenantterm\":\"rejected\",\"frontiersdefaultterm\":\"rejected\",\"category\":\"process\"},{\"sequencenumber\":64,\"key\":\"publish\",\"tenantterm\":\"publish\",\"frontiersdefaultterm\":\"publish\",\"category\":\"core\"},{\"sequencenumber\":65,\"key\":\"published\",\"tenantterm\":\"published\",\"frontiersdefaultterm\":\"published\",\"category\":\"core\"},{\"sequencenumber\":66,\"key\":\"publication\",\"tenantterm\":\"publication\",\"frontiersdefaultterm\":\"publication\",\"category\":\"core\"},{\"sequencenumber\":67,\"key\":\"peer_review\",\"tenantterm\":\"peer review\",\"frontiersdefaultterm\":\"peer review\",\"category\":\"peer review process\"},{\"sequencenumber\":68,\"key\":\"peer_reviewed\",\"tenantterm\":\"peer reviewed\",\"frontiersdefaultterm\":\"peer reviewed\",\"category\":\"peer review process\"},{\"sequencenumber\":69,\"key\":\"initial_validation\",\"tenantterm\":\"initial validation\",\"frontiersdefaultterm\":\"initial validation\",\"category\":\"peer review process\"},{\"sequencenumber\":70,\"key\":\"editorial_assignment\",\"tenantterm\":\"editorial assignment\",\"frontiersdefaultterm\":\"editorial assignment\",\"category\":\"peer review process\"},{\"sequencenumber\":71,\"key\":\"independent_review\",\"tenantterm\":\"independent review\",\"frontiersdefaultterm\":\"independent review\",\"category\":\"peer review process\"},{\"sequencenumber\":72,\"key\":\"interactive_review\",\"tenantterm\":\"interactive review\",\"frontiersdefaultterm\":\"interactive review\",\"category\":\"peer review process\"},{\"sequencenumber\":73,\"key\":\"review\",\"tenantterm\":\"review\",\"frontiersdefaultterm\":\"review\",\"category\":\"peer review process\"},{\"sequencenumber\":74,\"key\":\"reviewing\",\"tenantterm\":\"reviewing\",\"frontiersdefaultterm\":\"reviewing\",\"category\":\"peer review process\"},{\"sequencenumber\":75,\"key\":\"reviewer\",\"tenantterm\":\"reviewer\",\"frontiersdefaultterm\":\"reviewer\",\"category\":\"label (role)\"},{\"sequencenumber\":76,\"key\":\"reviewers\",\"tenantterm\":\"reviewers\",\"frontiersdefaultterm\":\"reviewers\",\"category\":\"label (role)\"},{\"sequencenumber\":77,\"key\":\"review_finalized\",\"tenantterm\":\"review finalized\",\"frontiersdefaultterm\":\"review finalized\",\"category\":\"peer review process\"},{\"sequencenumber\":78,\"key\":\"final_decision\",\"tenantterm\":\"final decision\",\"frontiersdefaultterm\":\"final decision\",\"category\":\"peer review process\"},{\"sequencenumber\":79,\"key\":\"final_validation\",\"tenantterm\":\"final validation\",\"frontiersdefaultterm\":\"final validation\",\"category\":\"peer review process\"},{\"sequencenumber\":80,\"key\":\"ae_accept_manuscript\",\"tenantterm\":\"recommend to accept manuscript\",\"frontiersdefaultterm\":\"accept manuscript\",\"category\":\"process\"},{\"sequencenumber\":81,\"key\":\"fee\",\"tenantterm\":\"fee\",\"frontiersdefaultterm\":\"fee\",\"category\":\"accounting\"},{\"sequencenumber\":82,\"key\":\"fees\",\"tenantterm\":\"fees\",\"frontiersdefaultterm\":\"fees\",\"category\":\"accounting\"},{\"sequencenumber\":83,\"key\":\"guest_associate_editor\",\"tenantterm\":\"guest associate editor\",\"frontiersdefaultterm\":\"guest associate editor\",\"category\":\"label (role)\"},{\"sequencenumber\":84,\"key\":\"guest_associate_editors\",\"tenantterm\":\"guest associate editors\",\"frontiersdefaultterm\":\"guest associate editors\",\"category\":\"label (role)\"},{\"sequencenumber\":85,\"key\":\"in_review\",\"tenantterm\":\"in review\",\"frontiersdefaultterm\":\"in review\",\"category\":\"peer review process\"},{\"sequencenumber\":86,\"key\":\"institutional_member\",\"tenantterm\":\"institutional partner\",\"frontiersdefaultterm\":\"institutional partner\",\"category\":\"accounting\"},{\"sequencenumber\":87,\"key\":\"institutional_membership\",\"tenantterm\":\"institutional partnership\",\"frontiersdefaultterm\":\"institutional partnership\",\"category\":\"accounting\"},{\"sequencenumber\":88,\"key\":\"article_processing_charge\",\"tenantterm\":\"article processing charge\",\"frontiersdefaultterm\":\"article processing charge\",\"category\":\"accounting\"},{\"sequencenumber\":89,\"key\":\"article_processing_charges\",\"tenantterm\":\"article processing charges\",\"frontiersdefaultterm\":\"article processing charges\",\"category\":\"accounting\"},{\"sequencenumber\":90,\"key\":\"apcs\",\"tenantterm\":\"apcs\",\"frontiersdefaultterm\":\"apcs\",\"category\":\"accounting\"},{\"sequencenumber\":91,\"key\":\"apc\",\"tenantterm\":\"apc\",\"frontiersdefaultterm\":\"apc\",\"category\":\"accounting\"},{\"sequencenumber\":92,\"key\":\"received\",\"tenantterm\":\"received\",\"frontiersdefaultterm\":\"received\",\"description\":\"date manuscript was received on.\",\"category\":\"core\"},{\"sequencenumber\":93,\"key\":\"transferred\",\"tenantterm\":\"transferred\",\"frontiersdefaultterm\":\"transferred\",\"category\":\"core\"},{\"sequencenumber\":94,\"key\":\"transfer\",\"tenantterm\":\"transfer\",\"frontiersdefaultterm\":\"transfer\",\"category\":\"core\"},{\"sequencenumber\":95,\"key\":\"research_topic\",\"tenantterm\":\"research topic\",\"frontiersdefaultterm\":\"research topic\",\"category\":\"core\"},{\"sequencenumber\":96,\"key\":\"research_topics\",\"tenantterm\":\"research topics\",\"frontiersdefaultterm\":\"research topics\",\"category\":\"core\"},{\"sequencenumber\":97,\"key\":\"topic_editor\",\"tenantterm\":\"topic editor\",\"frontiersdefaultterm\":\"topic editor\",\"category\":\"label (role)\"},{\"sequencenumber\":98,\"key\":\"review_editor\",\"tenantterm\":\"community reviewer\",\"frontiersdefaultterm\":\"review editor\",\"category\":\"label (role)\"},{\"sequencenumber\":99,\"key\":\"title\",\"tenantterm\":\"title\",\"frontiersdefaultterm\":\"title\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":100,\"key\":\"running_title\",\"tenantterm\":\"running title\",\"frontiersdefaultterm\":\"running title\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":101,\"key\":\"submit\",\"tenantterm\":\"submit\",\"frontiersdefaultterm\":\"submit\",\"category\":\"process\"},{\"sequencenumber\":102,\"key\":\"submitted\",\"tenantterm\":\"submitted\",\"frontiersdefaultterm\":\"submitted\",\"category\":\"process\"},{\"sequencenumber\":103,\"key\":\"submitting\",\"tenantterm\":\"submitting\",\"frontiersdefaultterm\":\"submitting\",\"category\":\"process\"},{\"sequencenumber\":104,\"key\":\"t_e\",\"tenantterm\":\"te\",\"frontiersdefaultterm\":\"te\",\"category\":\"label (role)\"},{\"sequencenumber\":105,\"key\":\"topic\",\"tenantterm\":\"topic\",\"frontiersdefaultterm\":\"topic\",\"category\":\"process\"},{\"sequencenumber\":106,\"key\":\"topic_summary\",\"tenantterm\":\"topic summary\",\"frontiersdefaultterm\":\"topic summary\",\"category\":\"process\"},{\"sequencenumber\":107,\"key\":\"figure\",\"tenantterm\":\"figure\",\"frontiersdefaultterm\":\"figure\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":108,\"key\":\"figures\",\"tenantterm\":\"figures\",\"frontiersdefaultterm\":\"figures\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":109,\"key\":\"editorial_file\",\"tenantterm\":\"editorial file\",\"frontiersdefaultterm\":\"editorial file\",\"category\":\"core\"},{\"sequencenumber\":110,\"key\":\"editorial_files\",\"tenantterm\":\"editorial files\",\"frontiersdefaultterm\":\"editorial files\",\"category\":\"core\"},{\"sequencenumber\":111,\"key\":\"e_book\",\"tenantterm\":\"e-book\",\"frontiersdefaultterm\":\"e-book\",\"category\":\"core\"},{\"sequencenumber\":112,\"key\":\"organization\",\"tenantterm\":\"organization\",\"frontiersdefaultterm\":\"organization\",\"category\":\"core\"},{\"sequencenumber\":113,\"key\":\"institution\",\"tenantterm\":\"institution\",\"frontiersdefaultterm\":\"institution\",\"category\":\"core\"},{\"sequencenumber\":114,\"key\":\"reference\",\"tenantterm\":\"reference\",\"frontiersdefaultterm\":\"reference\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":115,\"key\":\"references\",\"tenantterm\":\"references\",\"frontiersdefaultterm\":\"references\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":116,\"key\":\"sce\",\"tenantterm\":\"sce\",\"frontiersdefaultterm\":\"sce\",\"description\":\"abbreviation for specialty chief editor\",\"category\":\"label (role)\"},{\"sequencenumber\":117,\"key\":\"submission\",\"tenantterm\":\"submission\",\"frontiersdefaultterm\":\"submission\",\"category\":\"process\"},{\"sequencenumber\":118,\"key\":\"submissions\",\"tenantterm\":\"submissions\",\"frontiersdefaultterm\":\"submissions\",\"category\":\"process\"},{\"sequencenumber\":119,\"key\":\"editing\",\"tenantterm\":\"editing\",\"frontiersdefaultterm\":\"editing\",\"category\":\"process\"},{\"sequencenumber\":120,\"key\":\"in_preparation\",\"tenantterm\":\"in preparation\",\"frontiersdefaultterm\":\"in preparation\",\"category\":\"process\"},{\"sequencenumber\":121,\"key\":\"country_region\",\"tenantterm\":\"country/region\",\"frontiersdefaultterm\":\"country/region\",\"description\":\"because of political issues, some of the country listings are actually classified as `regions` and we need to include this. however other clients may not want to do this.\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":122,\"key\":\"countries_regions\",\"tenantterm\":\"countries/regions\",\"frontiersdefaultterm\":\"countries/regions\",\"description\":\"because of political issues, some of the country listings are actually classified as `regions` and we need to include this. however other clients may not want to do this.\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":123,\"key\":\"specialty\",\"tenantterm\":\"specialty\",\"frontiersdefaultterm\":\"specialty\",\"category\":\"core\"},{\"sequencenumber\":124,\"key\":\"specialties\",\"tenantterm\":\"specialties\",\"frontiersdefaultterm\":\"specialties\",\"category\":\"core\"},{\"sequencenumber\":125,\"key\":\"associate_editors\",\"tenantterm\":\"associate editors\",\"frontiersdefaultterm\":\"associate editors\",\"description\":\"an editorial role on a specialty that a registered user may hold. this gives them rights to different functionality and parts of the platform\",\"category\":\"label (role)\"},{\"sequencenumber\":126,\"key\":\"reviewed\",\"tenantterm\":\"reviewed\",\"frontiersdefaultterm\":\"reviewed\",\"category\":\"peer review process\"},{\"sequencenumber\":127,\"key\":\"institutional_members\",\"tenantterm\":\"institutional partners\",\"frontiersdefaultterm\":\"institutional partners\",\"category\":\"accounting\"},{\"sequencenumber\":128,\"key\":\"institutional_memberships\",\"tenantterm\":\"institutional partnerships\",\"frontiersdefaultterm\":\"institutional partnerships\",\"category\":\"accounting\"},{\"sequencenumber\":129,\"key\":\"assistant_field_chief_editors\",\"tenantterm\":\"assistant field chief editors\",\"frontiersdefaultterm\":\"assistant field chief editors\",\"category\":\"label (role)\"},{\"sequencenumber\":130,\"key\":\"publications\",\"tenantterm\":\"publications\",\"frontiersdefaultterm\":\"publications\",\"category\":\"process\"},{\"sequencenumber\":131,\"key\":\"ae_accepted\",\"tenantterm\":\"recommended acceptance\",\"frontiersdefaultterm\":\"accepted\",\"category\":\"process\"},{\"sequencenumber\":132,\"key\":\"field_journal\",\"tenantterm\":\"field journal\",\"frontiersdefaultterm\":\"field journal\",\"category\":\"taxonomy\"},{\"sequencenumber\":133,\"key\":\"field_journals\",\"tenantterm\":\"field journals\",\"frontiersdefaultterm\":\"field journals\",\"category\":\"taxonomy\"},{\"sequencenumber\":134,\"key\":\"program_manager\",\"tenantterm\":\"program manager\",\"frontiersdefaultterm\":\"program manager\",\"category\":\"label (role)\"},{\"sequencenumber\":135,\"key\":\"journal_manager\",\"tenantterm\":\"journal manager\",\"frontiersdefaultterm\":\"journal manager\",\"category\":\"label (role)\"},{\"sequencenumber\":136,\"key\":\"journal_specialist\",\"tenantterm\":\"journal specialist\",\"frontiersdefaultterm\":\"journal specialist\",\"category\":\"label (role)\"},{\"sequencenumber\":137,\"key\":\"program_managers\",\"tenantterm\":\"program managers\",\"frontiersdefaultterm\":\"program managers\",\"category\":\"label (role)\"},{\"sequencenumber\":138,\"key\":\"journal_managers\",\"tenantterm\":\"journal managers\",\"frontiersdefaultterm\":\"journal managers\",\"category\":\"label (role)\"},{\"sequencenumber\":139,\"key\":\"journal_specialists\",\"tenantterm\":\"journal specialists\",\"frontiersdefaultterm\":\"journal specialists\",\"category\":\"label (role)\"},{\"sequencenumber\":140,\"key\":\"cover_letter\",\"tenantterm\":\"manuscript contribution to the field\",\"frontiersdefaultterm\":\"manuscript contribution to the field\",\"category\":\"process\"},{\"sequencenumber\":141,\"key\":\"ae_accepted_manuscript\",\"tenantterm\":\"recommended to accept manuscript\",\"frontiersdefaultterm\":\"accepted manuscript\",\"category\":\"process\"},{\"sequencenumber\":142,\"key\":\"recommend_for_rejection\",\"tenantterm\":\"recommend for rejection\",\"frontiersdefaultterm\":\"recommend for rejection\",\"category\":\"process\"},{\"sequencenumber\":143,\"key\":\"recommended_for_rejection\",\"tenantterm\":\"recommended for rejection\",\"frontiersdefaultterm\":\"recommended for rejection\",\"category\":\"process\"},{\"sequencenumber\":144,\"key\":\"ae\",\"tenantterm\":\"ae\",\"frontiersdefaultterm\":\"ae\",\"description\":\"associate editor - board member\",\"category\":\"label (role)\"},{\"sequencenumber\":145,\"key\":\"re\",\"tenantterm\":\"re\",\"frontiersdefaultterm\":\"re\",\"description\":\"review editor\",\"category\":\"label (role)\"},{\"sequencenumber\":146,\"key\":\"rev\",\"tenantterm\":\"rev\",\"frontiersdefaultterm\":\"rev\",\"description\":\"reviewer\",\"category\":\"label (role)\"},{\"sequencenumber\":147,\"key\":\"aut\",\"tenantterm\":\"aut\",\"frontiersdefaultterm\":\"aut\",\"description\":\"author\",\"category\":\"label (role)\"},{\"sequencenumber\":148,\"key\":\"coraut\",\"tenantterm\":\"coraut\",\"frontiersdefaultterm\":\"coraut\",\"description\":\"corresponding author\",\"category\":\"label (role)\"},{\"sequencenumber\":149,\"key\":\"saut\",\"tenantterm\":\"saut\",\"frontiersdefaultterm\":\"saut\",\"description\":\"submitting author\",\"category\":\"label (role)\"},{\"sequencenumber\":150,\"key\":\"coaut\",\"tenantterm\":\"coaut\",\"frontiersdefaultterm\":\"coaut\",\"description\":\"co-author\",\"category\":\"label (role)\"},{\"sequencenumber\":151,\"key\":\"tsof\",\"tenantterm\":\"tsof\",\"frontiersdefaultterm\":\"tsof\",\"description\":\"typesetter\",\"category\":\"label (role)\"},{\"sequencenumber\":152,\"key\":\"typesetting_office\",\"tenantterm\":\"typesetting office\",\"frontiersdefaultterm\":\"typesetting office\",\"category\":\"product\"},{\"sequencenumber\":153,\"key\":\"config\",\"tenantterm\":\"config\",\"frontiersdefaultterm\":\"config\",\"description\":\"configuration office role\",\"category\":\"label (role)\"},{\"sequencenumber\":154,\"key\":\"jm\",\"tenantterm\":\"jm\",\"frontiersdefaultterm\":\"jm\",\"description\":\"journal manager\",\"category\":\"label (role)\"},{\"sequencenumber\":155,\"key\":\"rte\",\"tenantterm\":\"rte\",\"frontiersdefaultterm\":\"rte\",\"description\":\"research topic editor\",\"category\":\"label (role)\"},{\"sequencenumber\":156,\"key\":\"organizations\",\"tenantterm\":\"organizations\",\"frontiersdefaultterm\":\"organizations\",\"category\":\"core\"},{\"sequencenumber\":157,\"key\":\"publishing\",\"tenantterm\":\"publishing\",\"frontiersdefaultterm\":\"publishing\",\"category\":\"core\"},{\"sequencenumber\":158,\"key\":\"acceptance\",\"tenantterm\":\"acceptance\",\"frontiersdefaultterm\":\"acceptance\",\"category\":\"process\"},{\"sequencenumber\":159,\"key\":\"preferred_associate_editor\",\"tenantterm\":\"preferred associate editor\",\"frontiersdefaultterm\":\"preferred associate editor\",\"category\":\"label (role)\"},{\"sequencenumber\":160,\"key\":\"topic_editors\",\"tenantterm\":\"topic editors\",\"frontiersdefaultterm\":\"topic editors\",\"category\":\"label (role)\"},{\"sequencenumber\":161,\"key\":\"institutions\",\"tenantterm\":\"institutions\",\"frontiersdefaultterm\":\"institutions\",\"category\":\"core\"},{\"sequencenumber\":162,\"key\":\"author(s)\",\"tenantterm\":\"author(s)\",\"frontiersdefaultterm\":\"author(s)\",\"category\":\"label (role)\"},{\"sequencenumber\":163,\"key\":\"figure(s)\",\"tenantterm\":\"figure(s)\",\"frontiersdefaultterm\":\"figure(s)\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":164,\"key\":\"co-authors\",\"tenantterm\":\"co-authors\",\"frontiersdefaultterm\":\"co-authors\",\"description\":\"co-authors\",\"category\":\"label (role)\"},{\"sequencenumber\":165,\"key\":\"editorial_board_members\",\"tenantterm\":\"editorial board members\",\"frontiersdefaultterm\":\"editorial board members\",\"description\":\"editorial board members\",\"category\":\"label (role)\"},{\"sequencenumber\":166,\"key\":\"editorial_board\",\"tenantterm\":\"editorial board\",\"frontiersdefaultterm\":\"editorial board\",\"description\":\"editorial board\",\"category\":\"product\"},{\"sequencenumber\":167,\"key\":\"co-authorship\",\"tenantterm\":\"co-authorship\",\"frontiersdefaultterm\":\"co-authorship\",\"description\":\"co-authorship\",\"category\":\"misc.\"},{\"sequencenumber\":168,\"key\":\"role_id_1\",\"tenantterm\":\"registration office\",\"frontiersdefaultterm\":\"registration office\",\"category\":\"user role\"},{\"sequencenumber\":169,\"key\":\"role_id_2\",\"tenantterm\":\"editorial office\",\"frontiersdefaultterm\":\"editorial office\",\"category\":\"user role\"},{\"sequencenumber\":170,\"key\":\"role_id_7\",\"tenantterm\":\"field chief editor\",\"frontiersdefaultterm\":\"field chief editor\",\"category\":\"user role\"},{\"sequencenumber\":171,\"key\":\"role_id_8\",\"tenantterm\":\"assistant field chief editor\",\"frontiersdefaultterm\":\"assistant field chief editor\",\"category\":\"user role\"},{\"sequencenumber\":172,\"key\":\"role_id_9\",\"tenantterm\":\"specialty chief editor\",\"frontiersdefaultterm\":\"specialty chief editor\",\"category\":\"user role\"},{\"sequencenumber\":173,\"key\":\"role_id_10\",\"tenantterm\":\"assistant specialty chief editor\",\"frontiersdefaultterm\":\"assistant specialty chief editor\",\"category\":\"user role\"},{\"sequencenumber\":174,\"key\":\"role_id_11\",\"tenantterm\":\"associate editor\",\"frontiersdefaultterm\":\"associate editor\",\"category\":\"user role\"},{\"sequencenumber\":175,\"key\":\"role_id_12\",\"tenantterm\":\"guest associate editor\",\"frontiersdefaultterm\":\"guest associate editor\",\"category\":\"user role\"},{\"sequencenumber\":176,\"key\":\"role_id_13\",\"tenantterm\":\"review editor\",\"frontiersdefaultterm\":\"review editor\",\"category\":\"user role\"},{\"sequencenumber\":177,\"key\":\"role_id_14\",\"tenantterm\":\"reviewer\",\"frontiersdefaultterm\":\"reviewer\",\"category\":\"user role\"},{\"sequencenumber\":178,\"key\":\"role_id_15\",\"tenantterm\":\"author\",\"frontiersdefaultterm\":\"author\",\"category\":\"user role\"},{\"sequencenumber\":179,\"key\":\"role_id_16\",\"tenantterm\":\"corresponding author\",\"frontiersdefaultterm\":\"corresponding author\",\"category\":\"user role\"},{\"sequencenumber\":180,\"key\":\"role_id_17\",\"tenantterm\":\"submitting author\",\"frontiersdefaultterm\":\"submitting author\",\"category\":\"user role\"},{\"sequencenumber\":181,\"key\":\"role_id_18\",\"tenantterm\":\"co-author\",\"frontiersdefaultterm\":\"co-author\",\"category\":\"user role\"},{\"sequencenumber\":182,\"key\":\"role_id_20\",\"tenantterm\":\"production office\",\"frontiersdefaultterm\":\"production office\",\"category\":\"user role\"},{\"sequencenumber\":183,\"key\":\"role_id_22\",\"tenantterm\":\"typesetting office (typesetter)\",\"frontiersdefaultterm\":\"typesetting office (typesetter)\",\"category\":\"user role\"},{\"sequencenumber\":184,\"key\":\"role_id_24\",\"tenantterm\":\"registered user\",\"frontiersdefaultterm\":\"registered user\",\"category\":\"user role\"},{\"sequencenumber\":185,\"key\":\"role_id_35\",\"tenantterm\":\"job office\",\"frontiersdefaultterm\":\"job office\",\"category\":\"user role\"},{\"sequencenumber\":186,\"key\":\"role_id_41\",\"tenantterm\":\"special event administrator\",\"frontiersdefaultterm\":\"special event administrator\",\"category\":\"user role\"},{\"sequencenumber\":187,\"key\":\"role_id_42\",\"tenantterm\":\"special event reviewer\",\"frontiersdefaultterm\":\"special event reviewer\",\"category\":\"user role\"},{\"sequencenumber\":188,\"key\":\"role_id_43\",\"tenantterm\":\"submit abstract\",\"frontiersdefaultterm\":\"submit abstract\",\"category\":\"user role\"},{\"sequencenumber\":189,\"key\":\"role_id_52\",\"tenantterm\":\"events office\",\"frontiersdefaultterm\":\"events office\",\"category\":\"user role\"},{\"sequencenumber\":190,\"key\":\"role_id_53\",\"tenantterm\":\"event administrator\",\"frontiersdefaultterm\":\"event administrator\",\"category\":\"user role\"},{\"sequencenumber\":191,\"key\":\"role_id_89\",\"tenantterm\":\"content management office\",\"frontiersdefaultterm\":\"content management office\",\"category\":\"user role\"},{\"sequencenumber\":192,\"key\":\"role_id_98\",\"tenantterm\":\"accounting office\",\"frontiersdefaultterm\":\"accounting office\",\"category\":\"user role\"},{\"sequencenumber\":193,\"key\":\"role_id_99\",\"tenantterm\":\"projects\",\"frontiersdefaultterm\":\"projects\",\"category\":\"user role\"},{\"sequencenumber\":194,\"key\":\"role_id_103\",\"tenantterm\":\"configuration office\",\"frontiersdefaultterm\":\"configuration office\",\"category\":\"user role\"},{\"sequencenumber\":195,\"key\":\"role_id_104\",\"tenantterm\":\"beta user\",\"frontiersdefaultterm\":\"beta user\",\"category\":\"user role\"},{\"sequencenumber\":196,\"key\":\"role_id_106\",\"tenantterm\":\"wfconf\",\"frontiersdefaultterm\":\"wfconf\",\"category\":\"user role\"},{\"sequencenumber\":197,\"key\":\"role_id_107\",\"tenantterm\":\"rt management beta user\",\"frontiersdefaultterm\":\"rt management beta user\",\"category\":\"user role\"},{\"sequencenumber\":198,\"key\":\"role_id_108\",\"tenantterm\":\"deo beta user\",\"frontiersdefaultterm\":\"deo beta user\",\"category\":\"user role\"},{\"sequencenumber\":199,\"key\":\"role_id_109\",\"tenantterm\":\"search beta user\",\"frontiersdefaultterm\":\"search beta user\",\"category\":\"user role\"},{\"sequencenumber\":200,\"key\":\"role_id_110\",\"tenantterm\":\"journal manager\",\"frontiersdefaultterm\":\"journal manager\",\"category\":\"user role\"},{\"sequencenumber\":201,\"key\":\"role_id_111\",\"tenantterm\":\"myfrontiers beta user\",\"frontiersdefaultterm\":\"myfrontiers beta user\",\"category\":\"user role\"},{\"sequencenumber\":202,\"key\":\"role_id_21\",\"tenantterm\":\"copy editor\",\"frontiersdefaultterm\":\"copy editor\",\"category\":\"user role\"},{\"sequencenumber\":203,\"key\":\"role_id_1_abr\",\"tenantterm\":\"rof\",\"frontiersdefaultterm\":\"rof\",\"category\":\"user role\"},{\"sequencenumber\":204,\"key\":\"role_id_2_abr\",\"tenantterm\":\"eof\",\"frontiersdefaultterm\":\"eof\",\"category\":\"user role\"},{\"sequencenumber\":205,\"key\":\"role_id_7_abr\",\"tenantterm\":\"fce\",\"frontiersdefaultterm\":\"fce\",\"category\":\"user role\"},{\"sequencenumber\":206,\"key\":\"role_id_8_abr\",\"tenantterm\":\"afce\",\"frontiersdefaultterm\":\"afce\",\"category\":\"user role\"},{\"sequencenumber\":207,\"key\":\"role_id_9_abr\",\"tenantterm\":\"sce\",\"frontiersdefaultterm\":\"sce\",\"category\":\"user role\"},{\"sequencenumber\":208,\"key\":\"role_id_10_abr\",\"tenantterm\":\"asce\",\"frontiersdefaultterm\":\"asce\",\"category\":\"user role\"},{\"sequencenumber\":209,\"key\":\"role_id_11_abr\",\"tenantterm\":\"ae\",\"frontiersdefaultterm\":\"ae\",\"category\":\"user role\"},{\"sequencenumber\":210,\"key\":\"role_id_12_abr\",\"tenantterm\":\"gae\",\"frontiersdefaultterm\":\"gae\",\"category\":\"user role\"},{\"sequencenumber\":211,\"key\":\"role_id_13_abr\",\"tenantterm\":\"re\",\"frontiersdefaultterm\":\"re\",\"category\":\"user role\"},{\"sequencenumber\":212,\"key\":\"role_id_14_abr\",\"tenantterm\":\"rev\",\"frontiersdefaultterm\":\"rev\",\"category\":\"user role\"},{\"sequencenumber\":213,\"key\":\"role_id_15_abr\",\"tenantterm\":\"aut\",\"frontiersdefaultterm\":\"aut\",\"category\":\"user role\"},{\"sequencenumber\":214,\"key\":\"role_id_16_abr\",\"tenantterm\":\"coraut\",\"frontiersdefaultterm\":\"coraut\",\"category\":\"user role\"},{\"sequencenumber\":215,\"key\":\"role_id_17_abr\",\"tenantterm\":\"saut\",\"frontiersdefaultterm\":\"saut\",\"category\":\"user role\"},{\"sequencenumber\":216,\"key\":\"role_id_18_abr\",\"tenantterm\":\"coaut\",\"frontiersdefaultterm\":\"coaut\",\"category\":\"user role\"},{\"sequencenumber\":217,\"key\":\"role_id_20_abr\",\"tenantterm\":\"pof\",\"frontiersdefaultterm\":\"pof\",\"category\":\"user role\"},{\"sequencenumber\":218,\"key\":\"role_id_22_abr\",\"tenantterm\":\"tsof\",\"frontiersdefaultterm\":\"tsof\",\"category\":\"user role\"},{\"sequencenumber\":219,\"key\":\"role_id_24_abr\",\"tenantterm\":\"ru\",\"frontiersdefaultterm\":\"ru\",\"category\":\"user role\"},{\"sequencenumber\":220,\"key\":\"role_id_35_abr\",\"tenantterm\":\"jof\",\"frontiersdefaultterm\":\"jof\",\"category\":\"user role\"},{\"sequencenumber\":221,\"key\":\"role_id_41_abr\",\"tenantterm\":\"se-adm\",\"frontiersdefaultterm\":\"se-adm\",\"category\":\"user role\"},{\"sequencenumber\":222,\"key\":\"role_id_42_abr\",\"tenantterm\":\"se-rev\",\"frontiersdefaultterm\":\"se-rev\",\"category\":\"user role\"},{\"sequencenumber\":223,\"key\":\"role_id_43_abr\",\"tenantterm\":\"se-aut\",\"frontiersdefaultterm\":\"se-aut\",\"category\":\"user role\"},{\"sequencenumber\":224,\"key\":\"role_id_52_abr\",\"tenantterm\":\"evof\",\"frontiersdefaultterm\":\"evof\",\"category\":\"user role\"},{\"sequencenumber\":225,\"key\":\"role_id_53_abr\",\"tenantterm\":\"ev-adm\",\"frontiersdefaultterm\":\"ev-adm\",\"category\":\"user role\"},{\"sequencenumber\":226,\"key\":\"role_id_89_abr\",\"tenantterm\":\"comof\",\"frontiersdefaultterm\":\"comof\",\"category\":\"user role\"},{\"sequencenumber\":227,\"key\":\"role_id_98_abr\",\"tenantterm\":\"aof\",\"frontiersdefaultterm\":\"aof\",\"category\":\"user role\"},{\"sequencenumber\":228,\"key\":\"role_id_99_abr\",\"tenantterm\":\"projects\",\"frontiersdefaultterm\":\"projects\",\"category\":\"user role\"},{\"sequencenumber\":229,\"key\":\"role_id_103_abr\",\"tenantterm\":\"config\",\"frontiersdefaultterm\":\"config\",\"category\":\"user role\"},{\"sequencenumber\":230,\"key\":\"role_id_104_abr\",\"tenantterm\":\"beta\",\"frontiersdefaultterm\":\"beta\",\"category\":\"user role\"},{\"sequencenumber\":231,\"key\":\"role_id_106_abr\",\"tenantterm\":\"wfconf\",\"frontiersdefaultterm\":\"wfconf\",\"category\":\"user role\"},{\"sequencenumber\":232,\"key\":\"role_id_107_abr\",\"tenantterm\":\"rtbeta\",\"frontiersdefaultterm\":\"rtbeta\",\"category\":\"user role\"},{\"sequencenumber\":233,\"key\":\"role_id_108_abr\",\"tenantterm\":\"deobeta\",\"frontiersdefaultterm\":\"deobeta\",\"category\":\"user role\"},{\"sequencenumber\":234,\"key\":\"role_id_109_abr\",\"tenantterm\":\"searchbeta\",\"frontiersdefaultterm\":\"searchbeta\",\"category\":\"user role\"},{\"sequencenumber\":235,\"key\":\"role_id_110_abr\",\"tenantterm\":\"jm\",\"frontiersdefaultterm\":\"jm\",\"category\":\"user role\"},{\"sequencenumber\":236,\"key\":\"role_id_111_abr\",\"tenantterm\":\"mfbeta\",\"frontiersdefaultterm\":\"mfbeta\",\"category\":\"user role\"},{\"sequencenumber\":237,\"key\":\"role_id_21_abr\",\"tenantterm\":\"coped\",\"frontiersdefaultterm\":\"coped\",\"category\":\"user role\"},{\"sequencenumber\":238,\"key\":\"reviewer_editorial_board\",\"tenantterm\":\"editorial board\",\"frontiersdefaultterm\":\"editorial board\",\"description\":\"this is the label for the review editorial board\",\"category\":\"label\"},{\"sequencenumber\":239,\"key\":\"field_chief_editor\",\"tenantterm\":\"field chief editor\",\"frontiersdefaultterm\":\"field chief editor\",\"category\":\"label (role)\"},{\"sequencenumber\":240,\"key\":\"field_chief_editors\",\"tenantterm\":\"field chief editors\",\"frontiersdefaultterm\":\"field chief editors\",\"category\":\"label (role)\"},{\"sequencenumber\":241,\"key\":\"editor\",\"tenantterm\":\"editor\",\"frontiersdefaultterm\":\"editor\",\"category\":\"label (role)\"},{\"sequencenumber\":242,\"key\":\"editors\",\"tenantterm\":\"editors\",\"frontiersdefaultterm\":\"editors\",\"category\":\"label (role)\"},{\"sequencenumber\":243,\"key\":\"board\",\"tenantterm\":\"board\",\"frontiersdefaultterm\":\"board\",\"category\":\"label\"},{\"sequencenumber\":244,\"key\":\"boards\",\"tenantterm\":\"boards\",\"frontiersdefaultterm\":\"boards\",\"category\":\"label\"},{\"sequencenumber\":245,\"key\":\"article_collection\",\"tenantterm\":\"article collection\",\"frontiersdefaultterm\":\"article collection\",\"category\":\"label\"},{\"sequencenumber\":246,\"key\":\"article_collections\",\"tenantterm\":\"article collections\",\"frontiersdefaultterm\":\"article collections\",\"category\":\"label\"},{\"sequencenumber\":247,\"key\":\"handling_editor\",\"tenantterm\":\"handling editor\",\"frontiersdefaultterm\":\"associate editor\",\"description\":\"this terminology key is for the person assigned to edit a manuscript. it is a label for the temporary handling editor assignment.\",\"category\":\"label (role)\"},{\"sequencenumber\":248,\"key\":\"handling_editors\",\"tenantterm\":\"handling editors\",\"frontiersdefaultterm\":\"associate editors\",\"description\":\"this terminology key is for the person assigned to edit a manuscript. it is a label for the temporary handling editor assignment.\",\"category\":\"label (role)\"},{\"sequencenumber\":249,\"key\":\"ae_accept\",\"tenantterm\":\"recommend acceptance\",\"frontiersdefaultterm\":\"accept\",\"category\":\"process\"},{\"sequencenumber\":250,\"key\":\"rtm\",\"tenantterm\":\"rtm\",\"frontiersdefaultterm\":\"rtm\",\"category\":\"product\"},{\"sequencenumber\":251,\"key\":\"frontiers_media_sa\",\"tenantterm\":\"frontiers media s.a\",\"frontiersdefaultterm\":\"frontiers media s.a\",\"category\":\"customer\"},{\"sequencenumber\":252,\"key\":\"review_editors\",\"tenantterm\":\"community reviewers\",\"frontiersdefaultterm\":\"review editors\",\"category\":\"label (role)\"},{\"sequencenumber\":253,\"key\":\"journal_card_chief_editor\",\"tenantterm\":\"chief editor\",\"frontiersdefaultterm\":\"chief editor\",\"category\":\"label (role)\"},{\"sequencenumber\":254,\"key\":\"journal_card_chief_editors\",\"tenantterm\":\"chief editors\",\"frontiersdefaultterm\":\"chief editors\",\"category\":\"label (role)\"},{\"sequencenumber\":255,\"key\":\"call_for_papers\",\"tenantterm\":\"call for papers\",\"frontiersdefaultterm\":\"call for papers\",\"category\":\"label\"},{\"sequencenumber\":256,\"key\":\"calls_for_papers\",\"tenantterm\":\"calls for papers\",\"frontiersdefaultterm\":\"calls for papers\",\"category\":\"label\"},{\"sequencenumber\":257,\"key\":\"supervising_editor\",\"tenantterm\":\"supervising editor\",\"frontiersdefaultterm\":\"supervising editor\",\"description\":\"a chief or assistant chief editor who is assigned to a manuscript to supervise.\",\"category\":\"role\",\"externalkey\":\"supervising_editor\"},{\"sequencenumber\":258,\"key\":\"supervising_editors\",\"tenantterm\":\"supervising editors\",\"frontiersdefaultterm\":\"supervising editors\",\"description\":\"a chief or assistant chief editor who is assigned to a manuscript to supervise.\",\"category\":\"role\",\"externalkey\":\"supervising_editors\"},{\"sequencenumber\":259,\"key\":\"reviewer_endorse\",\"tenantterm\":\"endorse\",\"frontiersdefaultterm\":\"endorse\",\"category\":\"label\"},{\"sequencenumber\":260,\"key\":\"reviewer_endorsed\",\"tenantterm\":\"endorsed\",\"frontiersdefaultterm\":\"endorsed\",\"category\":\"label\"},{\"sequencenumber\":261,\"key\":\"reviewer_endorse_publication\",\"tenantterm\":\"endorse publication\",\"frontiersdefaultterm\":\"endorse publication\",\"category\":\"label\"},{\"sequencenumber\":262,\"key\":\"reviewer_endorsed_publication\",\"tenantterm\":\"endorsed publication\",\"frontiersdefaultterm\":\"endorsed publication\",\"category\":\"label\"},{\"sequencenumber\":263,\"key\":\"editor_role\",\"tenantterm\":\"editor role\",\"frontiersdefaultterm\":\"editor role\",\"category\":\"label\"},{\"sequencenumber\":264,\"key\":\"editor_roles\",\"tenantterm\":\"editor roles\",\"frontiersdefaultterm\":\"editor roles\",\"category\":\"label\"},{\"sequencenumber\":265,\"key\":\"editorial_role\",\"tenantterm\":\"editorial role\",\"frontiersdefaultterm\":\"editorial role\",\"category\":\"label\"},{\"sequencenumber\":266,\"key\":\"editorial_roles\",\"tenantterm\":\"editorial roles\",\"frontiersdefaultterm\":\"editorial roles\",\"category\":\"label\"},{\"sequencenumber\":267,\"key\":\"call_for_paper\",\"tenantterm\":\"call for paper\",\"frontiersdefaultterm\":\"call for paper\",\"category\":\"label\"},{\"sequencenumber\":268,\"key\":\"research_topic_abstract\",\"tenantterm\":\"manuscript summary\",\"frontiersdefaultterm\":\"manuscript summary\",\"category\":\"process\"},{\"sequencenumber\":269,\"key\":\"research_topic_abstracts\",\"tenantterm\":\"manuscript summaries\",\"frontiersdefaultterm\":\"manuscript summaries\",\"category\":\"process\"},{\"sequencenumber\":270,\"key\":\"submissions_team_manager\",\"tenantterm\":\"journal manager\",\"frontiersdefaultterm\":\"content manager\",\"category\":\"process\"},{\"sequencenumber\":271,\"key\":\"submissions_team\",\"tenantterm\":\"journal team\",\"frontiersdefaultterm\":\"content team\",\"category\":\"process\"},{\"sequencenumber\":272,\"key\":\"topic_coordinator\",\"tenantterm\":\"topic coordinator\",\"frontiersdefaultterm\":\"topic coordinator\",\"category\":\"process\"},{\"sequencenumber\":273,\"key\":\"topic_coordinators\",\"tenantterm\":\"topic coordinators\",\"frontiersdefaultterm\":\"topic coordinators\",\"category\":\"process\"},{\"sequencenumber\":274,\"key\":\"frontiers_journal_team\",\"tenantterm\":\"frontiers journal team\",\"frontiersdefaultterm\":\"frontiers journal team\",\"category\":\"label (role)\"},{\"sequencenumber\":275,\"key\":\"research_topic_ic_submission\",\"tenantterm\":\"rt:ic submission\",\"frontiersdefaultterm\":\"rt:ic submission\",\"category\":\"label (role)\"},{\"sequencenumber\":276,\"key\":\"research_topic_ic_submission_participant\",\"tenantterm\":\"rt:ic submission participant\",\"frontiersdefaultterm\":\"rt:ic submission participant\",\"category\":\"label (role)\"}]}'\n",impactgtmid:"gtm-njf2ml9b",impactgtmauth:"fyo-7nodm9w37qgfms03sa",impactgtmpreview:"env-1",impactgooglemapsapikey:"aizasyctehx2eu8pwfi86gw9fi00ftcykk6ifr8",qualtricsv4tov3:"'{\"enabled\":true,\"interceptid\":\"si_er0e2ze69oz8yn4\",\"projectid\":\"zn_cloy77jhkpc8gai\",\"brandid\":\"frontiersin\"}'\n",qualtricsumux:"'{\"enabled\":false,\"interceptid\":\"si_89fphy3etxqbwtu\",\"projectid\":\"zn_cloy77jhkpc8gai\",\"brandid\":\"frontiersin\"}'\n",qualtricscontinuousbrand:"'{\"enabled\":true,\"interceptid\":\"si_9zut94ut81fcrh4\",\"projectid\":\"zn_cloy77jhkpc8gai\",\"brandid\":\"frontiersin\"}'\n",defaultarticletemplate:"v3"},app:{baseurl:"/",buildid:"f2d5b6d8-d01c-4534-90b9-d659f10f17ca",buildassetsdir:"ap-2024/_nuxt",cdnurl:""}}## Results
the findings of the ddqn-inspired model demonstrate a high precision of 87% compared to the proposed model. this finding demonstrates the potential of the proposed approach for identifying asd based on social media content. discussion: ultimately, the proposed system was compared against the existing system that used the same dataset. the proposed approach is based on variations in the text of social media interactions, which can assist physicians and clinicians in performing symptom studies within digital footprint environments. 1 introduction asd is among the most prevalent neurodevelopmental disorders. asd is often demonstrated in children by age three and is defined by impairments in social interactions and communication, repetitive sensory-motor activities, and stereotypical behavioral patterns ( 1 ). asd is a congenital neurodevelopmental condition characterized by symptoms that are evident in early infancy. autism, characterized by restricted interests, repetitive behaviors, and significant disparities in social communication and interaction, typically emerges during early developmental stages and presents challenges in various social functioning domains. a child with autism induces significant anxiety within the family due to several factors, including the ambiguity of the diagnosis, the intensity and persistence of the disease, and the child’s nonconformity to social norms. in opposition, social awareness of autism is markedly inadequate, often conflated with intellectual disability and seen as an incurable ailment ( 2 , 3 ). the asd concept is displayed in figure 1 . figure 1 figure 1 . displays the asd concept. content on social media, particularly videos and text disseminated by parents and caregivers, has emerged as a significant resource for facilitating the early identification of asd ( 4 , 5 ). social media are technological tools designed for sharing, enabling users to create networks or engage in existing ones. in that order, the pew research center identified the most popular social media sites as youtube, facebook, instagram, pinterest, linkedin, snapchat, twitter, and whatsapp ( 6 ). most consumers use these networks daily. this research utilizes twitter data to assess the stigmatization of autism and associated terminology, picked based on accessibility and popularity, with analysis conducted using artificial intelligence technologies ( 7 ). conventional diagnostic methods, which primarily rely on observational and behavioral evaluations, often encounter issues with accessibility, consistency, and timeliness. recent technology breakthroughs, especially in artificial intelligence (ai), and sensor-based techniques, provide novel opportunities for improving asd identification. by developing more objective, accurate, and scalable approaches, these technologies transform diagnostic methodologies for autism spectrum disorder (asd) ( 8 – 10 ). one new way to study the motor patterns, attentional processes, and physiological responses linked to asd in real-time is wearable sensors, eye-tracking devices, and multimodal virtual reality settings. these technologies have the potential to give non-invasive, continuous monitoring, which might help with the early diagnosis of asd and shed light on neurological and behavioral traits that have been hard to document reliably. nevertheless, advancements in contemporary research are required to substantiate their efficacy. sensor-based techniques may facilitate the identification of stereotyped behaviors and motor patterns linked to asd in realistic environments, potentially yielding data that could guide timely and customized therapies ( 11 ). neuroimaging and microbiome analysis further advance this technical domain by indicating neurological and biological traits specific to asd. ai-enhanced neuroimaging aids in identifying structural and functional brain connection patterns associated with asd, thereby enhancing the understanding of its neuroanatomical foundation ( 12 ). the research conducted by neeharika and riyazuddin et al. ( 13 ) aimed to enhance the accuracy of asd screening by using feature selection methods in conjunction with sophisticated machine learning classifiers. their research included several datasets spanning infants, children, adolescents, and adults, enabling a thorough assessment of asd characteristics across different age demographics. authors’ use of mlp model capacity to reliably and rapidly identify asd, indicating a beneficial screening instrument suitable for various age groups, facilitating both clinical evaluations and extensive screenings. wall et al. ( 14 ) investigated machine learning (ml) algorithms for diagnosing asd using a standard dataset. the researchers focused on the alternating decision tree classifier to identify a limited yet efficient set of queries that optimize the diagnostic procedure. alzakari et al. ( 15 ) proposed a novel two-phase methodology to tackle the variability in asd features with ml approaches, including behavioral, linguistic, and physical data. the first step concentrates on identifying asd, using feature engineering methodologies and ml algorithms, including a logistic regression (lr) and support vector machine (svm) ensemble, attaining a classification with high accuracy. eeg assesses brain activity and may identify children predisposed to developing asd, hence facilitating early diagnosis. eeg data is used to compare asd and hc ( 16 – 18 ). in ( 19 ), the cnn model was used for classification after transforming the data into a two-dimensional format. while eeg may facilitate the diagnosis of asd, it is constrained by other factors, such as signal noise. the research has used social media to investigate asd. however, exploiting these prevalent platforms and innovative online data sources may be feasible to enhance the comprehension of these diseases. previous research has utilized twitter data to investigate discussions on asd-related material, indicating that this subject is frequently addressed on this platform ( 20 ). considering the use of social media for researching asd is particularly significant, as a recent analysis indicated that around 80% of individuals with asd engage with prominent social media platforms ( 21 ). this study aims to build upon previous research and enhance our comprehension of whether publicly accessible social media data from twitter may provide insights into the existence of digital diagnostic indicators for asd ( 22 ). furthermore, we want to assess the viability of establishing a digital phenotype for asd using social media. beykikhoshk et al. ( 20 ) examined twitter’s potential as a data-mining tool to comprehend the actions, challenges, and requirements of autistic individuals. the first finding pertained to the attributes of participants inside the autism subgroup of tweets, indicating that these tweets were highly informative and had considerable potential usefulness for public health experts and policymakers. tomeny et al. ( 23 ) examined demographic correlations of autism-related anti-vaccine opinions on twitter from 2009 to 2015. their results indicated that the frequency of autism-related anti-vaccine views online was alarming, with anti-vaccine tweets connecting with news events and demonstrating geographical clustering. from 2015 to 2019, tárraga-mínguez et al. ( 24 ) examined the phrases “autism” and “asperger” in spain in relation to google search peaks. the public view of autism was significantly impacted by how the condition was portrayed in the news and on social media, and the authors found that social marketing campaigns had a significant role in normalizing autism. in this research ( 25 ), looked at how people sought assistance. the results showed a strong correlation in google search interest between the terms “asperger syndrome” and “greta thunberg,” reaching their highest point in 2019. online traffic to the asperger/autism network and autism speaks websites increased steadily from june to december 2019, indicating a correlation between help-seeking behavior and thunberg’s fame, according to the research. according to the results, the stigma associated with asperger’s disorder may have been positively affected by thunberg’s public exposure. 1.1 contribution the use of tweets from twitter for the detection of asd is substantial, since it offers extensive, real-time, user-generated data that facilitates the early identification of asd-related behaviors, particularly via self-reported experiences and parental observations. this methodology promotes the advancement of suggested models, namely lstm, cnn-lstm, and inspired ddqn, for natural language processing to examine linguistic patterns, feelings, and keywords related to asd. it provides insights into popular views, stigma, and misconceptions around autism, guiding awareness initiatives and public health measures. twitter data is a powerful and accessible resource for enhancing early detection and understanding of asd in diverse groups. utilizing social media in this manner may offer more accessible and timely screening, particularly in regions with limited healthcare resources. 2 materials and methods figure 2 shows the pipeline of the proposed system to provide a broader perspective to researchers and developers. the framework delineates the processing phases for the pipeline that utilizes social media content to diagnose asd. below, we present a comprehensive assessment of each step. figure 2 figure 2 . farmwork of asd system. 2.1 dataset to help with the early diagnosis of asd by using proposed systems, the tasd-dataset includes comprehensive textual sequences that depict the everyday lives of children with and without asd. it offers new elements, including noise sensitivity, sharing interest, sign communication, and tiptoe flapping, it combines critical asd assessment aspects like attention response, word repetition, and emotional empathy, as shown in figure 3 . parents may get detailed insights and better identify signs of autism spectrum disorder (asd) due to the deepening of certain behaviors. the dataset contains 172 tweets from the asd class and 158 non-asd tweets. figure 4 shows the class of the dataset. figure 3 figure 3 . features of the dataset. figure 4 figure 4 . label of the dataset. 2.2 preprocessing text preprocessing is an essential step in the text processing process. words, sentences, and paragraphs can all be found in a text, which is defined as a meaningful sequence of characters. preprocessing methods feed text data to a proposed algorithm in a better form than in its natural state. a tweet can contain different viewpoints on the data it represents. tweets that have not been preprocessed are highly unstructured and contain redundant data. to address these issues, several steps are taken to preprocess tweets for detecting asd, as shown in figure 5 . figure 5 figure 5 . preprocessing asd text analysis. 2.3 text cleaning the clean text preprocessing method is a significant step in text datasets because the text contains several extra contexts to preprocess and normalize raw text data for analysis. in these steps, the use is transformed to lowercase to guarantee consistency and prevent differentiation between “asd” and “non-asd.” subsequently, any characters that are not letters, numerals, or spaces are eliminated by a regular expression, so punctuation and other symbols that might create extraneous noise are removed. this method is ultimately applied to the ‘text’ column of the data frame, ensuring that all text elements are sanitized and prepared for feature extraction. figure 6 displays the clean text process. figure 6 figure 6 . clean text. 2.4 label encoding the labelencoder method converts text class (asd and non-asd) into numbers, designating 0 for asd and 1 for non-asd. this transformation updates the classification effort by enabling the model to see the labels as numerical values instead of text. equations 1 , 2 show the label encoding. yclassification ∈ ( asd , non − asd ) then      ( 1 ) y = labelencoder ( yclassifcation ) → y ∈ { 0 , 1 }      ( 2 ) 2.5 tokenization and padding tokenization and padding are essential nlp preprocessing procedures that transform unprocessed text into a numerical representation appropriate for machine learning models, particularly neural networks. figure 7 shows the tokenization and padding equation 3 . figure 7 figure 7 . sample of text tokenization and padding. 2.5.1 tokenizer tokenizer procedures transform textual data into a numerical representation suitable for input into neural networks. they convert a text corpus into integer sequences, assigning a distinct index to each unique word according to its frequency, as shown in equation 3 . the tokenizer processing is shown in figure 8 . index ( w ) = rank f ( w ) if rank f ( w ) ≤ v      ( 3 ) figure 8 figure 8 . tokenizer analysis: word frequencies and sequence lengths. where rank f ( w ) is rank w frequency f ( w ) and v is the maximum number of words. 2.5.2 fit texts this phase is crucial for transforming unprocessed text into numerical sequences suitable for input into the proposed system. 2.5.3 texts_to_sequences to convert unprocessed text input into sequences of word indices according to the mapping acquired via as shown in equation 4 . sequence ( t i ) = [ index ( w 1 ) , index ( w 2 ) , … … … , index ( w m ) ]      ( 4 ) where is the t i is the sentence of the text contained, and w is the words of the text, whereas the index ( w 1 ) is an index of the words in the context. 2.5.4 padding_sequences normalize sequence lengths, which may differ post-tokenization, by padding shorter sequences and truncating larger ones to a predetermined length as shown in equation 5 . the padding and truncated b are fixed on the length. l = 200 . the padding processing is shown in figure 7 . x = ∣ x 1 x 2 . . . . y ∣ ∈ ℝ nxl     (5) where x is features contain padding and are tokenized, l is the length of the vector. the number of texts is indicated n , and ∈ ℝ nxl is matrix lues. 2.6 proposed systems 2.6.1 convolutional neural networks the cnn model is at the core of all advanced machine learning and deep learning applications. they can successfully address text classification, image recognition, object identification, and semantic segmentation. using the same method with a task as different as natural language processing is counterintuitive ( 7 ). the structure is presented in figure 9 . equation 6 presents the convolution layer of cnn. o ( x , y ) = ∑ i = 1 h ∑ j = 1 w i ( x + i , y + j ) ∗ k ( i , j ) + b      ( 6 ) figure 9 figure 9 . structure cnn. where the features of text o ( x , y ) the feature of the text is mapped by using. i ( x + i , y + j ) is weighted by a neural network and b is biased to adjust the neural. the relu activation function is equation 7 , the max pooling function is presented in equation 8 . the dense layer is given in equation 9 . f ( x ) = max ( 0 , x )      ( 7 ) o ( x , y ) = ∑ i = 1 h ∑ j = 1 w i ( x + i , y + j ) ∗ k ( i , j ) + b      ( 8 ) o = w · x + b      ( 9 ) 2.6.2 long short-term memory network an lstm network is an advanced form of a sequential neural network. it fixes the problem of rnn gradients fading over time. rnns often handle long-term storage. at a high level, the operation of an lstm is comparable to that of a single rnn neuron. the inner workings of the lstm network are outlined in this section. the lstm consists of three parts, each performing a particular function, as seen in figure 10 below. in the first step, it is decided whether the information from the previous time stamp is significant enough to be saved or if it is harmless enough to be deleted. in the second step, the cell will try to acquire new information by analyzing the data that has been presented to it. in the third and final step, the cell incorporates the data from the most recent time stamp into the data stored in the next time stamp. these three components constitute what is referred to as a gate for an lstm cell. the “forget” gate comes first, followed by the “input” section, and then the “output” section is used to define the last portion as shown in equations 10 – 14 . forget gate : f t = σ ( w f . x t + w f . h t − 1 + b f )      ( 10 ) input gate : i t = σ ( w c . x t + w i . h t − 1 + b i )      ( 11 ) cell gate : c t = ( w f ∗ ( . h t − 1 , x t ) b f )      ( 12 ) output gate : o t = σ ( w o + x t + w o . h t − 1 + v o . c t + b o )      ( 13 ) hidden layer : h t = o t + tanh ( c t )      ( 14 ) figure 10 figure 10 . lstm model. in figure 10 , c t represent the prior and current states of the cell, respectively. both h t − 1 and h represents the cell output that was processed before the one now being processed. it is common practice to disregard f t as a gate, even though it is the input gate. the output of a sigmoid gate is symbolized here by o t . the cable that connects the cell gates is where all the data collected by the cell gates is sent to and from c . the f t layer decides to remember anything, and the f t the output is multiplied by c to do so (t-1). after that, c (t-1) is multiplied by the product of the sigmoid layer gate and the tanh layer gate, and the output h t is generated by point-wise multiplication of o t and tanh. the lstm architecture is intended to capture long-term relationships in twitter text data. the preprocessing converts input words that start with an embedding layer into 128-dimensional dense vectors. the lstm layer with 64 units is then used to mitigate overfitting, integrating dropout and recurrent dropout with 0.5. an l2 regularization term is further included in the lstm and output dense layer. table 1 shows parameters of the lstm model. table 1 table 1 . lstm parameters model. 2.6.3 cnn-lstm model the cnn-lstm model is a hybrid architecture that combines convolutional neural networks (cnn) for spatial feature extraction and long short-term memory (lstm) networks for sequential learning, making it highly effective for analyzing text data such as tweets. the model begins with an embedding layer that transforms each word into a 256-dimensional dense vector, capturing the semantic meaning of words. this is followed by a 1d convolutional layer with 64 filters and a kernel size of 5, which scans through the text to detect local patterns and n-gram features such as common word combinations or phrases often associated with asd. a batch normalization layer is applied to stabilize and accelerate training, followed by a max pooling layer that reduces the dimensionality and computational load by selecting the most prominent features. a dropout layer with a rate of 0.5 is then used to prevent overfitting by randomly deactivating some neurons during training. the output is passed into a 64-unit lstm layer that captures the temporal dependencies and contextual relationships across the tweet sequence. finally, a dense layer with sigmoid activation performs binary classification to predict whether the tweet indicates asd-related content. the model is trained using the adam optimizer, binary cross-entropy loss, class weights, and regularization to handle imbalanced data and improve generalization. the critical parameters of the cnn-lstm model are displayed in table 2 . table 2 table 2 . cnn-lstm parameters. 2.6.4 double deep q-network (ddqn-inspired) the double q-learning model was introduced by h. van hasselt in 2010, addressing the issue of significant overestimations of action value (q-value) inherent in traditional q-learning. in fundamental q-learning, the agent’s optimal strategy is consistently to select the most advantageous action in any specific state. this concept’s premise is that the optimal action corresponds to the highest expected or estimated q-value. initially, the agent lacks any knowledge of the environment; it must first estimate q(s, a) and subsequently update these estimates with each iteration. the q-values exhibit considerable noise, leading to uncertainty about whether the action associated with the highest expected or estimated q-value is genuinely the optimal choice. double q-learning employs two distinct action-value functions, q and q’, as estimators. even if q and q’ exhibit noise, this noise can be interpreted as a uniform distribution as shown figure 11 the update procedure exhibits some variations compared to the basic version. the action selection and action evaluation processes are separated into two distinct maximum function estimators. shown in equations 15 , 16 . figure 11 figure 11 . ddqn-inspired model. let the vector of a neural network’s weights be represented by θ . we establish two q-networks: the online q-network q (s, a; θ(t)) and the target q-network q (s, a; θ (t)). to be more specific, the training of q (s, a; Χ (t)) is done by modifying the weights (t) at time slot t in relation to the goal value y(t). y ( t ) = g ( t ) + ( s ′ , argmax q ( s ′ , a ∗ ; θ ′ ( t ) ) ; θ ′ ( t ) )      ( 15 ) y ( t ) = g ( t ) + ( s ′ , argmax q ( s ′ , a ∗ ; θ ′ ) ; θ i − 1 )      ( 16 ) the reinforcement learning mechanism integrates generative artificial intelligence for decision-making and prediction tasks, as shown in equations 15 , 16 . this equation indicates the generative which produces the estimation or hypothesis at a given time t . double q − learning used next state, whereas the s’ is exit state and argmax q ( s ′ , a ∗ ; θ ′ ( t ) ) defined as the action of a ∗ to maximize the predicted q-value based on the current parameters. to estimate the q-value of this selected action in the next state, the outer q-function q’ employs the older parameters. θ i − 1 1, which helps reduce overestimation bias. this combination makes applications for predicting asd from social media content domains possible. the ddqn model is used to classify asd and non-asd cases utilizing text data. the model utilizes a preprocessing step for text processing that encompasses data loading, cleaning (including lowercasing, removal of special characters, and normalization of spaces), and tokenization, constrained by a maximum vocabulary of 10,000 words and a sequence length of 200. the model architecture, drawing from the double deep q-network (ddqn) model comprises an input layer, an embedding layer with 256 dimensions, and two parallel lstm branches, each containing 64 units, a dropout rate of 0.5, and l2 regularization to capture sequential patterns effectively. the model uses the adam optimizer with a learning rate of 1e-4 and employs binary cross-entropy loss. it is trained for 30 epochs, incorporating early stopping and learning rate reduction callbacks to mitigate overfitting. parameters of ddqn-inspired are shown in table 3 . table 3 table 3 . parameters of ddqn-inspired. 3 performance of the framework 3.1 performance of lstm figure 12 presents the accuracy and loss metrics used to train and validate an lstm model over 30 epochs. the validation accuracy of the lstm model, displayed in red, begins at a lower value and increases to about 81%. the blue line in the accuracy plot (a) shows the training accuracy of the lstm model; it increases gradually from around 50% to almost 99%, showing that the model learns the training data well over time. the plot (b) shows the loss of the lstm model; the blue line represents the training loss, which drops gradually from around 0.7 to less than 0.2, suggesting that the model is getting a better fit to the training data. meanwhile, the red validation loss line declines from around 0.7 to about 0.3. while the training loss continues to grow, the validation loss reaches a level and exhibits small oscillations, suggesting that the model’s generalizability may stabilize. figure 12 figure 12 . performance of the lstm model. the roc curve illustrated in figure 13 shows the efficacy of the lstm model in differentiating between the classes. the graph illustrates the tp rate (sensitivity) in relation to the fp rate across different threshold levels. the lstm model attains an auc of 0.95, demonstrating exceptional classification capability. the auc of 1.0, but a result of 0.5 indicates random chance. figure 13 figure 13 . roc of the lstm model. 3.2 performance of the cnn-lstm model figure 14 presents plots illustrating the performance of a cnn-lstm model over 25 epochs, showing its training and validation metrics for accuracy and loss. the accuracy plot (a) illustrates the training accuracy (blue line), which increases progressively from approximately 51.42% to nearly 99.53%, indicating effective learning from the training data. in contrast, the validation accuracy (red line) rises to about 83.02% with some variability, indicating satisfactory but imperfect generalization. the loss plot (b) shows the training loss (blue line) declining steadily from 0.7140 to below 0.0760, indicating enhanced model fit. in contrast, the validation loss (red line) decreases from 0.7130 to approximately 0.3530, with a slight decline toward the conclusion. this notification indicates that the cnn-lstm model demonstrates efficient learning, as evidenced by the difference between the training and validation measures. figure 14 figure 14 . performance of the lstm model. figure 15 illustrates the roc curve for the cnn-lstm model, illustrating its classification performance at various thresholds. the graph illustrates the tp rate (sensitivity) in relation to the fp rate, with the auc recorded at 92%. the elevated auc value indicates the model has robust discriminative capability in differentiating between the asd and non-asd classes. the roc ascends rapidly toward the top-left corner, as seen in the figure, indicating a high tp rate with few false positives. figure 15 figure 15 . roc of the cnn-lstm model. 3.3 performance of ddqn-inspired model graphs 16 illustrate the performance of a ddqn throughout 30 epochs. the accuracy plot (a) demonstrates that the training accuracy increases from around 58.02% to almost 98.58%, indicating the ddqn model successful learning from the training data over time. the validation accuracy of the ddqn is about 87, showing the best performance compared to different models like lstm and cnn-lstm. the plot (b) illustrates that the training loss decreases from about 0.8155 to around 0.1477, indicating a robust fit to the training data. the validation loss begins at 0.3831 with many fluctuations throughout ( figure 16 ). figure 16 figure 16 . performance of the ddqn-inspired model. figure 17 shows the roc curve for the ddqn model; it shows a visual representation of its classification capability, with the curve toward the top-left corner, indicating strong predictive power. the auc value of the ddqn model is 96%, demonstrating that the model can distinguish between the positive and negative classes. figure 17 figure 17 . roc ddqn-inspired model. 4 experiment and discussion results both the jupyter deep learning framework and the windows 10 operating system were utilized during the testing process. experiments were conducted using a machine with 16 gigabytes of ram and an intel core i7 central processing unit. the input dimensions of the experiment were a standard text dataset collected from the twitter api related to asd. the test was utilized in our database, while the remaining 20% was used as part of our validation set. the three dl models, namely lstm, cnn-lstm, and ddqn-inspired, were proposed for detecting asd from social media content. 4.1 measuring the model’s performance sensitivity, specificity, accuracy, recall, and f1 scores are assessment measures used to determine how successfully the algorithms identify asd. the related equations from 17 to 21 : accuracy = tp + tn tp + fp + fn + tn × 100 %      ( 17 ) sensitivity = tp tp + fn × 100 %      ( 18 ) precision = tp tp + fp × 100 %      ( 19 ) specificity = tn tn + fp × 100      ( 20 ) f 1 − score = 2 ∗ precision × sensitivity precision + sensitivity × 100      ( 21 ) 4.2 result of the lstm model the classification lstm model, presented in table 4 , summarizes its performance in differentiating between asd and non-asd patients, attaining an overall accuracy of 81%. the lstm model demonstrates in asd class a precision of 91%, indicating a high accuracy in identifying predicted asd cases. the lstm with recall metric scored 77% and an f1-score of 82% for detecting the asd class. the lstm model with non-asd class demonstrates a precision of 71%, a recall of 89%, and an f1-score of 79%, to identify non-asd cases. the macro average of the lstm model for all metrics is (precision: 81%, recall: 82%, f1-score: 81%). lstm model is recognized for its efficiency and scalability as a model for social media content. table 4 table 4 . lstm results. the confusion matrix for the lstm model is provided in figure 18 . it is presented in a clear manner. among the confirmed asd cases, 29 were accurately identified as asd, whereas 10 were incorrectly classified as non-asd, indicating strong performance with minor errors. in the true non-asd cases, 25 were correctly identified, while 3 were misclassified as asd, suggesting a generally effective detection process. the deep blue and light shades produce a tranquil visual, illustrating the model’s balanced approach in classifying the 67 total instances, demonstrating notable strength in identifying non-asd cases, while exhibiting marginally lower accuracy for asd. this matrix effectively illustrates the lstm model’s systematic approach to managing sequential data, such as text or time-series inputs, in a clear and comprehensible manner. figure 18 figure 18 . lstm model. 4.3 result of the cnn-lstm model table 5 displays the cnn-lstm model’s performance in distinguishing between asd and non-asd classes. the cnn-lstm model attained an overall accuracy of 85% across the dataset. in the asd label, a precision of 91% was achieved, a high percentage for predicting asd cases that were accurately recognized. the recall indicates that the model identified 82% of all genuine asd cases, resulting in an f1 score of 86%, better than the recall metric. the cnn-lstm model attained 78% accuracy, 89% recall, and an 83% f1 score for the non-asd class. the macro average, representing the unweighted mean of precision, recall, and f1 score across both classes, was 85, 86, and 85%, respectively. the findings indicate that the cnn-lstm model performs satisfactorily, exhibiting a marginally superior capacity to identify asd cases relative to non-asd cases accurately. table 5 table 5 . results of the cnn-lstm model. the confusion matrix of a cnn-lstm model is presented in figure 19 , for classifying instances into asd and non-asd. the matrix is structured with true labels on the vertical axis and predicted labels on the horizontal axis, providing a clear summary of the model’s classification outcomes. the matrix shows that out of the instances truly labeled as asd, the model correctly predicted 32 as asd tp while 7 were incorrectly classified as non-asd fn. for the instances truly labeled as non-asd, the model accurately identified 25 as non-asd tn but 3 were misclassified as asd fp. this indicates that the model demonstrates a relatively strong ability to correctly identify asd and non-asd cases, with higher accuracy for true positives (32 out of 39 asd cases) and true negatives (25 out of 28 non-asd cases). overall, the model exhibits promising performance with minimal misclassification errors. figure 19 figure 19 . results of cnn-lstm model. 4.4 results of double deep q-network the findings of the ddqn model are shown in table 6 , achieving a high precision of 87% compared to the other models. this finding demonstrates the potential of the proposed ddqn approach for identifying asd based on social media content. ultimately, the proposed system was compared against the existing one using the same dataset. the proposed approach may assist physicians in detecting asd and conducting symptomology research in a natural environment, attaining an overall accuracy of 87. the model for the asd class shows a precision of 95%, a recall of 79%, and an f1-score of 87%, indicating robust efficacy in accurately identifying asd patients. the non-asd class has a precision of 77%, a recall of 96%, and an f1-score of 86%, indicating somewhat reduced accuracy with robust recall. the macro average measures (precision 87%, recall 88%, f1-score 87%) indicate performance across both classes. table 6 table 6 . result of ddqn-inspired. the confusion matrix of the ddqn model is shown in figure 20 for the classification task between asd and non-asd cases. for correct classification of asd cases, the model correctly classified 31 instances as asd, represented by the top-left quadrant (tp). however, the ddqn model, misclassified 8 instances misclassifying true asd cases as non-asd, shown in the top-right quadrant (fn). on the other hand, the ddqn showed the true non-asd cases, accurately identified 27 instances as non-asd, depicted in the bottom-right quadrant (tn). at the same time, 1 instance was incorrectly labeled as asd, as shown in the bottom-left quadrant (fp). the confusion matrix of ddqn model highlights that it performs well overall, with a strong ability to correctly identify both asd and non-asd cases, as evidenced by the high counts of tp (31) and tn (27). figure 20 figure 20 . result of ddqn-inspired model. in the digital era, people frequently write content on social media to express their feelings, opinions, beliefs, and activities. this makes social media one of the most significant sources of data generation, allowing you to explore its opportunities and challenges. today, social media has become a mediator between people and the healthcare sector, enabling them to search for information about any specific disease and methods for diagnosing it. individuals within the mental health community use social media platforms such as twitter to seek information, exchange experiences, and get assistance about asd in an environment that is seen as more approachable and informal than conventional medical contexts. they often seek immediate, relevant information—whether to understand symptoms, identify coping mechanisms, or connect with others facing similar difficulties. figure 21 illustrates that word clouds are visual representations of text that highlight key terms and their frequency of use. we used wordcloud to compare asd and non-asd texts for instances of word repetition. figure 21 figure 21 . asd word cloud. the deployment model based on the deep q-network (dqn) model for diagnosing asd is shown in figure 22 . figure 22 figure 22 . deployment system-based text for detecting asd. step 1: data collections, including cleaning, normalization, and tokenization. step 2: model development: the preprocessed data is used to train and validate a deep q-network (dqn) model for classifying tweets as indicative of asd or non-asd patterns. step 3: application interface: an application interface is developed once the model has been trained. it integrates with users’ twitter accounts and continuously analyzes their tweets. step 4: deployment: the proposed system is deployed in the cloud for storing tweets, enabling real-time monitoring of incoming tweets. predictions are flagged for review by healthcare professionals, who validate the model’s output before categorizing individuals as potentially having asd or non-asd. this digital imprint may serve as an ancillary resource for mental health practitioners, providing insights into an individual’s emotional state and social behaviors in a natural environment, potentially facilitating early detection or corroborating a diagnosis. this method is a non-invasive means of data collection, particularly beneficial for individuals who lack rapid access to clinical assessments due to financial constraints, stigma, or resource scarcity. however, it should not replace professional diagnoses and must be conducted with ethical consideration to prevent misunderstanding. table 7 shows the findings of the proposed framework on the twitter dataset. it demonstrates that the suggested method outperforms the current systems in terms of accuracy, proving its efficacy and potential for performance improvements. table 7 table 7 . compared with the proposed asd system. 5 conclusion to assist people in identifying trends in their behavior, such as social challenges or sensory sensitivities, which may encourage them to pursue a formal diagnosis. the main objective of examining tweets for identifying asd is its ability to provide behavioral and emotional indicators associated with the disorder. this research was used to analyze the textual analysis of tweets to detect the behaviors in self-identified autistic individuals relative to others. the suggested framework was evaluated using information from the social media platform “twitter” collected from a public repository. before examining the proposed system, several preprocessing steps must be implemented in the text. the ‘text’ column is cleaned by converting it to lowercase, eliminating non-alphanumeric characters (excluding spaces) through regular expressions, normalizing whitespace to a single space, and removing any leading or trailing spaces. the asd and non-asd labels are converted into a numerical format (0 or 1) with labelencoder to accommodate the binary classification requirement. tokenization of the text data is performed using a tokenizer, restricting the vocabulary to 10,000 words, and then transforming the text into sequences of numbers. the sequences are padded to a standardized length of 200 tokens to maintain consistency for the proposed model input. the proposed data is ultimately divided into an 80% training and 20% testing ratio, and class weights are calculated to resolve any class imbalance. this preparation pipeline efficiently converts raw text data into a structured numerical representation appropriate for the proposed framework, while preserving academic integrity. the output of these preprocessing steps was processed using three dl models, such as short-term memory (cnn-lstm) and a double deep q-network (ddqn). the results of these proposals were proven, revealing that the ddqn model achieved a high accuracy score of 87% with respect to the accuracy measure. the proposed framework, based on real textual data, can be helpful for real-time offering natural, behavioral, and emotional data that might indicate asd-related characteristics. finally, we have observed that social media (twitter) postings include linguistic patterns, emotional expressions, and social interactions that can help official health officials detect asd based on the thorough symptoms of asd that are posted on the platform. this study utilized a conventional dataset sourced only from the twitter network. we will emphasize the necessity of gathering datasets from many platforms to enhance the model’s generalizability in the future. data availability statement the original contributions presented in the study are included in the article/supplementary material, further inquiries can be directed to the corresponding author/s. the dataset used in this study can be found at https://data.mendeley.com/datasets/87s2br3ptb/1 . ethics statement ethical approval was not required for the study involving human data in accordance with the local legislation and institutional requirements. written informed consent was not required, for either participation in the study or for the publication of potentially/indirectly identifying information, in accordance with the local legislation and institutional requirements. the social media data was accessed and analysed in accordance with the platform’s terms of use and all relevant institutional/national regulations. author contributions nf: supervision, conceptualization, software, methodology, writing – original draft, investigation, visualization, formal analysis, validation. aa: data curation, visualization, methodology, conceptualization, validation, software, formal analysis, writing – original draft. ne: investigation, writing – review & editing, validation, formal analysis. sa: visualization, software, formal analysis, writing – review & editing, data curation. funding the author(s) declare that financial support was received for the research and/or publication of this article. the authors extend their appreciation to the king salman center for disability research for funding this work through research group no ksrg-2024-288. conflict of interest the authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest. generative ai statement the authors declare that no gen ai was used in the creation of this manuscript. any alternative text (alt text) provided alongside figures in this article has been generated by frontiers with the support of artificial intelligence and reasonable efforts have been made to ensure accuracy, including review by the authors wherever possible. if you identify any issues, please contact us. publisher’s note all claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher. references 1. asd. (2023). available online at: https://www.healthline.com/health/signs-of-autism-in-3-year-old . google scholar 2. matson, jl, and goldin, rl. what is the future of assessment for autism spectrum disorders: short and long term. res autism spectr disord . (2014) 8:209–13. doi: 10.1016/j.rasd.2013.01.007 crossref full text | google scholar 3. srivastava, ak, and schwartz, ce. intellectual disability and autism spectrum disorders: causal genes and molecular mechanisms. neurosci biobehav rev . (2014) 46:161–74. doi: 10.1016/j.neubiorev.2014.02.015 pubmed abstract | crossref full text | google scholar 4. alhujaili, n, platt, e, khalid-khan, s, and groll, d. comparison of social media use among adolescents with autism spectrum disorder and non-asd adolescents. adolesc health med ther . (2022) 13:15–21. doi: 10.2147/ahmt.s344591 pubmed abstract | crossref full text | google scholar 5. angulo-jiménez, h, and dethorne, l. narratives about autism: an analysis of youtube videos by individuals who self-identify as autistic. am j speech lang pathol . (2019) 28:569–90. doi: 10.1044/2018_ajslp-18-0045 crossref full text | google scholar 6. pew research center. (2021). available online at: https://www.pewresearch.org/internet/2021/04/07/social-media-use-in-2021/ google scholar 7. liu, j-b, guan, l, cao, j, and chen, l. coherence analysis for a class of polygon networks with the noise disturbance. ieee trans syst man cybern syst . (2025) 2025:326. doi: 10.1109/tsmc.2025.3559326 crossref full text | google scholar 8. al-nefaie, ah, aldhyani, th, sultan, ha, and alzahrani eidah, m. application of artificial intelligence in modern healthcare for diagnosis of autism spectrum disorder. front med . (2025) 12:1569464. doi: 10.3389/fmed.2025.1569464 crossref full text | google scholar 9. kim, b, jeong, d, kim, jg, hong, h, and han, k. v-dat (virtual reality data analysis tool): supporting self-awareness for autistic people from multimodal vr sensor data . in: proceedings of the uist 2023—proceedings of the 36th annual acm symposium on user interface software and technology, san francisco, ca, usa, 29 october–1 november 2023. (2023). google scholar 10. chen, c, chander, a, and uchino, k. guided play: digital sensing and coaching for stereotypical play behavior in children with autism . in proceedings of the international conference on intelligent user interfaces, proceedings iui, marina del ray, ca, usa, 17–20 march 2019; part f1476. pp. 208–217. (2019). google scholar 11. parui, s, samanta, d, chakravorty, n, ghosh, u, and rodrigues, jj. artificial intelligence and sensor-based autism spectrum disorder diagnosis using brain connectivity analysis. comput electr eng . (2023) 108:108720. doi: 10.1016/j.compeleceng.2023.108720 crossref full text | google scholar 12. golestan, s, soleiman, p, and moradi, h. a comprehensive review of technologies used for screening, assessment, and rehabilitation of autism spectrum disorder. arxiv . (2018) 2018:10986. doi: 10.48550/arxiv.1807.10986 crossref full text | google scholar 13. neeharika, ch, and riyazuddin, ym. developing an artificial intelligence based model for autism spectrum disorder detection in children. j adv res appl sci eng technol . (2023) 32:57–72. doi: 10.37934/araset.32.1.5772 crossref full text | google scholar 14. wall, dp, dally, r, luyster, r, jung, j-y, and deluca, tf. use of artificial intelligence to shorten the behavioral diagnosis of autism. plos one . (2012) 7:e43855. doi: 10.1371/journal.pone.0043855 pubmed abstract | crossref full text | google scholar 15. alzakari, sa, allinjawi, a, aldrees, a, zamzami, n, umer, m, innab, n, et al. early detection of autism spectrum disorder using explainable ai and optimized teaching strategies. j neurosci methods . (2025) 413:110315. doi: 10.1016/j.jneumeth.2024.110315 pubmed abstract | crossref full text | google scholar 16. heunis, t, aldrich, c, peters, j, jeste, s, sahin, m, scheffer, c, et al. recurrence quantification analysis of resting state eeg signals in autism spectrum disorder—a systematic methodological exploration of technical and demographic confounders in the search for biomarkers. bmc med . (2018) 16:101. doi: 10.1186/s12916-018-1086-7 crossref full text | google scholar 17. vicnesh, j, wei, jke, oh, sl, arunkumar, n, abdulhay, e, ciaccio, ej, et al. autism spectrum disorder diagnostic system using hos bispectrum with eeg signals. int j environ res public health . (2020) 17:971. doi: 10.3390/ijerph17030971 crossref full text | google scholar 18. novielli, p, romano, d, magarelli, m, diacono, d, monaco, a, amoroso, n, et al. personalized identification of autism-related bacteria in the gut microbiome using explainable artificial intelligence. iscience . (2024) 27:110709. doi: 10.1016/j.isci.2024.110709 pubmed abstract | crossref full text | google scholar 19. bosl, wj, tager-flusberg, h, and nelson, ca. eeg analytics for early detection of autism spectrum disorder: a data-driven approach. sci rep . (2018) 8:1–20. doi: 10.1038/s41598-018-24318-x pubmed abstract | crossref full text | google scholar 20. beykikhoshk, a, arandjelović, o, phung, d, venkatesh, s, and caelli, t. using twitter to learn about the autism community. soc netw anal min . (2015) 5:261. doi: 10.1007/s13278-015-0261- crossref full text | google scholar 21. mazurek, mo. social media use among adults with autism spectrum disorders. comput hum behav . (2013) 29:1709–14. doi: 10.1016/j.chb.2013.02.004 crossref full text | google scholar 22. onnela, j, and rauch, sl. harnessing smartphone-based digital phenotyping to enhance behavioral and mental health. neuropsychopharmacology . (2016) 41:1691–6. doi: 10.1038/npp.2016.7.npp20167 pubmed abstract | crossref full text | google scholar 23. tomeny, ts, vargo, cj, and el-toukhy, s. geographic and demographic correlates of autism-related anti-vaccine beliefs on twitter, 2009–2015. soc sci med . (2017) 191:168–75. doi: 10.1016/j.socscimed.2017.08.041 pubmed abstract | crossref full text | google scholar 24. tárraga-mínguez, r, gómez-marí, i, and sanz-cervera, p. what motivates internet users to search for asperger syndrome and autism on google? int j environ res public health . (2020) 17:9386. doi: 10.3390/ijerph17249386 pubmed abstract | crossref full text | google scholar 25. hartwell, m, keener, a, coffey, s, chesher, t, torgerson, t, and vassar, m. brief report: public awareness of asperger syndrome following greta thunberg appearances. j autism dev disord . (2020) 51:2104–8. doi: 10.1007/s10803-020-04651-9 pubmed abstract | crossref full text | google scholar 26. rubio-martín, s, garcía-ordás, mt, bayón-gutiérrez, m, prieto-fernández, n, and benítez-andrades, ja. “ early detection of autism spectrum disorder through ai-powered analysis of social media texts ,” 2023 ieee 36th international symposium on computer-based medical systems (cbms), l’aquila, italy, pp. 235–240. (2023). google scholar 27. jaiswal, a, and washington, p. using #actuallyautistic on twitter for precision diagnosis of autism spectrum disorder: machine learning study. jmir form res . (2024) 8:e52660. doi: 10.2196/52660 crossref full text | google scholar keywords: autism spectrum disorders, diagnosing, social media, deep learning, disabilities, artificial intelligence citation: farhah ns, alqarni aa, ebrahim n and ahmad s (2025) diagnosing autism spectrum disorders using a double deep q-network framework based on social media footprints. front. med . 12:1646249. doi: 10.3389/fmed.2025.1646249 received: 16 june 2025; accepted: 28 july 2025; published: 20 august 2025. edited by: pardeep sangwan , maharaja surajmal institute of technology, india reviewed by: jia-bao liu , anhui jianzhu university, china muhammad adnan , kohat university of science and technology, pakistan copyright © 2025 farhah, alqarni, ebrahim and ahmad. this is an open-access article distributed under the terms of the creative commons attribution license (cc by) . the use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. no use, distribution or reproduction is permitted which does not comply with these terms. *correspondence: nesren s. farhah, bi5myxjoywhac2v1lmvkds5zyq== ; nadhem ebrahim, bmvicmfoaw1adwfrcm9ulmvkdq== ; sultan ahmad, cy5hbglzagvyqhbzyxuuzwr1lnnh disclaimer: all claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. any product that may be evaluated in this article or claim that may be made by its manufacturer is not guaranteed or endorsed by the publisher. download article download pdf readcube epub xml share on export citation endnote reference manager simple text file bibtex 1,193 total views 132 downloads citation numbers are available from dimensions view article impact view altmetric score share on edited by p s pardeep sangwan reviewed by j l jia-bao liu m a muhammad adnan table of contents abstract 1 introduction 2 materials and methods 3 performance of the framework 4 experiment and discussion results 5 conclusion data availability statement ethics statement author contributions funding conflict of interest generative ai statement publisher’s note references export citation endnote reference manager simple text file bibtex check for updates frontiers' impact articles published with frontiers have received 12 million total citations your research is the real superpower - learn how we maximise its impact through our leading community journals explore our impact metrics supplementary material download article download download pdf readcube epub xml guidelines author guidelines services for authors policies and publication ethics editor guidelines fee policy explore articles research topics journals how we publish outreach frontiers forum frontiers policy labs frontiers for young minds frontiers planet prize connect help center emails and alerts contact us submit career opportunities follow us © 2025 frontiers media s.a. all rights reserved privacy policy | terms and conditions [["shallowreactive",1],{"data":2,"state":4,"once":10,"_errors":11,"serverrendered":13,"path":14,"pinia":15},["shallowreactive",3],{},["reactive",5],{"$ssite-config":6},{"env":7,"name":8,"url":9},"production","frontiers articles","https://article-pages-2024.frontiersin.org/",["set"],["shallowreactive",12],{},true,"/journals/medicine/articles/10.3389/fmed.2025.1646249/full",["reactive",16],{"main":17,"user":514,"article":515,"articlehub":766,"mainheader":770},{"ibar":18,"footer":268,"newslettercomponent":-1,"snackbaritem":350,"toggleshowsnackbar":351,"contentfuljournal":352,"graphjournal":416,"settingsfeaturesswitchers":420,"templatetogglebanner":421,"tenantconfig":479},{"tenantlogo":19,"journallogo":19,"aboutus":20,"submiturl":113,"showsubmitbutton":13,"journal":114,"sectionterm":199,"aboutjournal":200,"mainlinks":249,"journallinks":256,"helpcenterlink":265},"",[21,38,47,71,87],{"title":22,"links":23},"who we are",[24,29,32,35],{"text":25,"url":26,"target":27,"arialabel":28},"mission and values","https://www.frontiersin.org/about/mission","_self",null,{"text":30,"url":31,"target":27,"arialabel":28},"history","https://www.frontiersin.org/about/history",{"text":33,"url":34,"target":27,"arialabel":28},"leadership","https://www.frontiersin.org/about/leadership",{"text":36,"url":37,"target":27,"arialabel":28},"awards","https://www.frontiersin.org/about/awards",{"title":39,"links":40},"impact and progress",[41,44],{"text":42,"url":43,"target":27,"arialabel":28},"frontiers' impact","https://www.frontiersin.org/about/impact",{"text":45,"url":46,"target":27,"arialabel":28},"our annual reports","https://www.frontiersin.org/about/annual-reports",{"title":48,"links":49},"publishing model",[50,53,56,59,62,65,68],{"text":51,"url":52,"target":27,"arialabel":28},"how we publish","https://www.frontiersin.org/about/how-we-publish",{"text":54,"url":55,"target":27,"arialabel":28},"open access","https://www.frontiersin.org/about/open-access",{"text":57,"url":58,"target":27,"arialabel":28},"peer review","https://www.frontiersin.org/about/peer-review",{"text":60,"url":61,"target":27,"arialabel":28},"research integrity","https://www.frontiersin.org/about/research-integrity",{"text":63,"url":64,"target":27,"arialabel":28},"research topics","https://www.frontiersin.org/about/research-topics",{"text":66,"url":67,"target":27,"arialabel":28},"fair² data management","https://www.frontiersin.org/about/fair-data-management",{"text":69,"url":70,"target":27,"arialabel":28},"fee policy","https://www.frontiersin.org/about/fee-policy",{"title":72,"links":73},"services",[74,78,81,84],{"text":75,"url":76,"target":77,"arialabel":28},"societies","https://publishingpartnerships.frontiersin.org/","_blank",{"text":79,"url":80,"target":27,"arialabel":28},"national consortia","https://www.frontiersin.org/open-access-agreements/consortia",{"text":82,"url":83,"target":27,"arialabel":28},"institutional partnerships","https://www.frontiersin.org/about/open-access-agreements",{"text":85,"url":86,"target":27,"arialabel":28},"collaborators","https://www.frontiersin.org/about/collaborators",{"title":88,"links":89},"more from frontiers",[90,94,97,101,105,109],{"text":91,"url":92,"target":77,"arialabel":93},"frontiers forum","https://forum.frontiersin.org/","this link will take you to the frontiers forum website",{"text":95,"url":96,"target":27,"arialabel":28},"frontiers planet prize","https://www.frontiersin.org/about/frontiers-planet-prize",{"text":98,"url":99,"target":77,"arialabel":100},"press office","https://pressoffice.frontiersin.org/","this link will take you to the frontiers press office website",{"text":102,"url":103,"target":27,"arialabel":104},"sustainability","https://www.frontiersin.org/about/sustainability","link to information about frontiers' sustainability",{"text":106,"url":107,"target":77,"arialabel":108},"career opportunities","https://careers.frontiersin.org/","this link will take you to the frontiers careers website",{"text":110,"url":111,"target":27,"arialabel":112},"contact us","https://www.frontiersin.org/about/contact","this link will take you to the help pages to contact our support team","https://www.frontiersin.org/submission/submit?domainid=2&fieldid=39&specialtyid=0&entitytype=2&entityid=602",{"id":115,"name":116,"slug":117,"sections":118},602,"frontiers in medicine","medicine",[119,123,127,131,135,139,143,147,151,155,159,163,167,171,175,179,183,187,191,195],{"id":120,"name":121,"slug":122},797,"dermatology","dermatology",{"id":124,"name":125,"slug":126},842,"family medicine and primary care","family-medicine-and-primary-care",{"id":128,"name":129,"slug":130},681,"gastroenterology","gastroenterology",{"id":132,"name":133,"slug":134},1321,"gene and cell therapy","gene-and-cell-therapy",{"id":136,"name":137,"slug":138},790,"geriatric medicine","geriatric-medicine",{"id":140,"name":141,"slug":142},1969,"healthcare professions education","healthcare-professions-education",{"id":144,"name":145,"slug":146},752,"hematology","hematology",{"id":148,"name":149,"slug":150},3648,"hepatobiliary diseases","hepatobiliary-diseases",{"id":152,"name":153,"slug":154},3379,"infectious diseases: pathogenesis and therapy","infectious-diseases-pathogenesis-and-therapy",{"id":156,"name":157,"slug":158},1139,"intensive care medicine and anesthesiology","intensive-care-medicine-and-anesthesiology",{"id":160,"name":161,"slug":162},768,"nephrology","nephrology",{"id":164,"name":165,"slug":166},815,"nuclear medicine","nuclear-medicine",{"id":168,"name":169,"slug":170},2526,"obstetrics and gynecology","obstetrics-and-gynecology",{"id":172,"name":173,"slug":174},1635,"ophthalmology","ophthalmology",{"id":176,"name":177,"slug":178},618,"pathology","pathology",{"id":180,"name":181,"slug":182},1307,"precision medicine","precision-medicine",{"id":184,"name":185,"slug":186},678,"pulmonary medicine","pulmonary-medicine",{"id":188,"name":189,"slug":190},1306,"regulatory science","regulatory-science",{"id":192,"name":193,"slug":194},662,"rheumatology","rheumatology",{"id":196,"name":197,"slug":198},1318,"translational medicine","translational-medicine","sections",[201,225],{"title":202,"links":203},"scope",[204,207,210,213,216,219,222],{"text":205,"url":206,"target":27,"arialabel":28},"field chief editors","https://www.frontiersin.org/journals/medicine/about#about-editors",{"text":208,"url":209,"target":27,"arialabel":28},"mission & scope","https://www.frontiersin.org/journals/medicine/about#about-scope",{"text":211,"url":212,"target":27,"arialabel":28},"facts","https://www.frontiersin.org/journals/medicine/about#about-facts",{"text":214,"url":215,"target":27,"arialabel":28},"journal sections","https://www.frontiersin.org/journals/medicine/about#about-submission",{"text":217,"url":218,"target":27,"arialabel":28},"open access statement","https://www.frontiersin.org/journals/medicine/about#about-open",{"text":220,"url":221,"target":27,"arialabel":28},"copyright statement","https://www.frontiersin.org/journals/medicine/about#copyright-statement",{"text":223,"url":224,"target":27,"arialabel":28},"quality","https://www.frontiersin.org/journals/medicine/about#about-quality",{"title":226,"links":227},"for authors",[228,231,234,237,240,243,246],{"text":229,"url":230,"target":27,"arialabel":28},"why submit?","https://www.frontiersin.org/journals/medicine/for-authors/why-submit",{"text":232,"url":233,"target":27,"arialabel":28},"article types","https://www.frontiersin.org/journals/medicine/for-authors/article-types",{"text":235,"url":236,"target":27,"arialabel":28},"author guidelines","https://www.frontiersin.org/journals/medicine/for-authors/author-guidelines",{"text":238,"url":239,"target":27,"arialabel":28},"editor guidelines","https://www.frontiersin.org/journals/medicine/for-authors/editor-guidelines",{"text":241,"url":242,"target":27,"arialabel":28},"publishing fees","https://www.frontiersin.org/journals/medicine/for-authors/publishing-fees",{"text":244,"url":245,"target":27,"arialabel":28},"submission checklist","https://www.frontiersin.org/journals/medicine/for-authors/submission-checklist",{"text":247,"url":248,"target":27,"arialabel":28},"contact editorial office","https://www.frontiersin.org/journals/medicine/for-authors/contact-editorial-office",[250,253],{"text":251,"url":252,"target":27,"arialabel":28},"all journals","https://www.frontiersin.org/journals",{"text":254,"url":255,"target":27,"arialabel":28},"all articles","https://www.frontiersin.org/articles",[257,260,262],{"text":258,"url":259,"target":27,"arialabel":28},"articles","articles",{"text":63,"url":261,"target":27,"arialabel":28},"research-topics",{"text":263,"url":264,"target":27,"arialabel":28},"editorial board","editors",{"text":266,"url":267,"target":77,"arialabel":266},"help center","https://helpcenter.frontiersin.org",{"blocks":269,"sociallinks":323,"copyright":347,"termsandconditionsurl":348,"privacypolicyurl":349},[270,284,294,308],{"title":271,"links":272},"guidelines",[273,275,278,281,283],{"text":235,"url":274,"target":27,"arialabel":28},"https://www.frontiersin.org/guidelines/author-guidelines",{"text":276,"url":277,"target":27,"arialabel":28},"services for authors","https://www.frontiersin.org/for-authors/author-services",{"text":279,"url":280,"target":27,"arialabel":28},"policies and publication ethics","https://www.frontiersin.org/guidelines/policies-and-publication-ethics",{"text":238,"url":282,"target":27,"arialabel":28},"https://www.frontiersin.org/guidelines/editor-guidelines",{"text":69,"url":70,"target":27,"arialabel":28},{"title":285,"links":286},"explore",[287,288,291,293],{"text":258,"url":255,"target":27,"arialabel":28},{"text":289,"url":290,"target":27,"arialabel":28},"research topics ","https://www.frontiersin.org/research-topics",{"text":292,"url":252,"target":27,"arialabel":28},"journals",{"text":51,"url":52,"target":27,"arialabel":28},{"title":295,"links":296},"outreach",[297,300,303,307],{"text":298,"url":92,"target":77,"arialabel":299},"frontiers forum ","frontiers forum website",{"text":301,"url":302,"target":77,"arialabel":28},"frontiers policy labs ","https://policylabs.frontiersin.org/",{"text":304,"url":305,"target":77,"arialabel":306},"frontiers for young minds","https://kids.frontiersin.org/","frontiers for young minds journal",{"text":95,"url":96,"target":27,"arialabel":28},{"title":309,"links":310},"connect",[311,312,316,319,322],{"text":266,"url":267,"target":77,"arialabel":266},{"text":313,"url":314,"target":77,"arialabel":315},"emails and alerts ","https://subscription-management.frontiersin.org/emails/preferences#block0","subscribe to frontiers emails",{"text":317,"url":111,"target":27,"arialabel":318},"contact us ","subscribe to newsletter",{"text":320,"url":321,"target":27,"arialabel":28},"submit","https://www.frontiersin.org/submission/submit",{"text":106,"url":107,"target":77,"arialabel":28},[324,332,337,342],{"link":325,"type":328,"color":329,"icon":330,"size":331,"hiddentext":13},{"text":326,"url":327,"target":77,"arialabel":326},"frontiers facebook","https://www.facebook.com/frontiersin","link","grey","facebook","medium",{"link":333,"type":328,"color":329,"icon":336,"size":331,"hiddentext":13},{"text":334,"url":335,"target":77,"arialabel":28},"frontiers twitter","https://twitter.com/frontiersin","twitter",{"link":338,"type":328,"color":329,"icon":341,"size":331,"hiddentext":13},{"text":339,"url":340,"target":77,"arialabel":28},"frontiers linkedin","https://www.linkedin.com/company/frontiers","linkedin",{"link":343,"type":328,"color":329,"icon":346,"size":331,"hiddentext":13},{"text":344,"url":345,"target":77,"arialabel":28},"frontiers instagram","https://www.instagram.com/frontiersin_","instagram","frontiers media s.a. all rights reserved","https://www.frontiersin.org/legal/terms-and-conditions","https://www.frontiersin.org/legal/privacy-policy",{},false,{"__typename":353,"identifier":115,"name":116,"slug":117,"banner":354,"description":409,"mission":410,"palette":411,"impactfactor":412,"citescore":413,"citations":414,"showtagline":28,"twitter":415},"journal",[355],{"id":356,"src":357,"name":358,"tags":359,"type":367,"width":368,"height":369,"idhash":370,"archive":371,"brandid":372,"limited":371,"filesize":373,"ispublic":374,"original":375,"copyright":376,"extension":377,"thumbnails":379,"datecreated":387,"description":388,"orientation":389,"usercreated":390,"watermarked":371,"datemodified":387,"datepublished":391,"ecsarchivefiles":392,"propertyoptions":393,"property_channel":398,"property_sub-type":400,"property_asset_type":402,"activeoriginalfocuspoint":404,"property_office_department":407},"3501f557-cafa-4218-930c20d1d930c78c","https://d2csxpduxe849s.cloudfront.net/media/e32629c6-9347-4f84-81feaef7bfa342b3/3501f557-cafa-4218-930c20d1d930c78c/webimage-5988957c-0534-4338-984381d67214c0af.png","fmed_main visual_purple_website",[360,361,362,363,364,365,366],"professional","medical","research","biotechnology","scientific","analy","lab","image",7360,4912,"67388dad93685635",0,"22c10171-81b3-4da6-99342f272a32e8bb",13595017,1,"https://brand.frontiersin.org/m/67388dad93685635/original/fmed_main-visual_purple_website.jpg","copyright (c) 2018 rosshelen/shutterstock. no use without permission.",[378],"jpg",{"mini":380,"thul":381,"webimage":357,"guidelines":382,"websitejpg_xl":383,"websitewebp_l":384,"websitewebp_m":385,"websitewebp_xl":386},"https://d2csxpduxe849s.cloudfront.net/media/e32629c6-9347-4f84-81feaef7bfa342b3/3501f557-cafa-4218-930c20d1d930c78c/mini-4ebc2476-6efb-4a3e-a669185b307fef72.png","https://d2csxpduxe849s.cloudfront.net/media/e32629c6-9347-4f84-81feaef7bfa342b3/3501f557-cafa-4218-930c20d1d930c78c/thul-78bd9351-8a86-4c7b-874fc1cc5caa92ce.png","https://d2csxpduxe849s.cloudfront.net/media/e32629c6-9347-4f84-81feaef7bfa342b3/3501f557-cafa-4218-930c20d1d930c78c/f6ff788e-26d5-4bc5-8cb92ee85a59ca4a/guidelines-fmed_main visual_purple_website.png","https://d2csxpduxe849s.cloudfront.net/media/e32629c6-9347-4f84-81feaef7bfa342b3/3501f557-cafa-4218-930c20d1d930c78c/f6ff788e-26d5-4bc5-8cb92ee85a59ca4a/websitejpg_xl-fmed_main visual_purple_website.jpg","https://d2csxpduxe849s.cloudfront.net/media/e32629c6-9347-4f84-81feaef7bfa342b3/3501f557-cafa-4218-930c20d1d930c78c/f6ff788e-26d5-4bc5-8cb92ee85a59ca4a/websitewebp_l-fmed_main visual_purple_website.webp","https://d2csxpduxe849s.cloudfront.net/media/e32629c6-9347-4f84-81feaef7bfa342b3/3501f557-cafa-4218-930c20d1d930c78c/f6ff788e-26d5-4bc5-8cb92ee85a59ca4a/websitewebp_m-fmed_main visual_purple_website.webp","https://d2csxpduxe849s.cloudfront.net/media/e32629c6-9347-4f84-81feaef7bfa342b3/3501f557-cafa-4218-930c20d1d930c78c/f6ff788e-26d5-4bc5-8cb92ee85a59ca4a/websitewebp_xl-fmed_main visual_purple_website.webp","2022-06-27t10:00:04z","laboratory assistant putting test tubes into the holder, close-up view focused on the tubes","landscape","caroline sutter","2022-06-27t09:27:09z",[],[394,395,396,397],"414fb2d4-2283-43fd-be14e534eca67928","6c18119b-14bd-4951-b437696f4357bd33","7c692885-db25-4858-b1fb4ff47b241e9b","d88c0047-ec30-4506-a7df28a4d765e1cf",[399],"frontiersin_org",[401],"main_visual",[403],"photography",{"x":405,"y":406},3680,2456,[408],"publishing","a highly cited multidisciplinary journal which advances our medical knowledge. it supports the translation of scientific advances into new therapies and diagnostic tools that will improve patient care.","\u003cp>frontiers in medicine is a broad-scope, multidisciplinary journal covering all established medical disciplines to improve clinical practice and patient care.\u003c/p>\n\n\u003cp>led by field chief editor prof michel goldman (université libre de bruxelles, belgium), frontiers in medicine is indexed in pubmed central (pmc), web of science (scie), and scopus, among others, and welcomes basic and clinical medical research that facilitate the translation of scientific advances into new therapies or diagnostic tools. topics include, but are not limited to:\u003c/p>\n\n\u003cul>\n \u003cli>dermatology\u003c/li>\n \u003cli>family medicine and primary care\u003c/li>\n \u003cli>gastroenterology\u003c/li>\n \u003cli>gene and cell therapy\u003c/li>\n \u003cli>geriatric medicine\u003c/li>\n \u003cli>healthcare professions education\u003c/li>\n \u003cli>hematology\u003c/li>\n \u003cli>hepatobiliary diseases\u003c/li>\n \u003cli>infectious diseases: pathogenesis and therapy\u003c/li>\n \u003cli>intensive care medicine and anesthesiology\u003c/li>\n \u003cli>nephrology\u003c/li>\n \u003cli>nuclear medicine\u003c/li>\n \u003cli>obstetrics and gynecology\u003c/li>\n \u003cli>ophthalmology\u003c/li>\n \u003cli>pathology\u003c/li>\n \u003cli>precision medicine\u003c/li>\n \u003cli>pulmonary medicine\u003c/li>\n \u003cli>regulatory science\u003c/li>\n \u003cli>rheumatology\u003c/li>\n \u003cli>translational medicine.\u003c/li>\n\u003c/ul>\n\n\u003cp>in addition to papers that provide a link between basic research and clinical practice, a particular emphasis is given to studies that are directly relevant to patient care.\u003c/p>\n\n\u003cp>as well as the established medical disciplines, frontiers in medicine aims to publish research that will facilitate:\u003c/p>\n\n\u003cul>\n \u003cli>access to medicinal products and medical devices worldwide\u003c/li>\n \u003cli>addressing the grand health challenges around the world\u003c/li>\n \u003cli>the exploitation of big data and the use of novel information and communication tools in the assessment of new medicines\u003c/li>\n \u003cli>the scientific bases for guidelines and decisions from regulatory authorities\u003c/li>\n \u003cli>the use of patient-reported outcomes under real world conditions.\u003c/li>\n\u003c/ul>\n\n\u003cp>all studies must contribute insights into the field of medicine. papers which do not primarily focus on a medical discipline are not suitable for publication in this journal. manuscripts that focus solely on the molecular or cellular mechanisms of diseases without a foundation in clinical medicine are not suitable for publication in this journal. similarly, studies that are purely descriptive or observational, without a clear hypothesis or mechanistic investigation, are not within the scope of this journal. research that is primarily epidemiological or public health-oriented, without a foundation in the pathophysiology or treatment of disease, is also not appropriate for this journal.\u003c/p>\n\n\u003cp>frontiers’ journals require that manuscripts primarily comprising computational studies of public data, must include appropriate validation. please refer to the \u003ca href=\"https://www.frontiersin.org/guidelines/policies-and-publication-ethics#standards-for-research-methodology:~:text=complaints%20and%20allegations.-,standards%20for%20research%20methodology,-experiments\">frontiers standards for research methodology policy\u003c/a>, for more information. manuscripts not adhering to these standards will not be considered.\u003cp>\n\n\u003cp>frontiers in medicine is committed to advancing developments in the field of medicine by allowing unrestricted access to articles and communicating scientific knowledge to researchers and the public alike, to enable the scientific breakthroughs of the future.\u003c/p>\n\n\u003cp>ethics statement:\u003c/p>\n\n\u003cp>all manuscripts submitted to frontiers in medicine that have been conducted in human subjects must conform with current regulations and the declaration of helsinki. ethics committee approval and informed patient consent are required for studies involving human subjects. ethics committee approval is also needed for studies involving animals. phase i - phase iv clinical trials submitted for publication in frontiers in medicine must have been registered with an appropriate public trials registry at the time or before the first patient enrolment. the information on the clinical trial registration (unique identifier and url) must be included in the abstract. authors are required to disclose all apparent or potential conflicts of interest according to the icmje guidelines and those of frontiers.\u003c/p>\n\n\u003cp>frontiers endeavors to follow the guidelines and best practice recommendations published by the committee on publication ethics (cope). authors should refer to the author guidelines for full details.\u003c/p>","purple","3.9","3.6","176752","@frontmedicine",{"id":115,"name":116,"slug":117,"abbreviation":417,"isonline":13,"isopenforsubmissions":13,"citescore":418,"impactfactor":419},"fmed",6,3,{"displaytitlepilllabels":13,"displayrelatedarticlesbox":13,"showeditors":13,"showreviewers":13,"showloopimpactlink":13,"enablefigshare":351,"usexmlimages":13},{"ispublic":13,"allowcompanyusers":351,"whitelistemails":422,"enablealljournals":13,"whitelistjournals":444},[423,424,425,426,427,428,429,430,431,428,432,433,434,435,436,437,438,439,440,441,442,443],"y2fybg9zlmxvcmnhqgzyb250awvyc2lulm9yzw==","zgfuawvslmx1ekbmcm9udgllcnnpbi5vcmc=","bgf1cmeudgvuyubmcm9udgllcnnpbi5vcmc=","cmfmywvslnjpyw5jag9aznjvbnrpzxjzaw4ub3jn","amftzxmuc21hbgxib25lqgzyb250awvyc2lulm9yzw==","znjhbi5tb3jlbm9aznjvbnrpzxjzaw4ub3jn","c2ftdwvslmzlcm5hbmrlekbmcm9udgllcnnpbi5vcmc=","ymfyymfyys5jyxjjyw5naxvaznjvbnrpzxjzaw4ub3jn","axzhbi5zyw50yw1hcmlhqgzyb250awvyc2lulm9yzw==","ahvllnryyw5aznjvbnrpzxjzaw4ub3jn","z29uy2fsby52yxjnyxnaznjvbnrpzxjzaw4ub3jn","bhvjawuuc2vubkbmcm9udgllcnnpbi5vcmc=","bg9ybi5mcmfzzxjaznjvbnrpzxjzaw4ub3jn","zwxzys5jyxjyb25aznjvbnrpzxjzaw4ub3jn","bwfhcnrlbi52yw5kawpja0bmcm9udgllcnnpbi5vcmc=","ymluzgh1lmtyaxnobmfuqgzyb250awvyc2lulm9yzw==","bwf0dghldy5hdhr3yxrlcnnaznjvbnrpzxjzaw4ub3jn","z2l1bglhlnzhbhnly2noaubmcm9udgllcnnpbi5vcmc=","zmfiawfulmrlbgxhbw9ydgvaznjvbnrpzxjzaw4ub3jn","dmlqyxlhbi5wcebwaxrzb2x1dglvbnmuy29t","z3vpbgxhdw1llnnldxjhdebmcm9udgllcnnpbi5vcmc=",[445,446,447,406,448,449,374,450,115,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478],2232,1729,2357,2176,2333,1843,106,616,310,657,3123,1468,2137,628,1566,2726,2086,1490,451,141,1335,2655,1238,604,698,1547,176,1440,403,1239,755,2136,609,1534,{"spaceid":374,"name":374,"availablejournalpages":480,"announcement":484},[259,264,261,481,482,483],"volumes","about","community-reviewers",{"__typename":485,"sys":486,"preheader":42,"title":488,"description":489,"image":490,"link":512},"announcement",{"id":487},"5ittnttqgazppgh6rx0alm","articles published with frontiers have received 12 million total citations","your research is the real superpower - learn how we maximise its impact through our leading community journals",[491],{"archive":371,"brandid":372,"copyright":28,"datecreated":492,"datemodified":493,"datepublished":494,"description":28,"extension":495,"filesize":497,"height":498,"id":499,"ispublic":371,"limited":371,"name":500,"orientation":389,"original":28,"thumbnails":501,"type":367,"watermarked":371,"width":508,"videopreviewurls":509,"tags":510,"textmetaproperties":511,"src":502},"2025-06-18t12:58:01z","2025-06-18t14:15:34z","2025-06-18t12:57:32z",[496],"png",1365026,920,"7c5269c4-3c83-4591-951a74d15b95daea","impact metrics banner for article pages",{"webimage":502,"thul":503,"mini":504,"websitewebp_l":505,"websitewebp_m":506,"guidelines":507},"https://brand.frontiersin.org/m/59ee6275cb9a849c/webimage-impact-metrics-banner-for-article-pages.png","https://brand.frontiersin.org/m/59ee6275cb9a849c/thul-impact-metrics-banner-for-article-pages.png","https://brand.frontiersin.org/m/59ee6275cb9a849c/mini-impact-metrics-banner-for-article-pages.png","https://brand.frontiersin.org/asset/7c5269c4-3c83-4591-951a-74d15b95daea/websitewebp_l/impact-metrics-banner-for-article-pages.webp","https://brand.frontiersin.org/asset/7c5269c4-3c83-4591-951a-74d15b95daea/websitewebp_m/impact-metrics-banner-for-article-pages.webp","https://brand.frontiersin.org/asset/7c5269c4-3c83-4591-951a-74d15b95daea/guidelines/impact-metrics-banner-for-article-pages.png",1600,[],[],[],{"text":513,"url":43,"target":27,"arialabel":28},"explore our impact metrics",{"loggeduserinfo":-1},{"currentarticle":516,"ispreviewpage":351,"hassupplementaldata":351,"showcrossmarkwidget":13,"articletemplate":646,"currentarticlepagemetainfo":647,"xmlparsedarticlecontent":-1,"xmlparsingerror":-1},{"id":517,"doi":518,"title":519,"acceptancedate":520,"receptiondate":521,"publicationdate":522,"lastmodifieddate":523,"ispublished":13,"abstract":524,"researchtopic":525,"articletype":531,"stage":534,"keywords":536,"authors":543,"editors":584,"reviewers":592,"journal":607,"section":615,"impactmetrics":617,"volume":620,"articlevolume":621,"relatedarticles":622,"ispublishedv2":13,"contents":623,"files":626},1646249,"10.3389/fmed.2025.1646249","diagnosing autism spectrum disorders using a double deep q-network framework based on social media footprints","2025-07-28t08:25:45.000z","2025-06-16t12:25:51.000z","2025-08-20t00:00:00.000z","2025-10-21t02:22:52.270z","introductionsocial media is increasingly used in many contexts within the healthcare sector. the improved prevalence of internet use via computers or mobile devices presents an opportunity for social media to serve as a tool for the rapid and direct distribution of essential health information. autism spectrum disorders (asd) are a comprehensive neurodevelopmental syndrome with enduring effects. twitter has become a platform for the asd community, offering substantial assistance to its members by disseminating information on their beliefs and perspectives via language and emotional expression. adults with asd have considerable social and emotional challenges, while also demonstrating abilities and interests in screen-based technologies.methodsthe novelty of this research lies in its use in the context of twitter to analyze and identify asd. this research used twitter as the primary data source to examine the behavioral traits and immediate emotional expressions of persons with asd. we applied convolutional neural networks with long short-term memory (cnn-lstm), lstm, and double deep q-network (ddqn-inspired) using a standardized dataset including 172 tweets from the asd class and 158 tweets from the non-asd class. the dataset was processed to exclude lowercase text and special characters, followed by a tokenization approach to convert the text into integer word sequences. the encoding was used to transform the classes into binary labels. following preprocessing, the proposed framework was implemented to identify asd.resultsthe findings of the ddqn-inspired model demonstrate a high precision of 87% compared to the proposed model. this finding demonstrates the potential of the proposed approach for identifying asd based on social media content.discussionultimately, the proposed system was compared against the existing system that used the same dataset. the proposed approach is based on variations in the text of social media interactions, which can assist physicians and clinicians in performing symptom studies within digital footprint environments.",{"id":526,"title":527,"articlescount":528,"ismagazinepage":351,"slug":529,"isopenforsubmission":351,"views":530},69516,"ai innovations in neuroimaging: transforming brain analysis",10,"ai-innovations-in-neuroimaging-transforming-brain-analysis",16647,{"id":532,"name":533},24,"original research",{"id":535,"name":19},18,[537,538,539,540,541,542],"artificial intelligence","deep learning","social media","disabilities","autism spectrum disorders","diagnosing",[544,555,564,573],{"id":545,"firstname":546,"middlename":19,"lastname":547,"givennames":548,"iscorresponding":351,"isprofilepublic":13,"userid":545,"email":-1,"affiliations":549},2586659,"nesren s.","farhah","nesren s. ",[550,553],{"organizationname":551,"countryname":552,"cityname":19,"statename":19,"zipcode":19},"department of health informatics, college of health science, saudi electronic university","saudi arabia",{"organizationname":554,"countryname":552,"cityname":19,"statename":19,"zipcode":19},"king salman center for disability research",{"id":556,"firstname":557,"middlename":19,"lastname":558,"givennames":559,"iscorresponding":351,"isprofilepublic":13,"userid":556,"email":-1,"affiliations":560},3164796,"ahmed abdullah","alqarni","ahmed abdullah ",[561,562],{"organizationname":554,"countryname":552,"cityname":19,"statename":19,"zipcode":19},{"organizationname":563,"countryname":552,"cityname":19,"statename":19,"zipcode":19},"department of computer sciences and information technology, al-baha university",{"id":565,"firstname":566,"middlename":19,"lastname":567,"givennames":568,"iscorresponding":351,"isprofilepublic":13,"userid":565,"email":-1,"affiliations":569},3077810,"nadhem","ebrahim","nadhem ",[570],{"organizationname":571,"countryname":572,"cityname":19,"statename":19,"zipcode":19},"department of computer science, college of engineering and polymer science, university of akron","united states",{"id":574,"firstname":575,"middlename":19,"lastname":576,"givennames":577,"iscorresponding":351,"isprofilepublic":13,"userid":574,"email":-1,"affiliations":578},1762668,"sultan","ahmad","sultan ",[579,581],{"organizationname":580,"countryname":552,"cityname":19,"statename":19,"zipcode":19},"department of computer science, college of computer engineering and sciences, prince sattam bin abdulaziz university",{"organizationname":582,"countryname":583,"cityname":19,"statename":19,"zipcode":19},"school of computer science and engineering, lovely professional university","india",[585],{"id":586,"firstname":587,"middlename":19,"lastname":588,"givennames":589,"iscorresponding":351,"isprofilepublic":13,"userid":586,"email":-1,"affiliations":590},2928766,"pardeep","sangwan","pardeep ",[591],{"organizationname":19,"countryname":19,"cityname":19,"statename":19,"zipcode":19},[593,600],{"id":594,"firstname":595,"middlename":19,"lastname":596,"givennames":597,"iscorresponding":351,"isprofilepublic":13,"userid":594,"email":-1,"affiliations":598},1743107,"jia-bao","liu","jia-bao ",[599],{"organizationname":19,"countryname":19,"cityname":19,"statename":19,"zipcode":19},{"id":601,"firstname":602,"middlename":19,"lastname":603,"givennames":604,"iscorresponding":351,"isprofilepublic":13,"userid":601,"email":-1,"affiliations":605},3104897,"muhammad","adnan","muhammad ",[606],{"organizationname":19,"countryname":19,"cityname":19,"statename":19,"zipcode":19},{"id":115,"slug":117,"name":116,"shortname":608,"electronicissn":609,"field":610,"specialtyid":28,"journalsectionpaths":613},"front. med.","2296-858x",{"id":611,"domainid":612},39,2,[614],{"section":615},{"id":180,"name":181,"slug":182,"specialtyid":616},1754,{"views":618,"downloads":619,"citations":371},1193,132,12,"volume 12 - 2025",[],{"titlehtml":519,"fulltexthtml":624,"menuhtml":625},"\u003cdiv class=\"journalabstract\"> \u003ca id=\"h1\" name=\"h1\">\u003c/a>\n \u003cdiv class=\"authors\">\u003cspan class=\"author-wrapper notranslate\">\u003ca href=\"https://loop.frontiersin.org/people/2586659\" class=\"user-id-2586659\">\u003cimg class=\"pr5\" src=\"https://loop.frontiersin.org/images/profile/2586659/74\" onerror=\"this.onerror=null;this.src='https://loop.frontiersin.org/cdn/images/profile/default_32.jpg';\" alt=\"nesren s. farhah,
\">nesren s. farhah\u003c/a>\u003csup>1,2\u003c/sup>\u003csup>*\u003c/sup>\u003c/span>\u003cspan class=\"author-wrapper notranslate\">\u003ca href=\"https://loop.frontiersin.org/people/3164796\" class=\"user-id-3164796\">\u003cimg class=\"pr5\" src=\"https://loop.frontiersin.org/images/profile/3164796/74\" onerror=\"this.onerror=null;this.src='https://loop.frontiersin.org/cdn/images/profile/default_32.jpg';\" alt=\"ahmed abdullah alqarni,\">ahmed abdullah alqarni\u003c/a>\u003csup>2,3\u003c/sup>\u003c/span>\u003cspan class=\"author-wrapper notranslate\">\u003ca href=\"https://loop.frontiersin.org/people/3077810\" class=\"user-id-3077810\">\u003cimg class=\"pr5\" src=\"https://loop.frontiersin.org/images/profile/3077810/74\" onerror=\"this.onerror=null;this.src='https://loop.frontiersin.org/cdn/images/profile/default_32.jpg';\" alt=\"nadhem ebrahim
\">nadhem ebrahim\u003c/a>\u003csup>4\u003c/sup>\u003csup>*\u003c/sup>\u003c/span>\u003cspan class=\"author-wrapper notranslate\">\u003ca href=\"https://loop.frontiersin.org/people/1762668\" class=\"user-id-1762668\">\u003cimg class=\"pr5\" src=\"https://loop.frontiersin.org/images/profile/1762668/74\" onerror=\"this.onerror=null;this.src='https://loop.frontiersin.org/cdn/images/profile/default_32.jpg';\" alt=\"sultan ahmad,
\">sultan ahmad\u003c/a>\u003csup>5,6\u003c/sup>\u003csup>*\u003c/sup>\u003c/span>\u003c/div> \u003cul class=\"notes\"> \u003cli>\u003cspan>\u003csup>1\u003c/sup>\u003c/span>department of health informatics, college of health science, saudi electronic university, riyadh, saudi arabia\u003c/li> \u003cli>\u003cspan>\u003csup>2\u003c/sup>\u003c/span>king salman center for disability research, riyadh, saudi arabia\u003c/li> \u003cli>\u003cspan>\u003csup>3\u003c/sup>\u003c/span>department of computer sciences and information technology, al-baha university, al-baha, saudi arabia\u003c/li> \u003cli>\u003cspan>\u003csup>4\u003c/sup>\u003c/span>department of computer science, college of engineering and polymer science, university of akron, oh, united states\u003c/li> \u003cli>\u003cspan>\u003csup>5\u003c/sup>\u003c/span>department of computer science, college of computer engineering and sciences, prince sattam bin abdulaziz university, al-kharj, saudi arabia\u003c/li> \u003cli>\u003cspan>\u003csup>6\u003c/sup>\u003c/span>school of computer science and engineering, lovely professional university, phagwara, india\u003c/li> \u003c/ul>\n\u003cp class=\"mb15\">\u003cb>introduction:\u003c/b> social media is increasingly used in many contexts within the healthcare sector. the improved prevalence of internet use via computers or mobile devices presents an opportunity for social media to serve as a tool for the rapid and direct distribution of essential health information. autism spectrum disorders (asd) are a comprehensive neurodevelopmental syndrome with enduring effects. twitter has become a platform for the asd community, offering substantial assistance to its members by disseminating information on their beliefs and perspectives via language and emotional expression. adults with asd have considerable social and emotional challenges, while also demonstrating abilities and interests in screen-based technologies.\u003c/p>\n\u003cp class=\"mb15\">\u003cb>methods:\u003c/b> the novelty of this research lies in its use in the context of twitter to analyze and identify asd. this research used twitter as the primary data source to examine the behavioral traits and immediate emotional expressions of persons with asd. we applied convolutional neural networks with long short-term memory (cnn-lstm), lstm, and double deep q-network (ddqn-inspired) using a standardized dataset including 172 tweets from the asd class and 158 tweets from the non-asd class. the dataset was processed to exclude lowercase text and special characters, followed by a tokenization approach to convert the text into integer word sequences. the encoding was used to transform the classes into binary labels. following preprocessing, the proposed framework was implemented to identify asd.\u003c/p>\n\u003cp class=\"mb15\">\u003cb>results:\u003c/b> the findings of the ddqn-inspired model demonstrate a high precision of 87% compared to the proposed model. this finding demonstrates the potential of the proposed approach for identifying asd based on social media content.\u003c/p>\n\u003cp class=\"mb0\">\u003cb>discussion:\u003c/b> ultimately, the proposed system was compared against the existing system that used the same dataset. the proposed approach is based on variations in the text of social media interactions, which can assist physicians and clinicians in performing symptom studies within digital footprint environments.\u003c/p> \u003cdiv class=\"clear\">\u003c/div> \u003c/div> \u003cdiv class=\"journalfulltext\"> \u003ca id=\"h2\" name=\"h2\">\u003c/a>\n\u003ch2>1 introduction\u003c/h2>\n\u003cp class=\"mb0\">asd is among the most prevalent neurodevelopmental disorders. asd is often demonstrated in children by age three and is defined by impairments in social interactions and communication, repetitive sensory-motor activities, and stereotypical behavioral patterns (\u003ca href=\"#ref1\">1\u003c/a>). asd is a congenital neurodevelopmental condition characterized by symptoms that are evident in early infancy. autism, characterized by restricted interests, repetitive behaviors, and significant disparities in social communication and interaction, typically emerges during early developmental stages and presents challenges in various social functioning domains. a child with autism induces significant anxiety within the family due to several factors, including the ambiguity of the diagnosis, the intensity and persistence of the disease, and the child’s nonconformity to social norms. in opposition, social awareness of autism is markedly inadequate, often conflated with intellectual disability and seen as an incurable ailment (\u003ca href=\"#ref2\">2\u003c/a>, \u003ca href=\"#ref3\">3\u003c/a>). the asd concept is displayed in \u003ca href=\"#fig1\">figure 1\u003c/a>.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 1\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g001.jpg\" name=\"figure1\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g001.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g001.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g001.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g001.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g001.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g001.jpg\" alt=\"nine icons representing concepts related to autism and interventions. top row: discrete trial training, pivotal response training, and verbal behavior intervention. middle row: impulsiveness and aggression, preference for solitude, delayed language development. bottom row: prescription drugs during pregnancy, family history of autism, assistive technologies. each icon illustrates its concept with relevant imagery.\" id=\"fig1\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 1\u003c/b>. displays the asd concept.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb15\">content on social media, particularly videos and text disseminated by parents and caregivers, has emerged as a significant resource for facilitating the early identification of asd (\u003ca href=\"#ref4\">4\u003c/a>, \u003ca href=\"#ref5\">5\u003c/a>). social media are technological tools designed for sharing, enabling users to create networks or engage in existing ones. in that order, the pew research center identified the most popular social media sites as youtube, facebook, instagram, pinterest, linkedin, snapchat, twitter, and whatsapp (\u003ca href=\"#ref6\">6\u003c/a>). most consumers use these networks daily. this research utilizes twitter data to assess the stigmatization of autism and associated terminology, picked based on accessibility and popularity, with analysis conducted using artificial intelligence technologies (\u003ca href=\"#ref7\">7\u003c/a>).\u003c/p>\n\u003cp class=\"mb15\">conventional diagnostic methods, which primarily rely on observational and behavioral evaluations, often encounter issues with accessibility, consistency, and timeliness. recent technology breakthroughs, especially in artificial intelligence (ai), and sensor-based techniques, provide novel opportunities for improving asd identification. by developing more objective, accurate, and scalable approaches, these technologies transform diagnostic methodologies for autism spectrum disorder (asd) (\u003ca href=\"#ref8\">8\u003c/a>–\u003ca href=\"#ref10\">10\u003c/a>). one new way to study the motor patterns, attentional processes, and physiological responses linked to asd in real-time is wearable sensors, eye-tracking devices, and multimodal virtual reality settings. these technologies have the potential to give non-invasive, continuous monitoring, which might help with the early diagnosis of asd and shed light on neurological and behavioral traits that have been hard to document reliably.\u003c/p>\n\u003cp class=\"mb15\">nevertheless, advancements in contemporary research are required to substantiate their efficacy. sensor-based techniques may facilitate the identification of stereotyped behaviors and motor patterns linked to asd in realistic environments, potentially yielding data that could guide timely and customized therapies (\u003ca href=\"#ref11\">11\u003c/a>). neuroimaging and microbiome analysis further advance this technical domain by indicating neurological and biological traits specific to asd. ai-enhanced neuroimaging aids in identifying structural and functional brain connection patterns associated with asd, thereby enhancing the understanding of its neuroanatomical foundation (\u003ca href=\"#ref12\">12\u003c/a>).\u003c/p>\n\u003cp class=\"mb15\">the research conducted by neeharika and riyazuddin et al. (\u003ca href=\"#ref13\">13\u003c/a>) aimed to enhance the accuracy of asd screening by using feature selection methods in conjunction with sophisticated machine learning classifiers. their research included several datasets spanning infants, children, adolescents, and adults, enabling a thorough assessment of asd characteristics across different age demographics. authors’ use of mlp model capacity to reliably and rapidly identify asd, indicating a beneficial screening instrument suitable for various age groups, facilitating both clinical evaluations and extensive screenings. wall et al. (\u003ca href=\"#ref14\">14\u003c/a>) investigated machine learning (ml) algorithms for diagnosing asd using a standard dataset. the researchers focused on the alternating decision tree classifier to identify a limited yet efficient set of queries that optimize the diagnostic procedure. alzakari et al. (\u003ca href=\"#ref15\">15\u003c/a>) proposed a novel two-phase methodology to tackle the variability in asd features with ml approaches, including behavioral, linguistic, and physical data. the first step concentrates on identifying asd, using feature engineering methodologies and ml algorithms, including a logistic regression (lr) and support vector machine (svm) ensemble, attaining a classification with high accuracy. eeg assesses brain activity and may identify children predisposed to developing asd, hence facilitating early diagnosis. eeg data is used to compare asd and hc (\u003ca href=\"#ref16\">16\u003c/a>–\u003ca href=\"#ref18\">18\u003c/a>). in (\u003ca href=\"#ref19\">19\u003c/a>), the cnn model was used for classification after transforming the data into a two-dimensional format. while eeg may facilitate the diagnosis of asd, it is constrained by other factors, such as signal noise.\u003c/p>\n\u003cp class=\"mb15\">the research has used social media to investigate asd. however, exploiting these prevalent platforms and innovative online data sources may be feasible to enhance the comprehension of these diseases. previous research has utilized twitter data to investigate discussions on asd-related material, indicating that this subject is frequently addressed on this platform (\u003ca href=\"#ref20\">20\u003c/a>). considering the use of social media for researching asd is particularly significant, as a recent analysis indicated that around 80% of individuals with asd engage with prominent social media platforms (\u003ca href=\"#ref21\">21\u003c/a>). this study aims to build upon previous research and enhance our comprehension of whether publicly accessible social media data from twitter may provide insights into the existence of digital diagnostic indicators for asd (\u003ca href=\"#ref22\">22\u003c/a>). furthermore, we want to assess the viability of establishing a digital phenotype for asd using social media.\u003c/p>\n\u003cp class=\"mb0\">beykikhoshk et al. (\u003ca href=\"#ref20\">20\u003c/a>) examined twitter’s potential as a data-mining tool to comprehend the actions, challenges, and requirements of autistic individuals. the first finding pertained to the attributes of participants inside the autism subgroup of tweets, indicating that these tweets were highly informative and had considerable potential usefulness for public health experts and policymakers. tomeny et al. (\u003ca href=\"#ref23\">23\u003c/a>) examined demographic correlations of autism-related anti-vaccine opinions on twitter from 2009 to 2015. their results indicated that the frequency of autism-related anti-vaccine views online was alarming, with anti-vaccine tweets connecting with news events and demonstrating geographical clustering. from 2015 to 2019, tárraga-mínguez et al. (\u003ca href=\"#ref24\">24\u003c/a>) examined the phrases “autism” and “asperger” in spain in relation to google search peaks. the public view of autism was significantly impacted by how the condition was portrayed in the news and on social media, and the authors found that social marketing campaigns had a significant role in normalizing autism. in this research (\u003ca href=\"#ref25\">25\u003c/a>), looked at how people sought assistance. the results showed a strong correlation in google search interest between the terms “asperger syndrome” and “greta thunberg,” reaching their highest point in 2019. online traffic to the asperger/autism network and autism speaks websites increased steadily from june to december 2019, indicating a correlation between help-seeking behavior and thunberg’s fame, according to the research. according to the results, the stigma associated with asperger’s disorder may have been positively affected by thunberg’s public exposure.\u003c/p>\n\u003ch3>1.1 contribution\u003c/h3>\n\u003cp class=\"mb0\">the use of tweets from twitter for the detection of asd is substantial, since it offers extensive, real-time, user-generated data that facilitates the early identification of asd-related behaviors, particularly via self-reported experiences and parental observations. this methodology promotes the advancement of suggested models, namely lstm, cnn-lstm, and inspired ddqn, for natural language processing to examine linguistic patterns, feelings, and keywords related to asd. it provides insights into popular views, stigma, and misconceptions around autism, guiding awareness initiatives and public health measures. twitter data is a powerful and accessible resource for enhancing early detection and understanding of asd in diverse groups. utilizing social media in this manner may offer more accessible and timely screening, particularly in regions with limited healthcare resources.\u003c/p> \u003ca id=\"h3\" name=\"h3\">\u003c/a>\n\u003ch2>2 materials and methods\u003c/h2>\n\u003cp class=\"mb0\">\u003ca href=\"#fig2\">figure 2\u003c/a> shows the pipeline of the proposed system to provide a broader perspective to researchers and developers. the framework delineates the processing phases for the pipeline that utilizes social media content to diagnose asd. below, we present a comprehensive assessment of each step.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 2\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g002.jpg\" name=\"figure2\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g002.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g002.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g002.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g002.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g002.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g002.jpg\" alt=\"flowchart depicting a process for analyzing twitter data. it starts with social media avatars and a twitter api feeding into a word cloud for asd-related terms. next, preprocessing involves text cleaning, label encoding, and tokenization. this data feeds into deep learning models, including lstm, cnn-lstm, and ddqn. outputs are classified as asd or non-asd, with corresponding graphs indicating training and validation accuracy over epochs.\" id=\"fig2\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 2\u003c/b>. farmwork of asd system.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch3>2.1 dataset\u003c/h3>\n\u003cp class=\"mb0\">to help with the early diagnosis of asd by using proposed systems, the tasd-dataset includes comprehensive textual sequences that depict the everyday lives of children with and without asd. it offers new elements, including noise sensitivity, sharing interest, sign communication, and tiptoe flapping, it combines critical asd assessment aspects like attention response, word repetition, and emotional empathy, as shown in \u003ca href=\"#fig3\">figure 3\u003c/a>. parents may get detailed insights and better identify signs of autism spectrum disorder (asd) due to the deepening of certain behaviors. the dataset contains 172 tweets from the asd class and 158 non-asd tweets. \u003ca href=\"#fig4\">figure 4\u003c/a> shows the class of the dataset.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 3\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g003.jpg\" name=\"figure3\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g003.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g003.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g003.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g003.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g003.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g003.jpg\" alt=\"bar chart titled “feature frequencies” showing the count of various behaviors. “word repetition” has the highest frequency at 2.00. other features like “attention response,” “change reaction,” and “eye contact” have frequencies of 1.00 each.\" id=\"fig3\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 3\u003c/b>. features of the dataset.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline mb15\">\u003c/div>\n\u003cdiv class=\"imageheaders\">figure 4\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g004.jpg\" name=\"figure4\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g004.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g004.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g004.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g004.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g004.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g004.jpg\" alt=\"bar chart titled “number of tweets per class” compares tweet counts for asd and non-asd categories. asd has around 175 tweets, while non-asd has about 160 tweets.\" id=\"fig4\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 4\u003c/b>. label of the dataset.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch3>2.2 preprocessing\u003c/h3>\n\u003cp class=\"mb0\">text preprocessing is an essential step in the text processing process. words, sentences, and paragraphs can all be found in a text, which is defined as a meaningful sequence of characters. preprocessing methods feed text data to a proposed algorithm in a better form than in its natural state. a tweet can contain different viewpoints on the data it represents. tweets that have not been preprocessed are highly unstructured and contain redundant data. to address these issues, several steps are taken to preprocess tweets for detecting asd, as shown in \u003ca href=\"#fig5\">figure 5\u003c/a>.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 5\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g005.jpg\" name=\"figure5\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g005.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g005.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g005.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g005.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g005.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g005.jpg\" alt=\"flowchart depicting a text preprocessing workflow with three stages: text cleaning, label encoding, and tokenization and padding. the tokenization and padding section includes tokenizer, texts_to_sequences, and padding_sequences. arrows indicate process flow from left to right.\" id=\"fig5\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 5\u003c/b>. preprocessing asd text analysis.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch3>2.3 text cleaning\u003c/h3>\n\u003cp class=\"mb0\">the clean text preprocessing method is a significant step in text datasets because the text contains several extra contexts to preprocess and normalize raw text data for analysis. in these steps, the use is transformed to lowercase to guarantee consistency and prevent differentiation between “asd” and “non-asd.” subsequently, any characters that are not letters, numerals, or spaces are eliminated by a regular expression, so punctuation and other symbols that might create extraneous noise are removed. this method is ultimately applied to the ‘text’ column of the data frame, ensuring that all text elements are sanitized and prepared for feature extraction. \u003ca href=\"#fig6\">figure 6\u003c/a> displays the clean text process.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 6\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g006.jpg\" name=\"figure6\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g006.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g006.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g006.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g006.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g006.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g006.jpg\" alt=\"bar chart titled “text cleaning progression - sample 1” showing text length in characters for four stages: original, lowercased, no special chars, and trimmed. each bar’s length is nearly the same, around 150-200 characters.\" id=\"fig6\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 6\u003c/b>. clean text.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch3>2.4 label encoding\u003c/h3>\n\u003cp class=\"mb0\">the labelencoder method converts text class (asd and non-asd) into numbers, designating 0 for asd and 1 for non-asd. this transformation updates the classification effort by enabling the model to see the labels as numerical values instead of text. \u003ca href=\"#eq1\">equations 1\u003c/a>, \u003ca href=\"#eq2\">2\u003c/a> show the label encoding.\u003c/p>\n\u003cdiv id=\"eq1\" class=\"equationimageholder\">\u003cmath id=\"m1\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext mathvariant=\"italic\">yclassification\u003c/mtext>\u003cmo>∈\u003c/mo>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi mathvariant=\"italic\">asd\u003c/mi>\u003cmo>,\u003c/mo>\u003cmtext mathvariant=\"italic\">non\u003c/mtext>\u003cmo>−\u003c/mo>\u003cmi mathvariant=\"italic\">asd\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmtext mathvariant=\"italic\">then\u003c/mtext>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>1\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq19\" class=\"equationimageholder\">\u003cmath id=\"m2\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmi>y\u003c/mi>\u003cmo>=\u003c/mo>\u003cmtext mathvariant=\"italic\">labelencoder\u003c/mtext>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmtext mathvariant=\"italic\">yclassifcation\u003c/mtext>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>→\u003c/mo>\u003cmi>y\u003c/mi>\u003cmo>∈\u003c/mo>\u003cmo stretchy=\"true\">{\u003c/mo>\u003cmn>0\u003c/mn>\u003cmo>,\u003c/mo>\u003cmn>1\u003c/mn>\u003cmo stretchy=\"true\">}\u003c/mo>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>2\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003ch3>2.5 tokenization and padding\u003c/h3>\n\u003cp class=\"mb0\">tokenization and padding are essential nlp preprocessing procedures that transform unprocessed text into a numerical representation appropriate for machine learning models, particularly neural networks. \u003ca href=\"#fig7\">figure 7\u003c/a> shows the tokenization and padding \u003ca href=\"#eq3\">equation 3\u003c/a>.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 7\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g007.jpg\" name=\"figure7\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g007.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g007.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g007.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g007.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g007.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g007.jpg\" alt=\"sample text tokenization and padding process with three horizontal bar graphs. the first graph shows original text words. the second graph illustrates the tokenized sequence using word indexes with varying heights. the third graph shows a padded sequence with a fixed length of twenty, ensuring uniform token index lengths. the indexes used are rearranged with zero padding.\" id=\"fig7\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 7\u003c/b>. sample of text tokenization and padding.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch4>2.5.1 tokenizer\u003c/h4>\n\u003cp class=\"mb0\">tokenizer procedures transform textual data into a numerical representation suitable for input into neural networks. they convert a text corpus into integer sequences, assigning a distinct index to each unique word according to its frequency, as shown in \u003ca href=\"#eq3\">equation 3\u003c/a>. the tokenizer processing is shown in \u003ca href=\"#fig8\">figure 8\u003c/a>.\u003c/p>\n\u003cdiv id=\"eq2\" class=\"equationimageholder\">\u003cmath id=\"m3\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext mathvariant=\"italic\">index\u003c/mtext>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>w\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>=\u003c/mo>\u003cmsub>\u003cmo mathvariant=\"italic\">rank\u003c/mo>\u003cmi>f\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>w\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmtext mathvariant=\"italic\">if\u003c/mtext>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmsub>\u003cmo mathvariant=\"italic\">rank\u003c/mo>\u003cmi>f\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>w\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>≤\u003c/mo>\u003cmi>v\u003c/mi>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>3\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 8\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g008.jpg\" name=\"figure8\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g008.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g008.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g008.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g008.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g008.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g008.jpg\" alt=\"three bar charts illustrate text data analysis. chart a shows the top 20 most frequent words with “to” being the highest. chart b depicts sequence length distribution before padding, peaking at around 20 tokens. chart c displays sequence lengths post-padding, fixed at 200 tokens, appearing as a single line at the 200 mark.\" id=\"fig8\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 8\u003c/b>. tokenizer analysis: word frequencies and sequence lengths.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">where \u003cmath id=\"m4\">\u003cmsub>\u003cmo mathvariant=\"italic\">rank\u003c/mo>\u003cmi>f\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>w\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003c/math>is rank \u003cmath id=\"m5\">\u003cmi>w\u003c/mi>\u003c/math> frequency \u003cmath id=\"m6\">\u003cmi>f\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>w\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/math> and \u003cmath id=\"m7\">\u003cmi>v\u003c/mi>\u003c/math> is the maximum number of words.\u003c/p>\n\u003ch4>2.5.2 fit texts\u003c/h4>\n\u003cp class=\"mb0\">this phase is crucial for transforming unprocessed text into numerical sequences suitable for input into the proposed system.\u003c/p>\n\u003ch4>2.5.3 texts_to_sequences\u003c/h4>\n\u003cp class=\"mb0\">to convert unprocessed text input into sequences of word indices according to the mapping acquired via as shown in \u003ca href=\"#eq4\">equation 4\u003c/a>.\u003c/p>\n\u003cdiv id=\"eq3\" class=\"equationimageholder\">\u003cmath id=\"m8\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext mathvariant=\"italic\">sequence\u003c/mtext>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>t\u003c/mi>\u003cmi>i\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>=\u003c/mo>\u003cmo stretchy=\"true\">[\u003c/mo>\u003cmtext mathvariant=\"italic\">index\u003c/mtext>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmn>1\u003c/mn>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>,\u003c/mo>\u003cmtext mathvariant=\"italic\">index\u003c/mtext>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmn>2\u003c/mn>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>,\u003c/mo>\u003cmo>…\u003c/mo>\u003cmo>…\u003c/mo>\u003cmo>…\u003c/mo>\u003cmo>,\u003c/mo>\u003cmtext mathvariant=\"italic\">index\u003c/mtext>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmi>m\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo stretchy=\"true\">]\u003c/mo>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>4\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cp class=\"mb0\">where is the \u003cmath id=\"m9\">\u003cmsub>\u003cmi>t\u003c/mi>\u003cmi>i\u003c/mi>\u003c/msub>\u003c/math> is the sentence of the text contained, and \u003cmath id=\"m10\">\u003cmi>w\u003c/mi>\u003c/math> is the words of the text, whereas the \u003cmath id=\"m11\">\u003cmtext mathvariant=\"italic\">index\u003c/mtext>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmn>1\u003c/mn>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/math> is an index of the words in the context.\u003c/p>\n\u003ch4>2.5.4 padding_sequences\u003c/h4>\n\u003cp class=\"mb0\">normalize sequence lengths, which may differ post-tokenization, by padding shorter sequences and truncating larger ones to a predetermined length as shown in \u003ca href=\"#eq5\">equation 5\u003c/a>. the padding and truncated b are fixed on the length. \u003cmath id=\"m12\">\u003cmi>l\u003c/mi>\u003cmo>=\u003c/mo>\u003cmn>200\u003c/mn>\u003c/math>. the padding processing is shown in \u003ca href=\"#fig7\">figure 7\u003c/a>.\u003c/p>\n\u003cdiv id=\"eq4\" class=\"equationimageholder\">\u003cmath id=\"m13\">\u003cmi>x\u003c/mi>\u003cmo>=\u003c/mo>\u003cmo>∣\u003c/mo>\u003cmrow>\u003cmtable displaystyle=\"true\">\u003cmtr>\u003cmtd>\u003cmsub>\u003cmi>x\u003c/mi>\u003cmn>1\u003c/mn>\u003c/msub>\u003c/mtd>\u003c/mtr>\u003cmtr>\u003cmtd>\u003cmsub>\u003cmi>x\u003c/mi>\u003cmn>2\u003c/mn>\u003c/msub>\u003c/mtd>\u003c/mtr>\u003cmtr>\u003cmtd>\u003cmtable>\u003cmtr>\u003cmtd>\u003cmo>.\u003c/mo>\u003c/mtd>\u003c/mtr>\u003cmtr>\u003cmtd>\u003cmo>.\u003c/mo>\u003c/mtd>\u003c/mtr>\u003cmtr>\u003cmtd>\u003cmo>.\u003c/mo>\u003c/mtd>\u003c/mtr>\u003cmtr>\u003cmtd>\u003cmo>.\u003c/mo>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/mtd>\u003c/mtr>\u003cmtr>\u003cmtd>\u003cmi>y\u003c/mi>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/mrow>\u003cmo>∣\u003c/mo>\u003cmo>∈\u003c/mo>\u003cmsup>\u003cmi>ℝ\u003c/mi>\u003cmi mathvariant=\"italic\">nxl\u003c/mi>\u003c/msup>\u003cmtext>    (5)\u003c/mtext>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cp class=\"mb0\">where \u003cmath id=\"m14\">\u003cmi>x\u003c/mi>\u003c/math> is features contain padding and are tokenized, \u003cmath id=\"m15\">\u003cmi>l\u003c/mi>\u003c/math> is the length of the vector. the number of texts is indicated \u003cmath id=\"m16\">\u003cmi>n\u003c/mi>\u003c/math>, and \u003cmath id=\"m17\">\u003cmo>∈\u003c/mo>\u003cmsup>\u003cmi>ℝ\u003c/mi>\u003cmi mathvariant=\"italic\">nxl\u003c/mi>\u003c/msup>\u003c/math> is matrix lues.\u003c/p>\n\u003ch3>2.6 proposed systems\u003c/h3>\n\u003ch4>2.6.1 convolutional neural networks\u003c/h4>\n\u003cp class=\"mb0\">the cnn model is at the core of all advanced machine learning and deep learning applications. they can successfully address text classification, image recognition, object identification, and semantic segmentation. using the same method with a task as different as natural language processing is counterintuitive (\u003ca href=\"#ref7\">7\u003c/a>). the structure is presented in \u003ca href=\"#fig9\">figure 9\u003c/a>. \u003ca href=\"#eq6\">equation 6\u003c/a> presents the convolution layer of cnn.\u003c/p>\n\u003cdiv id=\"eq5\" class=\"equationimageholder\">\u003cmath id=\"m18\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmi>o\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo>,\u003c/mo>\u003cmi>y\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>=\u003c/mo>\u003cmunderover>\u003cmo movablelimits=\"false\">∑\u003c/mo>\u003cmrow>\u003cmi>i\u003c/mi>\u003cmo>=\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003cmi>h\u003c/mi>\u003c/munderover>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmunderover>\u003cmo movablelimits=\"false\">∑\u003c/mo>\u003cmrow>\u003cmi>j\u003c/mi>\u003cmo>=\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003cmi>w\u003c/mi>\u003c/munderover>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmi>i\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi>i\u003c/mi>\u003cmo>,\u003c/mo>\u003cmi>y\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi>j\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>∗\u003c/mo>\u003cmi>k\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>i\u003c/mi>\u003cmo>,\u003c/mo>\u003cmi>j\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>+\u003c/mo>\u003cmi>b\u003c/mi>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>6\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 9\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g009.jpg\" name=\"figure9\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g009.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g009.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g009.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g009.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g009.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g009.jpg\" alt=\"flowchart depicting a text classification process using convolutional neural networks. it starts with a sentence matrix representation. colored blocks denote convolution results with filter sizes of two, three, and four. the results undergo one-max pooling, then concatenate into a single vector. finally, the vector classifies into categories: information giving, information seeking, feature request, solution proposal, problem discovery, aspect evaluation, and others.\" id=\"fig9\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 9\u003c/b>. structure cnn.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">where the features of text \u003cmath id=\"m19\">\u003cmi>o\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo>,\u003c/mo>\u003cmi>y\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/math> the feature of the text is mapped by using.\u003cmath id=\"m20\">\u003cmi>i\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi>i\u003c/mi>\u003cmo>,\u003c/mo>\u003cmi>y\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi>j\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/math> is weighted by a neural network and \u003cmath id=\"m21\">\u003cmi>b\u003c/mi>\u003c/math> is biased to adjust the neural. the relu activation function is \u003ca href=\"#eq20\">equation 7\u003c/a>, the max pooling function is presented in \u003ca href=\"#eq6\">equation 8\u003c/a>. the dense layer is given in \u003ca href=\"#eq7\">equation 9\u003c/a>.\u003c/p>\n\u003cdiv id=\"eq20\" class=\"equationimageholder\">\u003cmath id=\"m22\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmi>f\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>=\u003c/mo>\u003cmi>max\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmn>0\u003c/mn>\u003cmo>,\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>7\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq6\" class=\"equationimageholder\">\u003cmath id=\"m23\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmi>o\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo>,\u003c/mo>\u003cmi>y\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>=\u003c/mo>\u003cmunderover>\u003cmo movablelimits=\"false\">∑\u003c/mo>\u003cmrow>\u003cmi>i\u003c/mi>\u003cmo>=\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003cmi>h\u003c/mi>\u003c/munderover>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmunderover>\u003cmo movablelimits=\"false\">∑\u003c/mo>\u003cmrow>\u003cmi>j\u003c/mi>\u003cmo>=\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003cmi>w\u003c/mi>\u003c/munderover>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmi>i\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi>i\u003c/mi>\u003cmo>,\u003c/mo>\u003cmi>y\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi>j\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>∗\u003c/mo>\u003cmi>k\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>i\u003c/mi>\u003cmo>,\u003c/mo>\u003cmi>j\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>+\u003c/mo>\u003cmi>b\u003c/mi>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>8\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq7\" class=\"equationimageholder\">\u003cmath id=\"m24\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmi mathvariant=\"normal\">o\u003c/mi>\u003cmo>=\u003c/mo>\u003cmi>w\u003c/mi>\u003cmo>·\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi>b\u003c/mi>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>9\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003ch4>2.6.2 long short-term memory network\u003c/h4>\n\u003cp class=\"mb0\">an lstm network is an advanced form of a sequential neural network. it fixes the problem of rnn gradients fading over time. rnns often handle long-term storage. at a high level, the operation of an lstm is comparable to that of a single rnn neuron. the inner workings of the lstm network are outlined in this section. the lstm consists of three parts, each performing a particular function, as seen in \u003ca href=\"#fig10\">figure 10\u003c/a> below. in the first step, it is decided whether the information from the previous time stamp is significant enough to be saved or if it is harmless enough to be deleted. in the second step, the cell will try to acquire new information by analyzing the data that has been presented to it. in the third and final step, the cell incorporates the data from the most recent time stamp into the data stored in the next time stamp. these three components constitute what is referred to as a gate for an lstm cell. the “forget” gate comes first, followed by the “input” section, and then the “output” section is used to define the last portion as shown in \u003ca href=\"#eq10\">equations 10\u003c/a>– \u003ca href=\"#eq14\">14\u003c/a>.\u003c/p>\n\u003cdiv id=\"eq8\" class=\"equationimageholder\">\u003cmath id=\"m25\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext>forget gate\u003c/mtext>\u003cmo>:\u003c/mo>\u003cmsub>\u003cmi>f\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>=\u003c/mo>\u003cmi>σ\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmi>f\u003c/mi>\u003c/msub>\u003cmo>.\u003c/mo>\u003cmsub>\u003cmi>x\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmi>f\u003c/mi>\u003c/msub>\u003cmo>.\u003c/mo>\u003cmsub>\u003cmi>h\u003c/mi>\u003cmrow>\u003cmi>t\u003c/mi>\u003cmo>−\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmsub>\u003cmi>b\u003c/mi>\u003cmi>f\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>10\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq9\" class=\"equationimageholder\">\u003cmath id=\"m26\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext>input gate\u003c/mtext>\u003cmo>:\u003c/mo>\u003cmsub>\u003cmi>i\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>=\u003c/mo>\u003cmi>σ\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmi>c\u003c/mi>\u003c/msub>\u003cmo>.\u003c/mo>\u003cmsub>\u003cmi>x\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmi>i\u003c/mi>\u003c/msub>\u003cmo>.\u003c/mo>\u003cmsub>\u003cmi>h\u003c/mi>\u003cmrow>\u003cmi>t\u003c/mi>\u003cmo>−\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmsub>\u003cmi>b\u003c/mi>\u003cmi>i\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>11\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq10\" class=\"equationimageholder\">\u003cmath id=\"m27\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext>cell gate\u003c/mtext>\u003cmo>:\u003c/mo>\u003cmsub>\u003cmi>c\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>=\u003c/mo>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmi>f\u003c/mi>\u003c/msub>\u003cmo>∗\u003c/mo>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmo>.\u003c/mo>\u003cmsub>\u003cmi>h\u003c/mi>\u003cmrow>\u003cmi>t\u003c/mi>\u003cmo>−\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003c/msub>\u003cmo>,\u003c/mo>\u003cmsub>\u003cmi>x\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmsub>\u003cmi>b\u003c/mi>\u003cmi>f\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>12\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq11\" class=\"equationimageholder\">\u003cmath id=\"m28\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext>output gate\u003c/mtext>\u003cmo>:\u003c/mo>\u003cmsub>\u003cmi>o\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>=\u003c/mo>\u003cmi>σ\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmi>o\u003c/mi>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmsub>\u003cmi>x\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmi>o\u003c/mi>\u003c/msub>\u003cmo>.\u003c/mo>\u003cmsub>\u003cmi>h\u003c/mi>\u003cmrow>\u003cmi>t\u003c/mi>\u003cmo>−\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmsub>\u003cmi>v\u003c/mi>\u003cmi>o\u003c/mi>\u003c/msub>\u003cmo>.\u003c/mo>\u003cmsub>\u003cmi>c\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmsub>\u003cmi>b\u003c/mi>\u003cmi>o\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>13\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq12\" class=\"equationimageholder\">\u003cmath id=\"m29\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext>hidden layer\u003c/mtext>\u003cmo>:\u003c/mo>\u003cmsub>\u003cmi>h\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>=\u003c/mo>\u003cmsub>\u003cmi>o\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmi>tanh\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>c\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>14\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 10\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g010.jpg\" name=\"figure10\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g010.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g010.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g010.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g010.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g010.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g010.jpg\" alt=\"flowchart of an lstm neural network model with multiple layers. the input layer feeds into 25 features, which connect to lstm layer 1 with 128 neurons. relu activation leads to lstm layer 2 with 64 neurons, followed by a sigmoid activation for binary classification into class 0 or class 1.\" id=\"fig10\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 10\u003c/b>. lstm model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb15\">in \u003ca href=\"#fig10\">figure 10\u003c/a>, \u003cmath id=\"m30\">\u003cmsub>\u003cmi>c\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003c/math> represent the prior and current states of the cell, respectively. both \u003cmath id=\"m31\">\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmsub>\u003cmi>h\u003c/mi>\u003cmrow>\u003cmi>t\u003c/mi>\u003cmo>−\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003c/msub>\u003c/math> and \u003cmath id=\"m32\">\u003cmi>h\u003c/mi>\u003c/math> represents the cell output that was processed before the one now being processed. it is common practice to disregard \u003cmath id=\"m33\">\u003cmsub>\u003cmi>f\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003c/math> as a gate, even though it is the input gate. the output of a sigmoid gate is symbolized here by \u003cmath id=\"m34\">\u003cmsub>\u003cmi>o\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003c/math>. the cable that connects the cell gates is where all the data collected by the cell gates is sent to and from \u003cmath id=\"m35\">\u003cmi>c\u003c/mi>\u003c/math>. the \u003cmath id=\"m36\">\u003cmsub>\u003cmi>f\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003c/math> layer decides to remember anything, and the\u003cmath id=\"m37\">\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmsub>\u003cmi>f\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmtext mathvariant=\"italic\">the\u003c/mtext>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003c/math>output is multiplied by c to do so (t-1). after that, c (t-1) is multiplied by the product of the sigmoid layer gate and the tanh layer gate, and the output h t is generated by point-wise multiplication of \u003cmath id=\"m38\">\u003cmsub>\u003cmi>o\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003c/math> and tanh.\u003c/p>\n\u003cp class=\"mb0\">the lstm architecture is intended to capture long-term relationships in twitter text data. the preprocessing converts input words that start with an embedding layer into 128-dimensional dense vectors. the lstm layer with 64 units is then used to mitigate overfitting, integrating dropout and recurrent dropout with 0.5. an l2 regularization term is further included in the lstm and output dense layer. \u003ca href=\"#tab1\">table 1\u003c/a> shows parameters of the lstm model.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">table 1\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t001.jpg\" name=\"table1\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t001.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t001.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t001.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t001.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t001.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t001.jpg\" alt=\"www.frontiersin.org\" id=\"tab1\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>table 1\u003c/b>. lstm parameters model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch4>2.6.3 cnn-lstm model\u003c/h4>\n\u003cp class=\"mb0\">the cnn-lstm model is a hybrid architecture that combines convolutional neural networks (cnn) for spatial feature extraction and long short-term memory (lstm) networks for sequential learning, making it highly effective for analyzing text data such as tweets. the model begins with an embedding layer that transforms each word into a 256-dimensional dense vector, capturing the semantic meaning of words. this is followed by a 1d convolutional layer with 64 filters and a kernel size of 5, which scans through the text to detect local patterns and n-gram features such as common word combinations or phrases often associated with asd. a batch normalization layer is applied to stabilize and accelerate training, followed by a max pooling layer that reduces the dimensionality and computational load by selecting the most prominent features. a dropout layer with a rate of 0.5 is then used to prevent overfitting by randomly deactivating some neurons during training. the output is passed into a 64-unit lstm layer that captures the temporal dependencies and contextual relationships across the tweet sequence. finally, a dense layer with sigmoid activation performs binary classification to predict whether the tweet indicates asd-related content. the model is trained using the adam optimizer, binary cross-entropy loss, class weights, and regularization to handle imbalanced data and improve generalization. the critical parameters of the cnn-lstm model are displayed in \u003ca href=\"#tab2\">table 2\u003c/a>.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">table 2\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t002.jpg\" name=\"table2\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t002.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t002.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t002.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t002.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t002.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t002.jpg\" alt=\"www.frontiersin.org\" id=\"tab2\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>table 2\u003c/b>. cnn-lstm parameters.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch4>2.6.4 double deep q-network (ddqn-inspired)\u003c/h4>\n\u003cp class=\"mb15\">the double q-learning model was introduced by h. van hasselt in 2010, addressing the issue of significant overestimations of action value (q-value) inherent in traditional q-learning. in fundamental q-learning, the agent’s optimal strategy is consistently to select the most advantageous action in any specific state. this concept’s premise is that the optimal action corresponds to the highest expected or estimated q-value. initially, the agent lacks any knowledge of the environment; it must first estimate q(s, a) and subsequently update these estimates with each iteration. the q-values exhibit considerable noise, leading to uncertainty about whether the action associated with the highest expected or estimated q-value is genuinely the optimal choice.\u003c/p>\n\u003cp class=\"mb0\">double q-learning employs two distinct action-value functions, q and q’, as estimators. even if q and q’ exhibit noise, this noise can be interpreted as a uniform distribution as shown \u003ca href=\"#fig11\">figure 11\u003c/a> the update procedure exhibits some variations compared to the basic version. the action selection and action evaluation processes are separated into two distinct maximum function estimators. shown in \u003ca href=\"#eq13\">equations 15\u003c/a>, \u003ca href=\"#eq16\">16\u003c/a>.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 11\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g011.jpg\" name=\"figure11\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g011.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g011.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g011.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g011.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g011.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g011.jpg\" alt=\"diagram illustrating the process of reinforcement learning with replay memory and q-networks. the replay memory outputs a mini-batch containing state, action, reward, and next state. this feeds into both the online and target q-networks. the online q-network outputs state-action pairs, which are used alongside the target q-network’s output in the loss function. a feedback loop connects the replay memory to the online q-network.\" id=\"fig11\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 11\u003c/b>. ddqn-inspired model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">let the vector of a neural network’s weights be represented by \u003ci>θ\u003c/i>. we establish two q-networks: the online q-network q (s, a; θ(t)) and the target q-network q (s, a; θ (t)). to be more specific, the training of q (s, a; \u003ci>Χ\u003c/i> (t)) is done by modifying the weights (t) at time slot t in relation to the goal value y(t).\u003c/p>\n\u003cdiv id=\"eq13\" class=\"equationimageholder\">\u003cmath id=\"m39\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmi>y\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>t\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>=\u003c/mo>\u003cmi>g\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>t\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>+\u003c/mo>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>s\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo>,\u003c/mo>\u003cmtext>argmax\u003c/mtext>\u003cmi>q\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>s\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo>,\u003c/mo>\u003cmsup>\u003cmi>a\u003c/mi>\u003cmo>∗\u003c/mo>\u003c/msup>\u003cmo>;\u003c/mo>\u003cmi>θ\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>t\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>;\u003c/mo>\u003cmi>θ\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>t\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>15\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq14\" class=\"equationimageholder\">\u003cmath id=\"m40\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmi>y\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>t\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>=\u003c/mo>\u003cmi>g\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>t\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>+\u003c/mo>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>s\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo>,\u003c/mo>\u003cmtext>argmax\u003c/mtext>\u003cmi>q\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>s\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo>,\u003c/mo>\u003cmsup>\u003cmi>a\u003c/mi>\u003cmo>∗\u003c/mo>\u003c/msup>\u003cmo>;\u003c/mo>\u003cmi>θ\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>;\u003c/mo>\u003cmsub>\u003cmi>θ\u003c/mi>\u003cmrow>\u003cmi>i\u003c/mi>\u003cmo>−\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>16\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cp class=\"mb15\">the reinforcement learning mechanism integrates generative artificial intelligence for decision-making and prediction tasks, as shown in \u003ca href=\"#eq15\">equations 15\u003c/a>, \u003ca href=\"#eq16\">16\u003c/a>. this equation indicates the generative which produces the estimation or hypothesis at a given time \u003cmath id=\"m41\">\u003cmi>t\u003c/mi>\u003c/math>.\u003cmath id=\"m42\">\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmtext mathvariant=\"italic\">double\u003c/mtext>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmi>q\u003c/mi>\u003cmo>−\u003c/mo>\u003cmtext mathvariant=\"italic\">learning\u003c/mtext>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003c/math>used next state, whereas the s’ is exit state and \u003cmath id=\"m43\">\u003cmtext>argmax\u003c/mtext>\u003cmi>q\u003c/mi>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>s\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo>,\u003c/mo>\u003cmsup>\u003cmi>a\u003c/mi>\u003cmo>∗\u003c/mo>\u003c/msup>\u003cmo>;\u003c/mo>\u003cmi>θ\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>t\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/math> defined as the action of \u003cmath id=\"m44\">\u003cmsup>\u003cmi>a\u003c/mi>\u003cmo>∗\u003c/mo>\u003c/msup>\u003c/math> to maximize the predicted q-value based on the current parameters. to estimate the q-value of this selected action in the next state, the outer q-function q’ employs the older parameters. \u003cmath id=\"m45\">\u003cmsub>\u003cmi>θ\u003c/mi>\u003cmrow>\u003cmi>i\u003c/mi>\u003cmo>−\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003c/msub>\u003c/math>1, which helps reduce overestimation bias. this combination makes applications for predicting asd from social media content domains possible.\u003c/p>\n\u003cp class=\"mb0\">the ddqn model is used to classify asd and non-asd cases utilizing text data. the model utilizes a preprocessing step for text processing that encompasses data loading, cleaning (including lowercasing, removal of special characters, and normalization of spaces), and tokenization, constrained by a maximum vocabulary of 10,000 words and a sequence length of 200. the model architecture, drawing from the double deep q-network (ddqn) model comprises an input layer, an embedding layer with 256 dimensions, and two parallel lstm branches, each containing 64 units, a dropout rate of 0.5, and l2 regularization to capture sequential patterns effectively. the model uses the adam optimizer with a learning rate of 1e-4 and employs binary cross-entropy loss. it is trained for 30 epochs, incorporating early stopping and learning rate reduction callbacks to mitigate overfitting. parameters of ddqn-inspired are shown in \u003ca href=\"#tab3\">table 3\u003c/a>.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">table 3\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t003.jpg\" name=\"table3\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t003.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t003.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t003.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t003.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t003.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t003.jpg\" alt=\"www.frontiersin.org\" id=\"tab3\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>table 3\u003c/b>. parameters of ddqn-inspired.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div> \u003ca id=\"h4\" name=\"h4\">\u003c/a>\n\u003ch2>3 performance of the framework\u003c/h2>\n\u003ch3>3.1 performance of lstm\u003c/h3>\n\u003cp class=\"mb0\">\u003ca href=\"#fig12\">figure 12\u003c/a> presents the accuracy and loss metrics used to train and validate an lstm model over 30 epochs. the validation accuracy of the lstm model, displayed in red, begins at a lower value and increases to about 81%. the blue line in the accuracy plot (a) shows the training accuracy of the lstm model; it increases gradually from around 50% to almost 99%, showing that the model learns the training data well over time. the plot (b) shows the loss of the lstm model; the blue line represents the training loss, which drops gradually from around 0.7 to less than 0.2, suggesting that the model is getting a better fit to the training data. meanwhile, the red validation loss line declines from around 0.7 to about 0.3. while the training loss continues to grow, the validation loss reaches a level and exhibits small oscillations, suggesting that the model’s generalizability may stabilize.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 12\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g012.jpg\" name=\"figure12\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g012.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g012.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g012.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g012.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g012.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g012.jpg\" alt=\"two line graphs depict an lstm model’s performance over 30 epochs. the left graph shows accuracy, with training accuracy rising from 0.5 to 0.9, while validation accuracy fluctuates around 0.8. the right graph displays loss, where training loss decreases from 0.7 to 0.1, and validation loss reduces from 0.7 to 0.3. both graphs feature blue lines for training metrics and red lines for validation metrics.\" id=\"fig12\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 12\u003c/b>. performance of the lstm model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">the roc curve illustrated in \u003ca href=\"#fig13\">figure 13\u003c/a> shows the efficacy of the lstm model in differentiating between the classes. the graph illustrates the tp rate (sensitivity) in relation to the fp rate across different threshold levels. the lstm model attains an auc of 0.95, demonstrating exceptional classification capability. the auc of 1.0, but a result of 0.5 indicates random chance.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 13\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g013.jpg\" name=\"figure13\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g013.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g013.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g013.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g013.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g013.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g013.jpg\" alt=\"roc curve for an lstm model showing the trade-off between true positive rate and false positive rate. the curve bends towards the top-left corner, with an area under the curve (auc) of 0.95, indicating high model performance. a diagonal dashed line represents random chance.\" id=\"fig13\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 13\u003c/b>. roc of the lstm model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch3>3.2 performance of the cnn-lstm model\u003c/h3>\n\u003cp class=\"mb0\">\u003ca href=\"#fig14\">figure 14\u003c/a> presents plots illustrating the performance of a cnn-lstm model over 25 epochs, showing its training and validation metrics for accuracy and loss. the accuracy plot (a) illustrates the training accuracy (blue line), which increases progressively from approximately 51.42% to nearly 99.53%, indicating effective learning from the training data. in contrast, the validation accuracy (red line) rises to about 83.02% with some variability, indicating satisfactory but imperfect generalization. the loss plot (b) shows the training loss (blue line) declining steadily from 0.7140 to below 0.0760, indicating enhanced model fit. in contrast, the validation loss (red line) decreases from 0.7130 to approximately 0.3530, with a slight decline toward the conclusion. this notification indicates that the cnn-lstm model demonstrates efficient learning, as evidenced by the difference between the training and validation measures.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 14\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g014.jpg\" name=\"figure14\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g014.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g014.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g014.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g014.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g014.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g014.jpg\" alt=\"two line graphs show cnn-lstm model performance. the left graph displays training and validation accuracy over 25 epochs. training accuracy improves significantly, surpassing validation accuracy, which fluctuates. the right graph depicts training and validation loss over the same epochs. training loss decreases sharply, while validation loss also reduces but stabilizes after an initial drop.\" id=\"fig14\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 14\u003c/b>. performance of the lstm model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">\u003ca href=\"#fig15\">figure 15\u003c/a> illustrates the roc curve for the cnn-lstm model, illustrating its classification performance at various thresholds. the graph illustrates the tp rate (sensitivity) in relation to the fp rate, with the auc recorded at 92%. the elevated auc value indicates the model has robust discriminative capability in differentiating between the asd and non-asd classes. the roc ascends rapidly toward the top-left corner, as seen in the figure, indicating a high tp rate with few false positives.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 15\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g015.jpg\" name=\"figure15\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g015.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g015.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g015.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g015.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g015.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g015.jpg\" alt=\"roc curve for a cnn_lstm model, showing the true positive rate against the false positive rate. the curve is above the diagonal, with an area under the curve (auc) of 0.92, indicating strong model performance.\" id=\"fig15\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 15\u003c/b>. roc of the cnn-lstm model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch3>3.3 performance of ddqn-inspired model\u003c/h3>\n\u003cp class=\"mb0\">graphs 16 illustrate the performance of a ddqn throughout 30 epochs. the accuracy plot (a) demonstrates that the training accuracy increases from around 58.02% to almost 98.58%, indicating the ddqn model successful learning from the training data over time. the validation accuracy of the ddqn is about 87, showing the best performance compared to different models like lstm and cnn-lstm. the plot (b) illustrates that the training loss decreases from about 0.8155 to around 0.1477, indicating a robust fit to the training data. the validation loss begins at 0.3831 with many fluctuations throughout (\u003ca href=\"#fig16\">figure 16\u003c/a>).\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 16\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g016.jpg\" name=\"figure16\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g016.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g016.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g016.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g016.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g016.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g016.jpg\" alt=\"two graphs display the performance of a ddqn_t model over 30 epochs. graph (a) shows training accuracy in blue and validation accuracy in red, both improving over time. graph (b) illustrates training loss in blue and validation loss in red, both decreasing with some fluctuations.\" id=\"fig16\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 16\u003c/b>. performance of the \u003ci>ddqn-inspired\u003c/i> model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">\u003ca href=\"#fig17\">figure 17\u003c/a> shows the roc curve for the ddqn model; it shows a visual representation of its classification capability, with the curve toward the top-left corner, indicating strong predictive power. the auc value of the ddqn model is 96%, demonstrating that the model can distinguish between the positive and negative classes.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 17\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g017.jpg\" name=\"figure17\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g017.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g017.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g017.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g017.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g017.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g017.jpg\" alt=\"receiver operating characteristic (roc) curve illustrating a ddqn-inspired model performance. the curve shows the trade-off between true positive rate and false positive rate with an area under the curve (auc) of 0.96, indicating high accuracy.\" id=\"fig17\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 17\u003c/b>. roc \u003ci>ddqn-inspired model.\u003c/i>\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div> \u003ca id=\"h5\" name=\"h5\">\u003c/a>\n\u003ch2>4 experiment and discussion results\u003c/h2>\n\u003cp class=\"mb0\">both the jupyter deep learning framework and the windows 10 operating system were utilized during the testing process. experiments were conducted using a machine with 16 gigabytes of ram and an intel core i7 central processing unit. the input dimensions of the experiment were a standard text dataset collected from the twitter api related to asd. the test was utilized in our database, while the remaining 20% was used as part of our validation set. the three dl models, namely lstm, cnn-lstm, and ddqn-inspired, were proposed for detecting asd from social media content.\u003c/p>\n\u003ch3>4.1 measuring the model’s performance\u003c/h3>\n\u003cp class=\"mb0\">sensitivity, specificity, accuracy, recall, and f1 scores are assessment measures used to determine how successfully the algorithms identify asd. the related equations from \u003ca href=\"#eq17\">17\u003c/a> to \u003ca href=\"#eq21\">21\u003c/a>:\u003c/p>\n\u003cdiv id=\"eq15\" class=\"equationimageholder\">\u003cmath id=\"m46\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext mathvariant=\"italic\">accuracy\u003c/mtext>\u003cmo>=\u003c/mo>\u003cmfrac>\u003cmrow>\u003cmi mathvariant=\"italic\">tp\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi mathvariant=\"italic\">tn\u003c/mi>\u003c/mrow>\u003cmrow>\u003cmi mathvariant=\"italic\">tp\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi mathvariant=\"italic\">fp\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi mathvariant=\"italic\">fn\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi mathvariant=\"italic\">tn\u003c/mi>\u003c/mrow>\u003c/mfrac>\u003cmo>×\u003c/mo>\u003cmn>100\u003c/mn>\u003cmo>%\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>17\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq16\" class=\"equationimageholder\">\u003cmath id=\"m47\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext mathvariant=\"italic\">sensitivity\u003c/mtext>\u003cmo>=\u003c/mo>\u003cmfrac>\u003cmi mathvariant=\"italic\">tp\u003c/mi>\u003cmrow>\u003cmi mathvariant=\"italic\">tp\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi mathvariant=\"italic\">fn\u003c/mi>\u003c/mrow>\u003c/mfrac>\u003cmo>×\u003c/mo>\u003cmn>100\u003c/mn>\u003cmo>%\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>18\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq17\" class=\"equationimageholder\">\u003cmath id=\"m48\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext mathvariant=\"italic\">precision\u003c/mtext>\u003cmo>=\u003c/mo>\u003cmfrac>\u003cmi mathvariant=\"italic\">tp\u003c/mi>\u003cmrow>\u003cmi mathvariant=\"italic\">tp\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi mathvariant=\"italic\">fp\u003c/mi>\u003c/mrow>\u003c/mfrac>\u003cmo>×\u003c/mo>\u003cmn>100\u003c/mn>\u003cmo>%\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>19\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq21\" class=\"equationimageholder\">\u003cmath id=\"m49\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext mathvariant=\"italic\">specificity\u003c/mtext>\u003cmo>=\u003c/mo>\u003cmfrac>\u003cmi mathvariant=\"italic\">tn\u003c/mi>\u003cmrow>\u003cmi mathvariant=\"italic\">tn\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi mathvariant=\"italic\">fp\u003c/mi>\u003c/mrow>\u003c/mfrac>\u003cmo>×\u003c/mo>\u003cmn>100\u003c/mn>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>20\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq18\" class=\"equationimageholder\">\u003cmath id=\"m50\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmi>f\u003c/mi>\u003cmn>1\u003c/mn>\u003cmo>−\u003c/mo>\u003cmtext mathvariant=\"italic\">score\u003c/mtext>\u003cmo>=\u003c/mo>\u003cmn>2\u003c/mn>\u003cmo>∗\u003c/mo>\u003cmfrac>\u003cmrow>\u003cmtext mathvariant=\"italic\">precision\u003c/mtext>\u003cmo>×\u003c/mo>\u003cmtext mathvariant=\"italic\">sensitivity\u003c/mtext>\u003c/mrow>\u003cmrow>\u003cmtext mathvariant=\"italic\">precision\u003c/mtext>\u003cmo>+\u003c/mo>\u003cmtext mathvariant=\"italic\">sensitivity\u003c/mtext>\u003c/mrow>\u003c/mfrac>\u003cmo>×\u003c/mo>\u003cmn>100\u003c/mn>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>21\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003ch3>4.2 result of the lstm model\u003c/h3>\n\u003cp class=\"mb0\">the classification lstm model, presented in \u003ca href=\"#tab4\">table 4\u003c/a>, summarizes its performance in differentiating between asd and non-asd patients, attaining an overall accuracy of 81%. the lstm model demonstrates in asd class a precision of 91%, indicating a high accuracy in identifying predicted asd cases. the lstm with recall metric scored 77% and an f1-score of 82% for detecting the asd class. the lstm model with non-asd class demonstrates a precision of 71%, a recall of 89%, and an f1-score of 79%, to identify non-asd cases. the macro average of the lstm model for all metrics is (precision: 81%, recall: 82%, f1-score: 81%). lstm model is recognized for its efficiency and scalability as a model for social media content.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">table 4\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t004.jpg\" name=\"table4\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t004.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t004.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t004.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t004.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t004.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t004.jpg\" alt=\"www.frontiersin.org\" id=\"tab4\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>table 4\u003c/b>. lstm results.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">the confusion matrix for the lstm model is provided in \u003ca href=\"#fig18\">figure 18\u003c/a>. it is presented in a clear manner. among the confirmed asd cases, 29 were accurately identified as asd, whereas 10 were incorrectly classified as non-asd, indicating strong performance with minor errors. in the true non-asd cases, 25 were correctly identified, while 3 were misclassified as asd, suggesting a generally effective detection process. the deep blue and light shades produce a tranquil visual, illustrating the model’s balanced approach in classifying the 67 total instances, demonstrating notable strength in identifying non-asd cases, while exhibiting marginally lower accuracy for asd. this matrix effectively illustrates the lstm model’s systematic approach to managing sequential data, such as text or time-series inputs, in a clear and comprehensible manner.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 18\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g018.jpg\" name=\"figure18\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g018.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g018.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g018.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g018.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g018.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g018.jpg\" alt=\"confusion matrix for lstm model showing true labels versus predicted labels. the matrix includes 29 true positives for asd, 25 true negatives for non-asd, 10 false positives, and 3 false negatives. a color gradient represents value intensity.\" id=\"fig18\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 18\u003c/b>. lstm model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch3>4.3 result of the cnn-lstm model\u003c/h3>\n\u003cp class=\"mb0\">\u003ca href=\"#tab5\">table 5\u003c/a> displays the cnn-lstm model’s performance in distinguishing between asd and non-asd classes. the cnn-lstm model attained an overall accuracy of 85% across the dataset. in the asd label, a precision of 91% was achieved, a high percentage for predicting asd cases that were accurately recognized. the recall indicates that the model identified 82% of all genuine asd cases, resulting in an f1 score of 86%, better than the recall metric. the cnn-lstm model attained 78% accuracy, 89% recall, and an 83% f1 score for the non-asd class. the macro average, representing the unweighted mean of precision, recall, and f1 score across both classes, was 85, 86, and 85%, respectively. the findings indicate that the cnn-lstm model performs satisfactorily, exhibiting a marginally superior capacity to identify asd cases relative to non-asd cases accurately.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">table 5\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t005.jpg\" name=\"table5\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t005.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t005.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t005.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t005.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t005.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t005.jpg\" alt=\"www.frontiersin.org\" id=\"tab5\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>table 5\u003c/b>. results of the cnn-lstm model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">the confusion matrix of a cnn-lstm model is presented in \u003ca href=\"#fig19\">figure 19\u003c/a>, for classifying instances into asd and non-asd. the matrix is structured with true labels on the vertical axis and predicted labels on the horizontal axis, providing a clear summary of the model’s classification outcomes. the matrix shows that out of the instances truly labeled as asd, the model correctly predicted 32 as asd tp while 7 were incorrectly classified as non-asd fn. for the instances truly labeled as non-asd, the model accurately identified 25 as non-asd tn but 3 were misclassified as asd fp. this indicates that the model demonstrates a relatively strong ability to correctly identify asd and non-asd cases, with higher accuracy for true positives (32 out of 39 asd cases) and true negatives (25 out of 28 non-asd cases). overall, the model exhibits promising performance with minimal misclassification errors.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 19\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g019.jpg\" name=\"figure19\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g019.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g019.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g019.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g019.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g019.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g019.jpg\" alt=\"confusion matrix for cnn_lstm_model with predicted labels on the x-axis and true labels on the y-axis. it shows 32 true positives, 7 false negatives, 3 false positives, and 25 true negatives. a gradient bar on the right indicates color intensity from light to dark blue, representing increasing values from 0 to 30.\" id=\"fig19\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 19\u003c/b>. results of cnn-lstm model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch3>4.4 results of double deep q-network\u003c/h3>\n\u003cp class=\"mb0\">the findings of the ddqn model are shown in \u003ca href=\"#tab6\">table 6\u003c/a>, achieving a high precision of 87% compared to the other models. this finding demonstrates the potential of the proposed ddqn approach for identifying asd based on social media content. ultimately, the proposed system was compared against the existing one using the same dataset. the proposed approach may assist physicians in detecting asd and conducting symptomology research in a natural environment, attaining an overall accuracy of 87. the model for the asd class shows a precision of 95%, a recall of 79%, and an f1-score of 87%, indicating robust efficacy in accurately identifying asd patients. the non-asd class has a precision of 77%, a recall of 96%, and an f1-score of 86%, indicating somewhat reduced accuracy with robust recall. the macro average measures (precision 87%, recall 88%, f1-score 87%) indicate performance across both classes.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">table 6\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t006.jpg\" name=\"table6\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t006.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t006.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t006.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t006.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t006.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t006.jpg\" alt=\"www.frontiersin.org\" id=\"tab6\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>table 6\u003c/b>. result of ddqn-inspired.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">the confusion matrix of the ddqn model is shown in \u003ca href=\"#fig20\">figure 20\u003c/a> for the classification task between asd and non-asd cases. for correct classification of asd cases, the model correctly classified 31 instances as asd, represented by the top-left quadrant (tp). however, the ddqn model, misclassified 8 instances misclassifying true asd cases as non-asd, shown in the top-right quadrant (fn). on the other hand, the ddqn showed the true non-asd cases, accurately identified 27 instances as non-asd, depicted in the bottom-right quadrant (tn). at the same time, 1 instance was incorrectly labeled as asd, as shown in the bottom-left quadrant (fp). the confusion matrix of ddqn model highlights that it performs well overall, with a strong ability to correctly identify both asd and non-asd cases, as evidenced by the high counts of tp (31) and tn (27).\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 20\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g020.jpg\" name=\"figure20\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g020.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g020.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g020.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g020.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g020.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g020.jpg\" alt=\"confusion matrix title “ddqn-inspired confusion matrix”. the matrix shows actual versus predicted labels for asd and non-asd. true positives: 31, false positives: 8, false negatives: 1, true negatives: 27. a color bar on the right indicates intensity from light to dark blue, corresponding to values from 0 to 30.\" id=\"fig20\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 20\u003c/b>. result of ddqn-inspired model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb15\">in the digital era, people frequently write content on social media to express their feelings, opinions, beliefs, and activities. this makes social media one of the most significant sources of data generation, allowing you to explore its opportunities and challenges. today, social media has become a mediator between people and the healthcare sector, enabling them to search for information about any specific disease and methods for diagnosing it.\u003c/p>\n\u003cp class=\"mb0\">individuals within the mental health community use social media platforms such as twitter to seek information, exchange experiences, and get assistance about asd in an environment that is seen as more approachable and informal than conventional medical contexts. they often seek immediate, relevant information—whether to understand symptoms, identify coping mechanisms, or connect with others facing similar difficulties. \u003ca href=\"#fig21\">figure 21\u003c/a> illustrates that word clouds are visual representations of text that highlight key terms and their frequency of use. we used wordcloud to compare asd and non-asd texts for instances of word repetition.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 21\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g021.jpg\" name=\"figure21\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g021.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g021.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g021.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g021.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g021.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g021.jpg\" alt=\"word cloud with terms related to asd class, including prominent words like “toddler,” “ability,” “might,” “concerned,” “activities,” and “making.” other words such as “engage,” “learning,” “challenging,” “noise,” and “struggle” also appear, reflecting themes in autism education.\" id=\"fig21\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 21\u003c/b>. asd word cloud.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">the deployment model based on the deep q-network (dqn) model for diagnosing asd is shown in \u003ca href=\"#fig22\">figure 22\u003c/a>.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 22\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g022.jpg\" name=\"figure22\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g022.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g022.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g022.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g022.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g022.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g022.jpg\" alt=\"flowchart depicting a data collection and processing model using twitter api for tweet analysis. the process includes filtering tweets, preprocessing, and applying a deep q-network for model development. it involves validating and testing to build an application interface. the deployment phase includes user interaction, real-time monitoring, and cloud storage. health professionals validate predictions, classifying tweets as asd or non-asd.\" id=\"fig22\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 22\u003c/b>. deployment system-based text for detecting asd.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb15\">step 1: data collections, including cleaning, normalization, and tokenization.\u003c/p>\n\u003cp class=\"mb15\">step 2: model development: the preprocessed data is used to train and validate a deep q-network (dqn) model for classifying tweets as indicative of asd or non-asd patterns.\u003c/p>\n\u003cp class=\"mb15\">step 3: application interface: an application interface is developed once the model has been trained. it integrates with users’ twitter accounts and continuously analyzes their tweets.\u003c/p>\n\u003cp class=\"mb15\">step 4: deployment: the proposed system is deployed in the cloud for storing tweets, enabling real-time monitoring of incoming tweets. predictions are flagged for review by healthcare professionals, who validate the model’s output before categorizing individuals as potentially having asd or non-asd.\u003c/p>\n\u003cp class=\"mb0\">this digital imprint may serve as an ancillary resource for mental health practitioners, providing insights into an individual’s emotional state and social behaviors in a natural environment, potentially facilitating early detection or corroborating a diagnosis. this method is a non-invasive means of data collection, particularly beneficial for individuals who lack rapid access to clinical assessments due to financial constraints, stigma, or resource scarcity. however, it should not replace professional diagnoses and must be conducted with ethical consideration to prevent misunderstanding. \u003ca href=\"#tab7\">table 7\u003c/a> shows the findings of the proposed framework on the twitter dataset. it demonstrates that the suggested method outperforms the current systems in terms of accuracy, proving its efficacy and potential for performance improvements.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">table 7\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t007.jpg\" name=\"table7\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t007.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t007.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t007.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t007.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t007.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t007.jpg\" alt=\"www.frontiersin.org\" id=\"tab7\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>table 7\u003c/b>. compared with the proposed asd system.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div> \u003ca id=\"h6\" name=\"h6\">\u003c/a>\n\u003ch2>5 conclusion\u003c/h2>\n\u003cp class=\"mb0\">to assist people in identifying trends in their behavior, such as social challenges or sensory sensitivities, which may encourage them to pursue a formal diagnosis. the main objective of examining tweets for identifying asd is its ability to provide behavioral and emotional indicators associated with the disorder. this research was used to analyze the textual analysis of tweets to detect the behaviors in self-identified autistic individuals relative to others. the suggested framework was evaluated using information from the social media platform “twitter” collected from a public repository. before examining the proposed system, several preprocessing steps must be implemented in the text. the ‘text’ column is cleaned by converting it to lowercase, eliminating non-alphanumeric characters (excluding spaces) through regular expressions, normalizing whitespace to a single space, and removing any leading or trailing spaces. the asd and non-asd labels are converted into a numerical format (0 or 1) with labelencoder to accommodate the binary classification requirement. tokenization of the text data is performed using a tokenizer, restricting the vocabulary to 10,000 words, and then transforming the text into sequences of numbers. the sequences are padded to a standardized length of 200 tokens to maintain consistency for the proposed model input. the proposed data is ultimately divided into an 80% training and 20% testing ratio, and class weights are calculated to resolve any class imbalance. this preparation pipeline efficiently converts raw text data into a structured numerical representation appropriate for the proposed framework, while preserving academic integrity. the output of these preprocessing steps was processed using three dl models, such as short-term memory (cnn-lstm) and a double deep q-network (ddqn). the results of these proposals were proven, revealing that the ddqn model achieved a high accuracy score of 87% with respect to the accuracy measure. the proposed framework, based on real textual data, can be helpful for real-time offering natural, behavioral, and emotional data that might indicate asd-related characteristics. finally, we have observed that social media (twitter) postings include linguistic patterns, emotional expressions, and social interactions that can help official health officials detect asd based on the thorough symptoms of asd that are posted on the platform. this study utilized a conventional dataset sourced only from the twitter network. we will emphasize the necessity of gathering datasets from many platforms to enhance the model’s generalizability in the future.\u003c/p> \u003ca id=\"h7\" name=\"h7\">\u003c/a>\n\u003ch2>data availability statement\u003c/h2>\n\u003cp class=\"mb0\">the original contributions presented in the study are included in the article/supplementary material, further inquiries can be directed to the corresponding author/s. the dataset used in this study can be found at \u003ca href=\"https://data.mendeley.com/datasets/87s2br3ptb/1\">https://data.mendeley.com/datasets/87s2br3ptb/1\u003c/a>.\u003c/p> \u003ca id=\"h8\" name=\"h8\">\u003c/a>\n\u003ch2>ethics statement\u003c/h2>\n\u003cp class=\"mb0\">ethical approval was not required for the study involving human data in accordance with the local legislation and institutional requirements. written informed consent was not required, for either participation in the study or for the publication of potentially/indirectly identifying information, in accordance with the local legislation and institutional requirements. the social media data was accessed and analysed in accordance with the platform’s terms of use and all relevant institutional/national regulations.\u003c/p> \u003ca id=\"h9\" name=\"h9\">\u003c/a>\n\u003ch2>author contributions\u003c/h2>\n\u003cp class=\"mb0\">nf: supervision, conceptualization, software, methodology, writing – original draft, investigation, visualization, formal analysis, validation. aa: data curation, visualization, methodology, conceptualization, validation, software, formal analysis, writing – original draft. ne: investigation, writing – review & editing, validation, formal analysis. sa: visualization, software, formal analysis, writing – review & editing, data curation.\u003c/p> \u003ca id=\"h10\" name=\"h10\">\u003c/a>\n\u003ch2>funding\u003c/h2>\n\u003cp class=\"mb0\">the author(s) declare that financial support was received for the research and/or publication of this article. the authors extend their appreciation to the king salman center for disability research for funding this work through research group no ksrg-2024-288.\u003c/p> \u003ca id=\"h11\" name=\"h11\">\u003c/a>\n\u003ch2>conflict of interest\u003c/h2>\n\u003cp class=\"mb0\">the authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\u003c/p> \u003ca id=\"h12\" name=\"h12\">\u003c/a>\n\u003ch2>generative ai statement\u003c/h2>\n\u003cp class=\"mb15\">the authors declare that no gen ai was used in the creation of this manuscript.\u003c/p>\n\u003cp class=\"mb0\">any alternative text (alt text) provided alongside figures in this article has been generated by frontiers with the support of artificial intelligence and reasonable efforts have been made to ensure accuracy, including review by the authors wherever possible. if you identify any issues, please contact us.\u003c/p> \u003ca id=\"h13\" name=\"h13\">\u003c/a>\n\u003ch2>publisher’s note\u003c/h2>\n\u003cp class=\"mb0\">all claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.\u003c/p> \u003ca id=\"h14\" name=\"h14\">\u003c/a>\n\u003ch2>references\u003c/h2>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref1\" id=\"ref1\">\u003c/a>1. asd. (2023). available online at: \u003ca href=\"https://www.healthline.com/health/signs-of-autism-in-3-year-old\">https://www.healthline.com/health/signs-of-autism-in-3-year-old\u003c/a>.\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"http://scholar.google.com/scholar_lookup?publication_year=2023&\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref2\" id=\"ref2\">\u003c/a>2. matson, jl, and goldin, rl. what is the future of assessment for autism spectrum disorders: short and long term. \u003ci>res autism spectr disord\u003c/i>. (2014) 8:209–13. doi: 10.1016/j.rasd.2013.01.007\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.1016/j.rasd.2013.01.007\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=jl+matson&author=rl+goldin&publication_year=2014&title=what+is+the+future+of+assessment+for+autism+spectrum+disorders:+short+and+long+term&journal=res+autism+spectr+disord&volume=8&pages=209-13\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref3\" id=\"ref3\">\u003c/a>3. srivastava, ak, and schwartz, ce. intellectual disability and autism spectrum disorders: causal genes and molecular mechanisms. \u003ci>neurosci biobehav rev\u003c/i>. (2014) 46:161–74. doi: 10.1016/j.neubiorev.2014.02.015 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/24709068\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.1016/j.neubiorev.2014.02.015\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=ak+srivastava&author=ce+schwartz&publication_year=2014&title=intellectual+disability+and+autism+spectrum+disorders:+causal+genes+and+molecular+mechanisms&journal=neurosci+biobehav+rev&volume=46&pages=161-74\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref4\" id=\"ref4\">\u003c/a>4. alhujaili, n, platt, e, khalid-khan, s, and groll, d. comparison of social media use among adolescents with autism spectrum disorder and non-asd adolescents. \u003ci>adolesc health med ther\u003c/i>. (2022) 13:15–21. doi: 10.2147/ahmt.s344591 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/35136359\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.2147/ahmt.s344591\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=n+alhujaili&author=e+platt&author=s+khalid-khan&author=d+groll&publication_year=2022&title=comparison+of+social+media+use+among+adolescents+with+autism+spectrum+disorder+and+non-asd+adolescents&journal=adolesc+health+med+ther&volume=13&pages=15-21\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref5\" id=\"ref5\">\u003c/a>5. angulo-jiménez, h, and dethorne, l. narratives about autism: an analysis of youtube videos by individuals who self-identify as autistic. \u003ci>am j speech lang pathol\u003c/i>. (2019) 28:569–90. doi: 10.1044/2018_ajslp-18-0045\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.1044/2018_ajslp-18-0045\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=h+angulo-jiménez&author=l+dethorne&publication_year=2019&title=narratives+about+autism:+an+analysis+of+youtube+videos+by+individuals+who+self-identify+as+autistic&journal=am+j+speech+lang+pathol&volume=28&pages=569-90\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref6\" id=\"ref6\">\u003c/a>6. pew research center. (2021). available online at: \u003ca href=\"https://www.pewresearch.org/internet/2021/04/07/social-media-use-in-2021/\">https://www.pewresearch.org/internet/2021/04/07/social-media-use-in-2021/\u003c/a>\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"http://scholar.google.com/scholar_lookup?publication_year=2021&\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref7\" id=\"ref7\">\u003c/a>7. liu, j-b, guan, l, cao, j, and chen, l. coherence analysis for a class of polygon networks with the noise disturbance. \u003ci>ieee trans syst man cybern syst\u003c/i>. (2025) 2025:326. doi: 10.1109/tsmc.2025.3559326\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.1109/tsmc.2025.3559326\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=j-b+liu&author=l+guan&author=j+cao&author=l+chen&publication_year=2025&title=coherence+analysis+for+a+class+of+polygon+networks+with+the+noise+disturbance&journal=ieee+trans+syst+man+cybern+syst&volume=2025&pages=326\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref8\" id=\"ref8\">\u003c/a>8. al-nefaie, ah, aldhyani, th, sultan, ha, and alzahrani eidah, m. application of artificial intelligence in modern healthcare for diagnosis of autism spectrum disorder. \u003ci>front med\u003c/i>. (2025) 12:1569464. doi: 10.3389/fmed.2025.1569464\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.3389/fmed.2025.1569464\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=ah+al-nefaie&author=th+aldhyani&author=ha+sultan&author=m+alzahrani+eidah&publication_year=2025&title=application+of+artificial+intelligence+in+modern+healthcare+for+diagnosis+of+autism+spectrum+disorder&journal=front+med&volume=12&pages=1569464\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref9\" id=\"ref9\">\u003c/a>9. kim, b, jeong, d, kim, jg, hong, h, and han, k. \u003ci>v-dat (virtual reality data analysis tool): supporting self-awareness for autistic people from multimodal vr sensor data\u003c/i>. in: proceedings of the uist 2023—proceedings of the 36th annual acm symposium on user interface software and technology, san francisco, ca, usa, 29 october–1 november 2023. (2023).\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"http://scholar.google.com/scholar_lookup?author=b+kim&author=d+jeong&author=jg+kim&author=h+hong&author=k+han&publication_year=2023&\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref10\" id=\"ref10\">\u003c/a>10. chen, c, chander, a, and uchino, k. \u003ci>guided play: digital sensing and coaching for stereotypical play behavior in children with autism\u003c/i>. in proceedings of the international conference on intelligent user interfaces, proceedings iui, marina del ray, ca, usa, 17–20 march 2019; part f1476. pp. 208–217. (2019).\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"http://scholar.google.com/scholar_lookup?author=c+chen&author=a+chander&author=k+uchino&publication_year=2019&\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref11\" id=\"ref11\">\u003c/a>11. parui, s, samanta, d, chakravorty, n, ghosh, u, and rodrigues, jj. artificial intelligence and sensor-based autism spectrum disorder diagnosis using brain connectivity analysis. \u003ci>comput electr eng\u003c/i>. (2023) 108:108720. doi: 10.1016/j.compeleceng.2023.108720\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.1016/j.compeleceng.2023.108720\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=s+parui&author=d+samanta&author=n+chakravorty&author=u+ghosh&author=jj+rodrigues&publication_year=2023&title=artificial+intelligence+and+sensor-based+autism+spectrum+disorder+diagnosis+using+brain+connectivity+analysis&journal=comput+electr+eng&volume=108&pages=108720\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref12\" id=\"ref12\">\u003c/a>12. golestan, s, soleiman, p, and moradi, h. a comprehensive review of technologies used for screening, assessment, and rehabilitation of autism spectrum disorder. \u003ci>arxiv\u003c/i>. (2018) 2018:10986. doi: 10.48550/arxiv.1807.10986\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.48550/arxiv.1807.10986\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=s+golestan&author=p+soleiman&author=h+moradi&publication_year=2018&title=a+comprehensive+review+of+technologies+used+for+screening+assessment+and+rehabilitation+of+autism+spectrum+disorder&journal=arxiv&volume=2018&pages=10986\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref13\" id=\"ref13\">\u003c/a>13. neeharika, ch, and riyazuddin, ym. developing an artificial intelligence based model for autism spectrum disorder detection in children. \u003ci>j adv res appl sci eng technol\u003c/i>. (2023) 32:57–72. doi: 10.37934/araset.32.1.5772\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.37934/araset.32.1.5772\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=ch+neeharika&author=ym+riyazuddin&publication_year=2023&title=developing+an+artificial+intelligence+based+model+for+autism+spectrum+disorder+detection+in+children&journal=j+adv+res+appl+sci+eng+technol&volume=32&pages=57-72\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref14\" id=\"ref14\">\u003c/a>14. wall, dp, dally, r, luyster, r, jung, j-y, and deluca, tf. use of artificial intelligence to shorten the behavioral diagnosis of autism. \u003ci>plos one\u003c/i>. (2012) 7:e43855. doi: 10.1371/journal.pone.0043855 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/22952789\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.1371/journal.pone.0043855\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=dp+wall&author=r+dally&author=r+luyster&author=j-y+jung&author=tf+deluca&publication_year=2012&title=use+of+artificial+intelligence+to+shorten+the+behavioral+diagnosis+of+autism&journal=plos+one&volume=7&pages=e43855\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref15\" id=\"ref15\">\u003c/a>15. alzakari, sa, allinjawi, a, aldrees, a, zamzami, n, umer, m, innab, n, et al. early detection of autism spectrum disorder using explainable ai and optimized teaching strategies. \u003ci>j neurosci methods\u003c/i>. (2025) 413:110315. doi: 10.1016/j.jneumeth.2024.110315 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/39532186\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.1016/j.jneumeth.2024.110315\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=sa+alzakari&author=a+allinjawi&author=a+aldrees&author=n+zamzami&author=m+umer&author=n+innab&publication_year=2025&title=early+detection+of+autism+spectrum+disorder+using+explainable+ai+and+optimized+teaching+strategies&journal=j+neurosci+methods&volume=413&pages=110315\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref16\" id=\"ref16\">\u003c/a>16. heunis, t, aldrich, c, peters, j, jeste, s, sahin, m, scheffer, c, et al. recurrence quantification analysis of resting state eeg signals in autism spectrum disorder—a systematic methodological exploration of technical and demographic confounders in the search for biomarkers. \u003ci>bmc med\u003c/i>. (2018) 16:101. doi: 10.1186/s12916-018-1086-7\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.1186/s12916-018-1086-7\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=t+heunis&author=c+aldrich&author=j+peters&author=s+jeste&author=m+sahin&author=c+scheffer&publication_year=2018&title=recurrence+quantification+analysis+of+resting+state+eeg+signals+in+autism+spectrum+disorder—a+systematic+methodological+exploration+of+technical+and+demographic+confounders+in+the+search+for+biomarkers&journal=bmc+med&volume=16&pages=101\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref17\" id=\"ref17\">\u003c/a>17. vicnesh, j, wei, jke, oh, sl, arunkumar, n, abdulhay, e, ciaccio, ej, et al. autism spectrum disorder diagnostic system using hos bispectrum with eeg signals. \u003ci>int j environ res public health\u003c/i>. (2020) 17:971. doi: 10.3390/ijerph17030971\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.3390/ijerph17030971\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=j+vicnesh&author=jke+wei&author=sl+oh&author=n+arunkumar&author=e+abdulhay&author=ej+ciaccio&publication_year=2020&title=autism+spectrum+disorder+diagnostic+system+using+hos+bispectrum+with+eeg+signals&journal=int+j+environ+res+public+health&volume=17&pages=971\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref18\" id=\"ref18\">\u003c/a>18. novielli, p, romano, d, magarelli, m, diacono, d, monaco, a, amoroso, n, et al. personalized identification of autism-related bacteria in the gut microbiome using explainable artificial intelligence. \u003ci>iscience\u003c/i>. (2024) 27:110709. doi: 10.1016/j.isci.2024.110709 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/39286497\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.1016/j.isci.2024.110709\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=p+novielli&author=d+romano&author=m+magarelli&author=d+diacono&author=a+monaco&author=n+amoroso&publication_year=2024&title=personalized+identification+of+autism-related+bacteria+in+the+gut+microbiome+using+explainable+artificial+intelligence&journal=iscience&volume=27&pages=110709\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref19\" id=\"ref19\">\u003c/a>19. bosl, wj, tager-flusberg, h, and nelson, ca. eeg analytics for early detection of autism spectrum disorder: a data-driven approach. \u003ci>sci rep\u003c/i>. (2018) 8:1–20. doi: 10.1038/s41598-018-24318-x \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/29717196\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.1038/s41598-018-24318-x\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=wj+bosl&author=h+tager-flusberg&author=ca+nelson&publication_year=2018&title=eeg+analytics+for+early+detection+of+autism+spectrum+disorder:+a+data-driven+approach&journal=sci+rep&volume=8&pages=1-20\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref20\" id=\"ref20\">\u003c/a>20. beykikhoshk, a, arandjelović, o, phung, d, venkatesh, s, and caelli, t. using twitter to learn about the autism community. \u003ci>soc netw anal min\u003c/i>. (2015) 5:261. doi: 10.1007/s13278-015-0261-\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.1007/s13278-015-0261-\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=a+beykikhoshk&author=o+arandjelović&author=d+phung&author=s+venkatesh&author=t+caelli&publication_year=2015&title=using+twitter+to+learn+about+the+autism+community&journal=soc+netw+anal+min&volume=5&pages=261\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref21\" id=\"ref21\">\u003c/a>21. mazurek, mo. social media use among adults with autism spectrum disorders. \u003ci>comput hum behav\u003c/i>. (2013) 29:1709–14. doi: 10.1016/j.chb.2013.02.004\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.1016/j.chb.2013.02.004\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=mo+mazurek&publication_year=2013&title=social+media+use+among+adults+with+autism+spectrum+disorders&journal=comput+hum+behav&volume=29&pages=1709-14\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref22\" id=\"ref22\">\u003c/a>22. onnela, j, and rauch, sl. harnessing smartphone-based digital phenotyping to enhance behavioral and mental health. \u003ci>neuropsychopharmacology\u003c/i>. (2016) 41:1691–6. doi: 10.1038/npp.2016.7.npp20167 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/26818126\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.1038/npp.2016.7.npp20167\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=j+onnela&author=sl+rauch&publication_year=2016&title=harnessing+smartphone-based+digital+phenotyping+to+enhance+behavioral+and+mental+health&journal=neuropsychopharmacology&volume=41&pages=1691-6\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref23\" id=\"ref23\">\u003c/a>23. tomeny, ts, vargo, cj, and el-toukhy, s. geographic and demographic correlates of autism-related anti-vaccine beliefs on twitter, 2009–2015. \u003ci>soc sci med\u003c/i>. (2017) 191:168–75. doi: 10.1016/j.socscimed.2017.08.041 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/28926775\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.1016/j.socscimed.2017.08.041\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=ts+tomeny&author=cj+vargo&author=s+el-toukhy&publication_year=2017&title=geographic+and+demographic+correlates+of+autism-related+anti-vaccine+beliefs+on+twitter+2009–2015&journal=soc+sci+med&volume=191&pages=168-75\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref24\" id=\"ref24\">\u003c/a>24. tárraga-mínguez, r, gómez-marí, i, and sanz-cervera, p. what motivates internet users to search for asperger syndrome and autism on google? \u003ci>int j environ res public health\u003c/i>. (2020) 17:9386. doi: 10.3390/ijerph17249386 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/33333991\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.3390/ijerph17249386\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=r+tárraga-mínguez&author=i+gómez-marí&author=p+sanz-cervera&publication_year=2020&title=what+motivates+internet+users+to+search+for+asperger+syndrome+and+autism+on+google?&journal=int+j+environ+res+public+health&volume=17&pages=9386\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref25\" id=\"ref25\">\u003c/a>25. hartwell, m, keener, a, coffey, s, chesher, t, torgerson, t, and vassar, m. brief report: public awareness of asperger syndrome following greta thunberg appearances. \u003ci>j autism dev disord\u003c/i>. (2020) 51:2104–8. doi: 10.1007/s10803-020-04651-9 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/32812193\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.1007/s10803-020-04651-9\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=m+hartwell&author=a+keener&author=s+coffey&author=t+chesher&author=t+torgerson&author=m+vassar&publication_year=2020&title=brief+report:+public+awareness+of+asperger+syndrome+following+greta+thunberg+appearances&journal=j+autism+dev+disord&volume=51&pages=2104-8\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref26\" id=\"ref26\">\u003c/a>26. rubio-martín, s, garcía-ordás, mt, bayón-gutiérrez, m, prieto-fernández, n, and benítez-andrades, ja. “\u003ci>early detection of autism spectrum disorder through ai-powered analysis of social media texts\u003c/i>,” 2023 ieee 36th international symposium on computer-based medical systems (cbms), l’aquila, italy, pp. 235–240. (2023).\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"http://scholar.google.com/scholar_lookup?author=s+rubio-martín&author=mt+garcía-ordás&author=m+bayón-gutiérrez&author=n+prieto-fernández&author=ja+benítez-andrades&publication_year=2023&\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref27\" id=\"ref27\">\u003c/a>27. jaiswal, a, and washington, p. using #actuallyautistic on twitter for precision diagnosis of autism spectrum disorder: machine learning study. \u003ci>jmir form res\u003c/i>. (2024) 8:e52660. doi: 10.2196/52660\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.2196/52660\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=a+jaiswal&author=p+washington&publication_year=2024&title=using+#actuallyautistic+on+twitter+for+precision+diagnosis+of+autism+spectrum+disorder:+machine+learning+study&journal=jmir+form+res&volume=8&pages=e52660\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003c/div> \u003cdiv class=\"thinlinem20\">\u003c/div> \u003cdiv class=\"abstractsummary\">\n\u003cp>\u003cspan>keywords:\u003c/span> autism spectrum disorders, diagnosing, social media, deep learning, disabilities, artificial intelligence\u003c/p>\n\u003cp>\u003cspan>citation:\u003c/span> farhah ns, alqarni aa, ebrahim n and ahmad s (2025) diagnosing autism spectrum disorders using a double deep q-network framework based on social media footprints. \u003ci>front. med\u003c/i>. 12:1646249. doi: 10.3389/fmed.2025.1646249\u003c/p>\n\u003cp class=\"timestamps\">\u003cspan>received:\u003c/span> 16 june 2025; \u003cspan>accepted:\u003c/span> 28 july 2025;\u003cbr> \u003cspan>published:\u003c/span> 20 august 2025.\u003c/p> \u003cdiv>\n\u003cp>edited by:\u003c/p> \u003ca href=\"https://loop.frontiersin.org/people/2928766/overview\">pardeep sangwan\u003c/a>, maharaja surajmal institute of technology, india\u003c/div> \u003cdiv>\n\u003cp>reviewed by:\u003c/p> \u003ca href=\"https://loop.frontiersin.org/people/1743107/overview\">jia-bao liu\u003c/a>, anhui jianzhu university, china\u003cbr> \u003ca href=\"https://loop.frontiersin.org/people/3104897/overview\">muhammad adnan\u003c/a>, kohat university of science and technology, pakistan\u003c/div>\n\u003cp>\u003cspan>copyright\u003c/span> © 2025 farhah, alqarni, ebrahim and ahmad. this is an open-access article distributed under the terms of the \u003ca rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\" target=\"_blank\">creative commons attribution license (cc by)\u003c/a>. the use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. no use, distribution or reproduction is permitted which does not comply with these terms.\u003c/p>\n\u003cp>\u003cspan>*correspondence:\u003c/span> nesren s. farhah, \u003ca id=\"encmail\">bi5myxjoywhac2v1lmvkds5zyq==\u003c/a>; nadhem ebrahim, \u003ca id=\"encmail\">bmvicmfoaw1adwfrcm9ulmvkdq==\u003c/a>; sultan ahmad, \u003ca id=\"encmail\">cy5hbglzagvyqhbzyxuuzwr1lnnh\u003c/a>\u003c/p> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>","\u003cul class=\"flyoutjournal\"> \u003cli>\u003ca href=\"#h1\">abstract\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h2\">1 introduction\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h3\">2 materials and methods\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h4\">3 performance of the framework\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h5\">4 experiment and discussion results\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h6\">5 conclusion\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h7\">data availability statement\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h8\">ethics statement\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h9\">author contributions\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h10\">funding\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h11\">conflict of interest\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h12\">generative ai statement\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h13\">publisher’s note\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h14\">references\u003c/a>\u003c/li> \u003c/ul>",[627,633,639],{"name":628,"fileserverpackageentryid":19,"fileserverid":629,"fileserverversionnumber":374,"type":630},"epub.epub","1646249/epub",{"code":631,"name":632},"epub","epub",{"name":634,"fileserverpackageentryid":19,"fileserverid":635,"fileserverversionnumber":374,"type":636},"publishers-proof.pdf","1646249/publishers-proof",{"code":637,"name":638},"pdf","pdf",{"name":640,"fileserverpackageentryid":641,"fileserverid":642,"fileserverversionnumber":374,"type":643},"fmed-12-1646249.xml","fmed-12-1646249/fmed-12-1646249.xml","1646249/xml",{"code":644,"name":645},"nlm_xml","xml","v3",{"title":648,"link":649,"meta":653,"script":754},"frontiers | diagnosing autism spectrum disorders using a double deep q-network framework based on social media footprints",[650],{"rel":651,"href":652},"canonical","https://www.frontiersin.org/journals/medicine/articles/10.3389/fmed.2025.1646249/full",[654,657,660,662,665,669,672,676,679,682,685,687,689,691,693,695,698,701,703,706,708,710,713,716,719,722,725,729,733,736,739,742,745,748,751],{"hid":655,"property":655,"name":655,"content":656},"description","introductionsocial media is increasingly used in many contexts within the healthcare sector. the improved prevalence of internet use via computers or mobile ...",{"hid":658,"property":658,"name":659,"content":648},"og:title","title",{"hid":661,"property":661,"name":655,"content":656},"og:description",{"hid":663,"name":663,"content":664},"keywords","artificial intelligence,deep learning,social media,disabilities,autism spectrum disorders,diagnosing",{"hid":666,"property":666,"name":667,"content":668},"og:site_name","site_name","frontiers",{"hid":670,"property":670,"name":367,"content":671},"og:image","https://images-provider.frontiersin.org/api/ipx/w=1200&f=png/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g001.jpg",{"hid":673,"property":673,"name":674,"content":675},"og:type","type","article",{"hid":677,"property":677,"name":678,"content":652},"og:url","url",{"hid":680,"name":680,"content":681},"twitter:card","summary_large_image",{"hid":683,"name":683,"content":684},"citation_volume","12",{"hid":686,"name":686,"content":116},"citation_journal_title",{"hid":688,"name":688,"content":668},"citation_publisher",{"hid":690,"name":690,"content":608},"citation_journal_abbrev",{"hid":692,"name":692,"content":609},"citation_issn",{"hid":694,"name":694,"content":518},"citation_doi",{"hid":696,"name":696,"content":697},"citation_firstpage","1646249",{"hid":699,"name":699,"content":700},"citation_language","english",{"hid":702,"name":702,"content":519},"citation_title",{"hid":704,"name":704,"content":705},"citation_keywords","artificial intelligence; deep learning; social media; disabilities; autism spectrum disorders; diagnosing",{"hid":707,"name":707,"content":524},"citation_abstract",{"hid":709,"name":709,"content":533},"citation_article_type",{"hid":711,"name":711,"content":712},"citation_pdf_url","https://www.frontiersin.org/journals/medicine/articles/10.3389/fmed.2025.1646249/pdf",{"hid":714,"name":714,"content":715},"citation_xml_url","https://www.frontiersin.org/journals/medicine/articles/10.3389/fmed.2025.1646249/xml",{"hid":717,"name":717,"content":718},"citation_fulltext_world_readable","yes",{"hid":720,"name":720,"content":721},"citation_online_date","2025/07/28",{"hid":723,"name":723,"content":724},"citation_publication_date","2025/08/20",{"hid":726,"name":727,"content":728},"citation_author_0","citation_author","farhah, nesren s. ",{"hid":730,"name":731,"content":732},"citation_author_institution_0","citation_author_institution","department of health informatics, college of health science, saudi electronic university, saudi arabia",{"hid":734,"name":727,"content":735},"citation_author_1","alqarni, ahmed abdullah ",{"hid":737,"name":731,"content":738},"citation_author_institution_1","king salman center for disability research, saudi arabia",{"hid":740,"name":727,"content":741},"citation_author_2","ebrahim, nadhem ",{"hid":743,"name":731,"content":744},"citation_author_institution_2","department of computer science, college of engineering and polymer science, university of akron, united states",{"hid":746,"name":727,"content":747},"citation_author_3","ahmad, sultan ",{"hid":749,"name":731,"content":750},"citation_author_institution_3","department of computer science, college of computer engineering and sciences, prince sattam bin abdulaziz university, saudi arabia",{"hid":752,"name":752,"content":753},"dc.identifier","doi:10.3389/fmed.2025.1646249",[755,758,760,762,764],{"src":756,"body":13,"type":757,"async":13},"https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6","text/javascript",{"src":759,"body":13,"type":757,"async":13},"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/mathjax.js?config=tex-mml-am_chtml",{"src":761,"body":13,"type":757,"async":13},"https://d1bxh8uas1mnw7.cloudfront.net/assets/altmetric_badges-f0bc9b243ff5677d05460c1eb71834ca998946d764eb3bc244ab4b18ba50d21e.js",{"src":763,"body":13,"type":757,"async":13},"https://api.altmetric.com/v1/doi/10.3389/fmed.2025.1646249?callback=_altmetric.embed_callback&domain=www.frontiersin.org&key=3c130976ca2b8f2e88f8377633751ba1&cache_until=14-15",{"src":765,"body":13,"type":757,"async":13},"https://crossmark-cdn.crossref.org/widget/v2.0/widget.js",{"articlehubslug":19,"articlehubpage":767,"articlehubarticleslist":768,"canjournalhasarticlehub":351,"articledoilist":769},{},[],[],{"title":19,"image":-1,"breadcrumbs":771,"linkscollection":772,"metricscollection":774},[],{"total":371,"items":773},[],{"total":371,"items":775},[]] window.__nuxt__={};window.__nuxt__.config={public:{isdevmode:false,appname:"article-pages-2024",baseurl:"https://www.frontiersin.org",domain:"frontiersin.org",loopurl:"https://loop.frontiersin.org",ssmaindomain:"frontiersin.org",contentfulurl:"https://graphql.contentful.com/content/v1/spaces",spaceid:1,spacename:"frontiers",livespaceid:1,tenantlogourl:"",frontiersgraphurl:"https://apollo-federation-gateway.frontiersin.org",registrationapiurl:"https://onboarding-ui.frontiersin.org",emaildigestapiurl:"https://api-email-digest.frontiersin.org",journalfilesapiurl:"https://files-journal-api.frontiersin.org",searchapiurl:"https://search-api.frontiersin.org",productionforumapiurl:"https://production-forum-api-v2.frontiersin.org",gtmserverurl:"https://tag-manager.frontiersin.org",gtmid:"gtm-m322fv2",gtmauth:"owvbwxfajr21yqv1fe1caq",gtmpreview:"env-1",figsharepluginurl:"https://widgets.figshare.com/static/figshare.js",figshareapiurl:"https://api.figshare.com/v2/collections/search",figsharetimeout:3000,crossmarkpublisheddate:"2015/08/24",googlerecaptchasitekey:"6ldg3i0uaaaaaoc4quh35ubhgjotehp_stxhgr_v",googlerecaptchakeyname:"frontiersrecaptchav2",faviconsize16:"https://static2.frontiersin.org/static-resources/tenants/frontiers/favicon_16-tenantfavicon-frontiers.png",faviconsize32:"https://static2.frontiersin.org/static-resources/tenants/frontiers/favicon_32-tenantfavicon-frontiers.png",faviconsize180:"https://static2.frontiersin.org/static-resources/tenants/frontiers/favicon_180-tenantfavicon-frontiers.png",faviconsize192:"https://static2.frontiersin.org/static-resources/tenants/frontiers/favicon_192-tenantfavicon-frontiers.png",faviconsize512:"https://static2.frontiersin.org/static-resources/tenants/frontiers/favicon_512-tenantfavicon-frontiers.png",socialmediaimg:"https://brand.frontiersin.org/m/1c8bcb536c789e11/guidelines-frontiers_logo_1200x628_1-91to1.png",linkedarticlecopytext:"'{\"articletypecopytext\":[{\"articletypeid\":0,\"originalarticlecopytext\":\"part of this article's content has been mentioned in:\",\"linkedarticlecopytext\":\"this article mentions parts of:\"},{\"articletypeid\":122,\"originalarticlecopytext\":\"parts of this article's content have been modified or rectified in:\",\"linkedarticlecopytext\":\"this article is an erratum on:\"},{\"articletypeid\":129,\"originalarticlecopytext\":\"parts of this article's content have been modified or rectified in:\",\"linkedarticlecopytext\":\"this article is an addendum to:\"},{\"articletypeid\":128,\"originalarticlecopytext\":\"a correction has been applied to this article in:\",\"linkedarticlecopytext\":\"this article is a correction to:\"},{\"articletypeid\":134,\"originalarticlecopytext\":\"a retraction of this article was approved in:\",\"linkedarticlecopytext\":\"this article is a retraction of:\"},{\"articletypeid\":29,\"originalarticlecopytext\":\"a commentary has been posted on this article:\",\"linkedarticlecopytext\":\"this article is a commentary on:\"},{\"articletypeid\":30,\"originalarticlecopytext\":\"a commentary has been posted on this article:\",\"linkedarticlecopytext\":\"this article is a commentary on:\"}],\"articleidcopytext\":[]}'\n",acceptedarticleexcludedjournalids:"'[2766,979]'\n",articletypeconfigurablelabel:"\u003c\u003carticle-type:uppercase>> article",settingsfeaturesswitchers:"'{\"displaytitlepilllabels\":true,\"displayrelatedarticlesbox\":true,\"showeditors\":true,\"showreviewers\":true,\"showloopimpactlink\":true,\"enablefigshare\":false,\"usexmlimages\":true}'\n",journalswitharticlehub:"'{\"strings\":[\"science\"]}'\n",terminologysettings:"'{\"terms\":[{\"sequencenumber\":1,\"key\":\"frontiers\",\"tenantterm\":\"frontiers\",\"frontiersdefaultterm\":\"frontiers\",\"category\":\"customer\"},{\"sequencenumber\":2,\"key\":\"submission_system\",\"tenantterm\":\"submission system\",\"frontiersdefaultterm\":\"submission system\",\"category\":\"product\"},{\"sequencenumber\":3,\"key\":\"public_pages\",\"tenantterm\":\"public pages\",\"frontiersdefaultterm\":\"public pages\",\"category\":\"product\"},{\"sequencenumber\":4,\"key\":\"my_frontiers\",\"tenantterm\":\"my frontiers\",\"frontiersdefaultterm\":\"my frontiers\",\"category\":\"product\"},{\"sequencenumber\":5,\"key\":\"digital_editorial_office\",\"tenantterm\":\"digital editorial office\",\"frontiersdefaultterm\":\"digital editorial office\",\"category\":\"product\"},{\"sequencenumber\":6,\"key\":\"deo\",\"tenantterm\":\"deo\",\"frontiersdefaultterm\":\"deo\",\"category\":\"product\"},{\"sequencenumber\":7,\"key\":\"digital_editorial_office_for_chiefs\",\"tenantterm\":\"digital editorial office for chiefs\",\"frontiersdefaultterm\":\"digital editorial office for chiefs\",\"category\":\"product\"},{\"sequencenumber\":8,\"key\":\"digital_editorial_office_for_eof\",\"tenantterm\":\"digital editorial office for eof\",\"frontiersdefaultterm\":\"digital editorial office for eof\",\"category\":\"product\"},{\"sequencenumber\":9,\"key\":\"editorial_office\",\"tenantterm\":\"editorial office\",\"frontiersdefaultterm\":\"editorial office\",\"category\":\"product\"},{\"sequencenumber\":10,\"key\":\"eof\",\"tenantterm\":\"eof\",\"frontiersdefaultterm\":\"eof\",\"category\":\"product\"},{\"sequencenumber\":11,\"key\":\"research_topic_management\",\"tenantterm\":\"research topic management\",\"frontiersdefaultterm\":\"research topic management\",\"category\":\"product\"},{\"sequencenumber\":12,\"key\":\"review_forum\",\"tenantterm\":\"review forum\",\"frontiersdefaultterm\":\"review forum\",\"category\":\"product\"},{\"sequencenumber\":13,\"key\":\"accounting_office\",\"tenantterm\":\"accounting office\",\"frontiersdefaultterm\":\"accounting office\",\"category\":\"product\"},{\"sequencenumber\":14,\"key\":\"aof\",\"tenantterm\":\"aof\",\"frontiersdefaultterm\":\"aof\",\"category\":\"product\"},{\"sequencenumber\":15,\"key\":\"publishing_office\",\"tenantterm\":\"publishing office\",\"frontiersdefaultterm\":\"publishing office\",\"category\":\"product\"},{\"sequencenumber\":16,\"key\":\"production_office\",\"tenantterm\":\"production office forum\",\"frontiersdefaultterm\":\"production office forum\",\"category\":\"product\"},{\"sequencenumber\":17,\"key\":\"pof\",\"tenantterm\":\"pof\",\"frontiersdefaultterm\":\"pof\",\"category\":\"product\"},{\"sequencenumber\":18,\"key\":\"book_office_forum\",\"tenantterm\":\"book office forum\",\"frontiersdefaultterm\":\"book office forum\",\"category\":\"product\"},{\"sequencenumber\":19,\"key\":\"bof\",\"tenantterm\":\"bof\",\"frontiersdefaultterm\":\"bof\",\"category\":\"product\"},{\"sequencenumber\":20,\"key\":\"aira\",\"tenantterm\":\"aira\",\"frontiersdefaultterm\":\"aira\",\"category\":\"product\"},{\"sequencenumber\":21,\"key\":\"editorial_board_management\",\"tenantterm\":\"editorial board management\",\"frontiersdefaultterm\":\"editorial board management\",\"category\":\"product\"},{\"sequencenumber\":22,\"key\":\"ebm\",\"tenantterm\":\"ebm\",\"frontiersdefaultterm\":\"ebm\",\"category\":\"product\"},{\"sequencenumber\":23,\"key\":\"domain\",\"tenantterm\":\"domain\",\"frontiersdefaultterm\":\"domain\",\"category\":\"taxonomy\"},{\"sequencenumber\":24,\"key\":\"journal\",\"tenantterm\":\"journal\",\"frontiersdefaultterm\":\"journal\",\"category\":\"taxonomy\"},{\"sequencenumber\":25,\"key\":\"section\",\"tenantterm\":\"section\",\"frontiersdefaultterm\":\"section\",\"category\":\"taxonomy\"},{\"sequencenumber\":26,\"key\":\"domains\",\"tenantterm\":\"domains\",\"frontiersdefaultterm\":\"domains\",\"category\":\"taxonomy\"},{\"sequencenumber\":27,\"key\":\"specialty_section\",\"tenantterm\":\"specialty section\",\"frontiersdefaultterm\":\"specialty section\",\"category\":\"taxonomy\"},{\"sequencenumber\":28,\"key\":\"specialty_journal\",\"tenantterm\":\"specialty journal\",\"frontiersdefaultterm\":\"specialty journal\",\"category\":\"taxonomy\"},{\"sequencenumber\":29,\"key\":\"journals\",\"tenantterm\":\"journals\",\"frontiersdefaultterm\":\"journals\",\"category\":\"taxonomy\"},{\"sequencenumber\":30,\"key\":\"sections\",\"tenantterm\":\"sections\",\"frontiersdefaultterm\":\"sections\",\"category\":\"taxonomy\"},{\"sequencenumber\":31,\"key\":\"specialty_sections\",\"tenantterm\":\"specialty sections\",\"frontiersdefaultterm\":\"specialty sections\",\"category\":\"taxonomy\"},{\"sequencenumber\":32,\"key\":\"specialty_journals\",\"tenantterm\":\"specialty journals\",\"frontiersdefaultterm\":\"specialty journals\",\"category\":\"taxonomy\"},{\"sequencenumber\":33,\"key\":\"manuscript\",\"tenantterm\":\"manuscript\",\"frontiersdefaultterm\":\"manuscript\",\"category\":\"core\"},{\"sequencenumber\":34,\"key\":\"manuscripts\",\"tenantterm\":\"manuscripts\",\"frontiersdefaultterm\":\"manuscripts\",\"category\":\"core\"},{\"sequencenumber\":35,\"key\":\"article\",\"tenantterm\":\"article\",\"frontiersdefaultterm\":\"article\",\"category\":\"core\"},{\"sequencenumber\":36,\"key\":\"articles\",\"tenantterm\":\"articles\",\"frontiersdefaultterm\":\"articles\",\"category\":\"core\"},{\"sequencenumber\":37,\"key\":\"article_type\",\"tenantterm\":\"article type\",\"frontiersdefaultterm\":\"article type\",\"category\":\"core\"},{\"sequencenumber\":38,\"key\":\"article_types\",\"tenantterm\":\"article types\",\"frontiersdefaultterm\":\"article types\",\"category\":\"core\"},{\"sequencenumber\":39,\"key\":\"author\",\"tenantterm\":\"author\",\"frontiersdefaultterm\":\"author\",\"category\":\"label (role)\"},{\"sequencenumber\":40,\"key\":\"authors\",\"tenantterm\":\"authors\",\"frontiersdefaultterm\":\"authors\",\"category\":\"label (role)\"},{\"sequencenumber\":41,\"key\":\"authoring\",\"tenantterm\":\"authoring\",\"frontiersdefaultterm\":\"authoring\",\"category\":\"core\"},{\"sequencenumber\":42,\"key\":\"authored\",\"tenantterm\":\"authored\",\"frontiersdefaultterm\":\"authored\",\"category\":\"core\"},{\"sequencenumber\":43,\"key\":\"accept\",\"tenantterm\":\"accept\",\"frontiersdefaultterm\":\"accept\",\"category\":\"process\"},{\"sequencenumber\":44,\"key\":\"accepted\",\"tenantterm\":\"accepted\",\"frontiersdefaultterm\":\"accepted\",\"category\":\"process\"},{\"sequencenumber\":45,\"key\":\"assistant_field_chief_editor\",\"tenantterm\":\"assistant field chief editor\",\"frontiersdefaultterm\":\"assistant field chief editor\",\"description\":\"an editorial role on a field journal that a registered user may hold. this gives them rights to different functionality and parts of the platform\",\"category\":\"label (role)\"},{\"sequencenumber\":46,\"key\":\"assistant_specialty_chief_editor\",\"tenantterm\":\"assistant specialty chief editor\",\"frontiersdefaultterm\":\"assistant specialty chief editor\",\"description\":\"an editorial role on a specialty that a registered user may hold. this gives them rights to different functionality and parts of the platform\",\"category\":\"label (role)\"},{\"sequencenumber\":47,\"key\":\"assistant_specialty_chief_editors\",\"tenantterm\":\"assistant specialty chief editors\",\"frontiersdefaultterm\":\"assistant specialty chief editors\",\"category\":\"label (role)\"},{\"sequencenumber\":48,\"key\":\"associate_editor\",\"tenantterm\":\"associate editor\",\"frontiersdefaultterm\":\"associate editor\",\"description\":\"an editorial role on a specialty that a registered user may hold. this gives them rights to different functionality and parts of the platform\",\"category\":\"label (role)\"},{\"sequencenumber\":49,\"key\":\"specialty_chief_editor\",\"tenantterm\":\"specialty chief editor\",\"frontiersdefaultterm\":\"specialty chief editor\",\"description\":\"an editorial role on a specialty that a registered user may hold. this gives them rights to different functionality and parts of the platform\",\"category\":\"label (role)\"},{\"sequencenumber\":50,\"key\":\"specialty_chief_editors\",\"tenantterm\":\"specialty chief editors\",\"frontiersdefaultterm\":\"specialty chief editors\",\"category\":\"label (role)\"},{\"sequencenumber\":51,\"key\":\"chief_editor\",\"tenantterm\":\"chief editor\",\"frontiersdefaultterm\":\"chief editor\",\"category\":\"label (role)\"},{\"sequencenumber\":52,\"key\":\"chief_editors\",\"tenantterm\":\"chief editors\",\"frontiersdefaultterm\":\"chief editors\",\"category\":\"label (role)\"},{\"sequencenumber\":53,\"key\":\"call_for_participation\",\"tenantterm\":\"call for participation\",\"frontiersdefaultterm\":\"call for participation\",\"category\":\"process\"},{\"sequencenumber\":54,\"key\":\"citation\",\"tenantterm\":\"citation\",\"frontiersdefaultterm\":\"citation\",\"category\":\"misc.\"},{\"sequencenumber\":55,\"key\":\"citations\",\"tenantterm\":\"citations\",\"frontiersdefaultterm\":\"citations\",\"category\":\"misc.\"},{\"sequencenumber\":56,\"key\":\"contributor\",\"tenantterm\":\"contributor\",\"frontiersdefaultterm\":\"contributor\",\"category\":\"label (role)\"},{\"sequencenumber\":57,\"key\":\"contributors\",\"tenantterm\":\"contributors\",\"frontiersdefaultterm\":\"contributors\",\"category\":\"label (role)\"},{\"sequencenumber\":58,\"key\":\"corresponding_author\",\"tenantterm\":\"corresponding author\",\"frontiersdefaultterm\":\"corresponding author\",\"category\":\"label (role)\"},{\"sequencenumber\":59,\"key\":\"corresponding_authors\",\"tenantterm\":\"corresponding authors\",\"frontiersdefaultterm\":\"corresponding authors\",\"category\":\"label (role)\"},{\"sequencenumber\":60,\"key\":\"decline\",\"tenantterm\":\"decline\",\"frontiersdefaultterm\":\"decline\",\"category\":\"process\"},{\"sequencenumber\":61,\"key\":\"declined\",\"tenantterm\":\"declined\",\"frontiersdefaultterm\":\"declined\",\"category\":\"process\"},{\"sequencenumber\":62,\"key\":\"reject\",\"tenantterm\":\"reject\",\"frontiersdefaultterm\":\"reject\",\"category\":\"process\"},{\"sequencenumber\":63,\"key\":\"rejected\",\"tenantterm\":\"rejected\",\"frontiersdefaultterm\":\"rejected\",\"category\":\"process\"},{\"sequencenumber\":64,\"key\":\"publish\",\"tenantterm\":\"publish\",\"frontiersdefaultterm\":\"publish\",\"category\":\"core\"},{\"sequencenumber\":65,\"key\":\"published\",\"tenantterm\":\"published\",\"frontiersdefaultterm\":\"published\",\"category\":\"core\"},{\"sequencenumber\":66,\"key\":\"publication\",\"tenantterm\":\"publication\",\"frontiersdefaultterm\":\"publication\",\"category\":\"core\"},{\"sequencenumber\":67,\"key\":\"peer_review\",\"tenantterm\":\"peer review\",\"frontiersdefaultterm\":\"peer review\",\"category\":\"peer review process\"},{\"sequencenumber\":68,\"key\":\"peer_reviewed\",\"tenantterm\":\"peer reviewed\",\"frontiersdefaultterm\":\"peer reviewed\",\"category\":\"peer review process\"},{\"sequencenumber\":69,\"key\":\"initial_validation\",\"tenantterm\":\"initial validation\",\"frontiersdefaultterm\":\"initial validation\",\"category\":\"peer review process\"},{\"sequencenumber\":70,\"key\":\"editorial_assignment\",\"tenantterm\":\"editorial assignment\",\"frontiersdefaultterm\":\"editorial assignment\",\"category\":\"peer review process\"},{\"sequencenumber\":71,\"key\":\"independent_review\",\"tenantterm\":\"independent review\",\"frontiersdefaultterm\":\"independent review\",\"category\":\"peer review process\"},{\"sequencenumber\":72,\"key\":\"interactive_review\",\"tenantterm\":\"interactive review\",\"frontiersdefaultterm\":\"interactive review\",\"category\":\"peer review process\"},{\"sequencenumber\":73,\"key\":\"review\",\"tenantterm\":\"review\",\"frontiersdefaultterm\":\"review\",\"category\":\"peer review process\"},{\"sequencenumber\":74,\"key\":\"reviewing\",\"tenantterm\":\"reviewing\",\"frontiersdefaultterm\":\"reviewing\",\"category\":\"peer review process\"},{\"sequencenumber\":75,\"key\":\"reviewer\",\"tenantterm\":\"reviewer\",\"frontiersdefaultterm\":\"reviewer\",\"category\":\"label (role)\"},{\"sequencenumber\":76,\"key\":\"reviewers\",\"tenantterm\":\"reviewers\",\"frontiersdefaultterm\":\"reviewers\",\"category\":\"label (role)\"},{\"sequencenumber\":77,\"key\":\"review_finalized\",\"tenantterm\":\"review finalized\",\"frontiersdefaultterm\":\"review finalized\",\"category\":\"peer review process\"},{\"sequencenumber\":78,\"key\":\"final_decision\",\"tenantterm\":\"final decision\",\"frontiersdefaultterm\":\"final decision\",\"category\":\"peer review process\"},{\"sequencenumber\":79,\"key\":\"final_validation\",\"tenantterm\":\"final validation\",\"frontiersdefaultterm\":\"final validation\",\"category\":\"peer review process\"},{\"sequencenumber\":80,\"key\":\"ae_accept_manuscript\",\"tenantterm\":\"recommend to accept manuscript\",\"frontiersdefaultterm\":\"accept manuscript\",\"category\":\"process\"},{\"sequencenumber\":81,\"key\":\"fee\",\"tenantterm\":\"fee\",\"frontiersdefaultterm\":\"fee\",\"category\":\"accounting\"},{\"sequencenumber\":82,\"key\":\"fees\",\"tenantterm\":\"fees\",\"frontiersdefaultterm\":\"fees\",\"category\":\"accounting\"},{\"sequencenumber\":83,\"key\":\"guest_associate_editor\",\"tenantterm\":\"guest associate editor\",\"frontiersdefaultterm\":\"guest associate editor\",\"category\":\"label (role)\"},{\"sequencenumber\":84,\"key\":\"guest_associate_editors\",\"tenantterm\":\"guest associate editors\",\"frontiersdefaultterm\":\"guest associate editors\",\"category\":\"label (role)\"},{\"sequencenumber\":85,\"key\":\"in_review\",\"tenantterm\":\"in review\",\"frontiersdefaultterm\":\"in review\",\"category\":\"peer review process\"},{\"sequencenumber\":86,\"key\":\"institutional_member\",\"tenantterm\":\"institutional partner\",\"frontiersdefaultterm\":\"institutional partner\",\"category\":\"accounting\"},{\"sequencenumber\":87,\"key\":\"institutional_membership\",\"tenantterm\":\"institutional partnership\",\"frontiersdefaultterm\":\"institutional partnership\",\"category\":\"accounting\"},{\"sequencenumber\":88,\"key\":\"article_processing_charge\",\"tenantterm\":\"article processing charge\",\"frontiersdefaultterm\":\"article processing charge\",\"category\":\"accounting\"},{\"sequencenumber\":89,\"key\":\"article_processing_charges\",\"tenantterm\":\"article processing charges\",\"frontiersdefaultterm\":\"article processing charges\",\"category\":\"accounting\"},{\"sequencenumber\":90,\"key\":\"apcs\",\"tenantterm\":\"apcs\",\"frontiersdefaultterm\":\"apcs\",\"category\":\"accounting\"},{\"sequencenumber\":91,\"key\":\"apc\",\"tenantterm\":\"apc\",\"frontiersdefaultterm\":\"apc\",\"category\":\"accounting\"},{\"sequencenumber\":92,\"key\":\"received\",\"tenantterm\":\"received\",\"frontiersdefaultterm\":\"received\",\"description\":\"date manuscript was received on.\",\"category\":\"core\"},{\"sequencenumber\":93,\"key\":\"transferred\",\"tenantterm\":\"transferred\",\"frontiersdefaultterm\":\"transferred\",\"category\":\"core\"},{\"sequencenumber\":94,\"key\":\"transfer\",\"tenantterm\":\"transfer\",\"frontiersdefaultterm\":\"transfer\",\"category\":\"core\"},{\"sequencenumber\":95,\"key\":\"research_topic\",\"tenantterm\":\"research topic\",\"frontiersdefaultterm\":\"research topic\",\"category\":\"core\"},{\"sequencenumber\":96,\"key\":\"research_topics\",\"tenantterm\":\"research topics\",\"frontiersdefaultterm\":\"research topics\",\"category\":\"core\"},{\"sequencenumber\":97,\"key\":\"topic_editor\",\"tenantterm\":\"topic editor\",\"frontiersdefaultterm\":\"topic editor\",\"category\":\"label (role)\"},{\"sequencenumber\":98,\"key\":\"review_editor\",\"tenantterm\":\"community reviewer\",\"frontiersdefaultterm\":\"review editor\",\"category\":\"label (role)\"},{\"sequencenumber\":99,\"key\":\"title\",\"tenantterm\":\"title\",\"frontiersdefaultterm\":\"title\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":100,\"key\":\"running_title\",\"tenantterm\":\"running title\",\"frontiersdefaultterm\":\"running title\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":101,\"key\":\"submit\",\"tenantterm\":\"submit\",\"frontiersdefaultterm\":\"submit\",\"category\":\"process\"},{\"sequencenumber\":102,\"key\":\"submitted\",\"tenantterm\":\"submitted\",\"frontiersdefaultterm\":\"submitted\",\"category\":\"process\"},{\"sequencenumber\":103,\"key\":\"submitting\",\"tenantterm\":\"submitting\",\"frontiersdefaultterm\":\"submitting\",\"category\":\"process\"},{\"sequencenumber\":104,\"key\":\"t_e\",\"tenantterm\":\"te\",\"frontiersdefaultterm\":\"te\",\"category\":\"label (role)\"},{\"sequencenumber\":105,\"key\":\"topic\",\"tenantterm\":\"topic\",\"frontiersdefaultterm\":\"topic\",\"category\":\"process\"},{\"sequencenumber\":106,\"key\":\"topic_summary\",\"tenantterm\":\"topic summary\",\"frontiersdefaultterm\":\"topic summary\",\"category\":\"process\"},{\"sequencenumber\":107,\"key\":\"figure\",\"tenantterm\":\"figure\",\"frontiersdefaultterm\":\"figure\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":108,\"key\":\"figures\",\"tenantterm\":\"figures\",\"frontiersdefaultterm\":\"figures\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":109,\"key\":\"editorial_file\",\"tenantterm\":\"editorial file\",\"frontiersdefaultterm\":\"editorial file\",\"category\":\"core\"},{\"sequencenumber\":110,\"key\":\"editorial_files\",\"tenantterm\":\"editorial files\",\"frontiersdefaultterm\":\"editorial files\",\"category\":\"core\"},{\"sequencenumber\":111,\"key\":\"e_book\",\"tenantterm\":\"e-book\",\"frontiersdefaultterm\":\"e-book\",\"category\":\"core\"},{\"sequencenumber\":112,\"key\":\"organization\",\"tenantterm\":\"organization\",\"frontiersdefaultterm\":\"organization\",\"category\":\"core\"},{\"sequencenumber\":113,\"key\":\"institution\",\"tenantterm\":\"institution\",\"frontiersdefaultterm\":\"institution\",\"category\":\"core\"},{\"sequencenumber\":114,\"key\":\"reference\",\"tenantterm\":\"reference\",\"frontiersdefaultterm\":\"reference\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":115,\"key\":\"references\",\"tenantterm\":\"references\",\"frontiersdefaultterm\":\"references\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":116,\"key\":\"sce\",\"tenantterm\":\"sce\",\"frontiersdefaultterm\":\"sce\",\"description\":\"abbreviation for specialty chief editor\",\"category\":\"label (role)\"},{\"sequencenumber\":117,\"key\":\"submission\",\"tenantterm\":\"submission\",\"frontiersdefaultterm\":\"submission\",\"category\":\"process\"},{\"sequencenumber\":118,\"key\":\"submissions\",\"tenantterm\":\"submissions\",\"frontiersdefaultterm\":\"submissions\",\"category\":\"process\"},{\"sequencenumber\":119,\"key\":\"editing\",\"tenantterm\":\"editing\",\"frontiersdefaultterm\":\"editing\",\"category\":\"process\"},{\"sequencenumber\":120,\"key\":\"in_preparation\",\"tenantterm\":\"in preparation\",\"frontiersdefaultterm\":\"in preparation\",\"category\":\"process\"},{\"sequencenumber\":121,\"key\":\"country_region\",\"tenantterm\":\"country/region\",\"frontiersdefaultterm\":\"country/region\",\"description\":\"because of political issues, some of the country listings are actually classified as `regions` and we need to include this. however other clients may not want to do this.\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":122,\"key\":\"countries_regions\",\"tenantterm\":\"countries/regions\",\"frontiersdefaultterm\":\"countries/regions\",\"description\":\"because of political issues, some of the country listings are actually classified as `regions` and we need to include this. however other clients may not want to do this.\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":123,\"key\":\"specialty\",\"tenantterm\":\"specialty\",\"frontiersdefaultterm\":\"specialty\",\"category\":\"core\"},{\"sequencenumber\":124,\"key\":\"specialties\",\"tenantterm\":\"specialties\",\"frontiersdefaultterm\":\"specialties\",\"category\":\"core\"},{\"sequencenumber\":125,\"key\":\"associate_editors\",\"tenantterm\":\"associate editors\",\"frontiersdefaultterm\":\"associate editors\",\"description\":\"an editorial role on a specialty that a registered user may hold. this gives them rights to different functionality and parts of the platform\",\"category\":\"label (role)\"},{\"sequencenumber\":126,\"key\":\"reviewed\",\"tenantterm\":\"reviewed\",\"frontiersdefaultterm\":\"reviewed\",\"category\":\"peer review process\"},{\"sequencenumber\":127,\"key\":\"institutional_members\",\"tenantterm\":\"institutional partners\",\"frontiersdefaultterm\":\"institutional partners\",\"category\":\"accounting\"},{\"sequencenumber\":128,\"key\":\"institutional_memberships\",\"tenantterm\":\"institutional partnerships\",\"frontiersdefaultterm\":\"institutional partnerships\",\"category\":\"accounting\"},{\"sequencenumber\":129,\"key\":\"assistant_field_chief_editors\",\"tenantterm\":\"assistant field chief editors\",\"frontiersdefaultterm\":\"assistant field chief editors\",\"category\":\"label (role)\"},{\"sequencenumber\":130,\"key\":\"publications\",\"tenantterm\":\"publications\",\"frontiersdefaultterm\":\"publications\",\"category\":\"process\"},{\"sequencenumber\":131,\"key\":\"ae_accepted\",\"tenantterm\":\"recommended acceptance\",\"frontiersdefaultterm\":\"accepted\",\"category\":\"process\"},{\"sequencenumber\":132,\"key\":\"field_journal\",\"tenantterm\":\"field journal\",\"frontiersdefaultterm\":\"field journal\",\"category\":\"taxonomy\"},{\"sequencenumber\":133,\"key\":\"field_journals\",\"tenantterm\":\"field journals\",\"frontiersdefaultterm\":\"field journals\",\"category\":\"taxonomy\"},{\"sequencenumber\":134,\"key\":\"program_manager\",\"tenantterm\":\"program manager\",\"frontiersdefaultterm\":\"program manager\",\"category\":\"label (role)\"},{\"sequencenumber\":135,\"key\":\"journal_manager\",\"tenantterm\":\"journal manager\",\"frontiersdefaultterm\":\"journal manager\",\"category\":\"label (role)\"},{\"sequencenumber\":136,\"key\":\"journal_specialist\",\"tenantterm\":\"journal specialist\",\"frontiersdefaultterm\":\"journal specialist\",\"category\":\"label (role)\"},{\"sequencenumber\":137,\"key\":\"program_managers\",\"tenantterm\":\"program managers\",\"frontiersdefaultterm\":\"program managers\",\"category\":\"label (role)\"},{\"sequencenumber\":138,\"key\":\"journal_managers\",\"tenantterm\":\"journal managers\",\"frontiersdefaultterm\":\"journal managers\",\"category\":\"label (role)\"},{\"sequencenumber\":139,\"key\":\"journal_specialists\",\"tenantterm\":\"journal specialists\",\"frontiersdefaultterm\":\"journal specialists\",\"category\":\"label (role)\"},{\"sequencenumber\":140,\"key\":\"cover_letter\",\"tenantterm\":\"manuscript contribution to the field\",\"frontiersdefaultterm\":\"manuscript contribution to the field\",\"category\":\"process\"},{\"sequencenumber\":141,\"key\":\"ae_accepted_manuscript\",\"tenantterm\":\"recommended to accept manuscript\",\"frontiersdefaultterm\":\"accepted manuscript\",\"category\":\"process\"},{\"sequencenumber\":142,\"key\":\"recommend_for_rejection\",\"tenantterm\":\"recommend for rejection\",\"frontiersdefaultterm\":\"recommend for rejection\",\"category\":\"process\"},{\"sequencenumber\":143,\"key\":\"recommended_for_rejection\",\"tenantterm\":\"recommended for rejection\",\"frontiersdefaultterm\":\"recommended for rejection\",\"category\":\"process\"},{\"sequencenumber\":144,\"key\":\"ae\",\"tenantterm\":\"ae\",\"frontiersdefaultterm\":\"ae\",\"description\":\"associate editor - board member\",\"category\":\"label (role)\"},{\"sequencenumber\":145,\"key\":\"re\",\"tenantterm\":\"re\",\"frontiersdefaultterm\":\"re\",\"description\":\"review editor\",\"category\":\"label (role)\"},{\"sequencenumber\":146,\"key\":\"rev\",\"tenantterm\":\"rev\",\"frontiersdefaultterm\":\"rev\",\"description\":\"reviewer\",\"category\":\"label (role)\"},{\"sequencenumber\":147,\"key\":\"aut\",\"tenantterm\":\"aut\",\"frontiersdefaultterm\":\"aut\",\"description\":\"author\",\"category\":\"label (role)\"},{\"sequencenumber\":148,\"key\":\"coraut\",\"tenantterm\":\"coraut\",\"frontiersdefaultterm\":\"coraut\",\"description\":\"corresponding author\",\"category\":\"label (role)\"},{\"sequencenumber\":149,\"key\":\"saut\",\"tenantterm\":\"saut\",\"frontiersdefaultterm\":\"saut\",\"description\":\"submitting author\",\"category\":\"label (role)\"},{\"sequencenumber\":150,\"key\":\"coaut\",\"tenantterm\":\"coaut\",\"frontiersdefaultterm\":\"coaut\",\"description\":\"co-author\",\"category\":\"label (role)\"},{\"sequencenumber\":151,\"key\":\"tsof\",\"tenantterm\":\"tsof\",\"frontiersdefaultterm\":\"tsof\",\"description\":\"typesetter\",\"category\":\"label (role)\"},{\"sequencenumber\":152,\"key\":\"typesetting_office\",\"tenantterm\":\"typesetting office\",\"frontiersdefaultterm\":\"typesetting office\",\"category\":\"product\"},{\"sequencenumber\":153,\"key\":\"config\",\"tenantterm\":\"config\",\"frontiersdefaultterm\":\"config\",\"description\":\"configuration office role\",\"category\":\"label (role)\"},{\"sequencenumber\":154,\"key\":\"jm\",\"tenantterm\":\"jm\",\"frontiersdefaultterm\":\"jm\",\"description\":\"journal manager\",\"category\":\"label (role)\"},{\"sequencenumber\":155,\"key\":\"rte\",\"tenantterm\":\"rte\",\"frontiersdefaultterm\":\"rte\",\"description\":\"research topic editor\",\"category\":\"label (role)\"},{\"sequencenumber\":156,\"key\":\"organizations\",\"tenantterm\":\"organizations\",\"frontiersdefaultterm\":\"organizations\",\"category\":\"core\"},{\"sequencenumber\":157,\"key\":\"publishing\",\"tenantterm\":\"publishing\",\"frontiersdefaultterm\":\"publishing\",\"category\":\"core\"},{\"sequencenumber\":158,\"key\":\"acceptance\",\"tenantterm\":\"acceptance\",\"frontiersdefaultterm\":\"acceptance\",\"category\":\"process\"},{\"sequencenumber\":159,\"key\":\"preferred_associate_editor\",\"tenantterm\":\"preferred associate editor\",\"frontiersdefaultterm\":\"preferred associate editor\",\"category\":\"label (role)\"},{\"sequencenumber\":160,\"key\":\"topic_editors\",\"tenantterm\":\"topic editors\",\"frontiersdefaultterm\":\"topic editors\",\"category\":\"label (role)\"},{\"sequencenumber\":161,\"key\":\"institutions\",\"tenantterm\":\"institutions\",\"frontiersdefaultterm\":\"institutions\",\"category\":\"core\"},{\"sequencenumber\":162,\"key\":\"author(s)\",\"tenantterm\":\"author(s)\",\"frontiersdefaultterm\":\"author(s)\",\"category\":\"label (role)\"},{\"sequencenumber\":163,\"key\":\"figure(s)\",\"tenantterm\":\"figure(s)\",\"frontiersdefaultterm\":\"figure(s)\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":164,\"key\":\"co-authors\",\"tenantterm\":\"co-authors\",\"frontiersdefaultterm\":\"co-authors\",\"description\":\"co-authors\",\"category\":\"label (role)\"},{\"sequencenumber\":165,\"key\":\"editorial_board_members\",\"tenantterm\":\"editorial board members\",\"frontiersdefaultterm\":\"editorial board members\",\"description\":\"editorial board members\",\"category\":\"label (role)\"},{\"sequencenumber\":166,\"key\":\"editorial_board\",\"tenantterm\":\"editorial board\",\"frontiersdefaultterm\":\"editorial board\",\"description\":\"editorial board\",\"category\":\"product\"},{\"sequencenumber\":167,\"key\":\"co-authorship\",\"tenantterm\":\"co-authorship\",\"frontiersdefaultterm\":\"co-authorship\",\"description\":\"co-authorship\",\"category\":\"misc.\"},{\"sequencenumber\":168,\"key\":\"role_id_1\",\"tenantterm\":\"registration office\",\"frontiersdefaultterm\":\"registration office\",\"category\":\"user role\"},{\"sequencenumber\":169,\"key\":\"role_id_2\",\"tenantterm\":\"editorial office\",\"frontiersdefaultterm\":\"editorial office\",\"category\":\"user role\"},{\"sequencenumber\":170,\"key\":\"role_id_7\",\"tenantterm\":\"field chief editor\",\"frontiersdefaultterm\":\"field chief editor\",\"category\":\"user role\"},{\"sequencenumber\":171,\"key\":\"role_id_8\",\"tenantterm\":\"assistant field chief editor\",\"frontiersdefaultterm\":\"assistant field chief editor\",\"category\":\"user role\"},{\"sequencenumber\":172,\"key\":\"role_id_9\",\"tenantterm\":\"specialty chief editor\",\"frontiersdefaultterm\":\"specialty chief editor\",\"category\":\"user role\"},{\"sequencenumber\":173,\"key\":\"role_id_10\",\"tenantterm\":\"assistant specialty chief editor\",\"frontiersdefaultterm\":\"assistant specialty chief editor\",\"category\":\"user role\"},{\"sequencenumber\":174,\"key\":\"role_id_11\",\"tenantterm\":\"associate editor\",\"frontiersdefaultterm\":\"associate editor\",\"category\":\"user role\"},{\"sequencenumber\":175,\"key\":\"role_id_12\",\"tenantterm\":\"guest associate editor\",\"frontiersdefaultterm\":\"guest associate editor\",\"category\":\"user role\"},{\"sequencenumber\":176,\"key\":\"role_id_13\",\"tenantterm\":\"review editor\",\"frontiersdefaultterm\":\"review editor\",\"category\":\"user role\"},{\"sequencenumber\":177,\"key\":\"role_id_14\",\"tenantterm\":\"reviewer\",\"frontiersdefaultterm\":\"reviewer\",\"category\":\"user role\"},{\"sequencenumber\":178,\"key\":\"role_id_15\",\"tenantterm\":\"author\",\"frontiersdefaultterm\":\"author\",\"category\":\"user role\"},{\"sequencenumber\":179,\"key\":\"role_id_16\",\"tenantterm\":\"corresponding author\",\"frontiersdefaultterm\":\"corresponding author\",\"category\":\"user role\"},{\"sequencenumber\":180,\"key\":\"role_id_17\",\"tenantterm\":\"submitting author\",\"frontiersdefaultterm\":\"submitting author\",\"category\":\"user role\"},{\"sequencenumber\":181,\"key\":\"role_id_18\",\"tenantterm\":\"co-author\",\"frontiersdefaultterm\":\"co-author\",\"category\":\"user role\"},{\"sequencenumber\":182,\"key\":\"role_id_20\",\"tenantterm\":\"production office\",\"frontiersdefaultterm\":\"production office\",\"category\":\"user role\"},{\"sequencenumber\":183,\"key\":\"role_id_22\",\"tenantterm\":\"typesetting office (typesetter)\",\"frontiersdefaultterm\":\"typesetting office (typesetter)\",\"category\":\"user role\"},{\"sequencenumber\":184,\"key\":\"role_id_24\",\"tenantterm\":\"registered user\",\"frontiersdefaultterm\":\"registered user\",\"category\":\"user role\"},{\"sequencenumber\":185,\"key\":\"role_id_35\",\"tenantterm\":\"job office\",\"frontiersdefaultterm\":\"job office\",\"category\":\"user role\"},{\"sequencenumber\":186,\"key\":\"role_id_41\",\"tenantterm\":\"special event administrator\",\"frontiersdefaultterm\":\"special event administrator\",\"category\":\"user role\"},{\"sequencenumber\":187,\"key\":\"role_id_42\",\"tenantterm\":\"special event reviewer\",\"frontiersdefaultterm\":\"special event reviewer\",\"category\":\"user role\"},{\"sequencenumber\":188,\"key\":\"role_id_43\",\"tenantterm\":\"submit abstract\",\"frontiersdefaultterm\":\"submit abstract\",\"category\":\"user role\"},{\"sequencenumber\":189,\"key\":\"role_id_52\",\"tenantterm\":\"events office\",\"frontiersdefaultterm\":\"events office\",\"category\":\"user role\"},{\"sequencenumber\":190,\"key\":\"role_id_53\",\"tenantterm\":\"event administrator\",\"frontiersdefaultterm\":\"event administrator\",\"category\":\"user role\"},{\"sequencenumber\":191,\"key\":\"role_id_89\",\"tenantterm\":\"content management office\",\"frontiersdefaultterm\":\"content management office\",\"category\":\"user role\"},{\"sequencenumber\":192,\"key\":\"role_id_98\",\"tenantterm\":\"accounting office\",\"frontiersdefaultterm\":\"accounting office\",\"category\":\"user role\"},{\"sequencenumber\":193,\"key\":\"role_id_99\",\"tenantterm\":\"projects\",\"frontiersdefaultterm\":\"projects\",\"category\":\"user role\"},{\"sequencenumber\":194,\"key\":\"role_id_103\",\"tenantterm\":\"configuration office\",\"frontiersdefaultterm\":\"configuration office\",\"category\":\"user role\"},{\"sequencenumber\":195,\"key\":\"role_id_104\",\"tenantterm\":\"beta user\",\"frontiersdefaultterm\":\"beta user\",\"category\":\"user role\"},{\"sequencenumber\":196,\"key\":\"role_id_106\",\"tenantterm\":\"wfconf\",\"frontiersdefaultterm\":\"wfconf\",\"category\":\"user role\"},{\"sequencenumber\":197,\"key\":\"role_id_107\",\"tenantterm\":\"rt management beta user\",\"frontiersdefaultterm\":\"rt management beta user\",\"category\":\"user role\"},{\"sequencenumber\":198,\"key\":\"role_id_108\",\"tenantterm\":\"deo beta user\",\"frontiersdefaultterm\":\"deo beta user\",\"category\":\"user role\"},{\"sequencenumber\":199,\"key\":\"role_id_109\",\"tenantterm\":\"search beta user\",\"frontiersdefaultterm\":\"search beta user\",\"category\":\"user role\"},{\"sequencenumber\":200,\"key\":\"role_id_110\",\"tenantterm\":\"journal manager\",\"frontiersdefaultterm\":\"journal manager\",\"category\":\"user role\"},{\"sequencenumber\":201,\"key\":\"role_id_111\",\"tenantterm\":\"myfrontiers beta user\",\"frontiersdefaultterm\":\"myfrontiers beta user\",\"category\":\"user role\"},{\"sequencenumber\":202,\"key\":\"role_id_21\",\"tenantterm\":\"copy editor\",\"frontiersdefaultterm\":\"copy editor\",\"category\":\"user role\"},{\"sequencenumber\":203,\"key\":\"role_id_1_abr\",\"tenantterm\":\"rof\",\"frontiersdefaultterm\":\"rof\",\"category\":\"user role\"},{\"sequencenumber\":204,\"key\":\"role_id_2_abr\",\"tenantterm\":\"eof\",\"frontiersdefaultterm\":\"eof\",\"category\":\"user role\"},{\"sequencenumber\":205,\"key\":\"role_id_7_abr\",\"tenantterm\":\"fce\",\"frontiersdefaultterm\":\"fce\",\"category\":\"user role\"},{\"sequencenumber\":206,\"key\":\"role_id_8_abr\",\"tenantterm\":\"afce\",\"frontiersdefaultterm\":\"afce\",\"category\":\"user role\"},{\"sequencenumber\":207,\"key\":\"role_id_9_abr\",\"tenantterm\":\"sce\",\"frontiersdefaultterm\":\"sce\",\"category\":\"user role\"},{\"sequencenumber\":208,\"key\":\"role_id_10_abr\",\"tenantterm\":\"asce\",\"frontiersdefaultterm\":\"asce\",\"category\":\"user role\"},{\"sequencenumber\":209,\"key\":\"role_id_11_abr\",\"tenantterm\":\"ae\",\"frontiersdefaultterm\":\"ae\",\"category\":\"user role\"},{\"sequencenumber\":210,\"key\":\"role_id_12_abr\",\"tenantterm\":\"gae\",\"frontiersdefaultterm\":\"gae\",\"category\":\"user role\"},{\"sequencenumber\":211,\"key\":\"role_id_13_abr\",\"tenantterm\":\"re\",\"frontiersdefaultterm\":\"re\",\"category\":\"user role\"},{\"sequencenumber\":212,\"key\":\"role_id_14_abr\",\"tenantterm\":\"rev\",\"frontiersdefaultterm\":\"rev\",\"category\":\"user role\"},{\"sequencenumber\":213,\"key\":\"role_id_15_abr\",\"tenantterm\":\"aut\",\"frontiersdefaultterm\":\"aut\",\"category\":\"user role\"},{\"sequencenumber\":214,\"key\":\"role_id_16_abr\",\"tenantterm\":\"coraut\",\"frontiersdefaultterm\":\"coraut\",\"category\":\"user role\"},{\"sequencenumber\":215,\"key\":\"role_id_17_abr\",\"tenantterm\":\"saut\",\"frontiersdefaultterm\":\"saut\",\"category\":\"user role\"},{\"sequencenumber\":216,\"key\":\"role_id_18_abr\",\"tenantterm\":\"coaut\",\"frontiersdefaultterm\":\"coaut\",\"category\":\"user role\"},{\"sequencenumber\":217,\"key\":\"role_id_20_abr\",\"tenantterm\":\"pof\",\"frontiersdefaultterm\":\"pof\",\"category\":\"user role\"},{\"sequencenumber\":218,\"key\":\"role_id_22_abr\",\"tenantterm\":\"tsof\",\"frontiersdefaultterm\":\"tsof\",\"category\":\"user role\"},{\"sequencenumber\":219,\"key\":\"role_id_24_abr\",\"tenantterm\":\"ru\",\"frontiersdefaultterm\":\"ru\",\"category\":\"user role\"},{\"sequencenumber\":220,\"key\":\"role_id_35_abr\",\"tenantterm\":\"jof\",\"frontiersdefaultterm\":\"jof\",\"category\":\"user role\"},{\"sequencenumber\":221,\"key\":\"role_id_41_abr\",\"tenantterm\":\"se-adm\",\"frontiersdefaultterm\":\"se-adm\",\"category\":\"user role\"},{\"sequencenumber\":222,\"key\":\"role_id_42_abr\",\"tenantterm\":\"se-rev\",\"frontiersdefaultterm\":\"se-rev\",\"category\":\"user role\"},{\"sequencenumber\":223,\"key\":\"role_id_43_abr\",\"tenantterm\":\"se-aut\",\"frontiersdefaultterm\":\"se-aut\",\"category\":\"user role\"},{\"sequencenumber\":224,\"key\":\"role_id_52_abr\",\"tenantterm\":\"evof\",\"frontiersdefaultterm\":\"evof\",\"category\":\"user role\"},{\"sequencenumber\":225,\"key\":\"role_id_53_abr\",\"tenantterm\":\"ev-adm\",\"frontiersdefaultterm\":\"ev-adm\",\"category\":\"user role\"},{\"sequencenumber\":226,\"key\":\"role_id_89_abr\",\"tenantterm\":\"comof\",\"frontiersdefaultterm\":\"comof\",\"category\":\"user role\"},{\"sequencenumber\":227,\"key\":\"role_id_98_abr\",\"tenantterm\":\"aof\",\"frontiersdefaultterm\":\"aof\",\"category\":\"user role\"},{\"sequencenumber\":228,\"key\":\"role_id_99_abr\",\"tenantterm\":\"projects\",\"frontiersdefaultterm\":\"projects\",\"category\":\"user role\"},{\"sequencenumber\":229,\"key\":\"role_id_103_abr\",\"tenantterm\":\"config\",\"frontiersdefaultterm\":\"config\",\"category\":\"user role\"},{\"sequencenumber\":230,\"key\":\"role_id_104_abr\",\"tenantterm\":\"beta\",\"frontiersdefaultterm\":\"beta\",\"category\":\"user role\"},{\"sequencenumber\":231,\"key\":\"role_id_106_abr\",\"tenantterm\":\"wfconf\",\"frontiersdefaultterm\":\"wfconf\",\"category\":\"user role\"},{\"sequencenumber\":232,\"key\":\"role_id_107_abr\",\"tenantterm\":\"rtbeta\",\"frontiersdefaultterm\":\"rtbeta\",\"category\":\"user role\"},{\"sequencenumber\":233,\"key\":\"role_id_108_abr\",\"tenantterm\":\"deobeta\",\"frontiersdefaultterm\":\"deobeta\",\"category\":\"user role\"},{\"sequencenumber\":234,\"key\":\"role_id_109_abr\",\"tenantterm\":\"searchbeta\",\"frontiersdefaultterm\":\"searchbeta\",\"category\":\"user role\"},{\"sequencenumber\":235,\"key\":\"role_id_110_abr\",\"tenantterm\":\"jm\",\"frontiersdefaultterm\":\"jm\",\"category\":\"user role\"},{\"sequencenumber\":236,\"key\":\"role_id_111_abr\",\"tenantterm\":\"mfbeta\",\"frontiersdefaultterm\":\"mfbeta\",\"category\":\"user role\"},{\"sequencenumber\":237,\"key\":\"role_id_21_abr\",\"tenantterm\":\"coped\",\"frontiersdefaultterm\":\"coped\",\"category\":\"user role\"},{\"sequencenumber\":238,\"key\":\"reviewer_editorial_board\",\"tenantterm\":\"editorial board\",\"frontiersdefaultterm\":\"editorial board\",\"description\":\"this is the label for the review editorial board\",\"category\":\"label\"},{\"sequencenumber\":239,\"key\":\"field_chief_editor\",\"tenantterm\":\"field chief editor\",\"frontiersdefaultterm\":\"field chief editor\",\"category\":\"label (role)\"},{\"sequencenumber\":240,\"key\":\"field_chief_editors\",\"tenantterm\":\"field chief editors\",\"frontiersdefaultterm\":\"field chief editors\",\"category\":\"label (role)\"},{\"sequencenumber\":241,\"key\":\"editor\",\"tenantterm\":\"editor\",\"frontiersdefaultterm\":\"editor\",\"category\":\"label (role)\"},{\"sequencenumber\":242,\"key\":\"editors\",\"tenantterm\":\"editors\",\"frontiersdefaultterm\":\"editors\",\"category\":\"label (role)\"},{\"sequencenumber\":243,\"key\":\"board\",\"tenantterm\":\"board\",\"frontiersdefaultterm\":\"board\",\"category\":\"label\"},{\"sequencenumber\":244,\"key\":\"boards\",\"tenantterm\":\"boards\",\"frontiersdefaultterm\":\"boards\",\"category\":\"label\"},{\"sequencenumber\":245,\"key\":\"article_collection\",\"tenantterm\":\"article collection\",\"frontiersdefaultterm\":\"article collection\",\"category\":\"label\"},{\"sequencenumber\":246,\"key\":\"article_collections\",\"tenantterm\":\"article collections\",\"frontiersdefaultterm\":\"article collections\",\"category\":\"label\"},{\"sequencenumber\":247,\"key\":\"handling_editor\",\"tenantterm\":\"handling editor\",\"frontiersdefaultterm\":\"associate editor\",\"description\":\"this terminology key is for the person assigned to edit a manuscript. it is a label for the temporary handling editor assignment.\",\"category\":\"label (role)\"},{\"sequencenumber\":248,\"key\":\"handling_editors\",\"tenantterm\":\"handling editors\",\"frontiersdefaultterm\":\"associate editors\",\"description\":\"this terminology key is for the person assigned to edit a manuscript. it is a label for the temporary handling editor assignment.\",\"category\":\"label (role)\"},{\"sequencenumber\":249,\"key\":\"ae_accept\",\"tenantterm\":\"recommend acceptance\",\"frontiersdefaultterm\":\"accept\",\"category\":\"process\"},{\"sequencenumber\":250,\"key\":\"rtm\",\"tenantterm\":\"rtm\",\"frontiersdefaultterm\":\"rtm\",\"category\":\"product\"},{\"sequencenumber\":251,\"key\":\"frontiers_media_sa\",\"tenantterm\":\"frontiers media s.a\",\"frontiersdefaultterm\":\"frontiers media s.a\",\"category\":\"customer\"},{\"sequencenumber\":252,\"key\":\"review_editors\",\"tenantterm\":\"community reviewers\",\"frontiersdefaultterm\":\"review editors\",\"category\":\"label (role)\"},{\"sequencenumber\":253,\"key\":\"journal_card_chief_editor\",\"tenantterm\":\"chief editor\",\"frontiersdefaultterm\":\"chief editor\",\"category\":\"label (role)\"},{\"sequencenumber\":254,\"key\":\"journal_card_chief_editors\",\"tenantterm\":\"chief editors\",\"frontiersdefaultterm\":\"chief editors\",\"category\":\"label (role)\"},{\"sequencenumber\":255,\"key\":\"call_for_papers\",\"tenantterm\":\"call for papers\",\"frontiersdefaultterm\":\"call for papers\",\"category\":\"label\"},{\"sequencenumber\":256,\"key\":\"calls_for_papers\",\"tenantterm\":\"calls for papers\",\"frontiersdefaultterm\":\"calls for papers\",\"category\":\"label\"},{\"sequencenumber\":257,\"key\":\"supervising_editor\",\"tenantterm\":\"supervising editor\",\"frontiersdefaultterm\":\"supervising editor\",\"description\":\"a chief or assistant chief editor who is assigned to a manuscript to supervise.\",\"category\":\"role\",\"externalkey\":\"supervising_editor\"},{\"sequencenumber\":258,\"key\":\"supervising_editors\",\"tenantterm\":\"supervising editors\",\"frontiersdefaultterm\":\"supervising editors\",\"description\":\"a chief or assistant chief editor who is assigned to a manuscript to supervise.\",\"category\":\"role\",\"externalkey\":\"supervising_editors\"},{\"sequencenumber\":259,\"key\":\"reviewer_endorse\",\"tenantterm\":\"endorse\",\"frontiersdefaultterm\":\"endorse\",\"category\":\"label\"},{\"sequencenumber\":260,\"key\":\"reviewer_endorsed\",\"tenantterm\":\"endorsed\",\"frontiersdefaultterm\":\"endorsed\",\"category\":\"label\"},{\"sequencenumber\":261,\"key\":\"reviewer_endorse_publication\",\"tenantterm\":\"endorse publication\",\"frontiersdefaultterm\":\"endorse publication\",\"category\":\"label\"},{\"sequencenumber\":262,\"key\":\"reviewer_endorsed_publication\",\"tenantterm\":\"endorsed publication\",\"frontiersdefaultterm\":\"endorsed publication\",\"category\":\"label\"},{\"sequencenumber\":263,\"key\":\"editor_role\",\"tenantterm\":\"editor role\",\"frontiersdefaultterm\":\"editor role\",\"category\":\"label\"},{\"sequencenumber\":264,\"key\":\"editor_roles\",\"tenantterm\":\"editor roles\",\"frontiersdefaultterm\":\"editor roles\",\"category\":\"label\"},{\"sequencenumber\":265,\"key\":\"editorial_role\",\"tenantterm\":\"editorial role\",\"frontiersdefaultterm\":\"editorial role\",\"category\":\"label\"},{\"sequencenumber\":266,\"key\":\"editorial_roles\",\"tenantterm\":\"editorial roles\",\"frontiersdefaultterm\":\"editorial roles\",\"category\":\"label\"},{\"sequencenumber\":267,\"key\":\"call_for_paper\",\"tenantterm\":\"call for paper\",\"frontiersdefaultterm\":\"call for paper\",\"category\":\"label\"},{\"sequencenumber\":268,\"key\":\"research_topic_abstract\",\"tenantterm\":\"manuscript summary\",\"frontiersdefaultterm\":\"manuscript summary\",\"category\":\"process\"},{\"sequencenumber\":269,\"key\":\"research_topic_abstracts\",\"tenantterm\":\"manuscript summaries\",\"frontiersdefaultterm\":\"manuscript summaries\",\"category\":\"process\"},{\"sequencenumber\":270,\"key\":\"submissions_team_manager\",\"tenantterm\":\"journal manager\",\"frontiersdefaultterm\":\"content manager\",\"category\":\"process\"},{\"sequencenumber\":271,\"key\":\"submissions_team\",\"tenantterm\":\"journal team\",\"frontiersdefaultterm\":\"content team\",\"category\":\"process\"},{\"sequencenumber\":272,\"key\":\"topic_coordinator\",\"tenantterm\":\"topic coordinator\",\"frontiersdefaultterm\":\"topic coordinator\",\"category\":\"process\"},{\"sequencenumber\":273,\"key\":\"topic_coordinators\",\"tenantterm\":\"topic coordinators\",\"frontiersdefaultterm\":\"topic coordinators\",\"category\":\"process\"},{\"sequencenumber\":274,\"key\":\"frontiers_journal_team\",\"tenantterm\":\"frontiers journal team\",\"frontiersdefaultterm\":\"frontiers journal team\",\"category\":\"label (role)\"},{\"sequencenumber\":275,\"key\":\"research_topic_ic_submission\",\"tenantterm\":\"rt:ic submission\",\"frontiersdefaultterm\":\"rt:ic submission\",\"category\":\"label (role)\"},{\"sequencenumber\":276,\"key\":\"research_topic_ic_submission_participant\",\"tenantterm\":\"rt:ic submission participant\",\"frontiersdefaultterm\":\"rt:ic submission participant\",\"category\":\"label (role)\"}]}'\n",impactgtmid:"gtm-njf2ml9b",impactgtmauth:"fyo-7nodm9w37qgfms03sa",impactgtmpreview:"env-1",impactgooglemapsapikey:"aizasyctehx2eu8pwfi86gw9fi00ftcykk6ifr8",qualtricsv4tov3:"'{\"enabled\":true,\"interceptid\":\"si_er0e2ze69oz8yn4\",\"projectid\":\"zn_cloy77jhkpc8gai\",\"brandid\":\"frontiersin\"}'\n",qualtricsumux:"'{\"enabled\":false,\"interceptid\":\"si_89fphy3etxqbwtu\",\"projectid\":\"zn_cloy77jhkpc8gai\",\"brandid\":\"frontiersin\"}'\n",qualtricscontinuousbrand:"'{\"enabled\":true,\"interceptid\":\"si_9zut94ut81fcrh4\",\"projectid\":\"zn_cloy77jhkpc8gai\",\"brandid\":\"frontiersin\"}'\n",defaultarticletemplate:"v3"},app:{baseurl:"/",buildid:"f2d5b6d8-d01c-4534-90b9-d659f10f17ca",buildassetsdir:"ap-2024/_nuxt",cdnurl:""}}## Discussion
ultimately, the proposed system was compared against the existing system that used the same dataset. the proposed approach is based on variations in the text of social media interactions, which can assist physicians and clinicians in performing symptom studies within digital footprint environments. 1 introduction asd is among the most prevalent neurodevelopmental disorders. asd is often demonstrated in children by age three and is defined by impairments in social interactions and communication, repetitive sensory-motor activities, and stereotypical behavioral patterns ( 1 ). asd is a congenital neurodevelopmental condition characterized by symptoms that are evident in early infancy. autism, characterized by restricted interests, repetitive behaviors, and significant disparities in social communication and interaction, typically emerges during early developmental stages and presents challenges in various social functioning domains. a child with autism induces significant anxiety within the family due to several factors, including the ambiguity of the diagnosis, the intensity and persistence of the disease, and the child’s nonconformity to social norms. in opposition, social awareness of autism is markedly inadequate, often conflated with intellectual disability and seen as an incurable ailment ( 2 , 3 ). the asd concept is displayed in figure 1 . figure 1 figure 1 . displays the asd concept. content on social media, particularly videos and text disseminated by parents and caregivers, has emerged as a significant resource for facilitating the early identification of asd ( 4 , 5 ). social media are technological tools designed for sharing, enabling users to create networks or engage in existing ones. in that order, the pew research center identified the most popular social media sites as youtube, facebook, instagram, pinterest, linkedin, snapchat, twitter, and whatsapp ( 6 ). most consumers use these networks daily. this research utilizes twitter data to assess the stigmatization of autism and associated terminology, picked based on accessibility and popularity, with analysis conducted using artificial intelligence technologies ( 7 ). conventional diagnostic methods, which primarily rely on observational and behavioral evaluations, often encounter issues with accessibility, consistency, and timeliness. recent technology breakthroughs, especially in artificial intelligence (ai), and sensor-based techniques, provide novel opportunities for improving asd identification. by developing more objective, accurate, and scalable approaches, these technologies transform diagnostic methodologies for autism spectrum disorder (asd) ( 8 – 10 ). one new way to study the motor patterns, attentional processes, and physiological responses linked to asd in real-time is wearable sensors, eye-tracking devices, and multimodal virtual reality settings. these technologies have the potential to give non-invasive, continuous monitoring, which might help with the early diagnosis of asd and shed light on neurological and behavioral traits that have been hard to document reliably. nevertheless, advancements in contemporary research are required to substantiate their efficacy. sensor-based techniques may facilitate the identification of stereotyped behaviors and motor patterns linked to asd in realistic environments, potentially yielding data that could guide timely and customized therapies ( 11 ). neuroimaging and microbiome analysis further advance this technical domain by indicating neurological and biological traits specific to asd. ai-enhanced neuroimaging aids in identifying structural and functional brain connection patterns associated with asd, thereby enhancing the understanding of its neuroanatomical foundation ( 12 ). the research conducted by neeharika and riyazuddin et al. ( 13 ) aimed to enhance the accuracy of asd screening by using feature selection methods in conjunction with sophisticated machine learning classifiers. their research included several datasets spanning infants, children, adolescents, and adults, enabling a thorough assessment of asd characteristics across different age demographics. authors’ use of mlp model capacity to reliably and rapidly identify asd, indicating a beneficial screening instrument suitable for various age groups, facilitating both clinical evaluations and extensive screenings. wall et al. ( 14 ) investigated machine learning (ml) algorithms for diagnosing asd using a standard dataset. the researchers focused on the alternating decision tree classifier to identify a limited yet efficient set of queries that optimize the diagnostic procedure. alzakari et al. ( 15 ) proposed a novel two-phase methodology to tackle the variability in asd features with ml approaches, including behavioral, linguistic, and physical data. the first step concentrates on identifying asd, using feature engineering methodologies and ml algorithms, including a logistic regression (lr) and support vector machine (svm) ensemble, attaining a classification with high accuracy. eeg assesses brain activity and may identify children predisposed to developing asd, hence facilitating early diagnosis. eeg data is used to compare asd and hc ( 16 – 18 ). in ( 19 ), the cnn model was used for classification after transforming the data into a two-dimensional format. while eeg may facilitate the diagnosis of asd, it is constrained by other factors, such as signal noise. the research has used social media to investigate asd. however, exploiting these prevalent platforms and innovative online data sources may be feasible to enhance the comprehension of these diseases. previous research has utilized twitter data to investigate discussions on asd-related material, indicating that this subject is frequently addressed on this platform ( 20 ). considering the use of social media for researching asd is particularly significant, as a recent analysis indicated that around 80% of individuals with asd engage with prominent social media platforms ( 21 ). this study aims to build upon previous research and enhance our comprehension of whether publicly accessible social media data from twitter may provide insights into the existence of digital diagnostic indicators for asd ( 22 ). furthermore, we want to assess the viability of establishing a digital phenotype for asd using social media. beykikhoshk et al. ( 20 ) examined twitter’s potential as a data-mining tool to comprehend the actions, challenges, and requirements of autistic individuals. the first finding pertained to the attributes of participants inside the autism subgroup of tweets, indicating that these tweets were highly informative and had considerable potential usefulness for public health experts and policymakers. tomeny et al. ( 23 ) examined demographic correlations of autism-related anti-vaccine opinions on twitter from 2009 to 2015. their results indicated that the frequency of autism-related anti-vaccine views online was alarming, with anti-vaccine tweets connecting with news events and demonstrating geographical clustering. from 2015 to 2019, tárraga-mínguez et al. ( 24 ) examined the phrases “autism” and “asperger” in spain in relation to google search peaks. the public view of autism was significantly impacted by how the condition was portrayed in the news and on social media, and the authors found that social marketing campaigns had a significant role in normalizing autism. in this research ( 25 ), looked at how people sought assistance. the results showed a strong correlation in google search interest between the terms “asperger syndrome” and “greta thunberg,” reaching their highest point in 2019. online traffic to the asperger/autism network and autism speaks websites increased steadily from june to december 2019, indicating a correlation between help-seeking behavior and thunberg’s fame, according to the research. according to the results, the stigma associated with asperger’s disorder may have been positively affected by thunberg’s public exposure. 1.1 contribution the use of tweets from twitter for the detection of asd is substantial, since it offers extensive, real-time, user-generated data that facilitates the early identification of asd-related behaviors, particularly via self-reported experiences and parental observations. this methodology promotes the advancement of suggested models, namely lstm, cnn-lstm, and inspired ddqn, for natural language processing to examine linguistic patterns, feelings, and keywords related to asd. it provides insights into popular views, stigma, and misconceptions around autism, guiding awareness initiatives and public health measures. twitter data is a powerful and accessible resource for enhancing early detection and understanding of asd in diverse groups. utilizing social media in this manner may offer more accessible and timely screening, particularly in regions with limited healthcare resources. 2 materials and methods figure 2 shows the pipeline of the proposed system to provide a broader perspective to researchers and developers. the framework delineates the processing phases for the pipeline that utilizes social media content to diagnose asd. below, we present a comprehensive assessment of each step. figure 2 figure 2 . farmwork of asd system. 2.1 dataset to help with the early diagnosis of asd by using proposed systems, the tasd-dataset includes comprehensive textual sequences that depict the everyday lives of children with and without asd. it offers new elements, including noise sensitivity, sharing interest, sign communication, and tiptoe flapping, it combines critical asd assessment aspects like attention response, word repetition, and emotional empathy, as shown in figure 3 . parents may get detailed insights and better identify signs of autism spectrum disorder (asd) due to the deepening of certain behaviors. the dataset contains 172 tweets from the asd class and 158 non-asd tweets. figure 4 shows the class of the dataset. figure 3 figure 3 . features of the dataset. figure 4 figure 4 . label of the dataset. 2.2 preprocessing text preprocessing is an essential step in the text processing process. words, sentences, and paragraphs can all be found in a text, which is defined as a meaningful sequence of characters. preprocessing methods feed text data to a proposed algorithm in a better form than in its natural state. a tweet can contain different viewpoints on the data it represents. tweets that have not been preprocessed are highly unstructured and contain redundant data. to address these issues, several steps are taken to preprocess tweets for detecting asd, as shown in figure 5 . figure 5 figure 5 . preprocessing asd text analysis. 2.3 text cleaning the clean text preprocessing method is a significant step in text datasets because the text contains several extra contexts to preprocess and normalize raw text data for analysis. in these steps, the use is transformed to lowercase to guarantee consistency and prevent differentiation between “asd” and “non-asd.” subsequently, any characters that are not letters, numerals, or spaces are eliminated by a regular expression, so punctuation and other symbols that might create extraneous noise are removed. this method is ultimately applied to the ‘text’ column of the data frame, ensuring that all text elements are sanitized and prepared for feature extraction. figure 6 displays the clean text process. figure 6 figure 6 . clean text. 2.4 label encoding the labelencoder method converts text class (asd and non-asd) into numbers, designating 0 for asd and 1 for non-asd. this transformation updates the classification effort by enabling the model to see the labels as numerical values instead of text. equations 1 , 2 show the label encoding. yclassification ∈ ( asd , non − asd ) then      ( 1 ) y = labelencoder ( yclassifcation ) → y ∈ { 0 , 1 }      ( 2 ) 2.5 tokenization and padding tokenization and padding are essential nlp preprocessing procedures that transform unprocessed text into a numerical representation appropriate for machine learning models, particularly neural networks. figure 7 shows the tokenization and padding equation 3 . figure 7 figure 7 . sample of text tokenization and padding. 2.5.1 tokenizer tokenizer procedures transform textual data into a numerical representation suitable for input into neural networks. they convert a text corpus into integer sequences, assigning a distinct index to each unique word according to its frequency, as shown in equation 3 . the tokenizer processing is shown in figure 8 . index ( w ) = rank f ( w ) if rank f ( w ) ≤ v      ( 3 ) figure 8 figure 8 . tokenizer analysis: word frequencies and sequence lengths. where rank f ( w ) is rank w frequency f ( w ) and v is the maximum number of words. 2.5.2 fit texts this phase is crucial for transforming unprocessed text into numerical sequences suitable for input into the proposed system. 2.5.3 texts_to_sequences to convert unprocessed text input into sequences of word indices according to the mapping acquired via as shown in equation 4 . sequence ( t i ) = [ index ( w 1 ) , index ( w 2 ) , … … … , index ( w m ) ]      ( 4 ) where is the t i is the sentence of the text contained, and w is the words of the text, whereas the index ( w 1 ) is an index of the words in the context. 2.5.4 padding_sequences normalize sequence lengths, which may differ post-tokenization, by padding shorter sequences and truncating larger ones to a predetermined length as shown in equation 5 . the padding and truncated b are fixed on the length. l = 200 . the padding processing is shown in figure 7 . x = ∣ x 1 x 2 . . . . y ∣ ∈ ℝ nxl     (5) where x is features contain padding and are tokenized, l is the length of the vector. the number of texts is indicated n , and ∈ ℝ nxl is matrix lues. 2.6 proposed systems 2.6.1 convolutional neural networks the cnn model is at the core of all advanced machine learning and deep learning applications. they can successfully address text classification, image recognition, object identification, and semantic segmentation. using the same method with a task as different as natural language processing is counterintuitive ( 7 ). the structure is presented in figure 9 . equation 6 presents the convolution layer of cnn. o ( x , y ) = ∑ i = 1 h ∑ j = 1 w i ( x + i , y + j ) ∗ k ( i , j ) + b      ( 6 ) figure 9 figure 9 . structure cnn. where the features of text o ( x , y ) the feature of the text is mapped by using. i ( x + i , y + j ) is weighted by a neural network and b is biased to adjust the neural. the relu activation function is equation 7 , the max pooling function is presented in equation 8 . the dense layer is given in equation 9 . f ( x ) = max ( 0 , x )      ( 7 ) o ( x , y ) = ∑ i = 1 h ∑ j = 1 w i ( x + i , y + j ) ∗ k ( i , j ) + b      ( 8 ) o = w · x + b      ( 9 ) 2.6.2 long short-term memory network an lstm network is an advanced form of a sequential neural network. it fixes the problem of rnn gradients fading over time. rnns often handle long-term storage. at a high level, the operation of an lstm is comparable to that of a single rnn neuron. the inner workings of the lstm network are outlined in this section. the lstm consists of three parts, each performing a particular function, as seen in figure 10 below. in the first step, it is decided whether the information from the previous time stamp is significant enough to be saved or if it is harmless enough to be deleted. in the second step, the cell will try to acquire new information by analyzing the data that has been presented to it. in the third and final step, the cell incorporates the data from the most recent time stamp into the data stored in the next time stamp. these three components constitute what is referred to as a gate for an lstm cell. the “forget” gate comes first, followed by the “input” section, and then the “output” section is used to define the last portion as shown in equations 10 – 14 . forget gate : f t = σ ( w f . x t + w f . h t − 1 + b f )      ( 10 ) input gate : i t = σ ( w c . x t + w i . h t − 1 + b i )      ( 11 ) cell gate : c t = ( w f ∗ ( . h t − 1 , x t ) b f )      ( 12 ) output gate : o t = σ ( w o + x t + w o . h t − 1 + v o . c t + b o )      ( 13 ) hidden layer : h t = o t + tanh ( c t )      ( 14 ) figure 10 figure 10 . lstm model. in figure 10 , c t represent the prior and current states of the cell, respectively. both h t − 1 and h represents the cell output that was processed before the one now being processed. it is common practice to disregard f t as a gate, even though it is the input gate. the output of a sigmoid gate is symbolized here by o t . the cable that connects the cell gates is where all the data collected by the cell gates is sent to and from c . the f t layer decides to remember anything, and the f t the output is multiplied by c to do so (t-1). after that, c (t-1) is multiplied by the product of the sigmoid layer gate and the tanh layer gate, and the output h t is generated by point-wise multiplication of o t and tanh. the lstm architecture is intended to capture long-term relationships in twitter text data. the preprocessing converts input words that start with an embedding layer into 128-dimensional dense vectors. the lstm layer with 64 units is then used to mitigate overfitting, integrating dropout and recurrent dropout with 0.5. an l2 regularization term is further included in the lstm and output dense layer. table 1 shows parameters of the lstm model. table 1 table 1 . lstm parameters model. 2.6.3 cnn-lstm model the cnn-lstm model is a hybrid architecture that combines convolutional neural networks (cnn) for spatial feature extraction and long short-term memory (lstm) networks for sequential learning, making it highly effective for analyzing text data such as tweets. the model begins with an embedding layer that transforms each word into a 256-dimensional dense vector, capturing the semantic meaning of words. this is followed by a 1d convolutional layer with 64 filters and a kernel size of 5, which scans through the text to detect local patterns and n-gram features such as common word combinations or phrases often associated with asd. a batch normalization layer is applied to stabilize and accelerate training, followed by a max pooling layer that reduces the dimensionality and computational load by selecting the most prominent features. a dropout layer with a rate of 0.5 is then used to prevent overfitting by randomly deactivating some neurons during training. the output is passed into a 64-unit lstm layer that captures the temporal dependencies and contextual relationships across the tweet sequence. finally, a dense layer with sigmoid activation performs binary classification to predict whether the tweet indicates asd-related content. the model is trained using the adam optimizer, binary cross-entropy loss, class weights, and regularization to handle imbalanced data and improve generalization. the critical parameters of the cnn-lstm model are displayed in table 2 . table 2 table 2 . cnn-lstm parameters. 2.6.4 double deep q-network (ddqn-inspired) the double q-learning model was introduced by h. van hasselt in 2010, addressing the issue of significant overestimations of action value (q-value) inherent in traditional q-learning. in fundamental q-learning, the agent’s optimal strategy is consistently to select the most advantageous action in any specific state. this concept’s premise is that the optimal action corresponds to the highest expected or estimated q-value. initially, the agent lacks any knowledge of the environment; it must first estimate q(s, a) and subsequently update these estimates with each iteration. the q-values exhibit considerable noise, leading to uncertainty about whether the action associated with the highest expected or estimated q-value is genuinely the optimal choice. double q-learning employs two distinct action-value functions, q and q’, as estimators. even if q and q’ exhibit noise, this noise can be interpreted as a uniform distribution as shown figure 11 the update procedure exhibits some variations compared to the basic version. the action selection and action evaluation processes are separated into two distinct maximum function estimators. shown in equations 15 , 16 . figure 11 figure 11 . ddqn-inspired model. let the vector of a neural network’s weights be represented by θ . we establish two q-networks: the online q-network q (s, a; θ(t)) and the target q-network q (s, a; θ (t)). to be more specific, the training of q (s, a; Χ (t)) is done by modifying the weights (t) at time slot t in relation to the goal value y(t). y ( t ) = g ( t ) + ( s ′ , argmax q ( s ′ , a ∗ ; θ ′ ( t ) ) ; θ ′ ( t ) )      ( 15 ) y ( t ) = g ( t ) + ( s ′ , argmax q ( s ′ , a ∗ ; θ ′ ) ; θ i − 1 )      ( 16 ) the reinforcement learning mechanism integrates generative artificial intelligence for decision-making and prediction tasks, as shown in equations 15 , 16 . this equation indicates the generative which produces the estimation or hypothesis at a given time t . double q − learning used next state, whereas the s’ is exit state and argmax q ( s ′ , a ∗ ; θ ′ ( t ) ) defined as the action of a ∗ to maximize the predicted q-value based on the current parameters. to estimate the q-value of this selected action in the next state, the outer q-function q’ employs the older parameters. θ i − 1 1, which helps reduce overestimation bias. this combination makes applications for predicting asd from social media content domains possible. the ddqn model is used to classify asd and non-asd cases utilizing text data. the model utilizes a preprocessing step for text processing that encompasses data loading, cleaning (including lowercasing, removal of special characters, and normalization of spaces), and tokenization, constrained by a maximum vocabulary of 10,000 words and a sequence length of 200. the model architecture, drawing from the double deep q-network (ddqn) model comprises an input layer, an embedding layer with 256 dimensions, and two parallel lstm branches, each containing 64 units, a dropout rate of 0.5, and l2 regularization to capture sequential patterns effectively. the model uses the adam optimizer with a learning rate of 1e-4 and employs binary cross-entropy loss. it is trained for 30 epochs, incorporating early stopping and learning rate reduction callbacks to mitigate overfitting. parameters of ddqn-inspired are shown in table 3 . table 3 table 3 . parameters of ddqn-inspired. 3 performance of the framework 3.1 performance of lstm figure 12 presents the accuracy and loss metrics used to train and validate an lstm model over 30 epochs. the validation accuracy of the lstm model, displayed in red, begins at a lower value and increases to about 81%. the blue line in the accuracy plot (a) shows the training accuracy of the lstm model; it increases gradually from around 50% to almost 99%, showing that the model learns the training data well over time. the plot (b) shows the loss of the lstm model; the blue line represents the training loss, which drops gradually from around 0.7 to less than 0.2, suggesting that the model is getting a better fit to the training data. meanwhile, the red validation loss line declines from around 0.7 to about 0.3. while the training loss continues to grow, the validation loss reaches a level and exhibits small oscillations, suggesting that the model’s generalizability may stabilize. figure 12 figure 12 . performance of the lstm model. the roc curve illustrated in figure 13 shows the efficacy of the lstm model in differentiating between the classes. the graph illustrates the tp rate (sensitivity) in relation to the fp rate across different threshold levels. the lstm model attains an auc of 0.95, demonstrating exceptional classification capability. the auc of 1.0, but a result of 0.5 indicates random chance. figure 13 figure 13 . roc of the lstm model. 3.2 performance of the cnn-lstm model figure 14 presents plots illustrating the performance of a cnn-lstm model over 25 epochs, showing its training and validation metrics for accuracy and loss. the accuracy plot (a) illustrates the training accuracy (blue line), which increases progressively from approximately 51.42% to nearly 99.53%, indicating effective learning from the training data. in contrast, the validation accuracy (red line) rises to about 83.02% with some variability, indicating satisfactory but imperfect generalization. the loss plot (b) shows the training loss (blue line) declining steadily from 0.7140 to below 0.0760, indicating enhanced model fit. in contrast, the validation loss (red line) decreases from 0.7130 to approximately 0.3530, with a slight decline toward the conclusion. this notification indicates that the cnn-lstm model demonstrates efficient learning, as evidenced by the difference between the training and validation measures. figure 14 figure 14 . performance of the lstm model. figure 15 illustrates the roc curve for the cnn-lstm model, illustrating its classification performance at various thresholds. the graph illustrates the tp rate (sensitivity) in relation to the fp rate, with the auc recorded at 92%. the elevated auc value indicates the model has robust discriminative capability in differentiating between the asd and non-asd classes. the roc ascends rapidly toward the top-left corner, as seen in the figure, indicating a high tp rate with few false positives. figure 15 figure 15 . roc of the cnn-lstm model. 3.3 performance of ddqn-inspired model graphs 16 illustrate the performance of a ddqn throughout 30 epochs. the accuracy plot (a) demonstrates that the training accuracy increases from around 58.02% to almost 98.58%, indicating the ddqn model successful learning from the training data over time. the validation accuracy of the ddqn is about 87, showing the best performance compared to different models like lstm and cnn-lstm. the plot (b) illustrates that the training loss decreases from about 0.8155 to around 0.1477, indicating a robust fit to the training data. the validation loss begins at 0.3831 with many fluctuations throughout ( figure 16 ). figure 16 figure 16 . performance of the ddqn-inspired model. figure 17 shows the roc curve for the ddqn model; it shows a visual representation of its classification capability, with the curve toward the top-left corner, indicating strong predictive power. the auc value of the ddqn model is 96%, demonstrating that the model can distinguish between the positive and negative classes. figure 17 figure 17 . roc ddqn-inspired model. 4 experiment and discussion results both the jupyter deep learning framework and the windows 10 operating system were utilized during the testing process. experiments were conducted using a machine with 16 gigabytes of ram and an intel core i7 central processing unit. the input dimensions of the experiment were a standard text dataset collected from the twitter api related to asd. the test was utilized in our database, while the remaining 20% was used as part of our validation set. the three dl models, namely lstm, cnn-lstm, and ddqn-inspired, were proposed for detecting asd from social media content. 4.1 measuring the model’s performance sensitivity, specificity, accuracy, recall, and f1 scores are assessment measures used to determine how successfully the algorithms identify asd. the related equations from 17 to 21 : accuracy = tp + tn tp + fp + fn + tn × 100 %      ( 17 ) sensitivity = tp tp + fn × 100 %      ( 18 ) precision = tp tp + fp × 100 %      ( 19 ) specificity = tn tn + fp × 100      ( 20 ) f 1 − score = 2 ∗ precision × sensitivity precision + sensitivity × 100      ( 21 ) 4.2 result of the lstm model the classification lstm model, presented in table 4 , summarizes its performance in differentiating between asd and non-asd patients, attaining an overall accuracy of 81%. the lstm model demonstrates in asd class a precision of 91%, indicating a high accuracy in identifying predicted asd cases. the lstm with recall metric scored 77% and an f1-score of 82% for detecting the asd class. the lstm model with non-asd class demonstrates a precision of 71%, a recall of 89%, and an f1-score of 79%, to identify non-asd cases. the macro average of the lstm model for all metrics is (precision: 81%, recall: 82%, f1-score: 81%). lstm model is recognized for its efficiency and scalability as a model for social media content. table 4 table 4 . lstm results. the confusion matrix for the lstm model is provided in figure 18 . it is presented in a clear manner. among the confirmed asd cases, 29 were accurately identified as asd, whereas 10 were incorrectly classified as non-asd, indicating strong performance with minor errors. in the true non-asd cases, 25 were correctly identified, while 3 were misclassified as asd, suggesting a generally effective detection process. the deep blue and light shades produce a tranquil visual, illustrating the model’s balanced approach in classifying the 67 total instances, demonstrating notable strength in identifying non-asd cases, while exhibiting marginally lower accuracy for asd. this matrix effectively illustrates the lstm model’s systematic approach to managing sequential data, such as text or time-series inputs, in a clear and comprehensible manner. figure 18 figure 18 . lstm model. 4.3 result of the cnn-lstm model table 5 displays the cnn-lstm model’s performance in distinguishing between asd and non-asd classes. the cnn-lstm model attained an overall accuracy of 85% across the dataset. in the asd label, a precision of 91% was achieved, a high percentage for predicting asd cases that were accurately recognized. the recall indicates that the model identified 82% of all genuine asd cases, resulting in an f1 score of 86%, better than the recall metric. the cnn-lstm model attained 78% accuracy, 89% recall, and an 83% f1 score for the non-asd class. the macro average, representing the unweighted mean of precision, recall, and f1 score across both classes, was 85, 86, and 85%, respectively. the findings indicate that the cnn-lstm model performs satisfactorily, exhibiting a marginally superior capacity to identify asd cases relative to non-asd cases accurately. table 5 table 5 . results of the cnn-lstm model. the confusion matrix of a cnn-lstm model is presented in figure 19 , for classifying instances into asd and non-asd. the matrix is structured with true labels on the vertical axis and predicted labels on the horizontal axis, providing a clear summary of the model’s classification outcomes. the matrix shows that out of the instances truly labeled as asd, the model correctly predicted 32 as asd tp while 7 were incorrectly classified as non-asd fn. for the instances truly labeled as non-asd, the model accurately identified 25 as non-asd tn but 3 were misclassified as asd fp. this indicates that the model demonstrates a relatively strong ability to correctly identify asd and non-asd cases, with higher accuracy for true positives (32 out of 39 asd cases) and true negatives (25 out of 28 non-asd cases). overall, the model exhibits promising performance with minimal misclassification errors. figure 19 figure 19 . results of cnn-lstm model. 4.4 results of double deep q-network the findings of the ddqn model are shown in table 6 , achieving a high precision of 87% compared to the other models. this finding demonstrates the potential of the proposed ddqn approach for identifying asd based on social media content. ultimately, the proposed system was compared against the existing one using the same dataset. the proposed approach may assist physicians in detecting asd and conducting symptomology research in a natural environment, attaining an overall accuracy of 87. the model for the asd class shows a precision of 95%, a recall of 79%, and an f1-score of 87%, indicating robust efficacy in accurately identifying asd patients. the non-asd class has a precision of 77%, a recall of 96%, and an f1-score of 86%, indicating somewhat reduced accuracy with robust recall. the macro average measures (precision 87%, recall 88%, f1-score 87%) indicate performance across both classes. table 6 table 6 . result of ddqn-inspired. the confusion matrix of the ddqn model is shown in figure 20 for the classification task between asd and non-asd cases. for correct classification of asd cases, the model correctly classified 31 instances as asd, represented by the top-left quadrant (tp). however, the ddqn model, misclassified 8 instances misclassifying true asd cases as non-asd, shown in the top-right quadrant (fn). on the other hand, the ddqn showed the true non-asd cases, accurately identified 27 instances as non-asd, depicted in the bottom-right quadrant (tn). at the same time, 1 instance was incorrectly labeled as asd, as shown in the bottom-left quadrant (fp). the confusion matrix of ddqn model highlights that it performs well overall, with a strong ability to correctly identify both asd and non-asd cases, as evidenced by the high counts of tp (31) and tn (27). figure 20 figure 20 . result of ddqn-inspired model. in the digital era, people frequently write content on social media to express their feelings, opinions, beliefs, and activities. this makes social media one of the most significant sources of data generation, allowing you to explore its opportunities and challenges. today, social media has become a mediator between people and the healthcare sector, enabling them to search for information about any specific disease and methods for diagnosing it. individuals within the mental health community use social media platforms such as twitter to seek information, exchange experiences, and get assistance about asd in an environment that is seen as more approachable and informal than conventional medical contexts. they often seek immediate, relevant information—whether to understand symptoms, identify coping mechanisms, or connect with others facing similar difficulties. figure 21 illustrates that word clouds are visual representations of text that highlight key terms and their frequency of use. we used wordcloud to compare asd and non-asd texts for instances of word repetition. figure 21 figure 21 . asd word cloud. the deployment model based on the deep q-network (dqn) model for diagnosing asd is shown in figure 22 . figure 22 figure 22 . deployment system-based text for detecting asd. step 1: data collections, including cleaning, normalization, and tokenization. step 2: model development: the preprocessed data is used to train and validate a deep q-network (dqn) model for classifying tweets as indicative of asd or non-asd patterns. step 3: application interface: an application interface is developed once the model has been trained. it integrates with users’ twitter accounts and continuously analyzes their tweets. step 4: deployment: the proposed system is deployed in the cloud for storing tweets, enabling real-time monitoring of incoming tweets. predictions are flagged for review by healthcare professionals, who validate the model’s output before categorizing individuals as potentially having asd or non-asd. this digital imprint may serve as an ancillary resource for mental health practitioners, providing insights into an individual’s emotional state and social behaviors in a natural environment, potentially facilitating early detection or corroborating a diagnosis. this method is a non-invasive means of data collection, particularly beneficial for individuals who lack rapid access to clinical assessments due to financial constraints, stigma, or resource scarcity. however, it should not replace professional diagnoses and must be conducted with ethical consideration to prevent misunderstanding. table 7 shows the findings of the proposed framework on the twitter dataset. it demonstrates that the suggested method outperforms the current systems in terms of accuracy, proving its efficacy and potential for performance improvements. table 7 table 7 . compared with the proposed asd system. 5 conclusion to assist people in identifying trends in their behavior, such as social challenges or sensory sensitivities, which may encourage them to pursue a formal diagnosis. the main objective of examining tweets for identifying asd is its ability to provide behavioral and emotional indicators associated with the disorder. this research was used to analyze the textual analysis of tweets to detect the behaviors in self-identified autistic individuals relative to others. the suggested framework was evaluated using information from the social media platform “twitter” collected from a public repository. before examining the proposed system, several preprocessing steps must be implemented in the text. the ‘text’ column is cleaned by converting it to lowercase, eliminating non-alphanumeric characters (excluding spaces) through regular expressions, normalizing whitespace to a single space, and removing any leading or trailing spaces. the asd and non-asd labels are converted into a numerical format (0 or 1) with labelencoder to accommodate the binary classification requirement. tokenization of the text data is performed using a tokenizer, restricting the vocabulary to 10,000 words, and then transforming the text into sequences of numbers. the sequences are padded to a standardized length of 200 tokens to maintain consistency for the proposed model input. the proposed data is ultimately divided into an 80% training and 20% testing ratio, and class weights are calculated to resolve any class imbalance. this preparation pipeline efficiently converts raw text data into a structured numerical representation appropriate for the proposed framework, while preserving academic integrity. the output of these preprocessing steps was processed using three dl models, such as short-term memory (cnn-lstm) and a double deep q-network (ddqn). the results of these proposals were proven, revealing that the ddqn model achieved a high accuracy score of 87% with respect to the accuracy measure. the proposed framework, based on real textual data, can be helpful for real-time offering natural, behavioral, and emotional data that might indicate asd-related characteristics. finally, we have observed that social media (twitter) postings include linguistic patterns, emotional expressions, and social interactions that can help official health officials detect asd based on the thorough symptoms of asd that are posted on the platform. this study utilized a conventional dataset sourced only from the twitter network. we will emphasize the necessity of gathering datasets from many platforms to enhance the model’s generalizability in the future. data availability statement the original contributions presented in the study are included in the article/supplementary material, further inquiries can be directed to the corresponding author/s. the dataset used in this study can be found at https://data.mendeley.com/datasets/87s2br3ptb/1 . ethics statement ethical approval was not required for the study involving human data in accordance with the local legislation and institutional requirements. written informed consent was not required, for either participation in the study or for the publication of potentially/indirectly identifying information, in accordance with the local legislation and institutional requirements. the social media data was accessed and analysed in accordance with the platform’s terms of use and all relevant institutional/national regulations. author contributions nf: supervision, conceptualization, software, methodology, writing – original draft, investigation, visualization, formal analysis, validation. aa: data curation, visualization, methodology, conceptualization, validation, software, formal analysis, writing – original draft. ne: investigation, writing – review & editing, validation, formal analysis. sa: visualization, software, formal analysis, writing – review & editing, data curation. funding the author(s) declare that financial support was received for the research and/or publication of this article. the authors extend their appreciation to the king salman center for disability research for funding this work through research group no ksrg-2024-288. conflict of interest the authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest. generative ai statement the authors declare that no gen ai was used in the creation of this manuscript. any alternative text (alt text) provided alongside figures in this article has been generated by frontiers with the support of artificial intelligence and reasonable efforts have been made to ensure accuracy, including review by the authors wherever possible. if you identify any issues, please contact us. publisher’s note all claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher. references 1. asd. (2023). available online at: https://www.healthline.com/health/signs-of-autism-in-3-year-old . google scholar 2. matson, jl, and goldin, rl. what is the future of assessment for autism spectrum disorders: short and long term. res autism spectr disord . (2014) 8:209–13. doi: 10.1016/j.rasd.2013.01.007 crossref full text | google scholar 3. srivastava, ak, and schwartz, ce. intellectual disability and autism spectrum disorders: causal genes and molecular mechanisms. neurosci biobehav rev . (2014) 46:161–74. doi: 10.1016/j.neubiorev.2014.02.015 pubmed abstract | crossref full text | google scholar 4. alhujaili, n, platt, e, khalid-khan, s, and groll, d. comparison of social media use among adolescents with autism spectrum disorder and non-asd adolescents. adolesc health med ther . (2022) 13:15–21. doi: 10.2147/ahmt.s344591 pubmed abstract | crossref full text | google scholar 5. angulo-jiménez, h, and dethorne, l. narratives about autism: an analysis of youtube videos by individuals who self-identify as autistic. am j speech lang pathol . (2019) 28:569–90. doi: 10.1044/2018_ajslp-18-0045 crossref full text | google scholar 6. pew research center. (2021). available online at: https://www.pewresearch.org/internet/2021/04/07/social-media-use-in-2021/ google scholar 7. liu, j-b, guan, l, cao, j, and chen, l. coherence analysis for a class of polygon networks with the noise disturbance. ieee trans syst man cybern syst . (2025) 2025:326. doi: 10.1109/tsmc.2025.3559326 crossref full text | google scholar 8. al-nefaie, ah, aldhyani, th, sultan, ha, and alzahrani eidah, m. application of artificial intelligence in modern healthcare for diagnosis of autism spectrum disorder. front med . (2025) 12:1569464. doi: 10.3389/fmed.2025.1569464 crossref full text | google scholar 9. kim, b, jeong, d, kim, jg, hong, h, and han, k. v-dat (virtual reality data analysis tool): supporting self-awareness for autistic people from multimodal vr sensor data . in: proceedings of the uist 2023—proceedings of the 36th annual acm symposium on user interface software and technology, san francisco, ca, usa, 29 october–1 november 2023. (2023). google scholar 10. chen, c, chander, a, and uchino, k. guided play: digital sensing and coaching for stereotypical play behavior in children with autism . in proceedings of the international conference on intelligent user interfaces, proceedings iui, marina del ray, ca, usa, 17–20 march 2019; part f1476. pp. 208–217. (2019). google scholar 11. parui, s, samanta, d, chakravorty, n, ghosh, u, and rodrigues, jj. artificial intelligence and sensor-based autism spectrum disorder diagnosis using brain connectivity analysis. comput electr eng . (2023) 108:108720. doi: 10.1016/j.compeleceng.2023.108720 crossref full text | google scholar 12. golestan, s, soleiman, p, and moradi, h. a comprehensive review of technologies used for screening, assessment, and rehabilitation of autism spectrum disorder. arxiv . (2018) 2018:10986. doi: 10.48550/arxiv.1807.10986 crossref full text | google scholar 13. neeharika, ch, and riyazuddin, ym. developing an artificial intelligence based model for autism spectrum disorder detection in children. j adv res appl sci eng technol . (2023) 32:57–72. doi: 10.37934/araset.32.1.5772 crossref full text | google scholar 14. wall, dp, dally, r, luyster, r, jung, j-y, and deluca, tf. use of artificial intelligence to shorten the behavioral diagnosis of autism. plos one . (2012) 7:e43855. doi: 10.1371/journal.pone.0043855 pubmed abstract | crossref full text | google scholar 15. alzakari, sa, allinjawi, a, aldrees, a, zamzami, n, umer, m, innab, n, et al. early detection of autism spectrum disorder using explainable ai and optimized teaching strategies. j neurosci methods . (2025) 413:110315. doi: 10.1016/j.jneumeth.2024.110315 pubmed abstract | crossref full text | google scholar 16. heunis, t, aldrich, c, peters, j, jeste, s, sahin, m, scheffer, c, et al. recurrence quantification analysis of resting state eeg signals in autism spectrum disorder—a systematic methodological exploration of technical and demographic confounders in the search for biomarkers. bmc med . (2018) 16:101. doi: 10.1186/s12916-018-1086-7 crossref full text | google scholar 17. vicnesh, j, wei, jke, oh, sl, arunkumar, n, abdulhay, e, ciaccio, ej, et al. autism spectrum disorder diagnostic system using hos bispectrum with eeg signals. int j environ res public health . (2020) 17:971. doi: 10.3390/ijerph17030971 crossref full text | google scholar 18. novielli, p, romano, d, magarelli, m, diacono, d, monaco, a, amoroso, n, et al. personalized identification of autism-related bacteria in the gut microbiome using explainable artificial intelligence. iscience . (2024) 27:110709. doi: 10.1016/j.isci.2024.110709 pubmed abstract | crossref full text | google scholar 19. bosl, wj, tager-flusberg, h, and nelson, ca. eeg analytics for early detection of autism spectrum disorder: a data-driven approach. sci rep . (2018) 8:1–20. doi: 10.1038/s41598-018-24318-x pubmed abstract | crossref full text | google scholar 20. beykikhoshk, a, arandjelović, o, phung, d, venkatesh, s, and caelli, t. using twitter to learn about the autism community. soc netw anal min . (2015) 5:261. doi: 10.1007/s13278-015-0261- crossref full text | google scholar 21. mazurek, mo. social media use among adults with autism spectrum disorders. comput hum behav . (2013) 29:1709–14. doi: 10.1016/j.chb.2013.02.004 crossref full text | google scholar 22. onnela, j, and rauch, sl. harnessing smartphone-based digital phenotyping to enhance behavioral and mental health. neuropsychopharmacology . (2016) 41:1691–6. doi: 10.1038/npp.2016.7.npp20167 pubmed abstract | crossref full text | google scholar 23. tomeny, ts, vargo, cj, and el-toukhy, s. geographic and demographic correlates of autism-related anti-vaccine beliefs on twitter, 2009–2015. soc sci med . (2017) 191:168–75. doi: 10.1016/j.socscimed.2017.08.041 pubmed abstract | crossref full text | google scholar 24. tárraga-mínguez, r, gómez-marí, i, and sanz-cervera, p. what motivates internet users to search for asperger syndrome and autism on google? int j environ res public health . (2020) 17:9386. doi: 10.3390/ijerph17249386 pubmed abstract | crossref full text | google scholar 25. hartwell, m, keener, a, coffey, s, chesher, t, torgerson, t, and vassar, m. brief report: public awareness of asperger syndrome following greta thunberg appearances. j autism dev disord . (2020) 51:2104–8. doi: 10.1007/s10803-020-04651-9 pubmed abstract | crossref full text | google scholar 26. rubio-martín, s, garcía-ordás, mt, bayón-gutiérrez, m, prieto-fernández, n, and benítez-andrades, ja. “ early detection of autism spectrum disorder through ai-powered analysis of social media texts ,” 2023 ieee 36th international symposium on computer-based medical systems (cbms), l’aquila, italy, pp. 235–240. (2023). google scholar 27. jaiswal, a, and washington, p. using #actuallyautistic on twitter for precision diagnosis of autism spectrum disorder: machine learning study. jmir form res . (2024) 8:e52660. doi: 10.2196/52660 crossref full text | google scholar keywords: autism spectrum disorders, diagnosing, social media, deep learning, disabilities, artificial intelligence citation: farhah ns, alqarni aa, ebrahim n and ahmad s (2025) diagnosing autism spectrum disorders using a double deep q-network framework based on social media footprints. front. med . 12:1646249. doi: 10.3389/fmed.2025.1646249 received: 16 june 2025; accepted: 28 july 2025; published: 20 august 2025. edited by: pardeep sangwan , maharaja surajmal institute of technology, india reviewed by: jia-bao liu , anhui jianzhu university, china muhammad adnan , kohat university of science and technology, pakistan copyright © 2025 farhah, alqarni, ebrahim and ahmad. this is an open-access article distributed under the terms of the creative commons attribution license (cc by) . the use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. no use, distribution or reproduction is permitted which does not comply with these terms. *correspondence: nesren s. farhah, bi5myxjoywhac2v1lmvkds5zyq== ; nadhem ebrahim, bmvicmfoaw1adwfrcm9ulmvkdq== ; sultan ahmad, cy5hbglzagvyqhbzyxuuzwr1lnnh disclaimer: all claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. any product that may be evaluated in this article or claim that may be made by its manufacturer is not guaranteed or endorsed by the publisher. download article download pdf readcube epub xml share on export citation endnote reference manager simple text file bibtex 1,193 total views 132 downloads citation numbers are available from dimensions view article impact view altmetric score share on edited by p s pardeep sangwan reviewed by j l jia-bao liu m a muhammad adnan table of contents abstract 1 introduction 2 materials and methods 3 performance of the framework 4 experiment and discussion results 5 conclusion data availability statement ethics statement author contributions funding conflict of interest generative ai statement publisher’s note references export citation endnote reference manager simple text file bibtex check for updates frontiers' impact articles published with frontiers have received 12 million total citations your research is the real superpower - learn how we maximise its impact through our leading community journals explore our impact metrics supplementary material download article download download pdf readcube epub xml guidelines author guidelines services for authors policies and publication ethics editor guidelines fee policy explore articles research topics journals how we publish outreach frontiers forum frontiers policy labs frontiers for young minds frontiers planet prize connect help center emails and alerts contact us submit career opportunities follow us © 2025 frontiers media s.a. all rights reserved privacy policy | terms and conditions [["shallowreactive",1],{"data":2,"state":4,"once":10,"_errors":11,"serverrendered":13,"path":14,"pinia":15},["shallowreactive",3],{},["reactive",5],{"$ssite-config":6},{"env":7,"name":8,"url":9},"production","frontiers articles","https://article-pages-2024.frontiersin.org/",["set"],["shallowreactive",12],{},true,"/journals/medicine/articles/10.3389/fmed.2025.1646249/full",["reactive",16],{"main":17,"user":514,"article":515,"articlehub":766,"mainheader":770},{"ibar":18,"footer":268,"newslettercomponent":-1,"snackbaritem":350,"toggleshowsnackbar":351,"contentfuljournal":352,"graphjournal":416,"settingsfeaturesswitchers":420,"templatetogglebanner":421,"tenantconfig":479},{"tenantlogo":19,"journallogo":19,"aboutus":20,"submiturl":113,"showsubmitbutton":13,"journal":114,"sectionterm":199,"aboutjournal":200,"mainlinks":249,"journallinks":256,"helpcenterlink":265},"",[21,38,47,71,87],{"title":22,"links":23},"who we are",[24,29,32,35],{"text":25,"url":26,"target":27,"arialabel":28},"mission and values","https://www.frontiersin.org/about/mission","_self",null,{"text":30,"url":31,"target":27,"arialabel":28},"history","https://www.frontiersin.org/about/history",{"text":33,"url":34,"target":27,"arialabel":28},"leadership","https://www.frontiersin.org/about/leadership",{"text":36,"url":37,"target":27,"arialabel":28},"awards","https://www.frontiersin.org/about/awards",{"title":39,"links":40},"impact and progress",[41,44],{"text":42,"url":43,"target":27,"arialabel":28},"frontiers' impact","https://www.frontiersin.org/about/impact",{"text":45,"url":46,"target":27,"arialabel":28},"our annual reports","https://www.frontiersin.org/about/annual-reports",{"title":48,"links":49},"publishing model",[50,53,56,59,62,65,68],{"text":51,"url":52,"target":27,"arialabel":28},"how we publish","https://www.frontiersin.org/about/how-we-publish",{"text":54,"url":55,"target":27,"arialabel":28},"open access","https://www.frontiersin.org/about/open-access",{"text":57,"url":58,"target":27,"arialabel":28},"peer review","https://www.frontiersin.org/about/peer-review",{"text":60,"url":61,"target":27,"arialabel":28},"research integrity","https://www.frontiersin.org/about/research-integrity",{"text":63,"url":64,"target":27,"arialabel":28},"research topics","https://www.frontiersin.org/about/research-topics",{"text":66,"url":67,"target":27,"arialabel":28},"fair² data management","https://www.frontiersin.org/about/fair-data-management",{"text":69,"url":70,"target":27,"arialabel":28},"fee policy","https://www.frontiersin.org/about/fee-policy",{"title":72,"links":73},"services",[74,78,81,84],{"text":75,"url":76,"target":77,"arialabel":28},"societies","https://publishingpartnerships.frontiersin.org/","_blank",{"text":79,"url":80,"target":27,"arialabel":28},"national consortia","https://www.frontiersin.org/open-access-agreements/consortia",{"text":82,"url":83,"target":27,"arialabel":28},"institutional partnerships","https://www.frontiersin.org/about/open-access-agreements",{"text":85,"url":86,"target":27,"arialabel":28},"collaborators","https://www.frontiersin.org/about/collaborators",{"title":88,"links":89},"more from frontiers",[90,94,97,101,105,109],{"text":91,"url":92,"target":77,"arialabel":93},"frontiers forum","https://forum.frontiersin.org/","this link will take you to the frontiers forum website",{"text":95,"url":96,"target":27,"arialabel":28},"frontiers planet prize","https://www.frontiersin.org/about/frontiers-planet-prize",{"text":98,"url":99,"target":77,"arialabel":100},"press office","https://pressoffice.frontiersin.org/","this link will take you to the frontiers press office website",{"text":102,"url":103,"target":27,"arialabel":104},"sustainability","https://www.frontiersin.org/about/sustainability","link to information about frontiers' sustainability",{"text":106,"url":107,"target":77,"arialabel":108},"career opportunities","https://careers.frontiersin.org/","this link will take you to the frontiers careers website",{"text":110,"url":111,"target":27,"arialabel":112},"contact us","https://www.frontiersin.org/about/contact","this link will take you to the help pages to contact our support team","https://www.frontiersin.org/submission/submit?domainid=2&fieldid=39&specialtyid=0&entitytype=2&entityid=602",{"id":115,"name":116,"slug":117,"sections":118},602,"frontiers in medicine","medicine",[119,123,127,131,135,139,143,147,151,155,159,163,167,171,175,179,183,187,191,195],{"id":120,"name":121,"slug":122},797,"dermatology","dermatology",{"id":124,"name":125,"slug":126},842,"family medicine and primary care","family-medicine-and-primary-care",{"id":128,"name":129,"slug":130},681,"gastroenterology","gastroenterology",{"id":132,"name":133,"slug":134},1321,"gene and cell therapy","gene-and-cell-therapy",{"id":136,"name":137,"slug":138},790,"geriatric medicine","geriatric-medicine",{"id":140,"name":141,"slug":142},1969,"healthcare professions education","healthcare-professions-education",{"id":144,"name":145,"slug":146},752,"hematology","hematology",{"id":148,"name":149,"slug":150},3648,"hepatobiliary diseases","hepatobiliary-diseases",{"id":152,"name":153,"slug":154},3379,"infectious diseases: pathogenesis and therapy","infectious-diseases-pathogenesis-and-therapy",{"id":156,"name":157,"slug":158},1139,"intensive care medicine and anesthesiology","intensive-care-medicine-and-anesthesiology",{"id":160,"name":161,"slug":162},768,"nephrology","nephrology",{"id":164,"name":165,"slug":166},815,"nuclear medicine","nuclear-medicine",{"id":168,"name":169,"slug":170},2526,"obstetrics and gynecology","obstetrics-and-gynecology",{"id":172,"name":173,"slug":174},1635,"ophthalmology","ophthalmology",{"id":176,"name":177,"slug":178},618,"pathology","pathology",{"id":180,"name":181,"slug":182},1307,"precision medicine","precision-medicine",{"id":184,"name":185,"slug":186},678,"pulmonary medicine","pulmonary-medicine",{"id":188,"name":189,"slug":190},1306,"regulatory science","regulatory-science",{"id":192,"name":193,"slug":194},662,"rheumatology","rheumatology",{"id":196,"name":197,"slug":198},1318,"translational medicine","translational-medicine","sections",[201,225],{"title":202,"links":203},"scope",[204,207,210,213,216,219,222],{"text":205,"url":206,"target":27,"arialabel":28},"field chief editors","https://www.frontiersin.org/journals/medicine/about#about-editors",{"text":208,"url":209,"target":27,"arialabel":28},"mission & scope","https://www.frontiersin.org/journals/medicine/about#about-scope",{"text":211,"url":212,"target":27,"arialabel":28},"facts","https://www.frontiersin.org/journals/medicine/about#about-facts",{"text":214,"url":215,"target":27,"arialabel":28},"journal sections","https://www.frontiersin.org/journals/medicine/about#about-submission",{"text":217,"url":218,"target":27,"arialabel":28},"open access statement","https://www.frontiersin.org/journals/medicine/about#about-open",{"text":220,"url":221,"target":27,"arialabel":28},"copyright statement","https://www.frontiersin.org/journals/medicine/about#copyright-statement",{"text":223,"url":224,"target":27,"arialabel":28},"quality","https://www.frontiersin.org/journals/medicine/about#about-quality",{"title":226,"links":227},"for authors",[228,231,234,237,240,243,246],{"text":229,"url":230,"target":27,"arialabel":28},"why submit?","https://www.frontiersin.org/journals/medicine/for-authors/why-submit",{"text":232,"url":233,"target":27,"arialabel":28},"article types","https://www.frontiersin.org/journals/medicine/for-authors/article-types",{"text":235,"url":236,"target":27,"arialabel":28},"author guidelines","https://www.frontiersin.org/journals/medicine/for-authors/author-guidelines",{"text":238,"url":239,"target":27,"arialabel":28},"editor guidelines","https://www.frontiersin.org/journals/medicine/for-authors/editor-guidelines",{"text":241,"url":242,"target":27,"arialabel":28},"publishing fees","https://www.frontiersin.org/journals/medicine/for-authors/publishing-fees",{"text":244,"url":245,"target":27,"arialabel":28},"submission checklist","https://www.frontiersin.org/journals/medicine/for-authors/submission-checklist",{"text":247,"url":248,"target":27,"arialabel":28},"contact editorial office","https://www.frontiersin.org/journals/medicine/for-authors/contact-editorial-office",[250,253],{"text":251,"url":252,"target":27,"arialabel":28},"all journals","https://www.frontiersin.org/journals",{"text":254,"url":255,"target":27,"arialabel":28},"all articles","https://www.frontiersin.org/articles",[257,260,262],{"text":258,"url":259,"target":27,"arialabel":28},"articles","articles",{"text":63,"url":261,"target":27,"arialabel":28},"research-topics",{"text":263,"url":264,"target":27,"arialabel":28},"editorial board","editors",{"text":266,"url":267,"target":77,"arialabel":266},"help center","https://helpcenter.frontiersin.org",{"blocks":269,"sociallinks":323,"copyright":347,"termsandconditionsurl":348,"privacypolicyurl":349},[270,284,294,308],{"title":271,"links":272},"guidelines",[273,275,278,281,283],{"text":235,"url":274,"target":27,"arialabel":28},"https://www.frontiersin.org/guidelines/author-guidelines",{"text":276,"url":277,"target":27,"arialabel":28},"services for authors","https://www.frontiersin.org/for-authors/author-services",{"text":279,"url":280,"target":27,"arialabel":28},"policies and publication ethics","https://www.frontiersin.org/guidelines/policies-and-publication-ethics",{"text":238,"url":282,"target":27,"arialabel":28},"https://www.frontiersin.org/guidelines/editor-guidelines",{"text":69,"url":70,"target":27,"arialabel":28},{"title":285,"links":286},"explore",[287,288,291,293],{"text":258,"url":255,"target":27,"arialabel":28},{"text":289,"url":290,"target":27,"arialabel":28},"research topics ","https://www.frontiersin.org/research-topics",{"text":292,"url":252,"target":27,"arialabel":28},"journals",{"text":51,"url":52,"target":27,"arialabel":28},{"title":295,"links":296},"outreach",[297,300,303,307],{"text":298,"url":92,"target":77,"arialabel":299},"frontiers forum ","frontiers forum website",{"text":301,"url":302,"target":77,"arialabel":28},"frontiers policy labs ","https://policylabs.frontiersin.org/",{"text":304,"url":305,"target":77,"arialabel":306},"frontiers for young minds","https://kids.frontiersin.org/","frontiers for young minds journal",{"text":95,"url":96,"target":27,"arialabel":28},{"title":309,"links":310},"connect",[311,312,316,319,322],{"text":266,"url":267,"target":77,"arialabel":266},{"text":313,"url":314,"target":77,"arialabel":315},"emails and alerts ","https://subscription-management.frontiersin.org/emails/preferences#block0","subscribe to frontiers emails",{"text":317,"url":111,"target":27,"arialabel":318},"contact us ","subscribe to newsletter",{"text":320,"url":321,"target":27,"arialabel":28},"submit","https://www.frontiersin.org/submission/submit",{"text":106,"url":107,"target":77,"arialabel":28},[324,332,337,342],{"link":325,"type":328,"color":329,"icon":330,"size":331,"hiddentext":13},{"text":326,"url":327,"target":77,"arialabel":326},"frontiers facebook","https://www.facebook.com/frontiersin","link","grey","facebook","medium",{"link":333,"type":328,"color":329,"icon":336,"size":331,"hiddentext":13},{"text":334,"url":335,"target":77,"arialabel":28},"frontiers twitter","https://twitter.com/frontiersin","twitter",{"link":338,"type":328,"color":329,"icon":341,"size":331,"hiddentext":13},{"text":339,"url":340,"target":77,"arialabel":28},"frontiers linkedin","https://www.linkedin.com/company/frontiers","linkedin",{"link":343,"type":328,"color":329,"icon":346,"size":331,"hiddentext":13},{"text":344,"url":345,"target":77,"arialabel":28},"frontiers instagram","https://www.instagram.com/frontiersin_","instagram","frontiers media s.a. all rights reserved","https://www.frontiersin.org/legal/terms-and-conditions","https://www.frontiersin.org/legal/privacy-policy",{},false,{"__typename":353,"identifier":115,"name":116,"slug":117,"banner":354,"description":409,"mission":410,"palette":411,"impactfactor":412,"citescore":413,"citations":414,"showtagline":28,"twitter":415},"journal",[355],{"id":356,"src":357,"name":358,"tags":359,"type":367,"width":368,"height":369,"idhash":370,"archive":371,"brandid":372,"limited":371,"filesize":373,"ispublic":374,"original":375,"copyright":376,"extension":377,"thumbnails":379,"datecreated":387,"description":388,"orientation":389,"usercreated":390,"watermarked":371,"datemodified":387,"datepublished":391,"ecsarchivefiles":392,"propertyoptions":393,"property_channel":398,"property_sub-type":400,"property_asset_type":402,"activeoriginalfocuspoint":404,"property_office_department":407},"3501f557-cafa-4218-930c20d1d930c78c","https://d2csxpduxe849s.cloudfront.net/media/e32629c6-9347-4f84-81feaef7bfa342b3/3501f557-cafa-4218-930c20d1d930c78c/webimage-5988957c-0534-4338-984381d67214c0af.png","fmed_main visual_purple_website",[360,361,362,363,364,365,366],"professional","medical","research","biotechnology","scientific","analy","lab","image",7360,4912,"67388dad93685635",0,"22c10171-81b3-4da6-99342f272a32e8bb",13595017,1,"https://brand.frontiersin.org/m/67388dad93685635/original/fmed_main-visual_purple_website.jpg","copyright (c) 2018 rosshelen/shutterstock. no use without permission.",[378],"jpg",{"mini":380,"thul":381,"webimage":357,"guidelines":382,"websitejpg_xl":383,"websitewebp_l":384,"websitewebp_m":385,"websitewebp_xl":386},"https://d2csxpduxe849s.cloudfront.net/media/e32629c6-9347-4f84-81feaef7bfa342b3/3501f557-cafa-4218-930c20d1d930c78c/mini-4ebc2476-6efb-4a3e-a669185b307fef72.png","https://d2csxpduxe849s.cloudfront.net/media/e32629c6-9347-4f84-81feaef7bfa342b3/3501f557-cafa-4218-930c20d1d930c78c/thul-78bd9351-8a86-4c7b-874fc1cc5caa92ce.png","https://d2csxpduxe849s.cloudfront.net/media/e32629c6-9347-4f84-81feaef7bfa342b3/3501f557-cafa-4218-930c20d1d930c78c/f6ff788e-26d5-4bc5-8cb92ee85a59ca4a/guidelines-fmed_main visual_purple_website.png","https://d2csxpduxe849s.cloudfront.net/media/e32629c6-9347-4f84-81feaef7bfa342b3/3501f557-cafa-4218-930c20d1d930c78c/f6ff788e-26d5-4bc5-8cb92ee85a59ca4a/websitejpg_xl-fmed_main visual_purple_website.jpg","https://d2csxpduxe849s.cloudfront.net/media/e32629c6-9347-4f84-81feaef7bfa342b3/3501f557-cafa-4218-930c20d1d930c78c/f6ff788e-26d5-4bc5-8cb92ee85a59ca4a/websitewebp_l-fmed_main visual_purple_website.webp","https://d2csxpduxe849s.cloudfront.net/media/e32629c6-9347-4f84-81feaef7bfa342b3/3501f557-cafa-4218-930c20d1d930c78c/f6ff788e-26d5-4bc5-8cb92ee85a59ca4a/websitewebp_m-fmed_main visual_purple_website.webp","https://d2csxpduxe849s.cloudfront.net/media/e32629c6-9347-4f84-81feaef7bfa342b3/3501f557-cafa-4218-930c20d1d930c78c/f6ff788e-26d5-4bc5-8cb92ee85a59ca4a/websitewebp_xl-fmed_main visual_purple_website.webp","2022-06-27t10:00:04z","laboratory assistant putting test tubes into the holder, close-up view focused on the tubes","landscape","caroline sutter","2022-06-27t09:27:09z",[],[394,395,396,397],"414fb2d4-2283-43fd-be14e534eca67928","6c18119b-14bd-4951-b437696f4357bd33","7c692885-db25-4858-b1fb4ff47b241e9b","d88c0047-ec30-4506-a7df28a4d765e1cf",[399],"frontiersin_org",[401],"main_visual",[403],"photography",{"x":405,"y":406},3680,2456,[408],"publishing","a highly cited multidisciplinary journal which advances our medical knowledge. it supports the translation of scientific advances into new therapies and diagnostic tools that will improve patient care.","\u003cp>frontiers in medicine is a broad-scope, multidisciplinary journal covering all established medical disciplines to improve clinical practice and patient care.\u003c/p>\n\n\u003cp>led by field chief editor prof michel goldman (université libre de bruxelles, belgium), frontiers in medicine is indexed in pubmed central (pmc), web of science (scie), and scopus, among others, and welcomes basic and clinical medical research that facilitate the translation of scientific advances into new therapies or diagnostic tools. topics include, but are not limited to:\u003c/p>\n\n\u003cul>\n \u003cli>dermatology\u003c/li>\n \u003cli>family medicine and primary care\u003c/li>\n \u003cli>gastroenterology\u003c/li>\n \u003cli>gene and cell therapy\u003c/li>\n \u003cli>geriatric medicine\u003c/li>\n \u003cli>healthcare professions education\u003c/li>\n \u003cli>hematology\u003c/li>\n \u003cli>hepatobiliary diseases\u003c/li>\n \u003cli>infectious diseases: pathogenesis and therapy\u003c/li>\n \u003cli>intensive care medicine and anesthesiology\u003c/li>\n \u003cli>nephrology\u003c/li>\n \u003cli>nuclear medicine\u003c/li>\n \u003cli>obstetrics and gynecology\u003c/li>\n \u003cli>ophthalmology\u003c/li>\n \u003cli>pathology\u003c/li>\n \u003cli>precision medicine\u003c/li>\n \u003cli>pulmonary medicine\u003c/li>\n \u003cli>regulatory science\u003c/li>\n \u003cli>rheumatology\u003c/li>\n \u003cli>translational medicine.\u003c/li>\n\u003c/ul>\n\n\u003cp>in addition to papers that provide a link between basic research and clinical practice, a particular emphasis is given to studies that are directly relevant to patient care.\u003c/p>\n\n\u003cp>as well as the established medical disciplines, frontiers in medicine aims to publish research that will facilitate:\u003c/p>\n\n\u003cul>\n \u003cli>access to medicinal products and medical devices worldwide\u003c/li>\n \u003cli>addressing the grand health challenges around the world\u003c/li>\n \u003cli>the exploitation of big data and the use of novel information and communication tools in the assessment of new medicines\u003c/li>\n \u003cli>the scientific bases for guidelines and decisions from regulatory authorities\u003c/li>\n \u003cli>the use of patient-reported outcomes under real world conditions.\u003c/li>\n\u003c/ul>\n\n\u003cp>all studies must contribute insights into the field of medicine. papers which do not primarily focus on a medical discipline are not suitable for publication in this journal. manuscripts that focus solely on the molecular or cellular mechanisms of diseases without a foundation in clinical medicine are not suitable for publication in this journal. similarly, studies that are purely descriptive or observational, without a clear hypothesis or mechanistic investigation, are not within the scope of this journal. research that is primarily epidemiological or public health-oriented, without a foundation in the pathophysiology or treatment of disease, is also not appropriate for this journal.\u003c/p>\n\n\u003cp>frontiers’ journals require that manuscripts primarily comprising computational studies of public data, must include appropriate validation. please refer to the \u003ca href=\"https://www.frontiersin.org/guidelines/policies-and-publication-ethics#standards-for-research-methodology:~:text=complaints%20and%20allegations.-,standards%20for%20research%20methodology,-experiments\">frontiers standards for research methodology policy\u003c/a>, for more information. manuscripts not adhering to these standards will not be considered.\u003cp>\n\n\u003cp>frontiers in medicine is committed to advancing developments in the field of medicine by allowing unrestricted access to articles and communicating scientific knowledge to researchers and the public alike, to enable the scientific breakthroughs of the future.\u003c/p>\n\n\u003cp>ethics statement:\u003c/p>\n\n\u003cp>all manuscripts submitted to frontiers in medicine that have been conducted in human subjects must conform with current regulations and the declaration of helsinki. ethics committee approval and informed patient consent are required for studies involving human subjects. ethics committee approval is also needed for studies involving animals. phase i - phase iv clinical trials submitted for publication in frontiers in medicine must have been registered with an appropriate public trials registry at the time or before the first patient enrolment. the information on the clinical trial registration (unique identifier and url) must be included in the abstract. authors are required to disclose all apparent or potential conflicts of interest according to the icmje guidelines and those of frontiers.\u003c/p>\n\n\u003cp>frontiers endeavors to follow the guidelines and best practice recommendations published by the committee on publication ethics (cope). authors should refer to the author guidelines for full details.\u003c/p>","purple","3.9","3.6","176752","@frontmedicine",{"id":115,"name":116,"slug":117,"abbreviation":417,"isonline":13,"isopenforsubmissions":13,"citescore":418,"impactfactor":419},"fmed",6,3,{"displaytitlepilllabels":13,"displayrelatedarticlesbox":13,"showeditors":13,"showreviewers":13,"showloopimpactlink":13,"enablefigshare":351,"usexmlimages":13},{"ispublic":13,"allowcompanyusers":351,"whitelistemails":422,"enablealljournals":13,"whitelistjournals":444},[423,424,425,426,427,428,429,430,431,428,432,433,434,435,436,437,438,439,440,441,442,443],"y2fybg9zlmxvcmnhqgzyb250awvyc2lulm9yzw==","zgfuawvslmx1ekbmcm9udgllcnnpbi5vcmc=","bgf1cmeudgvuyubmcm9udgllcnnpbi5vcmc=","cmfmywvslnjpyw5jag9aznjvbnrpzxjzaw4ub3jn","amftzxmuc21hbgxib25lqgzyb250awvyc2lulm9yzw==","znjhbi5tb3jlbm9aznjvbnrpzxjzaw4ub3jn","c2ftdwvslmzlcm5hbmrlekbmcm9udgllcnnpbi5vcmc=","ymfyymfyys5jyxjjyw5naxvaznjvbnrpzxjzaw4ub3jn","axzhbi5zyw50yw1hcmlhqgzyb250awvyc2lulm9yzw==","ahvllnryyw5aznjvbnrpzxjzaw4ub3jn","z29uy2fsby52yxjnyxnaznjvbnrpzxjzaw4ub3jn","bhvjawuuc2vubkbmcm9udgllcnnpbi5vcmc=","bg9ybi5mcmfzzxjaznjvbnrpzxjzaw4ub3jn","zwxzys5jyxjyb25aznjvbnrpzxjzaw4ub3jn","bwfhcnrlbi52yw5kawpja0bmcm9udgllcnnpbi5vcmc=","ymluzgh1lmtyaxnobmfuqgzyb250awvyc2lulm9yzw==","bwf0dghldy5hdhr3yxrlcnnaznjvbnrpzxjzaw4ub3jn","z2l1bglhlnzhbhnly2noaubmcm9udgllcnnpbi5vcmc=","zmfiawfulmrlbgxhbw9ydgvaznjvbnrpzxjzaw4ub3jn","dmlqyxlhbi5wcebwaxrzb2x1dglvbnmuy29t","z3vpbgxhdw1llnnldxjhdebmcm9udgllcnnpbi5vcmc=",[445,446,447,406,448,449,374,450,115,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478],2232,1729,2357,2176,2333,1843,106,616,310,657,3123,1468,2137,628,1566,2726,2086,1490,451,141,1335,2655,1238,604,698,1547,176,1440,403,1239,755,2136,609,1534,{"spaceid":374,"name":374,"availablejournalpages":480,"announcement":484},[259,264,261,481,482,483],"volumes","about","community-reviewers",{"__typename":485,"sys":486,"preheader":42,"title":488,"description":489,"image":490,"link":512},"announcement",{"id":487},"5ittnttqgazppgh6rx0alm","articles published with frontiers have received 12 million total citations","your research is the real superpower - learn how we maximise its impact through our leading community journals",[491],{"archive":371,"brandid":372,"copyright":28,"datecreated":492,"datemodified":493,"datepublished":494,"description":28,"extension":495,"filesize":497,"height":498,"id":499,"ispublic":371,"limited":371,"name":500,"orientation":389,"original":28,"thumbnails":501,"type":367,"watermarked":371,"width":508,"videopreviewurls":509,"tags":510,"textmetaproperties":511,"src":502},"2025-06-18t12:58:01z","2025-06-18t14:15:34z","2025-06-18t12:57:32z",[496],"png",1365026,920,"7c5269c4-3c83-4591-951a74d15b95daea","impact metrics banner for article pages",{"webimage":502,"thul":503,"mini":504,"websitewebp_l":505,"websitewebp_m":506,"guidelines":507},"https://brand.frontiersin.org/m/59ee6275cb9a849c/webimage-impact-metrics-banner-for-article-pages.png","https://brand.frontiersin.org/m/59ee6275cb9a849c/thul-impact-metrics-banner-for-article-pages.png","https://brand.frontiersin.org/m/59ee6275cb9a849c/mini-impact-metrics-banner-for-article-pages.png","https://brand.frontiersin.org/asset/7c5269c4-3c83-4591-951a-74d15b95daea/websitewebp_l/impact-metrics-banner-for-article-pages.webp","https://brand.frontiersin.org/asset/7c5269c4-3c83-4591-951a-74d15b95daea/websitewebp_m/impact-metrics-banner-for-article-pages.webp","https://brand.frontiersin.org/asset/7c5269c4-3c83-4591-951a-74d15b95daea/guidelines/impact-metrics-banner-for-article-pages.png",1600,[],[],[],{"text":513,"url":43,"target":27,"arialabel":28},"explore our impact metrics",{"loggeduserinfo":-1},{"currentarticle":516,"ispreviewpage":351,"hassupplementaldata":351,"showcrossmarkwidget":13,"articletemplate":646,"currentarticlepagemetainfo":647,"xmlparsedarticlecontent":-1,"xmlparsingerror":-1},{"id":517,"doi":518,"title":519,"acceptancedate":520,"receptiondate":521,"publicationdate":522,"lastmodifieddate":523,"ispublished":13,"abstract":524,"researchtopic":525,"articletype":531,"stage":534,"keywords":536,"authors":543,"editors":584,"reviewers":592,"journal":607,"section":615,"impactmetrics":617,"volume":620,"articlevolume":621,"relatedarticles":622,"ispublishedv2":13,"contents":623,"files":626},1646249,"10.3389/fmed.2025.1646249","diagnosing autism spectrum disorders using a double deep q-network framework based on social media footprints","2025-07-28t08:25:45.000z","2025-06-16t12:25:51.000z","2025-08-20t00:00:00.000z","2025-10-21t02:22:52.270z","introductionsocial media is increasingly used in many contexts within the healthcare sector. the improved prevalence of internet use via computers or mobile devices presents an opportunity for social media to serve as a tool for the rapid and direct distribution of essential health information. autism spectrum disorders (asd) are a comprehensive neurodevelopmental syndrome with enduring effects. twitter has become a platform for the asd community, offering substantial assistance to its members by disseminating information on their beliefs and perspectives via language and emotional expression. adults with asd have considerable social and emotional challenges, while also demonstrating abilities and interests in screen-based technologies.methodsthe novelty of this research lies in its use in the context of twitter to analyze and identify asd. this research used twitter as the primary data source to examine the behavioral traits and immediate emotional expressions of persons with asd. we applied convolutional neural networks with long short-term memory (cnn-lstm), lstm, and double deep q-network (ddqn-inspired) using a standardized dataset including 172 tweets from the asd class and 158 tweets from the non-asd class. the dataset was processed to exclude lowercase text and special characters, followed by a tokenization approach to convert the text into integer word sequences. the encoding was used to transform the classes into binary labels. following preprocessing, the proposed framework was implemented to identify asd.resultsthe findings of the ddqn-inspired model demonstrate a high precision of 87% compared to the proposed model. this finding demonstrates the potential of the proposed approach for identifying asd based on social media content.discussionultimately, the proposed system was compared against the existing system that used the same dataset. the proposed approach is based on variations in the text of social media interactions, which can assist physicians and clinicians in performing symptom studies within digital footprint environments.",{"id":526,"title":527,"articlescount":528,"ismagazinepage":351,"slug":529,"isopenforsubmission":351,"views":530},69516,"ai innovations in neuroimaging: transforming brain analysis",10,"ai-innovations-in-neuroimaging-transforming-brain-analysis",16647,{"id":532,"name":533},24,"original research",{"id":535,"name":19},18,[537,538,539,540,541,542],"artificial intelligence","deep learning","social media","disabilities","autism spectrum disorders","diagnosing",[544,555,564,573],{"id":545,"firstname":546,"middlename":19,"lastname":547,"givennames":548,"iscorresponding":351,"isprofilepublic":13,"userid":545,"email":-1,"affiliations":549},2586659,"nesren s.","farhah","nesren s. ",[550,553],{"organizationname":551,"countryname":552,"cityname":19,"statename":19,"zipcode":19},"department of health informatics, college of health science, saudi electronic university","saudi arabia",{"organizationname":554,"countryname":552,"cityname":19,"statename":19,"zipcode":19},"king salman center for disability research",{"id":556,"firstname":557,"middlename":19,"lastname":558,"givennames":559,"iscorresponding":351,"isprofilepublic":13,"userid":556,"email":-1,"affiliations":560},3164796,"ahmed abdullah","alqarni","ahmed abdullah ",[561,562],{"organizationname":554,"countryname":552,"cityname":19,"statename":19,"zipcode":19},{"organizationname":563,"countryname":552,"cityname":19,"statename":19,"zipcode":19},"department of computer sciences and information technology, al-baha university",{"id":565,"firstname":566,"middlename":19,"lastname":567,"givennames":568,"iscorresponding":351,"isprofilepublic":13,"userid":565,"email":-1,"affiliations":569},3077810,"nadhem","ebrahim","nadhem ",[570],{"organizationname":571,"countryname":572,"cityname":19,"statename":19,"zipcode":19},"department of computer science, college of engineering and polymer science, university of akron","united states",{"id":574,"firstname":575,"middlename":19,"lastname":576,"givennames":577,"iscorresponding":351,"isprofilepublic":13,"userid":574,"email":-1,"affiliations":578},1762668,"sultan","ahmad","sultan ",[579,581],{"organizationname":580,"countryname":552,"cityname":19,"statename":19,"zipcode":19},"department of computer science, college of computer engineering and sciences, prince sattam bin abdulaziz university",{"organizationname":582,"countryname":583,"cityname":19,"statename":19,"zipcode":19},"school of computer science and engineering, lovely professional university","india",[585],{"id":586,"firstname":587,"middlename":19,"lastname":588,"givennames":589,"iscorresponding":351,"isprofilepublic":13,"userid":586,"email":-1,"affiliations":590},2928766,"pardeep","sangwan","pardeep ",[591],{"organizationname":19,"countryname":19,"cityname":19,"statename":19,"zipcode":19},[593,600],{"id":594,"firstname":595,"middlename":19,"lastname":596,"givennames":597,"iscorresponding":351,"isprofilepublic":13,"userid":594,"email":-1,"affiliations":598},1743107,"jia-bao","liu","jia-bao ",[599],{"organizationname":19,"countryname":19,"cityname":19,"statename":19,"zipcode":19},{"id":601,"firstname":602,"middlename":19,"lastname":603,"givennames":604,"iscorresponding":351,"isprofilepublic":13,"userid":601,"email":-1,"affiliations":605},3104897,"muhammad","adnan","muhammad ",[606],{"organizationname":19,"countryname":19,"cityname":19,"statename":19,"zipcode":19},{"id":115,"slug":117,"name":116,"shortname":608,"electronicissn":609,"field":610,"specialtyid":28,"journalsectionpaths":613},"front. med.","2296-858x",{"id":611,"domainid":612},39,2,[614],{"section":615},{"id":180,"name":181,"slug":182,"specialtyid":616},1754,{"views":618,"downloads":619,"citations":371},1193,132,12,"volume 12 - 2025",[],{"titlehtml":519,"fulltexthtml":624,"menuhtml":625},"\u003cdiv class=\"journalabstract\"> \u003ca id=\"h1\" name=\"h1\">\u003c/a>\n \u003cdiv class=\"authors\">\u003cspan class=\"author-wrapper notranslate\">\u003ca href=\"https://loop.frontiersin.org/people/2586659\" class=\"user-id-2586659\">\u003cimg class=\"pr5\" src=\"https://loop.frontiersin.org/images/profile/2586659/74\" onerror=\"this.onerror=null;this.src='https://loop.frontiersin.org/cdn/images/profile/default_32.jpg';\" alt=\"nesren s. farhah,
\">nesren s. farhah\u003c/a>\u003csup>1,2\u003c/sup>\u003csup>*\u003c/sup>\u003c/span>\u003cspan class=\"author-wrapper notranslate\">\u003ca href=\"https://loop.frontiersin.org/people/3164796\" class=\"user-id-3164796\">\u003cimg class=\"pr5\" src=\"https://loop.frontiersin.org/images/profile/3164796/74\" onerror=\"this.onerror=null;this.src='https://loop.frontiersin.org/cdn/images/profile/default_32.jpg';\" alt=\"ahmed abdullah alqarni,\">ahmed abdullah alqarni\u003c/a>\u003csup>2,3\u003c/sup>\u003c/span>\u003cspan class=\"author-wrapper notranslate\">\u003ca href=\"https://loop.frontiersin.org/people/3077810\" class=\"user-id-3077810\">\u003cimg class=\"pr5\" src=\"https://loop.frontiersin.org/images/profile/3077810/74\" onerror=\"this.onerror=null;this.src='https://loop.frontiersin.org/cdn/images/profile/default_32.jpg';\" alt=\"nadhem ebrahim
\">nadhem ebrahim\u003c/a>\u003csup>4\u003c/sup>\u003csup>*\u003c/sup>\u003c/span>\u003cspan class=\"author-wrapper notranslate\">\u003ca href=\"https://loop.frontiersin.org/people/1762668\" class=\"user-id-1762668\">\u003cimg class=\"pr5\" src=\"https://loop.frontiersin.org/images/profile/1762668/74\" onerror=\"this.onerror=null;this.src='https://loop.frontiersin.org/cdn/images/profile/default_32.jpg';\" alt=\"sultan ahmad,
\">sultan ahmad\u003c/a>\u003csup>5,6\u003c/sup>\u003csup>*\u003c/sup>\u003c/span>\u003c/div> \u003cul class=\"notes\"> \u003cli>\u003cspan>\u003csup>1\u003c/sup>\u003c/span>department of health informatics, college of health science, saudi electronic university, riyadh, saudi arabia\u003c/li> \u003cli>\u003cspan>\u003csup>2\u003c/sup>\u003c/span>king salman center for disability research, riyadh, saudi arabia\u003c/li> \u003cli>\u003cspan>\u003csup>3\u003c/sup>\u003c/span>department of computer sciences and information technology, al-baha university, al-baha, saudi arabia\u003c/li> \u003cli>\u003cspan>\u003csup>4\u003c/sup>\u003c/span>department of computer science, college of engineering and polymer science, university of akron, oh, united states\u003c/li> \u003cli>\u003cspan>\u003csup>5\u003c/sup>\u003c/span>department of computer science, college of computer engineering and sciences, prince sattam bin abdulaziz university, al-kharj, saudi arabia\u003c/li> \u003cli>\u003cspan>\u003csup>6\u003c/sup>\u003c/span>school of computer science and engineering, lovely professional university, phagwara, india\u003c/li> \u003c/ul>\n\u003cp class=\"mb15\">\u003cb>introduction:\u003c/b> social media is increasingly used in many contexts within the healthcare sector. the improved prevalence of internet use via computers or mobile devices presents an opportunity for social media to serve as a tool for the rapid and direct distribution of essential health information. autism spectrum disorders (asd) are a comprehensive neurodevelopmental syndrome with enduring effects. twitter has become a platform for the asd community, offering substantial assistance to its members by disseminating information on their beliefs and perspectives via language and emotional expression. adults with asd have considerable social and emotional challenges, while also demonstrating abilities and interests in screen-based technologies.\u003c/p>\n\u003cp class=\"mb15\">\u003cb>methods:\u003c/b> the novelty of this research lies in its use in the context of twitter to analyze and identify asd. this research used twitter as the primary data source to examine the behavioral traits and immediate emotional expressions of persons with asd. we applied convolutional neural networks with long short-term memory (cnn-lstm), lstm, and double deep q-network (ddqn-inspired) using a standardized dataset including 172 tweets from the asd class and 158 tweets from the non-asd class. the dataset was processed to exclude lowercase text and special characters, followed by a tokenization approach to convert the text into integer word sequences. the encoding was used to transform the classes into binary labels. following preprocessing, the proposed framework was implemented to identify asd.\u003c/p>\n\u003cp class=\"mb15\">\u003cb>results:\u003c/b> the findings of the ddqn-inspired model demonstrate a high precision of 87% compared to the proposed model. this finding demonstrates the potential of the proposed approach for identifying asd based on social media content.\u003c/p>\n\u003cp class=\"mb0\">\u003cb>discussion:\u003c/b> ultimately, the proposed system was compared against the existing system that used the same dataset. the proposed approach is based on variations in the text of social media interactions, which can assist physicians and clinicians in performing symptom studies within digital footprint environments.\u003c/p> \u003cdiv class=\"clear\">\u003c/div> \u003c/div> \u003cdiv class=\"journalfulltext\"> \u003ca id=\"h2\" name=\"h2\">\u003c/a>\n\u003ch2>1 introduction\u003c/h2>\n\u003cp class=\"mb0\">asd is among the most prevalent neurodevelopmental disorders. asd is often demonstrated in children by age three and is defined by impairments in social interactions and communication, repetitive sensory-motor activities, and stereotypical behavioral patterns (\u003ca href=\"#ref1\">1\u003c/a>). asd is a congenital neurodevelopmental condition characterized by symptoms that are evident in early infancy. autism, characterized by restricted interests, repetitive behaviors, and significant disparities in social communication and interaction, typically emerges during early developmental stages and presents challenges in various social functioning domains. a child with autism induces significant anxiety within the family due to several factors, including the ambiguity of the diagnosis, the intensity and persistence of the disease, and the child’s nonconformity to social norms. in opposition, social awareness of autism is markedly inadequate, often conflated with intellectual disability and seen as an incurable ailment (\u003ca href=\"#ref2\">2\u003c/a>, \u003ca href=\"#ref3\">3\u003c/a>). the asd concept is displayed in \u003ca href=\"#fig1\">figure 1\u003c/a>.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 1\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g001.jpg\" name=\"figure1\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g001.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g001.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g001.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g001.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g001.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g001.jpg\" alt=\"nine icons representing concepts related to autism and interventions. top row: discrete trial training, pivotal response training, and verbal behavior intervention. middle row: impulsiveness and aggression, preference for solitude, delayed language development. bottom row: prescription drugs during pregnancy, family history of autism, assistive technologies. each icon illustrates its concept with relevant imagery.\" id=\"fig1\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 1\u003c/b>. displays the asd concept.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb15\">content on social media, particularly videos and text disseminated by parents and caregivers, has emerged as a significant resource for facilitating the early identification of asd (\u003ca href=\"#ref4\">4\u003c/a>, \u003ca href=\"#ref5\">5\u003c/a>). social media are technological tools designed for sharing, enabling users to create networks or engage in existing ones. in that order, the pew research center identified the most popular social media sites as youtube, facebook, instagram, pinterest, linkedin, snapchat, twitter, and whatsapp (\u003ca href=\"#ref6\">6\u003c/a>). most consumers use these networks daily. this research utilizes twitter data to assess the stigmatization of autism and associated terminology, picked based on accessibility and popularity, with analysis conducted using artificial intelligence technologies (\u003ca href=\"#ref7\">7\u003c/a>).\u003c/p>\n\u003cp class=\"mb15\">conventional diagnostic methods, which primarily rely on observational and behavioral evaluations, often encounter issues with accessibility, consistency, and timeliness. recent technology breakthroughs, especially in artificial intelligence (ai), and sensor-based techniques, provide novel opportunities for improving asd identification. by developing more objective, accurate, and scalable approaches, these technologies transform diagnostic methodologies for autism spectrum disorder (asd) (\u003ca href=\"#ref8\">8\u003c/a>–\u003ca href=\"#ref10\">10\u003c/a>). one new way to study the motor patterns, attentional processes, and physiological responses linked to asd in real-time is wearable sensors, eye-tracking devices, and multimodal virtual reality settings. these technologies have the potential to give non-invasive, continuous monitoring, which might help with the early diagnosis of asd and shed light on neurological and behavioral traits that have been hard to document reliably.\u003c/p>\n\u003cp class=\"mb15\">nevertheless, advancements in contemporary research are required to substantiate their efficacy. sensor-based techniques may facilitate the identification of stereotyped behaviors and motor patterns linked to asd in realistic environments, potentially yielding data that could guide timely and customized therapies (\u003ca href=\"#ref11\">11\u003c/a>). neuroimaging and microbiome analysis further advance this technical domain by indicating neurological and biological traits specific to asd. ai-enhanced neuroimaging aids in identifying structural and functional brain connection patterns associated with asd, thereby enhancing the understanding of its neuroanatomical foundation (\u003ca href=\"#ref12\">12\u003c/a>).\u003c/p>\n\u003cp class=\"mb15\">the research conducted by neeharika and riyazuddin et al. (\u003ca href=\"#ref13\">13\u003c/a>) aimed to enhance the accuracy of asd screening by using feature selection methods in conjunction with sophisticated machine learning classifiers. their research included several datasets spanning infants, children, adolescents, and adults, enabling a thorough assessment of asd characteristics across different age demographics. authors’ use of mlp model capacity to reliably and rapidly identify asd, indicating a beneficial screening instrument suitable for various age groups, facilitating both clinical evaluations and extensive screenings. wall et al. (\u003ca href=\"#ref14\">14\u003c/a>) investigated machine learning (ml) algorithms for diagnosing asd using a standard dataset. the researchers focused on the alternating decision tree classifier to identify a limited yet efficient set of queries that optimize the diagnostic procedure. alzakari et al. (\u003ca href=\"#ref15\">15\u003c/a>) proposed a novel two-phase methodology to tackle the variability in asd features with ml approaches, including behavioral, linguistic, and physical data. the first step concentrates on identifying asd, using feature engineering methodologies and ml algorithms, including a logistic regression (lr) and support vector machine (svm) ensemble, attaining a classification with high accuracy. eeg assesses brain activity and may identify children predisposed to developing asd, hence facilitating early diagnosis. eeg data is used to compare asd and hc (\u003ca href=\"#ref16\">16\u003c/a>–\u003ca href=\"#ref18\">18\u003c/a>). in (\u003ca href=\"#ref19\">19\u003c/a>), the cnn model was used for classification after transforming the data into a two-dimensional format. while eeg may facilitate the diagnosis of asd, it is constrained by other factors, such as signal noise.\u003c/p>\n\u003cp class=\"mb15\">the research has used social media to investigate asd. however, exploiting these prevalent platforms and innovative online data sources may be feasible to enhance the comprehension of these diseases. previous research has utilized twitter data to investigate discussions on asd-related material, indicating that this subject is frequently addressed on this platform (\u003ca href=\"#ref20\">20\u003c/a>). considering the use of social media for researching asd is particularly significant, as a recent analysis indicated that around 80% of individuals with asd engage with prominent social media platforms (\u003ca href=\"#ref21\">21\u003c/a>). this study aims to build upon previous research and enhance our comprehension of whether publicly accessible social media data from twitter may provide insights into the existence of digital diagnostic indicators for asd (\u003ca href=\"#ref22\">22\u003c/a>). furthermore, we want to assess the viability of establishing a digital phenotype for asd using social media.\u003c/p>\n\u003cp class=\"mb0\">beykikhoshk et al. (\u003ca href=\"#ref20\">20\u003c/a>) examined twitter’s potential as a data-mining tool to comprehend the actions, challenges, and requirements of autistic individuals. the first finding pertained to the attributes of participants inside the autism subgroup of tweets, indicating that these tweets were highly informative and had considerable potential usefulness for public health experts and policymakers. tomeny et al. (\u003ca href=\"#ref23\">23\u003c/a>) examined demographic correlations of autism-related anti-vaccine opinions on twitter from 2009 to 2015. their results indicated that the frequency of autism-related anti-vaccine views online was alarming, with anti-vaccine tweets connecting with news events and demonstrating geographical clustering. from 2015 to 2019, tárraga-mínguez et al. (\u003ca href=\"#ref24\">24\u003c/a>) examined the phrases “autism” and “asperger” in spain in relation to google search peaks. the public view of autism was significantly impacted by how the condition was portrayed in the news and on social media, and the authors found that social marketing campaigns had a significant role in normalizing autism. in this research (\u003ca href=\"#ref25\">25\u003c/a>), looked at how people sought assistance. the results showed a strong correlation in google search interest between the terms “asperger syndrome” and “greta thunberg,” reaching their highest point in 2019. online traffic to the asperger/autism network and autism speaks websites increased steadily from june to december 2019, indicating a correlation between help-seeking behavior and thunberg’s fame, according to the research. according to the results, the stigma associated with asperger’s disorder may have been positively affected by thunberg’s public exposure.\u003c/p>\n\u003ch3>1.1 contribution\u003c/h3>\n\u003cp class=\"mb0\">the use of tweets from twitter for the detection of asd is substantial, since it offers extensive, real-time, user-generated data that facilitates the early identification of asd-related behaviors, particularly via self-reported experiences and parental observations. this methodology promotes the advancement of suggested models, namely lstm, cnn-lstm, and inspired ddqn, for natural language processing to examine linguistic patterns, feelings, and keywords related to asd. it provides insights into popular views, stigma, and misconceptions around autism, guiding awareness initiatives and public health measures. twitter data is a powerful and accessible resource for enhancing early detection and understanding of asd in diverse groups. utilizing social media in this manner may offer more accessible and timely screening, particularly in regions with limited healthcare resources.\u003c/p> \u003ca id=\"h3\" name=\"h3\">\u003c/a>\n\u003ch2>2 materials and methods\u003c/h2>\n\u003cp class=\"mb0\">\u003ca href=\"#fig2\">figure 2\u003c/a> shows the pipeline of the proposed system to provide a broader perspective to researchers and developers. the framework delineates the processing phases for the pipeline that utilizes social media content to diagnose asd. below, we present a comprehensive assessment of each step.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 2\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g002.jpg\" name=\"figure2\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g002.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g002.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g002.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g002.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g002.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g002.jpg\" alt=\"flowchart depicting a process for analyzing twitter data. it starts with social media avatars and a twitter api feeding into a word cloud for asd-related terms. next, preprocessing involves text cleaning, label encoding, and tokenization. this data feeds into deep learning models, including lstm, cnn-lstm, and ddqn. outputs are classified as asd or non-asd, with corresponding graphs indicating training and validation accuracy over epochs.\" id=\"fig2\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 2\u003c/b>. farmwork of asd system.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch3>2.1 dataset\u003c/h3>\n\u003cp class=\"mb0\">to help with the early diagnosis of asd by using proposed systems, the tasd-dataset includes comprehensive textual sequences that depict the everyday lives of children with and without asd. it offers new elements, including noise sensitivity, sharing interest, sign communication, and tiptoe flapping, it combines critical asd assessment aspects like attention response, word repetition, and emotional empathy, as shown in \u003ca href=\"#fig3\">figure 3\u003c/a>. parents may get detailed insights and better identify signs of autism spectrum disorder (asd) due to the deepening of certain behaviors. the dataset contains 172 tweets from the asd class and 158 non-asd tweets. \u003ca href=\"#fig4\">figure 4\u003c/a> shows the class of the dataset.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 3\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g003.jpg\" name=\"figure3\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g003.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g003.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g003.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g003.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g003.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g003.jpg\" alt=\"bar chart titled “feature frequencies” showing the count of various behaviors. “word repetition” has the highest frequency at 2.00. other features like “attention response,” “change reaction,” and “eye contact” have frequencies of 1.00 each.\" id=\"fig3\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 3\u003c/b>. features of the dataset.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline mb15\">\u003c/div>\n\u003cdiv class=\"imageheaders\">figure 4\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g004.jpg\" name=\"figure4\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g004.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g004.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g004.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g004.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g004.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g004.jpg\" alt=\"bar chart titled “number of tweets per class” compares tweet counts for asd and non-asd categories. asd has around 175 tweets, while non-asd has about 160 tweets.\" id=\"fig4\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 4\u003c/b>. label of the dataset.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch3>2.2 preprocessing\u003c/h3>\n\u003cp class=\"mb0\">text preprocessing is an essential step in the text processing process. words, sentences, and paragraphs can all be found in a text, which is defined as a meaningful sequence of characters. preprocessing methods feed text data to a proposed algorithm in a better form than in its natural state. a tweet can contain different viewpoints on the data it represents. tweets that have not been preprocessed are highly unstructured and contain redundant data. to address these issues, several steps are taken to preprocess tweets for detecting asd, as shown in \u003ca href=\"#fig5\">figure 5\u003c/a>.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 5\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g005.jpg\" name=\"figure5\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g005.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g005.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g005.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g005.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g005.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g005.jpg\" alt=\"flowchart depicting a text preprocessing workflow with three stages: text cleaning, label encoding, and tokenization and padding. the tokenization and padding section includes tokenizer, texts_to_sequences, and padding_sequences. arrows indicate process flow from left to right.\" id=\"fig5\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 5\u003c/b>. preprocessing asd text analysis.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch3>2.3 text cleaning\u003c/h3>\n\u003cp class=\"mb0\">the clean text preprocessing method is a significant step in text datasets because the text contains several extra contexts to preprocess and normalize raw text data for analysis. in these steps, the use is transformed to lowercase to guarantee consistency and prevent differentiation between “asd” and “non-asd.” subsequently, any characters that are not letters, numerals, or spaces are eliminated by a regular expression, so punctuation and other symbols that might create extraneous noise are removed. this method is ultimately applied to the ‘text’ column of the data frame, ensuring that all text elements are sanitized and prepared for feature extraction. \u003ca href=\"#fig6\">figure 6\u003c/a> displays the clean text process.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 6\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g006.jpg\" name=\"figure6\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g006.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g006.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g006.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g006.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g006.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g006.jpg\" alt=\"bar chart titled “text cleaning progression - sample 1” showing text length in characters for four stages: original, lowercased, no special chars, and trimmed. each bar’s length is nearly the same, around 150-200 characters.\" id=\"fig6\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 6\u003c/b>. clean text.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch3>2.4 label encoding\u003c/h3>\n\u003cp class=\"mb0\">the labelencoder method converts text class (asd and non-asd) into numbers, designating 0 for asd and 1 for non-asd. this transformation updates the classification effort by enabling the model to see the labels as numerical values instead of text. \u003ca href=\"#eq1\">equations 1\u003c/a>, \u003ca href=\"#eq2\">2\u003c/a> show the label encoding.\u003c/p>\n\u003cdiv id=\"eq1\" class=\"equationimageholder\">\u003cmath id=\"m1\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext mathvariant=\"italic\">yclassification\u003c/mtext>\u003cmo>∈\u003c/mo>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi mathvariant=\"italic\">asd\u003c/mi>\u003cmo>,\u003c/mo>\u003cmtext mathvariant=\"italic\">non\u003c/mtext>\u003cmo>−\u003c/mo>\u003cmi mathvariant=\"italic\">asd\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmtext mathvariant=\"italic\">then\u003c/mtext>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>1\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq19\" class=\"equationimageholder\">\u003cmath id=\"m2\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmi>y\u003c/mi>\u003cmo>=\u003c/mo>\u003cmtext mathvariant=\"italic\">labelencoder\u003c/mtext>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmtext mathvariant=\"italic\">yclassifcation\u003c/mtext>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>→\u003c/mo>\u003cmi>y\u003c/mi>\u003cmo>∈\u003c/mo>\u003cmo stretchy=\"true\">{\u003c/mo>\u003cmn>0\u003c/mn>\u003cmo>,\u003c/mo>\u003cmn>1\u003c/mn>\u003cmo stretchy=\"true\">}\u003c/mo>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>2\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003ch3>2.5 tokenization and padding\u003c/h3>\n\u003cp class=\"mb0\">tokenization and padding are essential nlp preprocessing procedures that transform unprocessed text into a numerical representation appropriate for machine learning models, particularly neural networks. \u003ca href=\"#fig7\">figure 7\u003c/a> shows the tokenization and padding \u003ca href=\"#eq3\">equation 3\u003c/a>.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 7\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g007.jpg\" name=\"figure7\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g007.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g007.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g007.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g007.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g007.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g007.jpg\" alt=\"sample text tokenization and padding process with three horizontal bar graphs. the first graph shows original text words. the second graph illustrates the tokenized sequence using word indexes with varying heights. the third graph shows a padded sequence with a fixed length of twenty, ensuring uniform token index lengths. the indexes used are rearranged with zero padding.\" id=\"fig7\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 7\u003c/b>. sample of text tokenization and padding.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch4>2.5.1 tokenizer\u003c/h4>\n\u003cp class=\"mb0\">tokenizer procedures transform textual data into a numerical representation suitable for input into neural networks. they convert a text corpus into integer sequences, assigning a distinct index to each unique word according to its frequency, as shown in \u003ca href=\"#eq3\">equation 3\u003c/a>. the tokenizer processing is shown in \u003ca href=\"#fig8\">figure 8\u003c/a>.\u003c/p>\n\u003cdiv id=\"eq2\" class=\"equationimageholder\">\u003cmath id=\"m3\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext mathvariant=\"italic\">index\u003c/mtext>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>w\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>=\u003c/mo>\u003cmsub>\u003cmo mathvariant=\"italic\">rank\u003c/mo>\u003cmi>f\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>w\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmtext mathvariant=\"italic\">if\u003c/mtext>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmsub>\u003cmo mathvariant=\"italic\">rank\u003c/mo>\u003cmi>f\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>w\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>≤\u003c/mo>\u003cmi>v\u003c/mi>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>3\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 8\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g008.jpg\" name=\"figure8\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g008.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g008.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g008.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g008.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g008.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g008.jpg\" alt=\"three bar charts illustrate text data analysis. chart a shows the top 20 most frequent words with “to” being the highest. chart b depicts sequence length distribution before padding, peaking at around 20 tokens. chart c displays sequence lengths post-padding, fixed at 200 tokens, appearing as a single line at the 200 mark.\" id=\"fig8\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 8\u003c/b>. tokenizer analysis: word frequencies and sequence lengths.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">where \u003cmath id=\"m4\">\u003cmsub>\u003cmo mathvariant=\"italic\">rank\u003c/mo>\u003cmi>f\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>w\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003c/math>is rank \u003cmath id=\"m5\">\u003cmi>w\u003c/mi>\u003c/math> frequency \u003cmath id=\"m6\">\u003cmi>f\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>w\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/math> and \u003cmath id=\"m7\">\u003cmi>v\u003c/mi>\u003c/math> is the maximum number of words.\u003c/p>\n\u003ch4>2.5.2 fit texts\u003c/h4>\n\u003cp class=\"mb0\">this phase is crucial for transforming unprocessed text into numerical sequences suitable for input into the proposed system.\u003c/p>\n\u003ch4>2.5.3 texts_to_sequences\u003c/h4>\n\u003cp class=\"mb0\">to convert unprocessed text input into sequences of word indices according to the mapping acquired via as shown in \u003ca href=\"#eq4\">equation 4\u003c/a>.\u003c/p>\n\u003cdiv id=\"eq3\" class=\"equationimageholder\">\u003cmath id=\"m8\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext mathvariant=\"italic\">sequence\u003c/mtext>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>t\u003c/mi>\u003cmi>i\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>=\u003c/mo>\u003cmo stretchy=\"true\">[\u003c/mo>\u003cmtext mathvariant=\"italic\">index\u003c/mtext>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmn>1\u003c/mn>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>,\u003c/mo>\u003cmtext mathvariant=\"italic\">index\u003c/mtext>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmn>2\u003c/mn>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>,\u003c/mo>\u003cmo>…\u003c/mo>\u003cmo>…\u003c/mo>\u003cmo>…\u003c/mo>\u003cmo>,\u003c/mo>\u003cmtext mathvariant=\"italic\">index\u003c/mtext>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmi>m\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo stretchy=\"true\">]\u003c/mo>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>4\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cp class=\"mb0\">where is the \u003cmath id=\"m9\">\u003cmsub>\u003cmi>t\u003c/mi>\u003cmi>i\u003c/mi>\u003c/msub>\u003c/math> is the sentence of the text contained, and \u003cmath id=\"m10\">\u003cmi>w\u003c/mi>\u003c/math> is the words of the text, whereas the \u003cmath id=\"m11\">\u003cmtext mathvariant=\"italic\">index\u003c/mtext>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmn>1\u003c/mn>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/math> is an index of the words in the context.\u003c/p>\n\u003ch4>2.5.4 padding_sequences\u003c/h4>\n\u003cp class=\"mb0\">normalize sequence lengths, which may differ post-tokenization, by padding shorter sequences and truncating larger ones to a predetermined length as shown in \u003ca href=\"#eq5\">equation 5\u003c/a>. the padding and truncated b are fixed on the length. \u003cmath id=\"m12\">\u003cmi>l\u003c/mi>\u003cmo>=\u003c/mo>\u003cmn>200\u003c/mn>\u003c/math>. the padding processing is shown in \u003ca href=\"#fig7\">figure 7\u003c/a>.\u003c/p>\n\u003cdiv id=\"eq4\" class=\"equationimageholder\">\u003cmath id=\"m13\">\u003cmi>x\u003c/mi>\u003cmo>=\u003c/mo>\u003cmo>∣\u003c/mo>\u003cmrow>\u003cmtable displaystyle=\"true\">\u003cmtr>\u003cmtd>\u003cmsub>\u003cmi>x\u003c/mi>\u003cmn>1\u003c/mn>\u003c/msub>\u003c/mtd>\u003c/mtr>\u003cmtr>\u003cmtd>\u003cmsub>\u003cmi>x\u003c/mi>\u003cmn>2\u003c/mn>\u003c/msub>\u003c/mtd>\u003c/mtr>\u003cmtr>\u003cmtd>\u003cmtable>\u003cmtr>\u003cmtd>\u003cmo>.\u003c/mo>\u003c/mtd>\u003c/mtr>\u003cmtr>\u003cmtd>\u003cmo>.\u003c/mo>\u003c/mtd>\u003c/mtr>\u003cmtr>\u003cmtd>\u003cmo>.\u003c/mo>\u003c/mtd>\u003c/mtr>\u003cmtr>\u003cmtd>\u003cmo>.\u003c/mo>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/mtd>\u003c/mtr>\u003cmtr>\u003cmtd>\u003cmi>y\u003c/mi>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/mrow>\u003cmo>∣\u003c/mo>\u003cmo>∈\u003c/mo>\u003cmsup>\u003cmi>ℝ\u003c/mi>\u003cmi mathvariant=\"italic\">nxl\u003c/mi>\u003c/msup>\u003cmtext>    (5)\u003c/mtext>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cp class=\"mb0\">where \u003cmath id=\"m14\">\u003cmi>x\u003c/mi>\u003c/math> is features contain padding and are tokenized, \u003cmath id=\"m15\">\u003cmi>l\u003c/mi>\u003c/math> is the length of the vector. the number of texts is indicated \u003cmath id=\"m16\">\u003cmi>n\u003c/mi>\u003c/math>, and \u003cmath id=\"m17\">\u003cmo>∈\u003c/mo>\u003cmsup>\u003cmi>ℝ\u003c/mi>\u003cmi mathvariant=\"italic\">nxl\u003c/mi>\u003c/msup>\u003c/math> is matrix lues.\u003c/p>\n\u003ch3>2.6 proposed systems\u003c/h3>\n\u003ch4>2.6.1 convolutional neural networks\u003c/h4>\n\u003cp class=\"mb0\">the cnn model is at the core of all advanced machine learning and deep learning applications. they can successfully address text classification, image recognition, object identification, and semantic segmentation. using the same method with a task as different as natural language processing is counterintuitive (\u003ca href=\"#ref7\">7\u003c/a>). the structure is presented in \u003ca href=\"#fig9\">figure 9\u003c/a>. \u003ca href=\"#eq6\">equation 6\u003c/a> presents the convolution layer of cnn.\u003c/p>\n\u003cdiv id=\"eq5\" class=\"equationimageholder\">\u003cmath id=\"m18\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmi>o\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo>,\u003c/mo>\u003cmi>y\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>=\u003c/mo>\u003cmunderover>\u003cmo movablelimits=\"false\">∑\u003c/mo>\u003cmrow>\u003cmi>i\u003c/mi>\u003cmo>=\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003cmi>h\u003c/mi>\u003c/munderover>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmunderover>\u003cmo movablelimits=\"false\">∑\u003c/mo>\u003cmrow>\u003cmi>j\u003c/mi>\u003cmo>=\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003cmi>w\u003c/mi>\u003c/munderover>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmi>i\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi>i\u003c/mi>\u003cmo>,\u003c/mo>\u003cmi>y\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi>j\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>∗\u003c/mo>\u003cmi>k\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>i\u003c/mi>\u003cmo>,\u003c/mo>\u003cmi>j\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>+\u003c/mo>\u003cmi>b\u003c/mi>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>6\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 9\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g009.jpg\" name=\"figure9\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g009.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g009.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g009.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g009.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g009.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g009.jpg\" alt=\"flowchart depicting a text classification process using convolutional neural networks. it starts with a sentence matrix representation. colored blocks denote convolution results with filter sizes of two, three, and four. the results undergo one-max pooling, then concatenate into a single vector. finally, the vector classifies into categories: information giving, information seeking, feature request, solution proposal, problem discovery, aspect evaluation, and others.\" id=\"fig9\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 9\u003c/b>. structure cnn.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">where the features of text \u003cmath id=\"m19\">\u003cmi>o\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo>,\u003c/mo>\u003cmi>y\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/math> the feature of the text is mapped by using.\u003cmath id=\"m20\">\u003cmi>i\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi>i\u003c/mi>\u003cmo>,\u003c/mo>\u003cmi>y\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi>j\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/math> is weighted by a neural network and \u003cmath id=\"m21\">\u003cmi>b\u003c/mi>\u003c/math> is biased to adjust the neural. the relu activation function is \u003ca href=\"#eq20\">equation 7\u003c/a>, the max pooling function is presented in \u003ca href=\"#eq6\">equation 8\u003c/a>. the dense layer is given in \u003ca href=\"#eq7\">equation 9\u003c/a>.\u003c/p>\n\u003cdiv id=\"eq20\" class=\"equationimageholder\">\u003cmath id=\"m22\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmi>f\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>=\u003c/mo>\u003cmi>max\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmn>0\u003c/mn>\u003cmo>,\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>7\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq6\" class=\"equationimageholder\">\u003cmath id=\"m23\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmi>o\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo>,\u003c/mo>\u003cmi>y\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>=\u003c/mo>\u003cmunderover>\u003cmo movablelimits=\"false\">∑\u003c/mo>\u003cmrow>\u003cmi>i\u003c/mi>\u003cmo>=\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003cmi>h\u003c/mi>\u003c/munderover>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmunderover>\u003cmo movablelimits=\"false\">∑\u003c/mo>\u003cmrow>\u003cmi>j\u003c/mi>\u003cmo>=\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003cmi>w\u003c/mi>\u003c/munderover>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmi>i\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi>i\u003c/mi>\u003cmo>,\u003c/mo>\u003cmi>y\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi>j\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>∗\u003c/mo>\u003cmi>k\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>i\u003c/mi>\u003cmo>,\u003c/mo>\u003cmi>j\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>+\u003c/mo>\u003cmi>b\u003c/mi>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>8\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq7\" class=\"equationimageholder\">\u003cmath id=\"m24\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmi mathvariant=\"normal\">o\u003c/mi>\u003cmo>=\u003c/mo>\u003cmi>w\u003c/mi>\u003cmo>·\u003c/mo>\u003cmi>x\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi>b\u003c/mi>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>9\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003ch4>2.6.2 long short-term memory network\u003c/h4>\n\u003cp class=\"mb0\">an lstm network is an advanced form of a sequential neural network. it fixes the problem of rnn gradients fading over time. rnns often handle long-term storage. at a high level, the operation of an lstm is comparable to that of a single rnn neuron. the inner workings of the lstm network are outlined in this section. the lstm consists of three parts, each performing a particular function, as seen in \u003ca href=\"#fig10\">figure 10\u003c/a> below. in the first step, it is decided whether the information from the previous time stamp is significant enough to be saved or if it is harmless enough to be deleted. in the second step, the cell will try to acquire new information by analyzing the data that has been presented to it. in the third and final step, the cell incorporates the data from the most recent time stamp into the data stored in the next time stamp. these three components constitute what is referred to as a gate for an lstm cell. the “forget” gate comes first, followed by the “input” section, and then the “output” section is used to define the last portion as shown in \u003ca href=\"#eq10\">equations 10\u003c/a>– \u003ca href=\"#eq14\">14\u003c/a>.\u003c/p>\n\u003cdiv id=\"eq8\" class=\"equationimageholder\">\u003cmath id=\"m25\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext>forget gate\u003c/mtext>\u003cmo>:\u003c/mo>\u003cmsub>\u003cmi>f\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>=\u003c/mo>\u003cmi>σ\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmi>f\u003c/mi>\u003c/msub>\u003cmo>.\u003c/mo>\u003cmsub>\u003cmi>x\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmi>f\u003c/mi>\u003c/msub>\u003cmo>.\u003c/mo>\u003cmsub>\u003cmi>h\u003c/mi>\u003cmrow>\u003cmi>t\u003c/mi>\u003cmo>−\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmsub>\u003cmi>b\u003c/mi>\u003cmi>f\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>10\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq9\" class=\"equationimageholder\">\u003cmath id=\"m26\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext>input gate\u003c/mtext>\u003cmo>:\u003c/mo>\u003cmsub>\u003cmi>i\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>=\u003c/mo>\u003cmi>σ\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmi>c\u003c/mi>\u003c/msub>\u003cmo>.\u003c/mo>\u003cmsub>\u003cmi>x\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmi>i\u003c/mi>\u003c/msub>\u003cmo>.\u003c/mo>\u003cmsub>\u003cmi>h\u003c/mi>\u003cmrow>\u003cmi>t\u003c/mi>\u003cmo>−\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmsub>\u003cmi>b\u003c/mi>\u003cmi>i\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>11\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq10\" class=\"equationimageholder\">\u003cmath id=\"m27\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext>cell gate\u003c/mtext>\u003cmo>:\u003c/mo>\u003cmsub>\u003cmi>c\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>=\u003c/mo>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmi>f\u003c/mi>\u003c/msub>\u003cmo>∗\u003c/mo>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmo>.\u003c/mo>\u003cmsub>\u003cmi>h\u003c/mi>\u003cmrow>\u003cmi>t\u003c/mi>\u003cmo>−\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003c/msub>\u003cmo>,\u003c/mo>\u003cmsub>\u003cmi>x\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmsub>\u003cmi>b\u003c/mi>\u003cmi>f\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>12\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq11\" class=\"equationimageholder\">\u003cmath id=\"m28\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext>output gate\u003c/mtext>\u003cmo>:\u003c/mo>\u003cmsub>\u003cmi>o\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>=\u003c/mo>\u003cmi>σ\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmi>o\u003c/mi>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmsub>\u003cmi>x\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmsub>\u003cmi>w\u003c/mi>\u003cmi>o\u003c/mi>\u003c/msub>\u003cmo>.\u003c/mo>\u003cmsub>\u003cmi>h\u003c/mi>\u003cmrow>\u003cmi>t\u003c/mi>\u003cmo>−\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmsub>\u003cmi>v\u003c/mi>\u003cmi>o\u003c/mi>\u003c/msub>\u003cmo>.\u003c/mo>\u003cmsub>\u003cmi>c\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmsub>\u003cmi>b\u003c/mi>\u003cmi>o\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>13\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq12\" class=\"equationimageholder\">\u003cmath id=\"m29\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext>hidden layer\u003c/mtext>\u003cmo>:\u003c/mo>\u003cmsub>\u003cmi>h\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>=\u003c/mo>\u003cmsub>\u003cmi>o\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo>+\u003c/mo>\u003cmi>tanh\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmsub>\u003cmi>c\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>14\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 10\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g010.jpg\" name=\"figure10\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g010.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g010.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g010.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g010.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g010.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g010.jpg\" alt=\"flowchart of an lstm neural network model with multiple layers. the input layer feeds into 25 features, which connect to lstm layer 1 with 128 neurons. relu activation leads to lstm layer 2 with 64 neurons, followed by a sigmoid activation for binary classification into class 0 or class 1.\" id=\"fig10\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 10\u003c/b>. lstm model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb15\">in \u003ca href=\"#fig10\">figure 10\u003c/a>, \u003cmath id=\"m30\">\u003cmsub>\u003cmi>c\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003c/math> represent the prior and current states of the cell, respectively. both \u003cmath id=\"m31\">\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmsub>\u003cmi>h\u003c/mi>\u003cmrow>\u003cmi>t\u003c/mi>\u003cmo>−\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003c/msub>\u003c/math> and \u003cmath id=\"m32\">\u003cmi>h\u003c/mi>\u003c/math> represents the cell output that was processed before the one now being processed. it is common practice to disregard \u003cmath id=\"m33\">\u003cmsub>\u003cmi>f\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003c/math> as a gate, even though it is the input gate. the output of a sigmoid gate is symbolized here by \u003cmath id=\"m34\">\u003cmsub>\u003cmi>o\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003c/math>. the cable that connects the cell gates is where all the data collected by the cell gates is sent to and from \u003cmath id=\"m35\">\u003cmi>c\u003c/mi>\u003c/math>. the \u003cmath id=\"m36\">\u003cmsub>\u003cmi>f\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003c/math> layer decides to remember anything, and the\u003cmath id=\"m37\">\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmsub>\u003cmi>f\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003cmtext mathvariant=\"italic\">the\u003c/mtext>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003c/math>output is multiplied by c to do so (t-1). after that, c (t-1) is multiplied by the product of the sigmoid layer gate and the tanh layer gate, and the output h t is generated by point-wise multiplication of \u003cmath id=\"m38\">\u003cmsub>\u003cmi>o\u003c/mi>\u003cmi>t\u003c/mi>\u003c/msub>\u003c/math> and tanh.\u003c/p>\n\u003cp class=\"mb0\">the lstm architecture is intended to capture long-term relationships in twitter text data. the preprocessing converts input words that start with an embedding layer into 128-dimensional dense vectors. the lstm layer with 64 units is then used to mitigate overfitting, integrating dropout and recurrent dropout with 0.5. an l2 regularization term is further included in the lstm and output dense layer. \u003ca href=\"#tab1\">table 1\u003c/a> shows parameters of the lstm model.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">table 1\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t001.jpg\" name=\"table1\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t001.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t001.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t001.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t001.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t001.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t001.jpg\" alt=\"www.frontiersin.org\" id=\"tab1\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>table 1\u003c/b>. lstm parameters model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch4>2.6.3 cnn-lstm model\u003c/h4>\n\u003cp class=\"mb0\">the cnn-lstm model is a hybrid architecture that combines convolutional neural networks (cnn) for spatial feature extraction and long short-term memory (lstm) networks for sequential learning, making it highly effective for analyzing text data such as tweets. the model begins with an embedding layer that transforms each word into a 256-dimensional dense vector, capturing the semantic meaning of words. this is followed by a 1d convolutional layer with 64 filters and a kernel size of 5, which scans through the text to detect local patterns and n-gram features such as common word combinations or phrases often associated with asd. a batch normalization layer is applied to stabilize and accelerate training, followed by a max pooling layer that reduces the dimensionality and computational load by selecting the most prominent features. a dropout layer with a rate of 0.5 is then used to prevent overfitting by randomly deactivating some neurons during training. the output is passed into a 64-unit lstm layer that captures the temporal dependencies and contextual relationships across the tweet sequence. finally, a dense layer with sigmoid activation performs binary classification to predict whether the tweet indicates asd-related content. the model is trained using the adam optimizer, binary cross-entropy loss, class weights, and regularization to handle imbalanced data and improve generalization. the critical parameters of the cnn-lstm model are displayed in \u003ca href=\"#tab2\">table 2\u003c/a>.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">table 2\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t002.jpg\" name=\"table2\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t002.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t002.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t002.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t002.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t002.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t002.jpg\" alt=\"www.frontiersin.org\" id=\"tab2\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>table 2\u003c/b>. cnn-lstm parameters.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch4>2.6.4 double deep q-network (ddqn-inspired)\u003c/h4>\n\u003cp class=\"mb15\">the double q-learning model was introduced by h. van hasselt in 2010, addressing the issue of significant overestimations of action value (q-value) inherent in traditional q-learning. in fundamental q-learning, the agent’s optimal strategy is consistently to select the most advantageous action in any specific state. this concept’s premise is that the optimal action corresponds to the highest expected or estimated q-value. initially, the agent lacks any knowledge of the environment; it must first estimate q(s, a) and subsequently update these estimates with each iteration. the q-values exhibit considerable noise, leading to uncertainty about whether the action associated with the highest expected or estimated q-value is genuinely the optimal choice.\u003c/p>\n\u003cp class=\"mb0\">double q-learning employs two distinct action-value functions, q and q’, as estimators. even if q and q’ exhibit noise, this noise can be interpreted as a uniform distribution as shown \u003ca href=\"#fig11\">figure 11\u003c/a> the update procedure exhibits some variations compared to the basic version. the action selection and action evaluation processes are separated into two distinct maximum function estimators. shown in \u003ca href=\"#eq13\">equations 15\u003c/a>, \u003ca href=\"#eq16\">16\u003c/a>.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 11\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g011.jpg\" name=\"figure11\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g011.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g011.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g011.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g011.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g011.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g011.jpg\" alt=\"diagram illustrating the process of reinforcement learning with replay memory and q-networks. the replay memory outputs a mini-batch containing state, action, reward, and next state. this feeds into both the online and target q-networks. the online q-network outputs state-action pairs, which are used alongside the target q-network’s output in the loss function. a feedback loop connects the replay memory to the online q-network.\" id=\"fig11\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 11\u003c/b>. ddqn-inspired model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">let the vector of a neural network’s weights be represented by \u003ci>θ\u003c/i>. we establish two q-networks: the online q-network q (s, a; θ(t)) and the target q-network q (s, a; θ (t)). to be more specific, the training of q (s, a; \u003ci>Χ\u003c/i> (t)) is done by modifying the weights (t) at time slot t in relation to the goal value y(t).\u003c/p>\n\u003cdiv id=\"eq13\" class=\"equationimageholder\">\u003cmath id=\"m39\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmi>y\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>t\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>=\u003c/mo>\u003cmi>g\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>t\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>+\u003c/mo>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>s\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo>,\u003c/mo>\u003cmtext>argmax\u003c/mtext>\u003cmi>q\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>s\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo>,\u003c/mo>\u003cmsup>\u003cmi>a\u003c/mi>\u003cmo>∗\u003c/mo>\u003c/msup>\u003cmo>;\u003c/mo>\u003cmi>θ\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>t\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>;\u003c/mo>\u003cmi>θ\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>t\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>15\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq14\" class=\"equationimageholder\">\u003cmath id=\"m40\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmi>y\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>t\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>=\u003c/mo>\u003cmi>g\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>t\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>+\u003c/mo>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>s\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo>,\u003c/mo>\u003cmtext>argmax\u003c/mtext>\u003cmi>q\u003c/mi>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>s\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo>,\u003c/mo>\u003cmsup>\u003cmi>a\u003c/mi>\u003cmo>∗\u003c/mo>\u003c/msup>\u003cmo>;\u003c/mo>\u003cmi>θ\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo>;\u003c/mo>\u003cmsub>\u003cmi>θ\u003c/mi>\u003cmrow>\u003cmi>i\u003c/mi>\u003cmo>−\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003c/msub>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>16\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cp class=\"mb15\">the reinforcement learning mechanism integrates generative artificial intelligence for decision-making and prediction tasks, as shown in \u003ca href=\"#eq15\">equations 15\u003c/a>, \u003ca href=\"#eq16\">16\u003c/a>. this equation indicates the generative which produces the estimation or hypothesis at a given time \u003cmath id=\"m41\">\u003cmi>t\u003c/mi>\u003c/math>.\u003cmath id=\"m42\">\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmtext mathvariant=\"italic\">double\u003c/mtext>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmi>q\u003c/mi>\u003cmo>−\u003c/mo>\u003cmtext mathvariant=\"italic\">learning\u003c/mtext>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003c/math>used next state, whereas the s’ is exit state and \u003cmath id=\"m43\">\u003cmtext>argmax\u003c/mtext>\u003cmi>q\u003c/mi>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>s\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo>,\u003c/mo>\u003cmsup>\u003cmi>a\u003c/mi>\u003cmo>∗\u003c/mo>\u003c/msup>\u003cmo>;\u003c/mo>\u003cmi>θ\u003c/mi>\u003cmo>′\u003c/mo>\u003cmo stretchy=\"true\">(\u003c/mo>\u003cmi>t\u003c/mi>\u003cmo stretchy=\"true\">)\u003c/mo>\u003cmo stretchy=\"true\">)\u003c/mo>\u003c/math> defined as the action of \u003cmath id=\"m44\">\u003cmsup>\u003cmi>a\u003c/mi>\u003cmo>∗\u003c/mo>\u003c/msup>\u003c/math> to maximize the predicted q-value based on the current parameters. to estimate the q-value of this selected action in the next state, the outer q-function q’ employs the older parameters. \u003cmath id=\"m45\">\u003cmsub>\u003cmi>θ\u003c/mi>\u003cmrow>\u003cmi>i\u003c/mi>\u003cmo>−\u003c/mo>\u003cmn>1\u003c/mn>\u003c/mrow>\u003c/msub>\u003c/math>1, which helps reduce overestimation bias. this combination makes applications for predicting asd from social media content domains possible.\u003c/p>\n\u003cp class=\"mb0\">the ddqn model is used to classify asd and non-asd cases utilizing text data. the model utilizes a preprocessing step for text processing that encompasses data loading, cleaning (including lowercasing, removal of special characters, and normalization of spaces), and tokenization, constrained by a maximum vocabulary of 10,000 words and a sequence length of 200. the model architecture, drawing from the double deep q-network (ddqn) model comprises an input layer, an embedding layer with 256 dimensions, and two parallel lstm branches, each containing 64 units, a dropout rate of 0.5, and l2 regularization to capture sequential patterns effectively. the model uses the adam optimizer with a learning rate of 1e-4 and employs binary cross-entropy loss. it is trained for 30 epochs, incorporating early stopping and learning rate reduction callbacks to mitigate overfitting. parameters of ddqn-inspired are shown in \u003ca href=\"#tab3\">table 3\u003c/a>.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">table 3\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t003.jpg\" name=\"table3\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t003.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t003.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t003.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t003.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t003.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t003.jpg\" alt=\"www.frontiersin.org\" id=\"tab3\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>table 3\u003c/b>. parameters of ddqn-inspired.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div> \u003ca id=\"h4\" name=\"h4\">\u003c/a>\n\u003ch2>3 performance of the framework\u003c/h2>\n\u003ch3>3.1 performance of lstm\u003c/h3>\n\u003cp class=\"mb0\">\u003ca href=\"#fig12\">figure 12\u003c/a> presents the accuracy and loss metrics used to train and validate an lstm model over 30 epochs. the validation accuracy of the lstm model, displayed in red, begins at a lower value and increases to about 81%. the blue line in the accuracy plot (a) shows the training accuracy of the lstm model; it increases gradually from around 50% to almost 99%, showing that the model learns the training data well over time. the plot (b) shows the loss of the lstm model; the blue line represents the training loss, which drops gradually from around 0.7 to less than 0.2, suggesting that the model is getting a better fit to the training data. meanwhile, the red validation loss line declines from around 0.7 to about 0.3. while the training loss continues to grow, the validation loss reaches a level and exhibits small oscillations, suggesting that the model’s generalizability may stabilize.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 12\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g012.jpg\" name=\"figure12\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g012.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g012.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g012.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g012.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g012.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g012.jpg\" alt=\"two line graphs depict an lstm model’s performance over 30 epochs. the left graph shows accuracy, with training accuracy rising from 0.5 to 0.9, while validation accuracy fluctuates around 0.8. the right graph displays loss, where training loss decreases from 0.7 to 0.1, and validation loss reduces from 0.7 to 0.3. both graphs feature blue lines for training metrics and red lines for validation metrics.\" id=\"fig12\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 12\u003c/b>. performance of the lstm model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">the roc curve illustrated in \u003ca href=\"#fig13\">figure 13\u003c/a> shows the efficacy of the lstm model in differentiating between the classes. the graph illustrates the tp rate (sensitivity) in relation to the fp rate across different threshold levels. the lstm model attains an auc of 0.95, demonstrating exceptional classification capability. the auc of 1.0, but a result of 0.5 indicates random chance.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 13\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g013.jpg\" name=\"figure13\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g013.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g013.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g013.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g013.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g013.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g013.jpg\" alt=\"roc curve for an lstm model showing the trade-off between true positive rate and false positive rate. the curve bends towards the top-left corner, with an area under the curve (auc) of 0.95, indicating high model performance. a diagonal dashed line represents random chance.\" id=\"fig13\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 13\u003c/b>. roc of the lstm model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch3>3.2 performance of the cnn-lstm model\u003c/h3>\n\u003cp class=\"mb0\">\u003ca href=\"#fig14\">figure 14\u003c/a> presents plots illustrating the performance of a cnn-lstm model over 25 epochs, showing its training and validation metrics for accuracy and loss. the accuracy plot (a) illustrates the training accuracy (blue line), which increases progressively from approximately 51.42% to nearly 99.53%, indicating effective learning from the training data. in contrast, the validation accuracy (red line) rises to about 83.02% with some variability, indicating satisfactory but imperfect generalization. the loss plot (b) shows the training loss (blue line) declining steadily from 0.7140 to below 0.0760, indicating enhanced model fit. in contrast, the validation loss (red line) decreases from 0.7130 to approximately 0.3530, with a slight decline toward the conclusion. this notification indicates that the cnn-lstm model demonstrates efficient learning, as evidenced by the difference between the training and validation measures.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 14\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g014.jpg\" name=\"figure14\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g014.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g014.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g014.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g014.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g014.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g014.jpg\" alt=\"two line graphs show cnn-lstm model performance. the left graph displays training and validation accuracy over 25 epochs. training accuracy improves significantly, surpassing validation accuracy, which fluctuates. the right graph depicts training and validation loss over the same epochs. training loss decreases sharply, while validation loss also reduces but stabilizes after an initial drop.\" id=\"fig14\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 14\u003c/b>. performance of the lstm model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">\u003ca href=\"#fig15\">figure 15\u003c/a> illustrates the roc curve for the cnn-lstm model, illustrating its classification performance at various thresholds. the graph illustrates the tp rate (sensitivity) in relation to the fp rate, with the auc recorded at 92%. the elevated auc value indicates the model has robust discriminative capability in differentiating between the asd and non-asd classes. the roc ascends rapidly toward the top-left corner, as seen in the figure, indicating a high tp rate with few false positives.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 15\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g015.jpg\" name=\"figure15\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g015.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g015.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g015.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g015.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g015.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g015.jpg\" alt=\"roc curve for a cnn_lstm model, showing the true positive rate against the false positive rate. the curve is above the diagonal, with an area under the curve (auc) of 0.92, indicating strong model performance.\" id=\"fig15\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 15\u003c/b>. roc of the cnn-lstm model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch3>3.3 performance of ddqn-inspired model\u003c/h3>\n\u003cp class=\"mb0\">graphs 16 illustrate the performance of a ddqn throughout 30 epochs. the accuracy plot (a) demonstrates that the training accuracy increases from around 58.02% to almost 98.58%, indicating the ddqn model successful learning from the training data over time. the validation accuracy of the ddqn is about 87, showing the best performance compared to different models like lstm and cnn-lstm. the plot (b) illustrates that the training loss decreases from about 0.8155 to around 0.1477, indicating a robust fit to the training data. the validation loss begins at 0.3831 with many fluctuations throughout (\u003ca href=\"#fig16\">figure 16\u003c/a>).\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 16\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g016.jpg\" name=\"figure16\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g016.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g016.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g016.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g016.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g016.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g016.jpg\" alt=\"two graphs display the performance of a ddqn_t model over 30 epochs. graph (a) shows training accuracy in blue and validation accuracy in red, both improving over time. graph (b) illustrates training loss in blue and validation loss in red, both decreasing with some fluctuations.\" id=\"fig16\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 16\u003c/b>. performance of the \u003ci>ddqn-inspired\u003c/i> model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">\u003ca href=\"#fig17\">figure 17\u003c/a> shows the roc curve for the ddqn model; it shows a visual representation of its classification capability, with the curve toward the top-left corner, indicating strong predictive power. the auc value of the ddqn model is 96%, demonstrating that the model can distinguish between the positive and negative classes.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 17\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g017.jpg\" name=\"figure17\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g017.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g017.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g017.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g017.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g017.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g017.jpg\" alt=\"receiver operating characteristic (roc) curve illustrating a ddqn-inspired model performance. the curve shows the trade-off between true positive rate and false positive rate with an area under the curve (auc) of 0.96, indicating high accuracy.\" id=\"fig17\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 17\u003c/b>. roc \u003ci>ddqn-inspired model.\u003c/i>\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div> \u003ca id=\"h5\" name=\"h5\">\u003c/a>\n\u003ch2>4 experiment and discussion results\u003c/h2>\n\u003cp class=\"mb0\">both the jupyter deep learning framework and the windows 10 operating system were utilized during the testing process. experiments were conducted using a machine with 16 gigabytes of ram and an intel core i7 central processing unit. the input dimensions of the experiment were a standard text dataset collected from the twitter api related to asd. the test was utilized in our database, while the remaining 20% was used as part of our validation set. the three dl models, namely lstm, cnn-lstm, and ddqn-inspired, were proposed for detecting asd from social media content.\u003c/p>\n\u003ch3>4.1 measuring the model’s performance\u003c/h3>\n\u003cp class=\"mb0\">sensitivity, specificity, accuracy, recall, and f1 scores are assessment measures used to determine how successfully the algorithms identify asd. the related equations from \u003ca href=\"#eq17\">17\u003c/a> to \u003ca href=\"#eq21\">21\u003c/a>:\u003c/p>\n\u003cdiv id=\"eq15\" class=\"equationimageholder\">\u003cmath id=\"m46\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext mathvariant=\"italic\">accuracy\u003c/mtext>\u003cmo>=\u003c/mo>\u003cmfrac>\u003cmrow>\u003cmi mathvariant=\"italic\">tp\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi mathvariant=\"italic\">tn\u003c/mi>\u003c/mrow>\u003cmrow>\u003cmi mathvariant=\"italic\">tp\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi mathvariant=\"italic\">fp\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi mathvariant=\"italic\">fn\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi mathvariant=\"italic\">tn\u003c/mi>\u003c/mrow>\u003c/mfrac>\u003cmo>×\u003c/mo>\u003cmn>100\u003c/mn>\u003cmo>%\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>17\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq16\" class=\"equationimageholder\">\u003cmath id=\"m47\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext mathvariant=\"italic\">sensitivity\u003c/mtext>\u003cmo>=\u003c/mo>\u003cmfrac>\u003cmi mathvariant=\"italic\">tp\u003c/mi>\u003cmrow>\u003cmi mathvariant=\"italic\">tp\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi mathvariant=\"italic\">fn\u003c/mi>\u003c/mrow>\u003c/mfrac>\u003cmo>×\u003c/mo>\u003cmn>100\u003c/mn>\u003cmo>%\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>18\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq17\" class=\"equationimageholder\">\u003cmath id=\"m48\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext mathvariant=\"italic\">precision\u003c/mtext>\u003cmo>=\u003c/mo>\u003cmfrac>\u003cmi mathvariant=\"italic\">tp\u003c/mi>\u003cmrow>\u003cmi mathvariant=\"italic\">tp\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi mathvariant=\"italic\">fp\u003c/mi>\u003c/mrow>\u003c/mfrac>\u003cmo>×\u003c/mo>\u003cmn>100\u003c/mn>\u003cmo>%\u003c/mo>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>19\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq21\" class=\"equationimageholder\">\u003cmath id=\"m49\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmtext mathvariant=\"italic\">specificity\u003c/mtext>\u003cmo>=\u003c/mo>\u003cmfrac>\u003cmi mathvariant=\"italic\">tn\u003c/mi>\u003cmrow>\u003cmi mathvariant=\"italic\">tn\u003c/mi>\u003cmo>+\u003c/mo>\u003cmi mathvariant=\"italic\">fp\u003c/mi>\u003c/mrow>\u003c/mfrac>\u003cmo>×\u003c/mo>\u003cmn>100\u003c/mn>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>20\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003cdiv id=\"eq18\" class=\"equationimageholder\">\u003cmath id=\"m50\">\u003cmtable class=\"eqnarray\" columnalign=\"left\">\u003cmtr>\u003cmtd>\u003cmi>f\u003c/mi>\u003cmn>1\u003c/mn>\u003cmo>−\u003c/mo>\u003cmtext mathvariant=\"italic\">score\u003c/mtext>\u003cmo>=\u003c/mo>\u003cmn>2\u003c/mn>\u003cmo>∗\u003c/mo>\u003cmfrac>\u003cmrow>\u003cmtext mathvariant=\"italic\">precision\u003c/mtext>\u003cmo>×\u003c/mo>\u003cmtext mathvariant=\"italic\">sensitivity\u003c/mtext>\u003c/mrow>\u003cmrow>\u003cmtext mathvariant=\"italic\">precision\u003c/mtext>\u003cmo>+\u003c/mo>\u003cmtext mathvariant=\"italic\">sensitivity\u003c/mtext>\u003c/mrow>\u003c/mfrac>\u003cmo>×\u003c/mo>\u003cmn>100\u003c/mn>\u003cmspace width=\"0.25em\">\u003c/mspace>\u003c/mtd>\u003cmtd>\u003cmstyle class=\"text\">\u003cmtext>    \u003c/mtext>\u003c/mstyle>\u003cmrow>\u003cmo stretchy=\"false\">(\u003c/mo>\u003cmn>21\u003c/mn>\u003cmo stretchy=\"false\">)\u003c/mo>\u003c/mrow>\u003c/mtd>\u003c/mtr>\u003c/mtable>\u003c/math> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>\n\u003ch3>4.2 result of the lstm model\u003c/h3>\n\u003cp class=\"mb0\">the classification lstm model, presented in \u003ca href=\"#tab4\">table 4\u003c/a>, summarizes its performance in differentiating between asd and non-asd patients, attaining an overall accuracy of 81%. the lstm model demonstrates in asd class a precision of 91%, indicating a high accuracy in identifying predicted asd cases. the lstm with recall metric scored 77% and an f1-score of 82% for detecting the asd class. the lstm model with non-asd class demonstrates a precision of 71%, a recall of 89%, and an f1-score of 79%, to identify non-asd cases. the macro average of the lstm model for all metrics is (precision: 81%, recall: 82%, f1-score: 81%). lstm model is recognized for its efficiency and scalability as a model for social media content.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">table 4\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t004.jpg\" name=\"table4\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t004.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t004.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t004.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t004.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t004.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t004.jpg\" alt=\"www.frontiersin.org\" id=\"tab4\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>table 4\u003c/b>. lstm results.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">the confusion matrix for the lstm model is provided in \u003ca href=\"#fig18\">figure 18\u003c/a>. it is presented in a clear manner. among the confirmed asd cases, 29 were accurately identified as asd, whereas 10 were incorrectly classified as non-asd, indicating strong performance with minor errors. in the true non-asd cases, 25 were correctly identified, while 3 were misclassified as asd, suggesting a generally effective detection process. the deep blue and light shades produce a tranquil visual, illustrating the model’s balanced approach in classifying the 67 total instances, demonstrating notable strength in identifying non-asd cases, while exhibiting marginally lower accuracy for asd. this matrix effectively illustrates the lstm model’s systematic approach to managing sequential data, such as text or time-series inputs, in a clear and comprehensible manner.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 18\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g018.jpg\" name=\"figure18\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g018.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g018.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g018.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g018.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g018.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g018.jpg\" alt=\"confusion matrix for lstm model showing true labels versus predicted labels. the matrix includes 29 true positives for asd, 25 true negatives for non-asd, 10 false positives, and 3 false negatives. a color gradient represents value intensity.\" id=\"fig18\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 18\u003c/b>. lstm model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch3>4.3 result of the cnn-lstm model\u003c/h3>\n\u003cp class=\"mb0\">\u003ca href=\"#tab5\">table 5\u003c/a> displays the cnn-lstm model’s performance in distinguishing between asd and non-asd classes. the cnn-lstm model attained an overall accuracy of 85% across the dataset. in the asd label, a precision of 91% was achieved, a high percentage for predicting asd cases that were accurately recognized. the recall indicates that the model identified 82% of all genuine asd cases, resulting in an f1 score of 86%, better than the recall metric. the cnn-lstm model attained 78% accuracy, 89% recall, and an 83% f1 score for the non-asd class. the macro average, representing the unweighted mean of precision, recall, and f1 score across both classes, was 85, 86, and 85%, respectively. the findings indicate that the cnn-lstm model performs satisfactorily, exhibiting a marginally superior capacity to identify asd cases relative to non-asd cases accurately.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">table 5\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t005.jpg\" name=\"table5\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t005.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t005.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t005.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t005.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t005.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t005.jpg\" alt=\"www.frontiersin.org\" id=\"tab5\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>table 5\u003c/b>. results of the cnn-lstm model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">the confusion matrix of a cnn-lstm model is presented in \u003ca href=\"#fig19\">figure 19\u003c/a>, for classifying instances into asd and non-asd. the matrix is structured with true labels on the vertical axis and predicted labels on the horizontal axis, providing a clear summary of the model’s classification outcomes. the matrix shows that out of the instances truly labeled as asd, the model correctly predicted 32 as asd tp while 7 were incorrectly classified as non-asd fn. for the instances truly labeled as non-asd, the model accurately identified 25 as non-asd tn but 3 were misclassified as asd fp. this indicates that the model demonstrates a relatively strong ability to correctly identify asd and non-asd cases, with higher accuracy for true positives (32 out of 39 asd cases) and true negatives (25 out of 28 non-asd cases). overall, the model exhibits promising performance with minimal misclassification errors.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 19\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g019.jpg\" name=\"figure19\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g019.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g019.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g019.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g019.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g019.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g019.jpg\" alt=\"confusion matrix for cnn_lstm_model with predicted labels on the x-axis and true labels on the y-axis. it shows 32 true positives, 7 false negatives, 3 false positives, and 25 true negatives. a gradient bar on the right indicates color intensity from light to dark blue, representing increasing values from 0 to 30.\" id=\"fig19\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 19\u003c/b>. results of cnn-lstm model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003ch3>4.4 results of double deep q-network\u003c/h3>\n\u003cp class=\"mb0\">the findings of the ddqn model are shown in \u003ca href=\"#tab6\">table 6\u003c/a>, achieving a high precision of 87% compared to the other models. this finding demonstrates the potential of the proposed ddqn approach for identifying asd based on social media content. ultimately, the proposed system was compared against the existing one using the same dataset. the proposed approach may assist physicians in detecting asd and conducting symptomology research in a natural environment, attaining an overall accuracy of 87. the model for the asd class shows a precision of 95%, a recall of 79%, and an f1-score of 87%, indicating robust efficacy in accurately identifying asd patients. the non-asd class has a precision of 77%, a recall of 96%, and an f1-score of 86%, indicating somewhat reduced accuracy with robust recall. the macro average measures (precision 87%, recall 88%, f1-score 87%) indicate performance across both classes.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">table 6\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t006.jpg\" name=\"table6\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t006.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t006.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t006.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t006.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t006.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t006.jpg\" alt=\"www.frontiersin.org\" id=\"tab6\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>table 6\u003c/b>. result of ddqn-inspired.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">the confusion matrix of the ddqn model is shown in \u003ca href=\"#fig20\">figure 20\u003c/a> for the classification task between asd and non-asd cases. for correct classification of asd cases, the model correctly classified 31 instances as asd, represented by the top-left quadrant (tp). however, the ddqn model, misclassified 8 instances misclassifying true asd cases as non-asd, shown in the top-right quadrant (fn). on the other hand, the ddqn showed the true non-asd cases, accurately identified 27 instances as non-asd, depicted in the bottom-right quadrant (tn). at the same time, 1 instance was incorrectly labeled as asd, as shown in the bottom-left quadrant (fp). the confusion matrix of ddqn model highlights that it performs well overall, with a strong ability to correctly identify both asd and non-asd cases, as evidenced by the high counts of tp (31) and tn (27).\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 20\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g020.jpg\" name=\"figure20\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g020.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g020.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g020.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g020.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g020.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g020.jpg\" alt=\"confusion matrix title “ddqn-inspired confusion matrix”. the matrix shows actual versus predicted labels for asd and non-asd. true positives: 31, false positives: 8, false negatives: 1, true negatives: 27. a color bar on the right indicates intensity from light to dark blue, corresponding to values from 0 to 30.\" id=\"fig20\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 20\u003c/b>. result of ddqn-inspired model.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb15\">in the digital era, people frequently write content on social media to express their feelings, opinions, beliefs, and activities. this makes social media one of the most significant sources of data generation, allowing you to explore its opportunities and challenges. today, social media has become a mediator between people and the healthcare sector, enabling them to search for information about any specific disease and methods for diagnosing it.\u003c/p>\n\u003cp class=\"mb0\">individuals within the mental health community use social media platforms such as twitter to seek information, exchange experiences, and get assistance about asd in an environment that is seen as more approachable and informal than conventional medical contexts. they often seek immediate, relevant information—whether to understand symptoms, identify coping mechanisms, or connect with others facing similar difficulties. \u003ca href=\"#fig21\">figure 21\u003c/a> illustrates that word clouds are visual representations of text that highlight key terms and their frequency of use. we used wordcloud to compare asd and non-asd texts for instances of word repetition.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 21\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g021.jpg\" name=\"figure21\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g021.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g021.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g021.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g021.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g021.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g021.jpg\" alt=\"word cloud with terms related to asd class, including prominent words like “toddler,” “ability,” “might,” “concerned,” “activities,” and “making.” other words such as “engage,” “learning,” “challenging,” “noise,” and “struggle” also appear, reflecting themes in autism education.\" id=\"fig21\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 21\u003c/b>. asd word cloud.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb0\">the deployment model based on the deep q-network (dqn) model for diagnosing asd is shown in \u003ca href=\"#fig22\">figure 22\u003c/a>.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">figure 22\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g022.jpg\" name=\"figure22\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g022.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g022.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g022.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g022.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g022.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g022.jpg\" alt=\"flowchart depicting a data collection and processing model using twitter api for tweet analysis. the process includes filtering tweets, preprocessing, and applying a deep q-network for model development. it involves validating and testing to build an application interface. the deployment phase includes user interaction, real-time monitoring, and cloud storage. health professionals validate predictions, classifying tweets as asd or non-asd.\" id=\"fig22\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>figure 22\u003c/b>. deployment system-based text for detecting asd.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div>\n\u003cp class=\"mb15\">step 1: data collections, including cleaning, normalization, and tokenization.\u003c/p>\n\u003cp class=\"mb15\">step 2: model development: the preprocessed data is used to train and validate a deep q-network (dqn) model for classifying tweets as indicative of asd or non-asd patterns.\u003c/p>\n\u003cp class=\"mb15\">step 3: application interface: an application interface is developed once the model has been trained. it integrates with users’ twitter accounts and continuously analyzes their tweets.\u003c/p>\n\u003cp class=\"mb15\">step 4: deployment: the proposed system is deployed in the cloud for storing tweets, enabling real-time monitoring of incoming tweets. predictions are flagged for review by healthcare professionals, who validate the model’s output before categorizing individuals as potentially having asd or non-asd.\u003c/p>\n\u003cp class=\"mb0\">this digital imprint may serve as an ancillary resource for mental health practitioners, providing insights into an individual’s emotional state and social behaviors in a natural environment, potentially facilitating early detection or corroborating a diagnosis. this method is a non-invasive means of data collection, particularly beneficial for individuals who lack rapid access to clinical assessments due to financial constraints, stigma, or resource scarcity. however, it should not replace professional diagnoses and must be conducted with ethical consideration to prevent misunderstanding. \u003ca href=\"#tab7\">table 7\u003c/a> shows the findings of the proposed framework on the twitter dataset. it demonstrates that the suggested method outperforms the current systems in terms of accuracy, proving its efficacy and potential for performance improvements.\u003c/p>\n\u003cdiv class=\"dottedline\">\u003c/div> \u003cdiv class=\"imageheaders\">table 7\u003c/div> \u003cdiv class=\"figuredesc\">\u003ca href=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t007.jpg\" name=\"table7\" target=\"_blank\">\n \u003cpicture>\n \u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=480&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t007.jpg\" media=\"(max-width: 563px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=370&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t007.jpg\" media=\"(max-width: 1024px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=290&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t007.jpg\" media=\"(max-width: 1441px)\">\u003csource type=\"image/webp\" srcset=\"https://images-provider.frontiersin.org/api/ipx/w=410&f=webp/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t007.jpg\" media=\"\">\u003csource type=\"image/jpg\" srcset=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t007.jpg\" media=\"\"> \u003cimg src=\"https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-t007.jpg\" alt=\"www.frontiersin.org\" id=\"tab7\" loading=\"lazy\">\n \u003c/picture>\n\u003c/a>\n\u003cp>\u003cb>table 7\u003c/b>. compared with the proposed asd system.\u003c/p>\u003c/div> \u003cdiv class=\"clear\">\u003c/div> \u003cdiv class=\"dottedline\">\u003c/div> \u003ca id=\"h6\" name=\"h6\">\u003c/a>\n\u003ch2>5 conclusion\u003c/h2>\n\u003cp class=\"mb0\">to assist people in identifying trends in their behavior, such as social challenges or sensory sensitivities, which may encourage them to pursue a formal diagnosis. the main objective of examining tweets for identifying asd is its ability to provide behavioral and emotional indicators associated with the disorder. this research was used to analyze the textual analysis of tweets to detect the behaviors in self-identified autistic individuals relative to others. the suggested framework was evaluated using information from the social media platform “twitter” collected from a public repository. before examining the proposed system, several preprocessing steps must be implemented in the text. the ‘text’ column is cleaned by converting it to lowercase, eliminating non-alphanumeric characters (excluding spaces) through regular expressions, normalizing whitespace to a single space, and removing any leading or trailing spaces. the asd and non-asd labels are converted into a numerical format (0 or 1) with labelencoder to accommodate the binary classification requirement. tokenization of the text data is performed using a tokenizer, restricting the vocabulary to 10,000 words, and then transforming the text into sequences of numbers. the sequences are padded to a standardized length of 200 tokens to maintain consistency for the proposed model input. the proposed data is ultimately divided into an 80% training and 20% testing ratio, and class weights are calculated to resolve any class imbalance. this preparation pipeline efficiently converts raw text data into a structured numerical representation appropriate for the proposed framework, while preserving academic integrity. the output of these preprocessing steps was processed using three dl models, such as short-term memory (cnn-lstm) and a double deep q-network (ddqn). the results of these proposals were proven, revealing that the ddqn model achieved a high accuracy score of 87% with respect to the accuracy measure. the proposed framework, based on real textual data, can be helpful for real-time offering natural, behavioral, and emotional data that might indicate asd-related characteristics. finally, we have observed that social media (twitter) postings include linguistic patterns, emotional expressions, and social interactions that can help official health officials detect asd based on the thorough symptoms of asd that are posted on the platform. this study utilized a conventional dataset sourced only from the twitter network. we will emphasize the necessity of gathering datasets from many platforms to enhance the model’s generalizability in the future.\u003c/p> \u003ca id=\"h7\" name=\"h7\">\u003c/a>\n\u003ch2>data availability statement\u003c/h2>\n\u003cp class=\"mb0\">the original contributions presented in the study are included in the article/supplementary material, further inquiries can be directed to the corresponding author/s. the dataset used in this study can be found at \u003ca href=\"https://data.mendeley.com/datasets/87s2br3ptb/1\">https://data.mendeley.com/datasets/87s2br3ptb/1\u003c/a>.\u003c/p> \u003ca id=\"h8\" name=\"h8\">\u003c/a>\n\u003ch2>ethics statement\u003c/h2>\n\u003cp class=\"mb0\">ethical approval was not required for the study involving human data in accordance with the local legislation and institutional requirements. written informed consent was not required, for either participation in the study or for the publication of potentially/indirectly identifying information, in accordance with the local legislation and institutional requirements. the social media data was accessed and analysed in accordance with the platform’s terms of use and all relevant institutional/national regulations.\u003c/p> \u003ca id=\"h9\" name=\"h9\">\u003c/a>\n\u003ch2>author contributions\u003c/h2>\n\u003cp class=\"mb0\">nf: supervision, conceptualization, software, methodology, writing – original draft, investigation, visualization, formal analysis, validation. aa: data curation, visualization, methodology, conceptualization, validation, software, formal analysis, writing – original draft. ne: investigation, writing – review & editing, validation, formal analysis. sa: visualization, software, formal analysis, writing – review & editing, data curation.\u003c/p> \u003ca id=\"h10\" name=\"h10\">\u003c/a>\n\u003ch2>funding\u003c/h2>\n\u003cp class=\"mb0\">the author(s) declare that financial support was received for the research and/or publication of this article. the authors extend their appreciation to the king salman center for disability research for funding this work through research group no ksrg-2024-288.\u003c/p> \u003ca id=\"h11\" name=\"h11\">\u003c/a>\n\u003ch2>conflict of interest\u003c/h2>\n\u003cp class=\"mb0\">the authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\u003c/p> \u003ca id=\"h12\" name=\"h12\">\u003c/a>\n\u003ch2>generative ai statement\u003c/h2>\n\u003cp class=\"mb15\">the authors declare that no gen ai was used in the creation of this manuscript.\u003c/p>\n\u003cp class=\"mb0\">any alternative text (alt text) provided alongside figures in this article has been generated by frontiers with the support of artificial intelligence and reasonable efforts have been made to ensure accuracy, including review by the authors wherever possible. if you identify any issues, please contact us.\u003c/p> \u003ca id=\"h13\" name=\"h13\">\u003c/a>\n\u003ch2>publisher’s note\u003c/h2>\n\u003cp class=\"mb0\">all claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.\u003c/p> \u003ca id=\"h14\" name=\"h14\">\u003c/a>\n\u003ch2>references\u003c/h2>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref1\" id=\"ref1\">\u003c/a>1. asd. (2023). available online at: \u003ca href=\"https://www.healthline.com/health/signs-of-autism-in-3-year-old\">https://www.healthline.com/health/signs-of-autism-in-3-year-old\u003c/a>.\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"http://scholar.google.com/scholar_lookup?publication_year=2023&\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref2\" id=\"ref2\">\u003c/a>2. matson, jl, and goldin, rl. what is the future of assessment for autism spectrum disorders: short and long term. \u003ci>res autism spectr disord\u003c/i>. (2014) 8:209–13. doi: 10.1016/j.rasd.2013.01.007\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.1016/j.rasd.2013.01.007\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=jl+matson&author=rl+goldin&publication_year=2014&title=what+is+the+future+of+assessment+for+autism+spectrum+disorders:+short+and+long+term&journal=res+autism+spectr+disord&volume=8&pages=209-13\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref3\" id=\"ref3\">\u003c/a>3. srivastava, ak, and schwartz, ce. intellectual disability and autism spectrum disorders: causal genes and molecular mechanisms. \u003ci>neurosci biobehav rev\u003c/i>. (2014) 46:161–74. doi: 10.1016/j.neubiorev.2014.02.015 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/24709068\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.1016/j.neubiorev.2014.02.015\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=ak+srivastava&author=ce+schwartz&publication_year=2014&title=intellectual+disability+and+autism+spectrum+disorders:+causal+genes+and+molecular+mechanisms&journal=neurosci+biobehav+rev&volume=46&pages=161-74\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref4\" id=\"ref4\">\u003c/a>4. alhujaili, n, platt, e, khalid-khan, s, and groll, d. comparison of social media use among adolescents with autism spectrum disorder and non-asd adolescents. \u003ci>adolesc health med ther\u003c/i>. (2022) 13:15–21. doi: 10.2147/ahmt.s344591 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/35136359\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.2147/ahmt.s344591\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=n+alhujaili&author=e+platt&author=s+khalid-khan&author=d+groll&publication_year=2022&title=comparison+of+social+media+use+among+adolescents+with+autism+spectrum+disorder+and+non-asd+adolescents&journal=adolesc+health+med+ther&volume=13&pages=15-21\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref5\" id=\"ref5\">\u003c/a>5. angulo-jiménez, h, and dethorne, l. narratives about autism: an analysis of youtube videos by individuals who self-identify as autistic. \u003ci>am j speech lang pathol\u003c/i>. (2019) 28:569–90. doi: 10.1044/2018_ajslp-18-0045\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.1044/2018_ajslp-18-0045\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=h+angulo-jiménez&author=l+dethorne&publication_year=2019&title=narratives+about+autism:+an+analysis+of+youtube+videos+by+individuals+who+self-identify+as+autistic&journal=am+j+speech+lang+pathol&volume=28&pages=569-90\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref6\" id=\"ref6\">\u003c/a>6. pew research center. (2021). available online at: \u003ca href=\"https://www.pewresearch.org/internet/2021/04/07/social-media-use-in-2021/\">https://www.pewresearch.org/internet/2021/04/07/social-media-use-in-2021/\u003c/a>\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"http://scholar.google.com/scholar_lookup?publication_year=2021&\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref7\" id=\"ref7\">\u003c/a>7. liu, j-b, guan, l, cao, j, and chen, l. coherence analysis for a class of polygon networks with the noise disturbance. \u003ci>ieee trans syst man cybern syst\u003c/i>. (2025) 2025:326. doi: 10.1109/tsmc.2025.3559326\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.1109/tsmc.2025.3559326\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=j-b+liu&author=l+guan&author=j+cao&author=l+chen&publication_year=2025&title=coherence+analysis+for+a+class+of+polygon+networks+with+the+noise+disturbance&journal=ieee+trans+syst+man+cybern+syst&volume=2025&pages=326\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref8\" id=\"ref8\">\u003c/a>8. al-nefaie, ah, aldhyani, th, sultan, ha, and alzahrani eidah, m. application of artificial intelligence in modern healthcare for diagnosis of autism spectrum disorder. \u003ci>front med\u003c/i>. (2025) 12:1569464. doi: 10.3389/fmed.2025.1569464\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.3389/fmed.2025.1569464\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=ah+al-nefaie&author=th+aldhyani&author=ha+sultan&author=m+alzahrani+eidah&publication_year=2025&title=application+of+artificial+intelligence+in+modern+healthcare+for+diagnosis+of+autism+spectrum+disorder&journal=front+med&volume=12&pages=1569464\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref9\" id=\"ref9\">\u003c/a>9. kim, b, jeong, d, kim, jg, hong, h, and han, k. \u003ci>v-dat (virtual reality data analysis tool): supporting self-awareness for autistic people from multimodal vr sensor data\u003c/i>. in: proceedings of the uist 2023—proceedings of the 36th annual acm symposium on user interface software and technology, san francisco, ca, usa, 29 october–1 november 2023. (2023).\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"http://scholar.google.com/scholar_lookup?author=b+kim&author=d+jeong&author=jg+kim&author=h+hong&author=k+han&publication_year=2023&\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref10\" id=\"ref10\">\u003c/a>10. chen, c, chander, a, and uchino, k. \u003ci>guided play: digital sensing and coaching for stereotypical play behavior in children with autism\u003c/i>. in proceedings of the international conference on intelligent user interfaces, proceedings iui, marina del ray, ca, usa, 17–20 march 2019; part f1476. pp. 208–217. (2019).\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"http://scholar.google.com/scholar_lookup?author=c+chen&author=a+chander&author=k+uchino&publication_year=2019&\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref11\" id=\"ref11\">\u003c/a>11. parui, s, samanta, d, chakravorty, n, ghosh, u, and rodrigues, jj. artificial intelligence and sensor-based autism spectrum disorder diagnosis using brain connectivity analysis. \u003ci>comput electr eng\u003c/i>. (2023) 108:108720. doi: 10.1016/j.compeleceng.2023.108720\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.1016/j.compeleceng.2023.108720\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=s+parui&author=d+samanta&author=n+chakravorty&author=u+ghosh&author=jj+rodrigues&publication_year=2023&title=artificial+intelligence+and+sensor-based+autism+spectrum+disorder+diagnosis+using+brain+connectivity+analysis&journal=comput+electr+eng&volume=108&pages=108720\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref12\" id=\"ref12\">\u003c/a>12. golestan, s, soleiman, p, and moradi, h. a comprehensive review of technologies used for screening, assessment, and rehabilitation of autism spectrum disorder. \u003ci>arxiv\u003c/i>. (2018) 2018:10986. doi: 10.48550/arxiv.1807.10986\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.48550/arxiv.1807.10986\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=s+golestan&author=p+soleiman&author=h+moradi&publication_year=2018&title=a+comprehensive+review+of+technologies+used+for+screening+assessment+and+rehabilitation+of+autism+spectrum+disorder&journal=arxiv&volume=2018&pages=10986\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref13\" id=\"ref13\">\u003c/a>13. neeharika, ch, and riyazuddin, ym. developing an artificial intelligence based model for autism spectrum disorder detection in children. \u003ci>j adv res appl sci eng technol\u003c/i>. (2023) 32:57–72. doi: 10.37934/araset.32.1.5772\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.37934/araset.32.1.5772\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=ch+neeharika&author=ym+riyazuddin&publication_year=2023&title=developing+an+artificial+intelligence+based+model+for+autism+spectrum+disorder+detection+in+children&journal=j+adv+res+appl+sci+eng+technol&volume=32&pages=57-72\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref14\" id=\"ref14\">\u003c/a>14. wall, dp, dally, r, luyster, r, jung, j-y, and deluca, tf. use of artificial intelligence to shorten the behavioral diagnosis of autism. \u003ci>plos one\u003c/i>. (2012) 7:e43855. doi: 10.1371/journal.pone.0043855 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/22952789\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.1371/journal.pone.0043855\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=dp+wall&author=r+dally&author=r+luyster&author=j-y+jung&author=tf+deluca&publication_year=2012&title=use+of+artificial+intelligence+to+shorten+the+behavioral+diagnosis+of+autism&journal=plos+one&volume=7&pages=e43855\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref15\" id=\"ref15\">\u003c/a>15. alzakari, sa, allinjawi, a, aldrees, a, zamzami, n, umer, m, innab, n, et al. early detection of autism spectrum disorder using explainable ai and optimized teaching strategies. \u003ci>j neurosci methods\u003c/i>. (2025) 413:110315. doi: 10.1016/j.jneumeth.2024.110315 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/39532186\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.1016/j.jneumeth.2024.110315\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=sa+alzakari&author=a+allinjawi&author=a+aldrees&author=n+zamzami&author=m+umer&author=n+innab&publication_year=2025&title=early+detection+of+autism+spectrum+disorder+using+explainable+ai+and+optimized+teaching+strategies&journal=j+neurosci+methods&volume=413&pages=110315\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref16\" id=\"ref16\">\u003c/a>16. heunis, t, aldrich, c, peters, j, jeste, s, sahin, m, scheffer, c, et al. recurrence quantification analysis of resting state eeg signals in autism spectrum disorder—a systematic methodological exploration of technical and demographic confounders in the search for biomarkers. \u003ci>bmc med\u003c/i>. (2018) 16:101. doi: 10.1186/s12916-018-1086-7\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.1186/s12916-018-1086-7\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=t+heunis&author=c+aldrich&author=j+peters&author=s+jeste&author=m+sahin&author=c+scheffer&publication_year=2018&title=recurrence+quantification+analysis+of+resting+state+eeg+signals+in+autism+spectrum+disorder—a+systematic+methodological+exploration+of+technical+and+demographic+confounders+in+the+search+for+biomarkers&journal=bmc+med&volume=16&pages=101\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref17\" id=\"ref17\">\u003c/a>17. vicnesh, j, wei, jke, oh, sl, arunkumar, n, abdulhay, e, ciaccio, ej, et al. autism spectrum disorder diagnostic system using hos bispectrum with eeg signals. \u003ci>int j environ res public health\u003c/i>. (2020) 17:971. doi: 10.3390/ijerph17030971\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.3390/ijerph17030971\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=j+vicnesh&author=jke+wei&author=sl+oh&author=n+arunkumar&author=e+abdulhay&author=ej+ciaccio&publication_year=2020&title=autism+spectrum+disorder+diagnostic+system+using+hos+bispectrum+with+eeg+signals&journal=int+j+environ+res+public+health&volume=17&pages=971\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref18\" id=\"ref18\">\u003c/a>18. novielli, p, romano, d, magarelli, m, diacono, d, monaco, a, amoroso, n, et al. personalized identification of autism-related bacteria in the gut microbiome using explainable artificial intelligence. \u003ci>iscience\u003c/i>. (2024) 27:110709. doi: 10.1016/j.isci.2024.110709 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/39286497\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.1016/j.isci.2024.110709\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=p+novielli&author=d+romano&author=m+magarelli&author=d+diacono&author=a+monaco&author=n+amoroso&publication_year=2024&title=personalized+identification+of+autism-related+bacteria+in+the+gut+microbiome+using+explainable+artificial+intelligence&journal=iscience&volume=27&pages=110709\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref19\" id=\"ref19\">\u003c/a>19. bosl, wj, tager-flusberg, h, and nelson, ca. eeg analytics for early detection of autism spectrum disorder: a data-driven approach. \u003ci>sci rep\u003c/i>. (2018) 8:1–20. doi: 10.1038/s41598-018-24318-x \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/29717196\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.1038/s41598-018-24318-x\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=wj+bosl&author=h+tager-flusberg&author=ca+nelson&publication_year=2018&title=eeg+analytics+for+early+detection+of+autism+spectrum+disorder:+a+data-driven+approach&journal=sci+rep&volume=8&pages=1-20\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref20\" id=\"ref20\">\u003c/a>20. beykikhoshk, a, arandjelović, o, phung, d, venkatesh, s, and caelli, t. using twitter to learn about the autism community. \u003ci>soc netw anal min\u003c/i>. (2015) 5:261. doi: 10.1007/s13278-015-0261-\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.1007/s13278-015-0261-\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=a+beykikhoshk&author=o+arandjelović&author=d+phung&author=s+venkatesh&author=t+caelli&publication_year=2015&title=using+twitter+to+learn+about+the+autism+community&journal=soc+netw+anal+min&volume=5&pages=261\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref21\" id=\"ref21\">\u003c/a>21. mazurek, mo. social media use among adults with autism spectrum disorders. \u003ci>comput hum behav\u003c/i>. (2013) 29:1709–14. doi: 10.1016/j.chb.2013.02.004\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.1016/j.chb.2013.02.004\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=mo+mazurek&publication_year=2013&title=social+media+use+among+adults+with+autism+spectrum+disorders&journal=comput+hum+behav&volume=29&pages=1709-14\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref22\" id=\"ref22\">\u003c/a>22. onnela, j, and rauch, sl. harnessing smartphone-based digital phenotyping to enhance behavioral and mental health. \u003ci>neuropsychopharmacology\u003c/i>. (2016) 41:1691–6. doi: 10.1038/npp.2016.7.npp20167 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/26818126\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.1038/npp.2016.7.npp20167\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=j+onnela&author=sl+rauch&publication_year=2016&title=harnessing+smartphone-based+digital+phenotyping+to+enhance+behavioral+and+mental+health&journal=neuropsychopharmacology&volume=41&pages=1691-6\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref23\" id=\"ref23\">\u003c/a>23. tomeny, ts, vargo, cj, and el-toukhy, s. geographic and demographic correlates of autism-related anti-vaccine beliefs on twitter, 2009–2015. \u003ci>soc sci med\u003c/i>. (2017) 191:168–75. doi: 10.1016/j.socscimed.2017.08.041 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/28926775\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.1016/j.socscimed.2017.08.041\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=ts+tomeny&author=cj+vargo&author=s+el-toukhy&publication_year=2017&title=geographic+and+demographic+correlates+of+autism-related+anti-vaccine+beliefs+on+twitter+2009–2015&journal=soc+sci+med&volume=191&pages=168-75\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref24\" id=\"ref24\">\u003c/a>24. tárraga-mínguez, r, gómez-marí, i, and sanz-cervera, p. what motivates internet users to search for asperger syndrome and autism on google? \u003ci>int j environ res public health\u003c/i>. (2020) 17:9386. doi: 10.3390/ijerph17249386 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/33333991\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.3390/ijerph17249386\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=r+tárraga-mínguez&author=i+gómez-marí&author=p+sanz-cervera&publication_year=2020&title=what+motivates+internet+users+to+search+for+asperger+syndrome+and+autism+on+google?&journal=int+j+environ+res+public+health&volume=17&pages=9386\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref25\" id=\"ref25\">\u003c/a>25. hartwell, m, keener, a, coffey, s, chesher, t, torgerson, t, and vassar, m. brief report: public awareness of asperger syndrome following greta thunberg appearances. \u003ci>j autism dev disord\u003c/i>. (2020) 51:2104–8. doi: 10.1007/s10803-020-04651-9 \u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/32812193\" target=\"_blank\">pubmed abstract\u003c/a> | \u003ca href=\"https://doi.org/10.1007/s10803-020-04651-9\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=m+hartwell&author=a+keener&author=s+coffey&author=t+chesher&author=t+torgerson&author=m+vassar&publication_year=2020&title=brief+report:+public+awareness+of+asperger+syndrome+following+greta+thunberg+appearances&journal=j+autism+dev+disord&volume=51&pages=2104-8\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref26\" id=\"ref26\">\u003c/a>26. rubio-martín, s, garcía-ordás, mt, bayón-gutiérrez, m, prieto-fernández, n, and benítez-andrades, ja. “\u003ci>early detection of autism spectrum disorder through ai-powered analysis of social media texts\u003c/i>,” 2023 ieee 36th international symposium on computer-based medical systems (cbms), l’aquila, italy, pp. 235–240. (2023).\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"http://scholar.google.com/scholar_lookup?author=s+rubio-martín&author=mt+garcía-ordás&author=m+bayón-gutiérrez&author=n+prieto-fernández&author=ja+benítez-andrades&publication_year=2023&\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003cdiv class=\"references\" style=\"margin-bottom:0.5em;\">\n\u003cp class=\"referencescopy1\">\u003ca name=\"ref27\" id=\"ref27\">\u003c/a>27. jaiswal, a, and washington, p. using #actuallyautistic on twitter for precision diagnosis of autism spectrum disorder: machine learning study. \u003ci>jmir form res\u003c/i>. (2024) 8:e52660. doi: 10.2196/52660\u003c/p>\n\u003cp class=\"referencescopy2\">\u003ca href=\"https://doi.org/10.2196/52660\" target=\"_blank\">crossref full text\u003c/a> | \u003ca href=\"http://scholar.google.com/scholar_lookup?author=a+jaiswal&author=p+washington&publication_year=2024&title=using+#actuallyautistic+on+twitter+for+precision+diagnosis+of+autism+spectrum+disorder:+machine+learning+study&journal=jmir+form+res&volume=8&pages=e52660\" target=\"_blank\">google scholar\u003c/a>\u003c/p>\u003c/div>\n\u003c/div> \u003cdiv class=\"thinlinem20\">\u003c/div> \u003cdiv class=\"abstractsummary\">\n\u003cp>\u003cspan>keywords:\u003c/span> autism spectrum disorders, diagnosing, social media, deep learning, disabilities, artificial intelligence\u003c/p>\n\u003cp>\u003cspan>citation:\u003c/span> farhah ns, alqarni aa, ebrahim n and ahmad s (2025) diagnosing autism spectrum disorders using a double deep q-network framework based on social media footprints. \u003ci>front. med\u003c/i>. 12:1646249. doi: 10.3389/fmed.2025.1646249\u003c/p>\n\u003cp class=\"timestamps\">\u003cspan>received:\u003c/span> 16 june 2025; \u003cspan>accepted:\u003c/span> 28 july 2025;\u003cbr> \u003cspan>published:\u003c/span> 20 august 2025.\u003c/p> \u003cdiv>\n\u003cp>edited by:\u003c/p> \u003ca href=\"https://loop.frontiersin.org/people/2928766/overview\">pardeep sangwan\u003c/a>, maharaja surajmal institute of technology, india\u003c/div> \u003cdiv>\n\u003cp>reviewed by:\u003c/p> \u003ca href=\"https://loop.frontiersin.org/people/1743107/overview\">jia-bao liu\u003c/a>, anhui jianzhu university, china\u003cbr> \u003ca href=\"https://loop.frontiersin.org/people/3104897/overview\">muhammad adnan\u003c/a>, kohat university of science and technology, pakistan\u003c/div>\n\u003cp>\u003cspan>copyright\u003c/span> © 2025 farhah, alqarni, ebrahim and ahmad. this is an open-access article distributed under the terms of the \u003ca rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\" target=\"_blank\">creative commons attribution license (cc by)\u003c/a>. the use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. no use, distribution or reproduction is permitted which does not comply with these terms.\u003c/p>\n\u003cp>\u003cspan>*correspondence:\u003c/span> nesren s. farhah, \u003ca id=\"encmail\">bi5myxjoywhac2v1lmvkds5zyq==\u003c/a>; nadhem ebrahim, \u003ca id=\"encmail\">bmvicmfoaw1adwfrcm9ulmvkdq==\u003c/a>; sultan ahmad, \u003ca id=\"encmail\">cy5hbglzagvyqhbzyxuuzwr1lnnh\u003c/a>\u003c/p> \u003cdiv class=\"clear\">\u003c/div> \u003c/div>","\u003cul class=\"flyoutjournal\"> \u003cli>\u003ca href=\"#h1\">abstract\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h2\">1 introduction\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h3\">2 materials and methods\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h4\">3 performance of the framework\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h5\">4 experiment and discussion results\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h6\">5 conclusion\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h7\">data availability statement\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h8\">ethics statement\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h9\">author contributions\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h10\">funding\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h11\">conflict of interest\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h12\">generative ai statement\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h13\">publisher’s note\u003c/a>\u003c/li> \u003cli>\u003ca href=\"#h14\">references\u003c/a>\u003c/li> \u003c/ul>",[627,633,639],{"name":628,"fileserverpackageentryid":19,"fileserverid":629,"fileserverversionnumber":374,"type":630},"epub.epub","1646249/epub",{"code":631,"name":632},"epub","epub",{"name":634,"fileserverpackageentryid":19,"fileserverid":635,"fileserverversionnumber":374,"type":636},"publishers-proof.pdf","1646249/publishers-proof",{"code":637,"name":638},"pdf","pdf",{"name":640,"fileserverpackageentryid":641,"fileserverid":642,"fileserverversionnumber":374,"type":643},"fmed-12-1646249.xml","fmed-12-1646249/fmed-12-1646249.xml","1646249/xml",{"code":644,"name":645},"nlm_xml","xml","v3",{"title":648,"link":649,"meta":653,"script":754},"frontiers | diagnosing autism spectrum disorders using a double deep q-network framework based on social media footprints",[650],{"rel":651,"href":652},"canonical","https://www.frontiersin.org/journals/medicine/articles/10.3389/fmed.2025.1646249/full",[654,657,660,662,665,669,672,676,679,682,685,687,689,691,693,695,698,701,703,706,708,710,713,716,719,722,725,729,733,736,739,742,745,748,751],{"hid":655,"property":655,"name":655,"content":656},"description","introductionsocial media is increasingly used in many contexts within the healthcare sector. the improved prevalence of internet use via computers or mobile ...",{"hid":658,"property":658,"name":659,"content":648},"og:title","title",{"hid":661,"property":661,"name":655,"content":656},"og:description",{"hid":663,"name":663,"content":664},"keywords","artificial intelligence,deep learning,social media,disabilities,autism spectrum disorders,diagnosing",{"hid":666,"property":666,"name":667,"content":668},"og:site_name","site_name","frontiers",{"hid":670,"property":670,"name":367,"content":671},"og:image","https://images-provider.frontiersin.org/api/ipx/w=1200&f=png/https://www.frontiersin.org/files/articles/1646249/fmed-12-1646249-html/image_m/fmed-12-1646249-g001.jpg",{"hid":673,"property":673,"name":674,"content":675},"og:type","type","article",{"hid":677,"property":677,"name":678,"content":652},"og:url","url",{"hid":680,"name":680,"content":681},"twitter:card","summary_large_image",{"hid":683,"name":683,"content":684},"citation_volume","12",{"hid":686,"name":686,"content":116},"citation_journal_title",{"hid":688,"name":688,"content":668},"citation_publisher",{"hid":690,"name":690,"content":608},"citation_journal_abbrev",{"hid":692,"name":692,"content":609},"citation_issn",{"hid":694,"name":694,"content":518},"citation_doi",{"hid":696,"name":696,"content":697},"citation_firstpage","1646249",{"hid":699,"name":699,"content":700},"citation_language","english",{"hid":702,"name":702,"content":519},"citation_title",{"hid":704,"name":704,"content":705},"citation_keywords","artificial intelligence; deep learning; social media; disabilities; autism spectrum disorders; diagnosing",{"hid":707,"name":707,"content":524},"citation_abstract",{"hid":709,"name":709,"content":533},"citation_article_type",{"hid":711,"name":711,"content":712},"citation_pdf_url","https://www.frontiersin.org/journals/medicine/articles/10.3389/fmed.2025.1646249/pdf",{"hid":714,"name":714,"content":715},"citation_xml_url","https://www.frontiersin.org/journals/medicine/articles/10.3389/fmed.2025.1646249/xml",{"hid":717,"name":717,"content":718},"citation_fulltext_world_readable","yes",{"hid":720,"name":720,"content":721},"citation_online_date","2025/07/28",{"hid":723,"name":723,"content":724},"citation_publication_date","2025/08/20",{"hid":726,"name":727,"content":728},"citation_author_0","citation_author","farhah, nesren s. ",{"hid":730,"name":731,"content":732},"citation_author_institution_0","citation_author_institution","department of health informatics, college of health science, saudi electronic university, saudi arabia",{"hid":734,"name":727,"content":735},"citation_author_1","alqarni, ahmed abdullah ",{"hid":737,"name":731,"content":738},"citation_author_institution_1","king salman center for disability research, saudi arabia",{"hid":740,"name":727,"content":741},"citation_author_2","ebrahim, nadhem ",{"hid":743,"name":731,"content":744},"citation_author_institution_2","department of computer science, college of engineering and polymer science, university of akron, united states",{"hid":746,"name":727,"content":747},"citation_author_3","ahmad, sultan ",{"hid":749,"name":731,"content":750},"citation_author_institution_3","department of computer science, college of computer engineering and sciences, prince sattam bin abdulaziz university, saudi arabia",{"hid":752,"name":752,"content":753},"dc.identifier","doi:10.3389/fmed.2025.1646249",[755,758,760,762,764],{"src":756,"body":13,"type":757,"async":13},"https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6","text/javascript",{"src":759,"body":13,"type":757,"async":13},"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/mathjax.js?config=tex-mml-am_chtml",{"src":761,"body":13,"type":757,"async":13},"https://d1bxh8uas1mnw7.cloudfront.net/assets/altmetric_badges-f0bc9b243ff5677d05460c1eb71834ca998946d764eb3bc244ab4b18ba50d21e.js",{"src":763,"body":13,"type":757,"async":13},"https://api.altmetric.com/v1/doi/10.3389/fmed.2025.1646249?callback=_altmetric.embed_callback&domain=www.frontiersin.org&key=3c130976ca2b8f2e88f8377633751ba1&cache_until=14-15",{"src":765,"body":13,"type":757,"async":13},"https://crossmark-cdn.crossref.org/widget/v2.0/widget.js",{"articlehubslug":19,"articlehubpage":767,"articlehubarticleslist":768,"canjournalhasarticlehub":351,"articledoilist":769},{},[],[],{"title":19,"image":-1,"breadcrumbs":771,"linkscollection":772,"metricscollection":774},[],{"total":371,"items":773},[],{"total":371,"items":775},[]] window.__nuxt__={};window.__nuxt__.config={public:{isdevmode:false,appname:"article-pages-2024",baseurl:"https://www.frontiersin.org",domain:"frontiersin.org",loopurl:"https://loop.frontiersin.org",ssmaindomain:"frontiersin.org",contentfulurl:"https://graphql.contentful.com/content/v1/spaces",spaceid:1,spacename:"frontiers",livespaceid:1,tenantlogourl:"",frontiersgraphurl:"https://apollo-federation-gateway.frontiersin.org",registrationapiurl:"https://onboarding-ui.frontiersin.org",emaildigestapiurl:"https://api-email-digest.frontiersin.org",journalfilesapiurl:"https://files-journal-api.frontiersin.org",searchapiurl:"https://search-api.frontiersin.org",productionforumapiurl:"https://production-forum-api-v2.frontiersin.org",gtmserverurl:"https://tag-manager.frontiersin.org",gtmid:"gtm-m322fv2",gtmauth:"owvbwxfajr21yqv1fe1caq",gtmpreview:"env-1",figsharepluginurl:"https://widgets.figshare.com/static/figshare.js",figshareapiurl:"https://api.figshare.com/v2/collections/search",figsharetimeout:3000,crossmarkpublisheddate:"2015/08/24",googlerecaptchasitekey:"6ldg3i0uaaaaaoc4quh35ubhgjotehp_stxhgr_v",googlerecaptchakeyname:"frontiersrecaptchav2",faviconsize16:"https://static2.frontiersin.org/static-resources/tenants/frontiers/favicon_16-tenantfavicon-frontiers.png",faviconsize32:"https://static2.frontiersin.org/static-resources/tenants/frontiers/favicon_32-tenantfavicon-frontiers.png",faviconsize180:"https://static2.frontiersin.org/static-resources/tenants/frontiers/favicon_180-tenantfavicon-frontiers.png",faviconsize192:"https://static2.frontiersin.org/static-resources/tenants/frontiers/favicon_192-tenantfavicon-frontiers.png",faviconsize512:"https://static2.frontiersin.org/static-resources/tenants/frontiers/favicon_512-tenantfavicon-frontiers.png",socialmediaimg:"https://brand.frontiersin.org/m/1c8bcb536c789e11/guidelines-frontiers_logo_1200x628_1-91to1.png",linkedarticlecopytext:"'{\"articletypecopytext\":[{\"articletypeid\":0,\"originalarticlecopytext\":\"part of this article's content has been mentioned in:\",\"linkedarticlecopytext\":\"this article mentions parts of:\"},{\"articletypeid\":122,\"originalarticlecopytext\":\"parts of this article's content have been modified or rectified in:\",\"linkedarticlecopytext\":\"this article is an erratum on:\"},{\"articletypeid\":129,\"originalarticlecopytext\":\"parts of this article's content have been modified or rectified in:\",\"linkedarticlecopytext\":\"this article is an addendum to:\"},{\"articletypeid\":128,\"originalarticlecopytext\":\"a correction has been applied to this article in:\",\"linkedarticlecopytext\":\"this article is a correction to:\"},{\"articletypeid\":134,\"originalarticlecopytext\":\"a retraction of this article was approved in:\",\"linkedarticlecopytext\":\"this article is a retraction of:\"},{\"articletypeid\":29,\"originalarticlecopytext\":\"a commentary has been posted on this article:\",\"linkedarticlecopytext\":\"this article is a commentary on:\"},{\"articletypeid\":30,\"originalarticlecopytext\":\"a commentary has been posted on this article:\",\"linkedarticlecopytext\":\"this article is a commentary on:\"}],\"articleidcopytext\":[]}'\n",acceptedarticleexcludedjournalids:"'[2766,979]'\n",articletypeconfigurablelabel:"\u003c\u003carticle-type:uppercase>> article",settingsfeaturesswitchers:"'{\"displaytitlepilllabels\":true,\"displayrelatedarticlesbox\":true,\"showeditors\":true,\"showreviewers\":true,\"showloopimpactlink\":true,\"enablefigshare\":false,\"usexmlimages\":true}'\n",journalswitharticlehub:"'{\"strings\":[\"science\"]}'\n",terminologysettings:"'{\"terms\":[{\"sequencenumber\":1,\"key\":\"frontiers\",\"tenantterm\":\"frontiers\",\"frontiersdefaultterm\":\"frontiers\",\"category\":\"customer\"},{\"sequencenumber\":2,\"key\":\"submission_system\",\"tenantterm\":\"submission system\",\"frontiersdefaultterm\":\"submission system\",\"category\":\"product\"},{\"sequencenumber\":3,\"key\":\"public_pages\",\"tenantterm\":\"public pages\",\"frontiersdefaultterm\":\"public pages\",\"category\":\"product\"},{\"sequencenumber\":4,\"key\":\"my_frontiers\",\"tenantterm\":\"my frontiers\",\"frontiersdefaultterm\":\"my frontiers\",\"category\":\"product\"},{\"sequencenumber\":5,\"key\":\"digital_editorial_office\",\"tenantterm\":\"digital editorial office\",\"frontiersdefaultterm\":\"digital editorial office\",\"category\":\"product\"},{\"sequencenumber\":6,\"key\":\"deo\",\"tenantterm\":\"deo\",\"frontiersdefaultterm\":\"deo\",\"category\":\"product\"},{\"sequencenumber\":7,\"key\":\"digital_editorial_office_for_chiefs\",\"tenantterm\":\"digital editorial office for chiefs\",\"frontiersdefaultterm\":\"digital editorial office for chiefs\",\"category\":\"product\"},{\"sequencenumber\":8,\"key\":\"digital_editorial_office_for_eof\",\"tenantterm\":\"digital editorial office for eof\",\"frontiersdefaultterm\":\"digital editorial office for eof\",\"category\":\"product\"},{\"sequencenumber\":9,\"key\":\"editorial_office\",\"tenantterm\":\"editorial office\",\"frontiersdefaultterm\":\"editorial office\",\"category\":\"product\"},{\"sequencenumber\":10,\"key\":\"eof\",\"tenantterm\":\"eof\",\"frontiersdefaultterm\":\"eof\",\"category\":\"product\"},{\"sequencenumber\":11,\"key\":\"research_topic_management\",\"tenantterm\":\"research topic management\",\"frontiersdefaultterm\":\"research topic management\",\"category\":\"product\"},{\"sequencenumber\":12,\"key\":\"review_forum\",\"tenantterm\":\"review forum\",\"frontiersdefaultterm\":\"review forum\",\"category\":\"product\"},{\"sequencenumber\":13,\"key\":\"accounting_office\",\"tenantterm\":\"accounting office\",\"frontiersdefaultterm\":\"accounting office\",\"category\":\"product\"},{\"sequencenumber\":14,\"key\":\"aof\",\"tenantterm\":\"aof\",\"frontiersdefaultterm\":\"aof\",\"category\":\"product\"},{\"sequencenumber\":15,\"key\":\"publishing_office\",\"tenantterm\":\"publishing office\",\"frontiersdefaultterm\":\"publishing office\",\"category\":\"product\"},{\"sequencenumber\":16,\"key\":\"production_office\",\"tenantterm\":\"production office forum\",\"frontiersdefaultterm\":\"production office forum\",\"category\":\"product\"},{\"sequencenumber\":17,\"key\":\"pof\",\"tenantterm\":\"pof\",\"frontiersdefaultterm\":\"pof\",\"category\":\"product\"},{\"sequencenumber\":18,\"key\":\"book_office_forum\",\"tenantterm\":\"book office forum\",\"frontiersdefaultterm\":\"book office forum\",\"category\":\"product\"},{\"sequencenumber\":19,\"key\":\"bof\",\"tenantterm\":\"bof\",\"frontiersdefaultterm\":\"bof\",\"category\":\"product\"},{\"sequencenumber\":20,\"key\":\"aira\",\"tenantterm\":\"aira\",\"frontiersdefaultterm\":\"aira\",\"category\":\"product\"},{\"sequencenumber\":21,\"key\":\"editorial_board_management\",\"tenantterm\":\"editorial board management\",\"frontiersdefaultterm\":\"editorial board management\",\"category\":\"product\"},{\"sequencenumber\":22,\"key\":\"ebm\",\"tenantterm\":\"ebm\",\"frontiersdefaultterm\":\"ebm\",\"category\":\"product\"},{\"sequencenumber\":23,\"key\":\"domain\",\"tenantterm\":\"domain\",\"frontiersdefaultterm\":\"domain\",\"category\":\"taxonomy\"},{\"sequencenumber\":24,\"key\":\"journal\",\"tenantterm\":\"journal\",\"frontiersdefaultterm\":\"journal\",\"category\":\"taxonomy\"},{\"sequencenumber\":25,\"key\":\"section\",\"tenantterm\":\"section\",\"frontiersdefaultterm\":\"section\",\"category\":\"taxonomy\"},{\"sequencenumber\":26,\"key\":\"domains\",\"tenantterm\":\"domains\",\"frontiersdefaultterm\":\"domains\",\"category\":\"taxonomy\"},{\"sequencenumber\":27,\"key\":\"specialty_section\",\"tenantterm\":\"specialty section\",\"frontiersdefaultterm\":\"specialty section\",\"category\":\"taxonomy\"},{\"sequencenumber\":28,\"key\":\"specialty_journal\",\"tenantterm\":\"specialty journal\",\"frontiersdefaultterm\":\"specialty journal\",\"category\":\"taxonomy\"},{\"sequencenumber\":29,\"key\":\"journals\",\"tenantterm\":\"journals\",\"frontiersdefaultterm\":\"journals\",\"category\":\"taxonomy\"},{\"sequencenumber\":30,\"key\":\"sections\",\"tenantterm\":\"sections\",\"frontiersdefaultterm\":\"sections\",\"category\":\"taxonomy\"},{\"sequencenumber\":31,\"key\":\"specialty_sections\",\"tenantterm\":\"specialty sections\",\"frontiersdefaultterm\":\"specialty sections\",\"category\":\"taxonomy\"},{\"sequencenumber\":32,\"key\":\"specialty_journals\",\"tenantterm\":\"specialty journals\",\"frontiersdefaultterm\":\"specialty journals\",\"category\":\"taxonomy\"},{\"sequencenumber\":33,\"key\":\"manuscript\",\"tenantterm\":\"manuscript\",\"frontiersdefaultterm\":\"manuscript\",\"category\":\"core\"},{\"sequencenumber\":34,\"key\":\"manuscripts\",\"tenantterm\":\"manuscripts\",\"frontiersdefaultterm\":\"manuscripts\",\"category\":\"core\"},{\"sequencenumber\":35,\"key\":\"article\",\"tenantterm\":\"article\",\"frontiersdefaultterm\":\"article\",\"category\":\"core\"},{\"sequencenumber\":36,\"key\":\"articles\",\"tenantterm\":\"articles\",\"frontiersdefaultterm\":\"articles\",\"category\":\"core\"},{\"sequencenumber\":37,\"key\":\"article_type\",\"tenantterm\":\"article type\",\"frontiersdefaultterm\":\"article type\",\"category\":\"core\"},{\"sequencenumber\":38,\"key\":\"article_types\",\"tenantterm\":\"article types\",\"frontiersdefaultterm\":\"article types\",\"category\":\"core\"},{\"sequencenumber\":39,\"key\":\"author\",\"tenantterm\":\"author\",\"frontiersdefaultterm\":\"author\",\"category\":\"label (role)\"},{\"sequencenumber\":40,\"key\":\"authors\",\"tenantterm\":\"authors\",\"frontiersdefaultterm\":\"authors\",\"category\":\"label (role)\"},{\"sequencenumber\":41,\"key\":\"authoring\",\"tenantterm\":\"authoring\",\"frontiersdefaultterm\":\"authoring\",\"category\":\"core\"},{\"sequencenumber\":42,\"key\":\"authored\",\"tenantterm\":\"authored\",\"frontiersdefaultterm\":\"authored\",\"category\":\"core\"},{\"sequencenumber\":43,\"key\":\"accept\",\"tenantterm\":\"accept\",\"frontiersdefaultterm\":\"accept\",\"category\":\"process\"},{\"sequencenumber\":44,\"key\":\"accepted\",\"tenantterm\":\"accepted\",\"frontiersdefaultterm\":\"accepted\",\"category\":\"process\"},{\"sequencenumber\":45,\"key\":\"assistant_field_chief_editor\",\"tenantterm\":\"assistant field chief editor\",\"frontiersdefaultterm\":\"assistant field chief editor\",\"description\":\"an editorial role on a field journal that a registered user may hold. this gives them rights to different functionality and parts of the platform\",\"category\":\"label (role)\"},{\"sequencenumber\":46,\"key\":\"assistant_specialty_chief_editor\",\"tenantterm\":\"assistant specialty chief editor\",\"frontiersdefaultterm\":\"assistant specialty chief editor\",\"description\":\"an editorial role on a specialty that a registered user may hold. this gives them rights to different functionality and parts of the platform\",\"category\":\"label (role)\"},{\"sequencenumber\":47,\"key\":\"assistant_specialty_chief_editors\",\"tenantterm\":\"assistant specialty chief editors\",\"frontiersdefaultterm\":\"assistant specialty chief editors\",\"category\":\"label (role)\"},{\"sequencenumber\":48,\"key\":\"associate_editor\",\"tenantterm\":\"associate editor\",\"frontiersdefaultterm\":\"associate editor\",\"description\":\"an editorial role on a specialty that a registered user may hold. this gives them rights to different functionality and parts of the platform\",\"category\":\"label (role)\"},{\"sequencenumber\":49,\"key\":\"specialty_chief_editor\",\"tenantterm\":\"specialty chief editor\",\"frontiersdefaultterm\":\"specialty chief editor\",\"description\":\"an editorial role on a specialty that a registered user may hold. this gives them rights to different functionality and parts of the platform\",\"category\":\"label (role)\"},{\"sequencenumber\":50,\"key\":\"specialty_chief_editors\",\"tenantterm\":\"specialty chief editors\",\"frontiersdefaultterm\":\"specialty chief editors\",\"category\":\"label (role)\"},{\"sequencenumber\":51,\"key\":\"chief_editor\",\"tenantterm\":\"chief editor\",\"frontiersdefaultterm\":\"chief editor\",\"category\":\"label (role)\"},{\"sequencenumber\":52,\"key\":\"chief_editors\",\"tenantterm\":\"chief editors\",\"frontiersdefaultterm\":\"chief editors\",\"category\":\"label (role)\"},{\"sequencenumber\":53,\"key\":\"call_for_participation\",\"tenantterm\":\"call for participation\",\"frontiersdefaultterm\":\"call for participation\",\"category\":\"process\"},{\"sequencenumber\":54,\"key\":\"citation\",\"tenantterm\":\"citation\",\"frontiersdefaultterm\":\"citation\",\"category\":\"misc.\"},{\"sequencenumber\":55,\"key\":\"citations\",\"tenantterm\":\"citations\",\"frontiersdefaultterm\":\"citations\",\"category\":\"misc.\"},{\"sequencenumber\":56,\"key\":\"contributor\",\"tenantterm\":\"contributor\",\"frontiersdefaultterm\":\"contributor\",\"category\":\"label (role)\"},{\"sequencenumber\":57,\"key\":\"contributors\",\"tenantterm\":\"contributors\",\"frontiersdefaultterm\":\"contributors\",\"category\":\"label (role)\"},{\"sequencenumber\":58,\"key\":\"corresponding_author\",\"tenantterm\":\"corresponding author\",\"frontiersdefaultterm\":\"corresponding author\",\"category\":\"label (role)\"},{\"sequencenumber\":59,\"key\":\"corresponding_authors\",\"tenantterm\":\"corresponding authors\",\"frontiersdefaultterm\":\"corresponding authors\",\"category\":\"label (role)\"},{\"sequencenumber\":60,\"key\":\"decline\",\"tenantterm\":\"decline\",\"frontiersdefaultterm\":\"decline\",\"category\":\"process\"},{\"sequencenumber\":61,\"key\":\"declined\",\"tenantterm\":\"declined\",\"frontiersdefaultterm\":\"declined\",\"category\":\"process\"},{\"sequencenumber\":62,\"key\":\"reject\",\"tenantterm\":\"reject\",\"frontiersdefaultterm\":\"reject\",\"category\":\"process\"},{\"sequencenumber\":63,\"key\":\"rejected\",\"tenantterm\":\"rejected\",\"frontiersdefaultterm\":\"rejected\",\"category\":\"process\"},{\"sequencenumber\":64,\"key\":\"publish\",\"tenantterm\":\"publish\",\"frontiersdefaultterm\":\"publish\",\"category\":\"core\"},{\"sequencenumber\":65,\"key\":\"published\",\"tenantterm\":\"published\",\"frontiersdefaultterm\":\"published\",\"category\":\"core\"},{\"sequencenumber\":66,\"key\":\"publication\",\"tenantterm\":\"publication\",\"frontiersdefaultterm\":\"publication\",\"category\":\"core\"},{\"sequencenumber\":67,\"key\":\"peer_review\",\"tenantterm\":\"peer review\",\"frontiersdefaultterm\":\"peer review\",\"category\":\"peer review process\"},{\"sequencenumber\":68,\"key\":\"peer_reviewed\",\"tenantterm\":\"peer reviewed\",\"frontiersdefaultterm\":\"peer reviewed\",\"category\":\"peer review process\"},{\"sequencenumber\":69,\"key\":\"initial_validation\",\"tenantterm\":\"initial validation\",\"frontiersdefaultterm\":\"initial validation\",\"category\":\"peer review process\"},{\"sequencenumber\":70,\"key\":\"editorial_assignment\",\"tenantterm\":\"editorial assignment\",\"frontiersdefaultterm\":\"editorial assignment\",\"category\":\"peer review process\"},{\"sequencenumber\":71,\"key\":\"independent_review\",\"tenantterm\":\"independent review\",\"frontiersdefaultterm\":\"independent review\",\"category\":\"peer review process\"},{\"sequencenumber\":72,\"key\":\"interactive_review\",\"tenantterm\":\"interactive review\",\"frontiersdefaultterm\":\"interactive review\",\"category\":\"peer review process\"},{\"sequencenumber\":73,\"key\":\"review\",\"tenantterm\":\"review\",\"frontiersdefaultterm\":\"review\",\"category\":\"peer review process\"},{\"sequencenumber\":74,\"key\":\"reviewing\",\"tenantterm\":\"reviewing\",\"frontiersdefaultterm\":\"reviewing\",\"category\":\"peer review process\"},{\"sequencenumber\":75,\"key\":\"reviewer\",\"tenantterm\":\"reviewer\",\"frontiersdefaultterm\":\"reviewer\",\"category\":\"label (role)\"},{\"sequencenumber\":76,\"key\":\"reviewers\",\"tenantterm\":\"reviewers\",\"frontiersdefaultterm\":\"reviewers\",\"category\":\"label (role)\"},{\"sequencenumber\":77,\"key\":\"review_finalized\",\"tenantterm\":\"review finalized\",\"frontiersdefaultterm\":\"review finalized\",\"category\":\"peer review process\"},{\"sequencenumber\":78,\"key\":\"final_decision\",\"tenantterm\":\"final decision\",\"frontiersdefaultterm\":\"final decision\",\"category\":\"peer review process\"},{\"sequencenumber\":79,\"key\":\"final_validation\",\"tenantterm\":\"final validation\",\"frontiersdefaultterm\":\"final validation\",\"category\":\"peer review process\"},{\"sequencenumber\":80,\"key\":\"ae_accept_manuscript\",\"tenantterm\":\"recommend to accept manuscript\",\"frontiersdefaultterm\":\"accept manuscript\",\"category\":\"process\"},{\"sequencenumber\":81,\"key\":\"fee\",\"tenantterm\":\"fee\",\"frontiersdefaultterm\":\"fee\",\"category\":\"accounting\"},{\"sequencenumber\":82,\"key\":\"fees\",\"tenantterm\":\"fees\",\"frontiersdefaultterm\":\"fees\",\"category\":\"accounting\"},{\"sequencenumber\":83,\"key\":\"guest_associate_editor\",\"tenantterm\":\"guest associate editor\",\"frontiersdefaultterm\":\"guest associate editor\",\"category\":\"label (role)\"},{\"sequencenumber\":84,\"key\":\"guest_associate_editors\",\"tenantterm\":\"guest associate editors\",\"frontiersdefaultterm\":\"guest associate editors\",\"category\":\"label (role)\"},{\"sequencenumber\":85,\"key\":\"in_review\",\"tenantterm\":\"in review\",\"frontiersdefaultterm\":\"in review\",\"category\":\"peer review process\"},{\"sequencenumber\":86,\"key\":\"institutional_member\",\"tenantterm\":\"institutional partner\",\"frontiersdefaultterm\":\"institutional partner\",\"category\":\"accounting\"},{\"sequencenumber\":87,\"key\":\"institutional_membership\",\"tenantterm\":\"institutional partnership\",\"frontiersdefaultterm\":\"institutional partnership\",\"category\":\"accounting\"},{\"sequencenumber\":88,\"key\":\"article_processing_charge\",\"tenantterm\":\"article processing charge\",\"frontiersdefaultterm\":\"article processing charge\",\"category\":\"accounting\"},{\"sequencenumber\":89,\"key\":\"article_processing_charges\",\"tenantterm\":\"article processing charges\",\"frontiersdefaultterm\":\"article processing charges\",\"category\":\"accounting\"},{\"sequencenumber\":90,\"key\":\"apcs\",\"tenantterm\":\"apcs\",\"frontiersdefaultterm\":\"apcs\",\"category\":\"accounting\"},{\"sequencenumber\":91,\"key\":\"apc\",\"tenantterm\":\"apc\",\"frontiersdefaultterm\":\"apc\",\"category\":\"accounting\"},{\"sequencenumber\":92,\"key\":\"received\",\"tenantterm\":\"received\",\"frontiersdefaultterm\":\"received\",\"description\":\"date manuscript was received on.\",\"category\":\"core\"},{\"sequencenumber\":93,\"key\":\"transferred\",\"tenantterm\":\"transferred\",\"frontiersdefaultterm\":\"transferred\",\"category\":\"core\"},{\"sequencenumber\":94,\"key\":\"transfer\",\"tenantterm\":\"transfer\",\"frontiersdefaultterm\":\"transfer\",\"category\":\"core\"},{\"sequencenumber\":95,\"key\":\"research_topic\",\"tenantterm\":\"research topic\",\"frontiersdefaultterm\":\"research topic\",\"category\":\"core\"},{\"sequencenumber\":96,\"key\":\"research_topics\",\"tenantterm\":\"research topics\",\"frontiersdefaultterm\":\"research topics\",\"category\":\"core\"},{\"sequencenumber\":97,\"key\":\"topic_editor\",\"tenantterm\":\"topic editor\",\"frontiersdefaultterm\":\"topic editor\",\"category\":\"label (role)\"},{\"sequencenumber\":98,\"key\":\"review_editor\",\"tenantterm\":\"community reviewer\",\"frontiersdefaultterm\":\"review editor\",\"category\":\"label (role)\"},{\"sequencenumber\":99,\"key\":\"title\",\"tenantterm\":\"title\",\"frontiersdefaultterm\":\"title\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":100,\"key\":\"running_title\",\"tenantterm\":\"running title\",\"frontiersdefaultterm\":\"running title\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":101,\"key\":\"submit\",\"tenantterm\":\"submit\",\"frontiersdefaultterm\":\"submit\",\"category\":\"process\"},{\"sequencenumber\":102,\"key\":\"submitted\",\"tenantterm\":\"submitted\",\"frontiersdefaultterm\":\"submitted\",\"category\":\"process\"},{\"sequencenumber\":103,\"key\":\"submitting\",\"tenantterm\":\"submitting\",\"frontiersdefaultterm\":\"submitting\",\"category\":\"process\"},{\"sequencenumber\":104,\"key\":\"t_e\",\"tenantterm\":\"te\",\"frontiersdefaultterm\":\"te\",\"category\":\"label (role)\"},{\"sequencenumber\":105,\"key\":\"topic\",\"tenantterm\":\"topic\",\"frontiersdefaultterm\":\"topic\",\"category\":\"process\"},{\"sequencenumber\":106,\"key\":\"topic_summary\",\"tenantterm\":\"topic summary\",\"frontiersdefaultterm\":\"topic summary\",\"category\":\"process\"},{\"sequencenumber\":107,\"key\":\"figure\",\"tenantterm\":\"figure\",\"frontiersdefaultterm\":\"figure\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":108,\"key\":\"figures\",\"tenantterm\":\"figures\",\"frontiersdefaultterm\":\"figures\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":109,\"key\":\"editorial_file\",\"tenantterm\":\"editorial file\",\"frontiersdefaultterm\":\"editorial file\",\"category\":\"core\"},{\"sequencenumber\":110,\"key\":\"editorial_files\",\"tenantterm\":\"editorial files\",\"frontiersdefaultterm\":\"editorial files\",\"category\":\"core\"},{\"sequencenumber\":111,\"key\":\"e_book\",\"tenantterm\":\"e-book\",\"frontiersdefaultterm\":\"e-book\",\"category\":\"core\"},{\"sequencenumber\":112,\"key\":\"organization\",\"tenantterm\":\"organization\",\"frontiersdefaultterm\":\"organization\",\"category\":\"core\"},{\"sequencenumber\":113,\"key\":\"institution\",\"tenantterm\":\"institution\",\"frontiersdefaultterm\":\"institution\",\"category\":\"core\"},{\"sequencenumber\":114,\"key\":\"reference\",\"tenantterm\":\"reference\",\"frontiersdefaultterm\":\"reference\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":115,\"key\":\"references\",\"tenantterm\":\"references\",\"frontiersdefaultterm\":\"references\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":116,\"key\":\"sce\",\"tenantterm\":\"sce\",\"frontiersdefaultterm\":\"sce\",\"description\":\"abbreviation for specialty chief editor\",\"category\":\"label (role)\"},{\"sequencenumber\":117,\"key\":\"submission\",\"tenantterm\":\"submission\",\"frontiersdefaultterm\":\"submission\",\"category\":\"process\"},{\"sequencenumber\":118,\"key\":\"submissions\",\"tenantterm\":\"submissions\",\"frontiersdefaultterm\":\"submissions\",\"category\":\"process\"},{\"sequencenumber\":119,\"key\":\"editing\",\"tenantterm\":\"editing\",\"frontiersdefaultterm\":\"editing\",\"category\":\"process\"},{\"sequencenumber\":120,\"key\":\"in_preparation\",\"tenantterm\":\"in preparation\",\"frontiersdefaultterm\":\"in preparation\",\"category\":\"process\"},{\"sequencenumber\":121,\"key\":\"country_region\",\"tenantterm\":\"country/region\",\"frontiersdefaultterm\":\"country/region\",\"description\":\"because of political issues, some of the country listings are actually classified as `regions` and we need to include this. however other clients may not want to do this.\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":122,\"key\":\"countries_regions\",\"tenantterm\":\"countries/regions\",\"frontiersdefaultterm\":\"countries/regions\",\"description\":\"because of political issues, some of the country listings are actually classified as `regions` and we need to include this. however other clients may not want to do this.\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":123,\"key\":\"specialty\",\"tenantterm\":\"specialty\",\"frontiersdefaultterm\":\"specialty\",\"category\":\"core\"},{\"sequencenumber\":124,\"key\":\"specialties\",\"tenantterm\":\"specialties\",\"frontiersdefaultterm\":\"specialties\",\"category\":\"core\"},{\"sequencenumber\":125,\"key\":\"associate_editors\",\"tenantterm\":\"associate editors\",\"frontiersdefaultterm\":\"associate editors\",\"description\":\"an editorial role on a specialty that a registered user may hold. this gives them rights to different functionality and parts of the platform\",\"category\":\"label (role)\"},{\"sequencenumber\":126,\"key\":\"reviewed\",\"tenantterm\":\"reviewed\",\"frontiersdefaultterm\":\"reviewed\",\"category\":\"peer review process\"},{\"sequencenumber\":127,\"key\":\"institutional_members\",\"tenantterm\":\"institutional partners\",\"frontiersdefaultterm\":\"institutional partners\",\"category\":\"accounting\"},{\"sequencenumber\":128,\"key\":\"institutional_memberships\",\"tenantterm\":\"institutional partnerships\",\"frontiersdefaultterm\":\"institutional partnerships\",\"category\":\"accounting\"},{\"sequencenumber\":129,\"key\":\"assistant_field_chief_editors\",\"tenantterm\":\"assistant field chief editors\",\"frontiersdefaultterm\":\"assistant field chief editors\",\"category\":\"label (role)\"},{\"sequencenumber\":130,\"key\":\"publications\",\"tenantterm\":\"publications\",\"frontiersdefaultterm\":\"publications\",\"category\":\"process\"},{\"sequencenumber\":131,\"key\":\"ae_accepted\",\"tenantterm\":\"recommended acceptance\",\"frontiersdefaultterm\":\"accepted\",\"category\":\"process\"},{\"sequencenumber\":132,\"key\":\"field_journal\",\"tenantterm\":\"field journal\",\"frontiersdefaultterm\":\"field journal\",\"category\":\"taxonomy\"},{\"sequencenumber\":133,\"key\":\"field_journals\",\"tenantterm\":\"field journals\",\"frontiersdefaultterm\":\"field journals\",\"category\":\"taxonomy\"},{\"sequencenumber\":134,\"key\":\"program_manager\",\"tenantterm\":\"program manager\",\"frontiersdefaultterm\":\"program manager\",\"category\":\"label (role)\"},{\"sequencenumber\":135,\"key\":\"journal_manager\",\"tenantterm\":\"journal manager\",\"frontiersdefaultterm\":\"journal manager\",\"category\":\"label (role)\"},{\"sequencenumber\":136,\"key\":\"journal_specialist\",\"tenantterm\":\"journal specialist\",\"frontiersdefaultterm\":\"journal specialist\",\"category\":\"label (role)\"},{\"sequencenumber\":137,\"key\":\"program_managers\",\"tenantterm\":\"program managers\",\"frontiersdefaultterm\":\"program managers\",\"category\":\"label (role)\"},{\"sequencenumber\":138,\"key\":\"journal_managers\",\"tenantterm\":\"journal managers\",\"frontiersdefaultterm\":\"journal managers\",\"category\":\"label (role)\"},{\"sequencenumber\":139,\"key\":\"journal_specialists\",\"tenantterm\":\"journal specialists\",\"frontiersdefaultterm\":\"journal specialists\",\"category\":\"label (role)\"},{\"sequencenumber\":140,\"key\":\"cover_letter\",\"tenantterm\":\"manuscript contribution to the field\",\"frontiersdefaultterm\":\"manuscript contribution to the field\",\"category\":\"process\"},{\"sequencenumber\":141,\"key\":\"ae_accepted_manuscript\",\"tenantterm\":\"recommended to accept manuscript\",\"frontiersdefaultterm\":\"accepted manuscript\",\"category\":\"process\"},{\"sequencenumber\":142,\"key\":\"recommend_for_rejection\",\"tenantterm\":\"recommend for rejection\",\"frontiersdefaultterm\":\"recommend for rejection\",\"category\":\"process\"},{\"sequencenumber\":143,\"key\":\"recommended_for_rejection\",\"tenantterm\":\"recommended for rejection\",\"frontiersdefaultterm\":\"recommended for rejection\",\"category\":\"process\"},{\"sequencenumber\":144,\"key\":\"ae\",\"tenantterm\":\"ae\",\"frontiersdefaultterm\":\"ae\",\"description\":\"associate editor - board member\",\"category\":\"label (role)\"},{\"sequencenumber\":145,\"key\":\"re\",\"tenantterm\":\"re\",\"frontiersdefaultterm\":\"re\",\"description\":\"review editor\",\"category\":\"label (role)\"},{\"sequencenumber\":146,\"key\":\"rev\",\"tenantterm\":\"rev\",\"frontiersdefaultterm\":\"rev\",\"description\":\"reviewer\",\"category\":\"label (role)\"},{\"sequencenumber\":147,\"key\":\"aut\",\"tenantterm\":\"aut\",\"frontiersdefaultterm\":\"aut\",\"description\":\"author\",\"category\":\"label (role)\"},{\"sequencenumber\":148,\"key\":\"coraut\",\"tenantterm\":\"coraut\",\"frontiersdefaultterm\":\"coraut\",\"description\":\"corresponding author\",\"category\":\"label (role)\"},{\"sequencenumber\":149,\"key\":\"saut\",\"tenantterm\":\"saut\",\"frontiersdefaultterm\":\"saut\",\"description\":\"submitting author\",\"category\":\"label (role)\"},{\"sequencenumber\":150,\"key\":\"coaut\",\"tenantterm\":\"coaut\",\"frontiersdefaultterm\":\"coaut\",\"description\":\"co-author\",\"category\":\"label (role)\"},{\"sequencenumber\":151,\"key\":\"tsof\",\"tenantterm\":\"tsof\",\"frontiersdefaultterm\":\"tsof\",\"description\":\"typesetter\",\"category\":\"label (role)\"},{\"sequencenumber\":152,\"key\":\"typesetting_office\",\"tenantterm\":\"typesetting office\",\"frontiersdefaultterm\":\"typesetting office\",\"category\":\"product\"},{\"sequencenumber\":153,\"key\":\"config\",\"tenantterm\":\"config\",\"frontiersdefaultterm\":\"config\",\"description\":\"configuration office role\",\"category\":\"label (role)\"},{\"sequencenumber\":154,\"key\":\"jm\",\"tenantterm\":\"jm\",\"frontiersdefaultterm\":\"jm\",\"description\":\"journal manager\",\"category\":\"label (role)\"},{\"sequencenumber\":155,\"key\":\"rte\",\"tenantterm\":\"rte\",\"frontiersdefaultterm\":\"rte\",\"description\":\"research topic editor\",\"category\":\"label (role)\"},{\"sequencenumber\":156,\"key\":\"organizations\",\"tenantterm\":\"organizations\",\"frontiersdefaultterm\":\"organizations\",\"category\":\"core\"},{\"sequencenumber\":157,\"key\":\"publishing\",\"tenantterm\":\"publishing\",\"frontiersdefaultterm\":\"publishing\",\"category\":\"core\"},{\"sequencenumber\":158,\"key\":\"acceptance\",\"tenantterm\":\"acceptance\",\"frontiersdefaultterm\":\"acceptance\",\"category\":\"process\"},{\"sequencenumber\":159,\"key\":\"preferred_associate_editor\",\"tenantterm\":\"preferred associate editor\",\"frontiersdefaultterm\":\"preferred associate editor\",\"category\":\"label (role)\"},{\"sequencenumber\":160,\"key\":\"topic_editors\",\"tenantterm\":\"topic editors\",\"frontiersdefaultterm\":\"topic editors\",\"category\":\"label (role)\"},{\"sequencenumber\":161,\"key\":\"institutions\",\"tenantterm\":\"institutions\",\"frontiersdefaultterm\":\"institutions\",\"category\":\"core\"},{\"sequencenumber\":162,\"key\":\"author(s)\",\"tenantterm\":\"author(s)\",\"frontiersdefaultterm\":\"author(s)\",\"category\":\"label (role)\"},{\"sequencenumber\":163,\"key\":\"figure(s)\",\"tenantterm\":\"figure(s)\",\"frontiersdefaultterm\":\"figure(s)\",\"category\":\"manuscript metadata\"},{\"sequencenumber\":164,\"key\":\"co-authors\",\"tenantterm\":\"co-authors\",\"frontiersdefaultterm\":\"co-authors\",\"description\":\"co-authors\",\"category\":\"label (role)\"},{\"sequencenumber\":165,\"key\":\"editorial_board_members\",\"tenantterm\":\"editorial board members\",\"frontiersdefaultterm\":\"editorial board members\",\"description\":\"editorial board members\",\"category\":\"label (role)\"},{\"sequencenumber\":166,\"key\":\"editorial_board\",\"tenantterm\":\"editorial board\",\"frontiersdefaultterm\":\"editorial board\",\"description\":\"editorial board\",\"category\":\"product\"},{\"sequencenumber\":167,\"key\":\"co-authorship\",\"tenantterm\":\"co-authorship\",\"frontiersdefaultterm\":\"co-authorship\",\"description\":\"co-authorship\",\"category\":\"misc.\"},{\"sequencenumber\":168,\"key\":\"role_id_1\",\"tenantterm\":\"registration office\",\"frontiersdefaultterm\":\"registration office\",\"category\":\"user role\"},{\"sequencenumber\":169,\"key\":\"role_id_2\",\"tenantterm\":\"editorial office\",\"frontiersdefaultterm\":\"editorial office\",\"category\":\"user role\"},{\"sequencenumber\":170,\"key\":\"role_id_7\",\"tenantterm\":\"field chief editor\",\"frontiersdefaultterm\":\"field chief editor\",\"category\":\"user role\"},{\"sequencenumber\":171,\"key\":\"role_id_8\",\"tenantterm\":\"assistant field chief editor\",\"frontiersdefaultterm\":\"assistant field chief editor\",\"category\":\"user role\"},{\"sequencenumber\":172,\"key\":\"role_id_9\",\"tenantterm\":\"specialty chief editor\",\"frontiersdefaultterm\":\"specialty chief editor\",\"category\":\"user role\"},{\"sequencenumber\":173,\"key\":\"role_id_10\",\"tenantterm\":\"assistant specialty chief editor\",\"frontiersdefaultterm\":\"assistant specialty chief editor\",\"category\":\"user role\"},{\"sequencenumber\":174,\"key\":\"role_id_11\",\"tenantterm\":\"associate editor\",\"frontiersdefaultterm\":\"associate editor\",\"category\":\"user role\"},{\"sequencenumber\":175,\"key\":\"role_id_12\",\"tenantterm\":\"guest associate editor\",\"frontiersdefaultterm\":\"guest associate editor\",\"category\":\"user role\"},{\"sequencenumber\":176,\"key\":\"role_id_13\",\"tenantterm\":\"review editor\",\"frontiersdefaultterm\":\"review editor\",\"category\":\"user role\"},{\"sequencenumber\":177,\"key\":\"role_id_14\",\"tenantterm\":\"reviewer\",\"frontiersdefaultterm\":\"reviewer\",\"category\":\"user role\"},{\"sequencenumber\":178,\"key\":\"role_id_15\",\"tenantterm\":\"author\",\"frontiersdefaultterm\":\"author\",\"category\":\"user role\"},{\"sequencenumber\":179,\"key\":\"role_id_16\",\"tenantterm\":\"corresponding author\",\"frontiersdefaultterm\":\"corresponding author\",\"category\":\"user role\"},{\"sequencenumber\":180,\"key\":\"role_id_17\",\"tenantterm\":\"submitting author\",\"frontiersdefaultterm\":\"submitting author\",\"category\":\"user role\"},{\"sequencenumber\":181,\"key\":\"role_id_18\",\"tenantterm\":\"co-author\",\"frontiersdefaultterm\":\"co-author\",\"category\":\"user role\"},{\"sequencenumber\":182,\"key\":\"role_id_20\",\"tenantterm\":\"production office\",\"frontiersdefaultterm\":\"production office\",\"category\":\"user role\"},{\"sequencenumber\":183,\"key\":\"role_id_22\",\"tenantterm\":\"typesetting office (typesetter)\",\"frontiersdefaultterm\":\"typesetting office (typesetter)\",\"category\":\"user role\"},{\"sequencenumber\":184,\"key\":\"role_id_24\",\"tenantterm\":\"registered user\",\"frontiersdefaultterm\":\"registered user\",\"category\":\"user role\"},{\"sequencenumber\":185,\"key\":\"role_id_35\",\"tenantterm\":\"job office\",\"frontiersdefaultterm\":\"job office\",\"category\":\"user role\"},{\"sequencenumber\":186,\"key\":\"role_id_41\",\"tenantterm\":\"special event administrator\",\"frontiersdefaultterm\":\"special event administrator\",\"category\":\"user role\"},{\"sequencenumber\":187,\"key\":\"role_id_42\",\"tenantterm\":\"special event reviewer\",\"frontiersdefaultterm\":\"special event reviewer\",\"category\":\"user role\"},{\"sequencenumber\":188,\"key\":\"role_id_43\",\"tenantterm\":\"submit abstract\",\"frontiersdefaultterm\":\"submit abstract\",\"category\":\"user role\"},{\"sequencenumber\":189,\"key\":\"role_id_52\",\"tenantterm\":\"events office\",\"frontiersdefaultterm\":\"events office\",\"category\":\"user role\"},{\"sequencenumber\":190,\"key\":\"role_id_53\",\"tenantterm\":\"event administrator\",\"frontiersdefaultterm\":\"event administrator\",\"category\":\"user role\"},{\"sequencenumber\":191,\"key\":\"role_id_89\",\"tenantterm\":\"content management office\",\"frontiersdefaultterm\":\"content management office\",\"category\":\"user role\"},{\"sequencenumber\":192,\"key\":\"role_id_98\",\"tenantterm\":\"accounting office\",\"frontiersdefaultterm\":\"accounting office\",\"category\":\"user role\"},{\"sequencenumber\":193,\"key\":\"role_id_99\",\"tenantterm\":\"projects\",\"frontiersdefaultterm\":\"projects\",\"category\":\"user role\"},{\"sequencenumber\":194,\"key\":\"role_id_103\",\"tenantterm\":\"configuration office\",\"frontiersdefaultterm\":\"configuration office\",\"category\":\"user role\"},{\"sequencenumber\":195,\"key\":\"role_id_104\",\"tenantterm\":\"beta user\",\"frontiersdefaultterm\":\"beta user\",\"category\":\"user role\"},{\"sequencenumber\":196,\"key\":\"role_id_106\",\"tenantterm\":\"wfconf\",\"frontiersdefaultterm\":\"wfconf\",\"category\":\"user role\"},{\"sequencenumber\":197,\"key\":\"role_id_107\",\"tenantterm\":\"rt management beta user\",\"frontiersdefaultterm\":\"rt management beta user\",\"category\":\"user role\"},{\"sequencenumber\":198,\"key\":\"role_id_108\",\"tenantterm\":\"deo beta user\",\"frontiersdefaultterm\":\"deo beta user\",\"category\":\"user role\"},{\"sequencenumber\":199,\"key\":\"role_id_109\",\"tenantterm\":\"search beta user\",\"frontiersdefaultterm\":\"search beta user\",\"category\":\"user role\"},{\"sequencenumber\":200,\"key\":\"role_id_110\",\"tenantterm\":\"journal manager\",\"frontiersdefaultterm\":\"journal manager\",\"category\":\"user role\"},{\"sequencenumber\":201,\"key\":\"role_id_111\",\"tenantterm\":\"myfrontiers beta user\",\"frontiersdefaultterm\":\"myfrontiers beta user\",\"category\":\"user role\"},{\"sequencenumber\":202,\"key\":\"role_id_21\",\"tenantterm\":\"copy editor\",\"frontiersdefaultterm\":\"copy editor\",\"category\":\"user role\"},{\"sequencenumber\":203,\"key\":\"role_id_1_abr\",\"tenantterm\":\"rof\",\"frontiersdefaultterm\":\"rof\",\"category\":\"user role\"},{\"sequencenumber\":204,\"key\":\"role_id_2_abr\",\"tenantterm\":\"eof\",\"frontiersdefaultterm\":\"eof\",\"category\":\"user role\"},{\"sequencenumber\":205,\"key\":\"role_id_7_abr\",\"tenantterm\":\"fce\",\"frontiersdefaultterm\":\"fce\",\"category\":\"user role\"},{\"sequencenumber\":206,\"key\":\"role_id_8_abr\",\"tenantterm\":\"afce\",\"frontiersdefaultterm\":\"afce\",\"category\":\"user role\"},{\"sequencenumber\":207,\"key\":\"role_id_9_abr\",\"tenantterm\":\"sce\",\"frontiersdefaultterm\":\"sce\",\"category\":\"user role\"},{\"sequencenumber\":208,\"key\":\"role_id_10_abr\",\"tenantterm\":\"asce\",\"frontiersdefaultterm\":\"asce\",\"category\":\"user role\"},{\"sequencenumber\":209,\"key\":\"role_id_11_abr\",\"tenantterm\":\"ae\",\"frontiersdefaultterm\":\"ae\",\"category\":\"user role\"},{\"sequencenumber\":210,\"key\":\"role_id_12_abr\",\"tenantterm\":\"gae\",\"frontiersdefaultterm\":\"gae\",\"category\":\"user role\"},{\"sequencenumber\":211,\"key\":\"role_id_13_abr\",\"tenantterm\":\"re\",\"frontiersdefaultterm\":\"re\",\"category\":\"user role\"},{\"sequencenumber\":212,\"key\":\"role_id_14_abr\",\"tenantterm\":\"rev\",\"frontiersdefaultterm\":\"rev\",\"category\":\"user role\"},{\"sequencenumber\":213,\"key\":\"role_id_15_abr\",\"tenantterm\":\"aut\",\"frontiersdefaultterm\":\"aut\",\"category\":\"user role\"},{\"sequencenumber\":214,\"key\":\"role_id_16_abr\",\"tenantterm\":\"coraut\",\"frontiersdefaultterm\":\"coraut\",\"category\":\"user role\"},{\"sequencenumber\":215,\"key\":\"role_id_17_abr\",\"tenantterm\":\"saut\",\"frontiersdefaultterm\":\"saut\",\"category\":\"user role\"},{\"sequencenumber\":216,\"key\":\"role_id_18_abr\",\"tenantterm\":\"coaut\",\"frontiersdefaultterm\":\"coaut\",\"category\":\"user role\"},{\"sequencenumber\":217,\"key\":\"role_id_20_abr\",\"tenantterm\":\"pof\",\"frontiersdefaultterm\":\"pof\",\"category\":\"user role\"},{\"sequencenumber\":218,\"key\":\"role_id_22_abr\",\"tenantterm\":\"tsof\",\"frontiersdefaultterm\":\"tsof\",\"category\":\"user role\"},{\"sequencenumber\":219,\"key\":\"role_id_24_abr\",\"tenantterm\":\"ru\",\"frontiersdefaultterm\":\"ru\",\"category\":\"user role\"},{\"sequencenumber\":220,\"key\":\"role_id_35_abr\",\"tenantterm\":\"jof\",\"frontiersdefaultterm\":\"jof\",\"category\":\"user role\"},{\"sequencenumber\":221,\"key\":\"role_id_41_abr\",\"tenantterm\":\"se-adm\",\"frontiersdefaultterm\":\"se-adm\",\"category\":\"user role\"},{\"sequencenumber\":222,\"key\":\"role_id_42_abr\",\"tenantterm\":\"se-rev\",\"frontiersdefaultterm\":\"se-rev\",\"category\":\"user role\"},{\"sequencenumber\":223,\"key\":\"role_id_43_abr\",\"tenantterm\":\"se-aut\",\"frontiersdefaultterm\":\"se-aut\",\"category\":\"user role\"},{\"sequencenumber\":224,\"key\":\"role_id_52_abr\",\"tenantterm\":\"evof\",\"frontiersdefaultterm\":\"evof\",\"category\":\"user role\"},{\"sequencenumber\":225,\"key\":\"role_id_53_abr\",\"tenantterm\":\"ev-adm\",\"frontiersdefaultterm\":\"ev-adm\",\"category\":\"user role\"},{\"sequencenumber\":226,\"key\":\"role_id_89_abr\",\"tenantterm\":\"comof\",\"frontiersdefaultterm\":\"comof\",\"category\":\"user role\"},{\"sequencenumber\":227,\"key\":\"role_id_98_abr\",\"tenantterm\":\"aof\",\"frontiersdefaultterm\":\"aof\",\"category\":\"user role\"},{\"sequencenumber\":228,\"key\":\"role_id_99_abr\",\"tenantterm\":\"projects\",\"frontiersdefaultterm\":\"projects\",\"category\":\"user role\"},{\"sequencenumber\":229,\"key\":\"role_id_103_abr\",\"tenantterm\":\"config\",\"frontiersdefaultterm\":\"config\",\"category\":\"user role\"},{\"sequencenumber\":230,\"key\":\"role_id_104_abr\",\"tenantterm\":\"beta\",\"frontiersdefaultterm\":\"beta\",\"category\":\"user role\"},{\"sequencenumber\":231,\"key\":\"role_id_106_abr\",\"tenantterm\":\"wfconf\",\"frontiersdefaultterm\":\"wfconf\",\"category\":\"user role\"},{\"sequencenumber\":232,\"key\":\"role_id_107_abr\",\"tenantterm\":\"rtbeta\",\"frontiersdefaultterm\":\"rtbeta\",\"category\":\"user role\"},{\"sequencenumber\":233,\"key\":\"role_id_108_abr\",\"tenantterm\":\"deobeta\",\"frontiersdefaultterm\":\"deobeta\",\"category\":\"user role\"},{\"sequencenumber\":234,\"key\":\"role_id_109_abr\",\"tenantterm\":\"searchbeta\",\"frontiersdefaultterm\":\"searchbeta\",\"category\":\"user role\"},{\"sequencenumber\":235,\"key\":\"role_id_110_abr\",\"tenantterm\":\"jm\",\"frontiersdefaultterm\":\"jm\",\"category\":\"user role\"},{\"sequencenumber\":236,\"key\":\"role_id_111_abr\",\"tenantterm\":\"mfbeta\",\"frontiersdefaultterm\":\"mfbeta\",\"category\":\"user role\"},{\"sequencenumber\":237,\"key\":\"role_id_21_abr\",\"tenantterm\":\"coped\",\"frontiersdefaultterm\":\"coped\",\"category\":\"user role\"},{\"sequencenumber\":238,\"key\":\"reviewer_editorial_board\",\"tenantterm\":\"editorial board\",\"frontiersdefaultterm\":\"editorial board\",\"description\":\"this is the label for the review editorial board\",\"category\":\"label\"},{\"sequencenumber\":239,\"key\":\"field_chief_editor\",\"tenantterm\":\"field chief editor\",\"frontiersdefaultterm\":\"field chief editor\",\"category\":\"label (role)\"},{\"sequencenumber\":240,\"key\":\"field_chief_editors\",\"tenantterm\":\"field chief editors\",\"frontiersdefaultterm\":\"field chief editors\",\"category\":\"label (role)\"},{\"sequencenumber\":241,\"key\":\"editor\",\"tenantterm\":\"editor\",\"frontiersdefaultterm\":\"editor\",\"category\":\"label (role)\"},{\"sequencenumber\":242,\"key\":\"editors\",\"tenantterm\":\"editors\",\"frontiersdefaultterm\":\"editors\",\"category\":\"label (role)\"},{\"sequencenumber\":243,\"key\":\"board\",\"tenantterm\":\"board\",\"frontiersdefaultterm\":\"board\",\"category\":\"label\"},{\"sequencenumber\":244,\"key\":\"boards\",\"tenantterm\":\"boards\",\"frontiersdefaultterm\":\"boards\",\"category\":\"label\"},{\"sequencenumber\":245,\"key\":\"article_collection\",\"tenantterm\":\"article collection\",\"frontiersdefaultterm\":\"article collection\",\"category\":\"label\"},{\"sequencenumber\":246,\"key\":\"article_collections\",\"tenantterm\":\"article collections\",\"frontiersdefaultterm\":\"article collections\",\"category\":\"label\"},{\"sequencenumber\":247,\"key\":\"handling_editor\",\"tenantterm\":\"handling editor\",\"frontiersdefaultterm\":\"associate editor\",\"description\":\"this terminology key is for the person assigned to edit a manuscript. it is a label for the temporary handling editor assignment.\",\"category\":\"label (role)\"},{\"sequencenumber\":248,\"key\":\"handling_editors\",\"tenantterm\":\"handling editors\",\"frontiersdefaultterm\":\"associate editors\",\"description\":\"this terminology key is for the person assigned to edit a manuscript. it is a label for the temporary handling editor assignment.\",\"category\":\"label (role)\"},{\"sequencenumber\":249,\"key\":\"ae_accept\",\"tenantterm\":\"recommend acceptance\",\"frontiersdefaultterm\":\"accept\",\"category\":\"process\"},{\"sequencenumber\":250,\"key\":\"rtm\",\"tenantterm\":\"rtm\",\"frontiersdefaultterm\":\"rtm\",\"category\":\"product\"},{\"sequencenumber\":251,\"key\":\"frontiers_media_sa\",\"tenantterm\":\"frontiers media s.a\",\"frontiersdefaultterm\":\"frontiers media s.a\",\"category\":\"customer\"},{\"sequencenumber\":252,\"key\":\"review_editors\",\"tenantterm\":\"community reviewers\",\"frontiersdefaultterm\":\"review editors\",\"category\":\"label (role)\"},{\"sequencenumber\":253,\"key\":\"journal_card_chief_editor\",\"tenantterm\":\"chief editor\",\"frontiersdefaultterm\":\"chief editor\",\"category\":\"label (role)\"},{\"sequencenumber\":254,\"key\":\"journal_card_chief_editors\",\"tenantterm\":\"chief editors\",\"frontiersdefaultterm\":\"chief editors\",\"category\":\"label (role)\"},{\"sequencenumber\":255,\"key\":\"call_for_papers\",\"tenantterm\":\"call for papers\",\"frontiersdefaultterm\":\"call for papers\",\"category\":\"label\"},{\"sequencenumber\":256,\"key\":\"calls_for_papers\",\"tenantterm\":\"calls for papers\",\"frontiersdefaultterm\":\"calls for papers\",\"category\":\"label\"},{\"sequencenumber\":257,\"key\":\"supervising_editor\",\"tenantterm\":\"supervising editor\",\"frontiersdefaultterm\":\"supervising editor\",\"description\":\"a chief or assistant chief editor who is assigned to a manuscript to supervise.\",\"category\":\"role\",\"externalkey\":\"supervising_editor\"},{\"sequencenumber\":258,\"key\":\"supervising_editors\",\"tenantterm\":\"supervising editors\",\"frontiersdefaultterm\":\"supervising editors\",\"description\":\"a chief or assistant chief editor who is assigned to a manuscript to supervise.\",\"category\":\"role\",\"externalkey\":\"supervising_editors\"},{\"sequencenumber\":259,\"key\":\"reviewer_endorse\",\"tenantterm\":\"endorse\",\"frontiersdefaultterm\":\"endorse\",\"category\":\"label\"},{\"sequencenumber\":260,\"key\":\"reviewer_endorsed\",\"tenantterm\":\"endorsed\",\"frontiersdefaultterm\":\"endorsed\",\"category\":\"label\"},{\"sequencenumber\":261,\"key\":\"reviewer_endorse_publication\",\"tenantterm\":\"endorse publication\",\"frontiersdefaultterm\":\"endorse publication\",\"category\":\"label\"},{\"sequencenumber\":262,\"key\":\"reviewer_endorsed_publication\",\"tenantterm\":\"endorsed publication\",\"frontiersdefaultterm\":\"endorsed publication\",\"category\":\"label\"},{\"sequencenumber\":263,\"key\":\"editor_role\",\"tenantterm\":\"editor role\",\"frontiersdefaultterm\":\"editor role\",\"category\":\"label\"},{\"sequencenumber\":264,\"key\":\"editor_roles\",\"tenantterm\":\"editor roles\",\"frontiersdefaultterm\":\"editor roles\",\"category\":\"label\"},{\"sequencenumber\":265,\"key\":\"editorial_role\",\"tenantterm\":\"editorial role\",\"frontiersdefaultterm\":\"editorial role\",\"category\":\"label\"},{\"sequencenumber\":266,\"key\":\"editorial_roles\",\"tenantterm\":\"editorial roles\",\"frontiersdefaultterm\":\"editorial roles\",\"category\":\"label\"},{\"sequencenumber\":267,\"key\":\"call_for_paper\",\"tenantterm\":\"call for paper\",\"frontiersdefaultterm\":\"call for paper\",\"category\":\"label\"},{\"sequencenumber\":268,\"key\":\"research_topic_abstract\",\"tenantterm\":\"manuscript summary\",\"frontiersdefaultterm\":\"manuscript summary\",\"category\":\"process\"},{\"sequencenumber\":269,\"key\":\"research_topic_abstracts\",\"tenantterm\":\"manuscript summaries\",\"frontiersdefaultterm\":\"manuscript summaries\",\"category\":\"process\"},{\"sequencenumber\":270,\"key\":\"submissions_team_manager\",\"tenantterm\":\"journal manager\",\"frontiersdefaultterm\":\"content manager\",\"category\":\"process\"},{\"sequencenumber\":271,\"key\":\"submissions_team\",\"tenantterm\":\"journal team\",\"frontiersdefaultterm\":\"content team\",\"category\":\"process\"},{\"sequencenumber\":272,\"key\":\"topic_coordinator\",\"tenantterm\":\"topic coordinator\",\"frontiersdefaultterm\":\"topic coordinator\",\"category\":\"process\"},{\"sequencenumber\":273,\"key\":\"topic_coordinators\",\"tenantterm\":\"topic coordinators\",\"frontiersdefaultterm\":\"topic coordinators\",\"category\":\"process\"},{\"sequencenumber\":274,\"key\":\"frontiers_journal_team\",\"tenantterm\":\"frontiers journal team\",\"frontiersdefaultterm\":\"frontiers journal team\",\"category\":\"label (role)\"},{\"sequencenumber\":275,\"key\":\"research_topic_ic_submission\",\"tenantterm\":\"rt:ic submission\",\"frontiersdefaultterm\":\"rt:ic submission\",\"category\":\"label (role)\"},{\"sequencenumber\":276,\"key\":\"research_topic_ic_submission_participant\",\"tenantterm\":\"rt:ic submission participant\",\"frontiersdefaultterm\":\"rt:ic submission participant\",\"category\":\"label (role)\"}]}'\n",impactgtmid:"gtm-njf2ml9b",impactgtmauth:"fyo-7nodm9w37qgfms03sa",impactgtmpreview:"env-1",impactgooglemapsapikey:"aizasyctehx2eu8pwfi86gw9fi00ftcykk6ifr8",qualtricsv4tov3:"'{\"enabled\":true,\"interceptid\":\"si_er0e2ze69oz8yn4\",\"projectid\":\"zn_cloy77jhkpc8gai\",\"brandid\":\"frontiersin\"}'\n",qualtricsumux:"'{\"enabled\":false,\"interceptid\":\"si_89fphy3etxqbwtu\",\"projectid\":\"zn_cloy77jhkpc8gai\",\"brandid\":\"frontiersin\"}'\n",qualtricscontinuousbrand:"'{\"enabled\":true,\"interceptid\":\"si_9zut94ut81fcrh4\",\"projectid\":\"zn_cloy77jhkpc8gai\",\"brandid\":\"frontiersin\"}'\n",defaultarticletemplate:"v3"},app:{baseurl:"/",buildid:"f2d5b6d8-d01c-4534-90b9-d659f10f17ca",buildassetsdir:"ap-2024/_nuxt",cdnurl:""}}## Scraping Notes- Successfully scraped from DOI.org