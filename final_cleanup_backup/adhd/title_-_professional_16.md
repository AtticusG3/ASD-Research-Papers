---
title: '- professional'
authors:
- AnnieAitken, Maia CLazerwitz, AllyEash, NeilHattangadi, PratikMukherjee, Elysa JMarco,
  Kevin AShapiro**Journal:** Translational Psychiatry
journal: Translational Psychiatry
doi: 10.1038/s41398-025-03592-0
publication_date: ''
source: Processed from scraped content
processing_date: '2025-10-21T22:15:08.455892'
content_type: research_paper
conditions:
- adhd
- asd
- related_disorders
topics:
- comorbidity
categories:
- adhd
- asd
- related-disorders
- comorbidity
reading_level: academic
audience:
- professional
- researcher
patient_friendly: false
search_priority: standard
keywords:
- clinical
- behavioral
- children
- therapy
search_tags:
- asd
- adhd
- related_disorders
- peer-reviewed
- comorbidity
- academic
- research
---

# - professional

**Authors:** AnnieAitken, Maia CLazerwitz, AllyEash, NeilHattangadi, PratikMukherjee, Elysa JMarco, Kevin AShapiro**Journal:** Translational Psychiatry

**Journal:** Translational Psychiatry

**DOI:** 10.1038/s41398-025-03592-0

## Abstract

Research aimed at understanding how baseline clinical and demographic characteristics influence outcomes over time is critically important to inform individualized therapeutic programs for children with neurodevelopmental differences. This study characterizes adaptive behavior trajectories in children receiving medical and behavioral therapy within a network of care centers with a shared data-gathering mechanism for intake and longitudinal assessments. We then take the further step of utilizing intake data to develop machine-learning models which predict differences in those trajectories. Specifically, we evaluated data from 1225 autistic children, aged 20-90 months, using latent class growth mixture modeling (LCGMM) with scores on the Vineland Adaptive Behavior Scales, 3

---
audience:
- professional
- researcher
authors:
- AnnieAitken
- Maia CLazerwitz
- AllyEash
- NeilHattangadi
- PratikMukherjee
- Elysa JMarco
- Kevin AShapiro
category: comorbidity
content_type: research_paper
doi: 10.1038/s41398-025-03592-0
journal: Translational Psychiatry
original_url: https://doi.org/10.1038/s41398-025-03592-0
patient_friendly: false
publication_date: '2025-10-11'
reading_level: academic
scraped_by: agent_c
scraping_date: '2025-10-21T10:52:46.717632'
source: web_scraping
title: 'Predictive modeling of adaptive behavior trajectories in autism: insights
from a clinical cohort study'
type: research_paper
---
# Predictive modeling of adaptive behavior trajectories in autism: insights from a clinical cohort study**Publication Date:** 2025-10-11
Open access
29 March 2023Individualized prediction models in ADHD: a systematic review and meta-regressionArticle
Open access
23 May 2024Cognitive behavioral markers of neurodevelopmental trajectories in rodentsArticle
Open access
30 October 2021## Cross-sectional and longitudinal neuroanatomical profiles of distinct clinical (adaptive) outcomes in autismArticle
Open access
29 March 2023## Individualized prediction models in ADHD: a systematic review and meta-regressionArticle
Open access
23 May 2024## Cognitive behavioral markers of neurodevelopmental trajectories in rodentsArticle
Open access
30 October 2021## BackgroundThe diagnostic category of Autism Spectrum Disorder (ASD) encompasses a range of neurodevelopmental differences that result in atypical trajectories in the development of adaptive functions, particularly in the domains of socialization and communication [1, 2]. In clinical practice, the assessment of adaptive functioning skills, often referred to as “adaptive behaviors,” is routinely used as a proxy for real-world ability and disability in autistic individuals over the course of the lifespan [3, 4].Recently, researchers have made significant efforts to characterize patterns of adaptive behavior outcomes in autism. These efforts have revealed substantial variation, with some children exhibiting more favorable developmental changes compared to others. This information is highly relevant to clinicians who seek to develop targeted therapeutic and medical approaches based on an individual’s unique psychosocial profile and neurobehavioral phenotype. Identifying how individuals may respond differently to clinical care is fundamental both to personalizing programs of intervention and to improving care delivery more broadly. Thus, there is a pressing need to identify predictors of differential trajectories of adaptive behavior change within the context of clinical care from the point of intake.The term “autism spectrum” itself underscores the inherent heterogeneity within the diagnostic construct. Individuals with an autism diagnosis differ in numerous aspects ranging from genetic risk factors to early-life experiences and sociodemographic variables, leading to diverse clinical and developmental outcomes [5]. One statistical technique that has been used to characterize the multifaceted nature of autism outcomes is latent class growth mixture modeling (LCGMM), which can capture variability in behavioral measures longitudinally from childhood to adulthood [6,7,8,9]. LCGMM offer several advantages over multilevel linear growth models, which are a traditional method for characterizing change and are particularly useful for modeling continuous change. In comparison, mixture models capture heterogeneity in patterns of change, enabling the identification of distinct trajectories that align more closely with real-world clinical observations. Prior studies have primarily analyzed standardized measures of adaptive behavior skills, such as the Vineland Adaptive Behavior Scales (VABS) [2], in children drawn from community samples without regard to specific interventions or treatments.Collectively, these studies have revealed that a significant proportion of autistic children follow trajectories characterized by little to no growth in adaptive behavior [6,7,8,9,10]. In other words, many children with a diagnosis of autism continue to lag significantly behind their peers in the development of adaptive behavior skills, despite presumably receiving some type of therapy within the community. However, the contribution of standard therapeutic interventions has not been comprehensively accounted for, as relevant clinical data are lacking in most research cohorts. It should also be noted that while research samples tend to emphasize psychometric characteristics, such as IQ, in predicting group membership, clinically relevant issues such as comorbid conditions and parent-reported concerns may not be routinely assessed.On the other hand, research into the effectiveness of clinical interventions for autism often does not sufficiently account for heterogeneity in the population of individuals with that diagnostic label. This has resulted in a “one-size-fits-all” approach to clinical intervention, typically comprising numerous hours of intensive behavioral interventions such as Applied Behavior Analysis (ABA) therapy and ad hoc provision of other developmental therapies including speech-language therapy, occupational therapy, and physical therapy [11]. In theory, a more individually tailored approach to therapy could offer improvements in both cost efficiency and clinical efficacy, substantially reducing the lifelong socioeconomic burdens associated with an autism diagnosis.Psychosocial, demographic, and longitudinal outcome data from various sources can be analyzed holistically using machine learning (ML) approaches, which have gained significant traction as a tool for predicting clinical outcomes in various mental health conditions [12]. In the realm of autism research, ML prediction models have been applied to identify subtypes of autism based on clinical data [7, 13], to develop precise diagnostic models [14, 15], and, more recently, to predict differential responses to medical treatments [16]. However, there is a paucity of studies employing ML to predict differential functional behavior outcomes among individuals with autism, and fewer still that systematically account for the impact of standard therapeutic interventions. From the perspective of autism care, therefore, there is a pressing need for studies that adopt a data-driven approach to explore predictors of variation in response to treatment. Such efforts should enhance the precision of intervention strategies and provide tailored support to individuals with autism, ultimately maximizing these individuals’ overall quality of life [17].Current studyThis study aimed to characterize the variability in adaptive behavior outcomes among autistic children, and to identify key clinical predictors of differential outcomes. The research described here is unique in part because it utilizes data gathered within the course of clinical care, rather than in the isolated context of a research study. Thus, in addition to adaptive behavior outcomes data from the Vineland Adaptive Behavior Scales, 3rd Edition (VABS-3), we had access to in-depth clinical intake information, including baseline socio-demographic data as well as standardized parent ratings for a variety of neurodevelopmental concerns and medical comorbidities. We were also able to gather information about the type and duration of therapies children received.The study had two primary objectives. First, we employed latent class growth mixture modeling (LCGMM) to uncover distinct trajectories of adaptive behavior change in a cohort of children (N = 1225) receiving clinical care within a network of centers with a uniform approach to autism treatment. We evaluated the Adaptive Behavior Composite (ABC) score and the standardized score from each subdomain on the VABS-3 to facilitate comparisons with previous latent class trajectory research [6, 8, 9, 11].Second, utilizing predictive ML algorithms, we investigated the importance of socio-demographic variables and clinical phenotypes in predicting membership in one of the observed trajectories of adaptive behavior change identified through LCGMM analysis. We also evaluated whether including information about therapeutic intensity - operationalized as cumulative hours of ABA and developmental therapies - would substantially alter the prediction of outcomes of our models. What makes this sample unique is that for each autistic child receiving care, the parent or caregiver completed a detailed standardized intake form prior to the initial visit, providing a rich source of demographic, historical, and baseline clinical data. Caregivers also reported adaptive behavior skills using the VABS-3 [18] every six months as part of routine clinical care.## Current studyThis study aimed to characterize the variability in adaptive behavior outcomes among autistic children, and to identify key clinical predictors of differential outcomes. The research described here is unique in part because it utilizes data gathered within the course of clinical care, rather than in the isolated context of a research study. Thus, in addition to adaptive behavior outcomes data from the Vineland Adaptive Behavior Scales, 3rd Edition (VABS-3), we had access to in-depth clinical intake information, including baseline socio-demographic data as well as standardized parent ratings for a variety of neurodevelopmental concerns and medical comorbidities. We were also able to gather information about the type and duration of therapies children received.
The study had two primary objectives. First, we employed latent class growth mixture modeling (LCGMM) to uncover distinct trajectories of adaptive behavior change in a cohort of children (N = 1225) receiving clinical care within a network of centers with a uniform approach to autism treatment. We evaluated the Adaptive Behavior Composite (ABC) score and the standardized score from each subdomain on the VABS-3 to facilitate comparisons with previous latent class trajectory research [6, 8, 9, 11].
Second, utilizing predictive ML algorithms, we investigated the importance of socio-demographic variables and clinical phenotypes in predicting membership in one of the observed trajectories of adaptive behavior change identified through LCGMM analysis. We also evaluated whether including information about therapeutic intensity - operationalized as cumulative hours of ABA and developmental therapies - would substantially alter the prediction of outcomes of our models. What makes this sample unique is that for each autistic child receiving care, the parent or caregiver completed a detailed standardized intake form prior to the initial visit, providing a rich source of demographic, historical, and baseline clinical data. Caregivers also reported adaptive behavior skills using the VABS-3 [18] every six months as part of routine clinical care.## ResultsDataset descriptionThis study leveraged deidentified clinical data from a network of 13 clinical sites with a uniform operational and therapeutic approach to autism care (Cortica Healthcare). The network included 8 sites in California, 2 sites in Texas, 2 sites in Illinois, and 1 site in New Jersey. The study was conducted according to principles outlined in the Declaration of Helsinki, and was approved by the WIRB-Copernicus Group, Institutional review board (protocol # 20224562). We received a waiver of informed consent from the institutional review board given that all aspects of this study were based on deidentified retrospective clinical data.We queried Cortica’s clinical research database for children with an autism diagnosis between the ages of 19 and 90 months who had at least two assessments using the (VABS-3) from 2016 through 2023 (N = 1225). All participants met clinical criteria for Autism Spectrum Disorder based on the Diagnostic and Statistical Manual of Mental Disorders, 5th Edition, as assessed by physicians and nurse practitioners with expertise in autism diagnosis. The clinical assessment was supported by one or more of three standardized diagnostic instruments: the Autism Diagnostic Interview – Revised; the Autism Diagnostic Observation Schedule, 2nd Edition; or the Childhood Autism Rating Scale, 2nd Edition.The full sample of 1225 participants was included in the latent class growth mixture modeling (LCGMM) analysis. For a subset of these participants (N = 729), we had access to comprehensive socio-demographic, historical, and clinical intake information provided prior to their initial visit (See Table 1 for full variable list). We used this subset of patients for the ML analysis. Full sample demographics are presented in Supplemental Information Table 1.Table 1 All variables included in machine learning analysis.Full size tableClusters of adaptive behavior growth trajectoriesWe used conditional LCGMM to identify distinct growth profiles of adaptive behavior change using repeated measures VABS-3 assessments in the Adaptive Behavior Composite, Socialization, Communication, and Daily Living Score (DLS) domains. We included initial VABS-3 symptom severity [19] as a covariate, as past literature has demonstrated a significant influence of baseline adaptive behavior levels on resultant outcomes [7]. For each domain, the 2-profile model was selected as the best fitting model, based on the highest entropy value, a low BIC, a significant LMR test, and each profile representing at least 5% of the entire sample (see Supplemental Information Table 2 for LCGMM iterative results). See Table 2 for details on the best fitting model for each VABS-3 outcome. The ABC, Socialization and Communication domains all showed a similar pattern of class distribution. Within these domains, class labels were determined based on the directionality of the estimated slope and starting intercept (Less Impairment/Improving Trajectory; Higher Impairment/Stable Trajectory). The groups with negative slope coefficients were described as “stable” because the slope was not significantly different than zero, and scores on the VABS-3 reflect an individual’s behavior relative to an age-matched normative sample (See Fig. 1). Thus, a negative slope reflects a deviation from typical change trajectories but does not imply regression of skills.Fig. 1: LCGMM classes and trajectories.Plot depicting the estimated average slope identified from the latent class growth mixture models for each identified latent class trajectory cluster (Lower Impairment/Improving Trajectory and Higher Impairment/Stable Trajectory). Individual raw data points are overlayed.Full size imageTable 2 Data-Driven clusters of adaptive behavior trajectories.Full size tableWithin the DLS subdomain, entropy was high, but class distribution was highly unequal. While the high entropy value suggests clear separation, the second class comprised less than 1% of individuals, indicating that most individuals clustered within a single, stable class, while the second class likely represented outliers rather than a meaningful latent subgroup. This pattern suggests that variability in daily living scores over time is best captured within a single trajectory rather than distinct latent classes. For this reason, DLS scores were excluded from subsequent predictive learning group classification.Definition of outcome groupsTo improve balance between classification groups, we created a dummy variable that corresponded to a 1 (Stable/Limited Gains) if children fell into the stable LCGMM class for any of the VABS-3 outcomes (Adaptive Behavior Composite, Socialization, or Communication) and a 0 (Multi-Domain Improvement) if they fell into the improved LCGMM cluster for all the VABS-3 outcomes (see Fig. 2). Using this definition, in the full sample, 339 children (39%) were classified as having Stable/Limited Gains, while 879 children (61%) demonstrated Multi-Domain Improvement. In the subset of children included in the predictive modeling analysis, 188 (35%) were classified as having Stable/Limited Gains, while 541 (65%) demonstrated Consistent Multi-Domain Improvement. For descriptive statistics of all predictor variables with the ML subgroup stratified by defined outcome group, see Supplemental Information Table 3.Fig. 2: Definition of outcome groups for machine learning.Stacked bar chart representing the adaptive behavior outcome group defined from the latent class growth mixture model.Full size imagePrediction models to differentiate stable and improved adaptive behavior trajectoriesThe goal of the machine learning analysis was to develop and evaluate prediction models capable of differentiating between Stable and Improved adaptive behavior trajectories with adequate accuracy. After data pre-processing and feature selection (see Methods), we tested the performance of six machine learning algorithms using 13 clinical intake variables with nested cross-validation (See Fig. 3). The three models employed and compared elastic net logistic regression, support vector machine, and random forest to predict group membership with the following sets of features: socio-demographic (age at first assessment, gender, socioeconomic status), historical (maternal age at birth, paternal age at birth, pre/perinatal mental health, infant temperament, history of developmental regression), and clinical phenotype (autism symptoms, sleep problems, attention deficit hyperactivity disorder (ADHD) symptoms, sensory processing disorder (SPD) symptoms, mood concerns, motor development concerns, communication/language concerns, seizures, tics or tremors, headaches, general developmental concerns, feeding problems, impulsivity, repetitive behaviors).Fig. 3: Schematic of machine learning model development and validation.Flowchart of machine learning models used for the prediction of adaptive behavior outcomes.Full size imageModel validation and tuningThe first set of machine learning models evaluated the predictive value of socio-demographic, historical, and phenotypic intake variables for discriminating between individuals who fell into the Limited Functional Gains behavior group versus the Multi-Domain Improvement behavior group. Table 3 presents the accuracy and AUC-ROC for each algorithm during the 10-fold cross validation. The random forest model out preformed the others with a validation AUC-ROC of 0.73. The elastic net logistic regression and support vector machine reached a validation AUC-ROC of 0.72 and 0.71, respectively. The secondary metric used to evaluate ML model selection during development was accuracy. All algorithms achieved a 74% accuracy rate. See Supplementary Table 4a–c for ML model results on individual VABS-3 subdomain outcome.Table 3 Machine learning models.Full size tableAdding behavioral and developmental therapy hours as predictorsWe conducted secondary machine learning analyses to evaluate whether differences in Applied Behavior Analysis (ABA) or developmental therapy (DT) dosage would predict Limited Functional Gains versus Multi-Domain Improvement group membership. Specifically, we included total hours of ABA therapy (direct services, i.e., including one-on-one therapy with the child and excluding hours of supervision among ABA providers) and developmental therapy. The model’s performance metrics showed little to no change, resulting in a random forest ROC-AUC of 0.75 and an accuracy rate of 75%. Full details on the model’s performance can be found in the Supplementary Information (SI Table 5). To mitigate model complexity and prevent overfitting, we evaluated our final validation model excluding hours of ABA or DT therapy in the final random forest model.Final model external validation performanceUsing the random forest algorithm, our final model demonstrated similar performance on the holdout validation set, yielding a ROC-AUC of 0.77 and an accuracy rate of 77.5%. Moreover, it exhibited a precision rate of 78.2%, a recall rate of 96.3%, and an F1 score of 0.863. Confusion matrices and predicted probability plots are depicted in Fig. 4a, b.Fig. 4: Model predictions in the external holdout set.a Confusion matrix for the real vs. predicted binary classification of the adaptive behavior trajectory group. Values correspond to proportions of predictions for each row, respectively. b Violin plot depicting the spread of the predicted probabilities for the binary classification of growth trajectories. Lower values in the Multi-Domain Improvement category correspond to better accuracy (closer to 0) and higher values in the Stable/Limited Gains category reflect better accuracy (closer to 1).Full size imagePredictive performance of variablesNext, we investigated the contributions of individual predictor variables to our model’s accuracy to gain a better understanding of which factors most strongly influence adaptive behavior trajectories. Variable importance was identified using Shapley values, which reflect the additive importance of a particular variable in a model-agnostic fashion (see Fig. 5a). We considered variables with Shapley values above the grand average (0.016) to be the most significant predictors.Fig. 5: Variable importance in predicting adaptive behavior outcomes.Variables included in the final random forest machine learning model for prediction of adaptive behavior change. a A stacked bar plot of Shapley importance. Absolute average values of Shapley importance scores “(mean|SHAP value|)”are indicated on the x-axis. b Violin plots of the distribution raw values for each feature variable between outcome groups with boxplots representing the median and interquartile range of each variable.Full size imageIn the socio-demographic domain, we found that lower socioeconomic status (SES) was the most important predictor of group membership in the Stable/Limited Gains cohort. In the domain of prenatal and early-life experiences, a history of developmental regression, parent report of infant temperament, and father’s age at birth were most predictive of group membership. Finally, among variables related to phenotype, severity of autism symptoms and ADHD symptoms, as well as parent-reported concerns about general development, motor development, communication/language, and mood were most predictive of adaptive function trajectory group membership (see Fig. 5b).Directionally, children in the Stable/Limited Gains group had younger fathers, were more likely to have had a difficult temperament in infancy, and were more likely to have demonstrated a loss in previously acquired developmental skills. Children in the Stable/Limited Gains group also had more severe symptoms of autism and ADHD at the time of intake, with parents more commonly indicating concern for general development, motor development, communication/language, and mood.## Dataset descriptionThis study leveraged deidentified clinical data from a network of 13 clinical sites with a uniform operational and therapeutic approach to autism care (Cortica Healthcare). The network included 8 sites in California, 2 sites in Texas, 2 sites in Illinois, and 1 site in New Jersey. The study was conducted according to principles outlined in the Declaration of Helsinki, and was approved by the WIRB-Copernicus Group, Institutional review board (protocol # 20224562). We received a waiver of informed consent from the institutional review board given that all aspects of this study were based on deidentified retrospective clinical data.
We queried Cortica’s clinical research database for children with an autism diagnosis between the ages of 19 and 90 months who had at least two assessments using the (VABS-3) from 2016 through 2023 (N = 1225). All participants met clinical criteria for Autism Spectrum Disorder based on the Diagnostic and Statistical Manual of Mental Disorders, 5th Edition, as assessed by physicians and nurse practitioners with expertise in autism diagnosis. The clinical assessment was supported by one or more of three standardized diagnostic instruments: the Autism Diagnostic Interview – Revised; the Autism Diagnostic Observation Schedule, 2nd Edition; or the Childhood Autism Rating Scale, 2nd Edition.
The full sample of 1225 participants was included in the latent class growth mixture modeling (LCGMM) analysis. For a subset of these participants (N = 729), we had access to comprehensive socio-demographic, historical, and clinical intake information provided prior to their initial visit (See Table 1 for full variable list). We used this subset of patients for the ML analysis. Full sample demographics are presented in Supplemental Information Table 1.
Table 1 All variables included in machine learning analysis.Full size table## Clusters of adaptive behavior growth trajectoriesWe used conditional LCGMM to identify distinct growth profiles of adaptive behavior change using repeated measures VABS-3 assessments in the Adaptive Behavior Composite, Socialization, Communication, and Daily Living Score (DLS) domains. We included initial VABS-3 symptom severity [19] as a covariate, as past literature has demonstrated a significant influence of baseline adaptive behavior levels on resultant outcomes [7]. For each domain, the 2-profile model was selected as the best fitting model, based on the highest entropy value, a low BIC, a significant LMR test, and each profile representing at least 5% of the entire sample (see Supplemental Information Table 2 for LCGMM iterative results). See Table 2 for details on the best fitting model for each VABS-3 outcome. The ABC, Socialization and Communication domains all showed a similar pattern of class distribution. Within these domains, class labels were determined based on the directionality of the estimated slope and starting intercept (Less Impairment/Improving Trajectory; Higher Impairment/Stable Trajectory). The groups with negative slope coefficients were described as “stable” because the slope was not significantly different than zero, and scores on the VABS-3 reflect an individual’s behavior relative to an age-matched normative sample (See Fig. 1). Thus, a negative slope reflects a deviation from typical change trajectories but does not imply regression of skills.
Fig. 1: LCGMM classes and trajectories.Plot depicting the estimated average slope identified from the latent class growth mixture models for each identified latent class trajectory cluster (Lower Impairment/Improving Trajectory and Higher Impairment/Stable Trajectory). Individual raw data points are overlayed.Full size image
Table 2 Data-Driven clusters of adaptive behavior trajectories.Full size table
Within the DLS subdomain, entropy was high, but class distribution was highly unequal. While the high entropy value suggests clear separation, the second class comprised less than 1% of individuals, indicating that most individuals clustered within a single, stable class, while the second class likely represented outliers rather than a meaningful latent subgroup. This pattern suggests that variability in daily living scores over time is best captured within a single trajectory rather than distinct latent classes. For this reason, DLS scores were excluded from subsequent predictive learning group classification.## Definition of outcome groupsTo improve balance between classification groups, we created a dummy variable that corresponded to a 1 (Stable/Limited Gains) if children fell into the stable LCGMM class for any of the VABS-3 outcomes (Adaptive Behavior Composite, Socialization, or Communication) and a 0 (Multi-Domain Improvement) if they fell into the improved LCGMM cluster for all the VABS-3 outcomes (see Fig. 2). Using this definition, in the full sample, 339 children (39%) were classified as having Stable/Limited Gains, while 879 children (61%) demonstrated Multi-Domain Improvement. In the subset of children included in the predictive modeling analysis, 188 (35%) were classified as having Stable/Limited Gains, while 541 (65%) demonstrated Consistent Multi-Domain Improvement. For descriptive statistics of all predictor variables with the ML subgroup stratified by defined outcome group, see Supplemental Information Table 3.
Fig. 2: Definition of outcome groups for machine learning.Stacked bar chart representing the adaptive behavior outcome group defined from the latent class growth mixture model.Full size image## Prediction models to differentiate stable and improved adaptive behavior trajectoriesThe goal of the machine learning analysis was to develop and evaluate prediction models capable of differentiating between Stable and Improved adaptive behavior trajectories with adequate accuracy. After data pre-processing and feature selection (see Methods), we tested the performance of six machine learning algorithms using 13 clinical intake variables with nested cross-validation (See Fig. 3). The three models employed and compared elastic net logistic regression, support vector machine, and random forest to predict group membership with the following sets of features: socio-demographic (age at first assessment, gender, socioeconomic status), historical (maternal age at birth, paternal age at birth, pre/perinatal mental health, infant temperament, history of developmental regression), and clinical phenotype (autism symptoms, sleep problems, attention deficit hyperactivity disorder (ADHD) symptoms, sensory processing disorder (SPD) symptoms, mood concerns, motor development concerns, communication/language concerns, seizures, tics or tremors, headaches, general developmental concerns, feeding problems, impulsivity, repetitive behaviors).
Fig. 3: Schematic of machine learning model development and validation.Flowchart of machine learning models used for the prediction of adaptive behavior outcomes.Full size image## Model validation and tuningThe first set of machine learning models evaluated the predictive value of socio-demographic, historical, and phenotypic intake variables for discriminating between individuals who fell into the Limited Functional Gains behavior group versus the Multi-Domain Improvement behavior group. Table 3 presents the accuracy and AUC-ROC for each algorithm during the 10-fold cross validation. The random forest model out preformed the others with a validation AUC-ROC of 0.73. The elastic net logistic regression and support vector machine reached a validation AUC-ROC of 0.72 and 0.71, respectively. The secondary metric used to evaluate ML model selection during development was accuracy. All algorithms achieved a 74% accuracy rate. See Supplementary Table 4a–c for ML model results on individual VABS-3 subdomain outcome.
Table 3 Machine learning models.Full size table## Adding behavioral and developmental therapy hours as predictorsWe conducted secondary machine learning analyses to evaluate whether differences in Applied Behavior Analysis (ABA) or developmental therapy (DT) dosage would predict Limited Functional Gains versus Multi-Domain Improvement group membership. Specifically, we included total hours of ABA therapy (direct services, i.e., including one-on-one therapy with the child and excluding hours of supervision among ABA providers) and developmental therapy. The model’s performance metrics showed little to no change, resulting in a random forest ROC-AUC of 0.75 and an accuracy rate of 75%. Full details on the model’s performance can be found in the Supplementary Information (SI Table 5). To mitigate model complexity and prevent overfitting, we evaluated our final validation model excluding hours of ABA or DT therapy in the final random forest model.## Final model external validation performanceUsing the random forest algorithm, our final model demonstrated similar performance on the holdout validation set, yielding a ROC-AUC of 0.77 and an accuracy rate of 77.5%. Moreover, it exhibited a precision rate of 78.2%, a recall rate of 96.3%, and an F1 score of 0.863. Confusion matrices and predicted probability plots are depicted in Fig. 4a, b.
Fig. 4: Model predictions in the external holdout set.a Confusion matrix for the real vs. predicted binary classification of the adaptive behavior trajectory group. Values correspond to proportions of predictions for each row, respectively. b Violin plot depicting the spread of the predicted probabilities for the binary classification of growth trajectories. Lower values in the Multi-Domain Improvement category correspond to better accuracy (closer to 0) and higher values in the Stable/Limited Gains category reflect better accuracy (closer to 1).Full size image## Predictive performance of variablesNext, we investigated the contributions of individual predictor variables to our model’s accuracy to gain a better understanding of which factors most strongly influence adaptive behavior trajectories. Variable importance was identified using Shapley values, which reflect the additive importance of a particular variable in a model-agnostic fashion (see Fig. 5a). We considered variables with Shapley values above the grand average (0.016) to be the most significant predictors.
Fig. 5: Variable importance in predicting adaptive behavior outcomes.Variables included in the final random forest machine learning model for prediction of adaptive behavior change. a A stacked bar plot of Shapley importance. Absolute average values of Shapley importance scores “(mean|SHAP value|)”are indicated on the x-axis. b Violin plots of the distribution raw values for each feature variable between outcome groups with boxplots representing the median and interquartile range of each variable.Full size image
In the socio-demographic domain, we found that lower socioeconomic status (SES) was the most important predictor of group membership in the Stable/Limited Gains cohort. In the domain of prenatal and early-life experiences, a history of developmental regression, parent report of infant temperament, and father’s age at birth were most predictive of group membership. Finally, among variables related to phenotype, severity of autism symptoms and ADHD symptoms, as well as parent-reported concerns about general development, motor development, communication/language, and mood were most predictive of adaptive function trajectory group membership (see Fig. 5b).
Directionally, children in the Stable/Limited Gains group had younger fathers, were more likely to have had a difficult temperament in infancy, and were more likely to have demonstrated a loss in previously acquired developmental skills. Children in the Stable/Limited Gains group also had more severe symptoms of autism and ADHD at the time of intake, with parents more commonly indicating concern for general development, motor development, communication/language, and mood.## DiscussionIn this study, we characterized trajectories of adaptive behavior change in a clinical cohort. Latent class models identified two distinct clusters of adaptive behavior change: a Less Impairment/Improving Trajectory group, with adaptive behavior scores that approximated age-matched norms over time, and a Higher Impairment/Stable Trajectory group, with slower change in adaptive skills as compared to peers. We then developed a machine learning model based on clinical intake information and data regarding interventions to predict which children might show more or less growth in adaptive skills over time. Using a wide range of socio-demographic, historical, and clinical phenotyping predictor variables, random forest machine learning models were able to predict course trajectory during care with an AUC-ROC of 0.77 and an accuracy of 77.5% in the external validation set. This study was motivated by a pressing need to characterize trajectories of adaptive behavior among autistic children in a clinically relevant context.Past literature using latent class growth mixture model (LCGMM) approaches to identify clusters of adaptive behavior change over time has relied on research cohorts of autistic children recruited from the community, with little information about the nature of the interventions and therapies those children were receiving [6, 8, 9, 11]. Interestingly, while these study populations did encompass children of diverse ages and varying levels of autism severity, a consistent finding has been that most children (70–100%) exhibit stable or regressing trajectories.Our study fills an important gap in the literature by examining outcomes in a large cohort receiving care delivered according to relatively standardized clinical criteria. In this cohort, approximately 75–91% of individuals show an improving growth trajectory across different VABS-3 domain scores.One possible explanation for this disparity is the nature of care received by our cohort. Unlike many prior studies, which assessed either naturalistic trajectories in the absence of detailed information about therapeutic interventions or specific standardized intervention programs, our study examined outcomes in children receiving care within a comprehensive clinical framework. All children in our cohort had access to a care model that integrated medical treatment alongside behavioral intervention and developmental therapies. In theory, such a comprehensive approach may support broader adaptive improvements. On the other hand, the model is inherently personalized, and therefore the heterogeneity of interventions received across children in the cohort makes it difficult to determine how differences in the observed growth trajectories might be related to treatment. Apart from any treatment-related differences, differences in population characteristics (including socioeconomic and demographic variables and baseline levels of function) and methodological approaches may have contributed to the finding of overall better outcomes in our cohort [20,21,22]. It is also important to note that slope estimates for our improving growth trajectory were relatively modest and may not necessarily reflect clinically significant change. Nevertheless, these findings highlight the potential impact of individualized, multi-modal care models and underscore the need for future research to clarify factors driving these discrepancies.Moreover, we were able develop machine learning models to predict which patients were more likely to show improvements in adaptive behavior. Cross-fold validation for our final model had an observed AUC-ROC of 0.73 and an accuracy of 74.0%, and performance in the external validation set showed an AUC-ROC of 0.77 and an accuracy of 77.5%. Our models appear to improve on the accuracy of previous machine learning models designed to predict autism developmental courses. For example, Préfontaine et al. [23] used machine learning to predict adaptive behavior change during behavioral intervention based on demographic information, IQ, and baseline autism severity features. Their best fitting model showed an accuracy of 68% [23]. Thus, our study extends the literature by applying a comprehensive workflow of machine learning development to predict adaptive behavior outcomes as defined from data-driven latent class approaches.Although very few studies have employed machine learning, other researchers have used inferential statistics to identify predictors of adaptive behavior development. This more traditional statistical approach has demonstrated that cognitive and language skills, presence of epilepsy, and severity of autism are risk factors for low growth trajectories [24]. These results overlap with our findings that autism symptom severity and parent concerns about development are the most robust predictors of outcome trajectory.Interestingly, when therapy intensity - operationalized as cumulative hours of ABA or DT - was added to our model, predictive accuracy did not improve. This would seem to offer counter evidence to research proposing a linear relation between duration and intensity of therapy with behavioral improvement [25, 26]. On the other hand, these findings add to growing literature suggesting the high total treatment duration of ABA therapy does not lead to improvement in treatment gains above average dosage levels [27]. It may in fact be the case, as demonstrated here, that increasing therapeutic hours is not necessarily effective or cost-efficient in improving real-world outcomes for all children [28].Our analysis of variable importance identified variables across several domains contributing significantly to the model. Importantly, SES was one of the most important indicating variables in our models. Individuals from lower SES backgrounds may lack some of the key resources required to support their autistic child; in many cases, accessing therapeutic services can be associated with a severe economic burden [29,30,31]. There is a dearth of research evaluating health disparities in autism diagnoses and outcomes, warranting a need for more intensive research within this domain.In addition, our data suggest that older paternal age at the time of the child’s birth predicted a more favorable adaptive behavior outcome. While this may seem counterintuitive given the literature suggesting that autism is more prevalent in children of older parents, the explanation may relate to the findings about SES that we have just discussed: it may be that older parents are more likely to be financially secure and stable.It is also notable that infant temperament was identified as a robust predictive variable: infants with fussier temperaments were more likely to fall into the Stable/Limited Gains adaptive behavior trajectory. This finding is in line with a large body of developmental literature describing infant temperament as an early marker for autism risk [32, 33]. Another top predictor within the domain of early life experiences was the presence of a history of developmental regression. Again, a great deal of literature has demonstrated the children with who have experienced a loss in previously attained abilities show less favorable developmental outcomes, perhaps attributable to underlying biological or developmental conditions that lead to autistic regression. This highlights the importance of a thorough etiologic evaluation not only to understand the contributors to a child’s neurodevelopmental condition, but also to inform prognosis and develop a plan of care [34, 35].Within the domain of phenotypes, several variables predicted adaptive behavior trajectory. These include two variables that are directly involved with the core features of autism: namely, global autism symptom severity (as measured by the Autism Quotient [36]) and parent communication and language concerns (identified using the ESSENCE-Q-REV [34]). This finding is not surprising given historical evidence showing that baseline autism symptoms are associated with response to treatment and developmental outcomes [7, 37, 38]. The item about general developmental concerns on the ESSENCE-Q-REV captures a range of parental observations about child development; the globally inclusive nature of this item is undoubtedly inherent to its predictive power [39]. Interestingly, motor developmental concerns were also identified as a top predictive variable. It is increasingly recognized that heterogeneity in the acquisition of motor skills is an important early predictor of neurodevelopmental outcomes, and specifically that motor developmental delays are a risk factor for later autism prognosis and severity.Finally, ADHD symptom severity (identified from the SNAP-IV [40]) and mood concerns (identified from the ESSENCE-Q-REV) demonstrated significant predictive ability in the machine learning model. It is likely that psychiatric comorbidities of autism – including ADHD, anxiety, and depression —may influence a child’s ability to show progress in adaptive behavior [41,42,43].Limitations and future directionsWhile we believe this study offers a major contribution to the literature on adaptive behavior outcomes in autism, several limitations require further discussion. Because the design of the study was based on chart review within an opportunistic clinical sample, there was no control group consisting of children not receiving autism care, or children receiving different types or models of therapy. In comparison to the general population of autistic individuals, our population likely drew from families with more resources (i.e., access to commercial medical insurance), or who were more likely to seek out a specific type of clinical environment. The geographical distribution of the sample was also constrained by the location of centers in the Cortica Healthcare network. Nonetheless, even given these constraints, we were able to identify robust demographic predictors of outcome, including socioeconomic status.Our decision to use VABS-3 standard scores as dependent variables within our LCGMM framework was driven primarily by considerations of comparability with previous research in this domain, which have also generally focused on standard scores [6, 8, 9, 11]. However, standard scores have limitations in their interpretation as indices of change. Further research should capitalize on metrics that may be more favorable for analyzing change, such as growth scale values or age-equivalent scores.It is also important to note that our phenotypic data consisted almost entirely of parent-reported questionnaires, as opposed to psychometric assessments that are typically conducted by a clinician. While these questionnaires (such as the Autism Quotient, SNAP-IV, and ESSENCE-Q-REV) have been validated in a research context, it is arguably the case that clinician-administered assessments would provide more consistent and accurate phenotypic data. On the other hand, such assessments are time- and labor-intensive and are often not practical in clinical environments, especially given the severity of current bottlenecks in access to diagnosis and therapy for autism [44, 45]. The intake measures used in this study are practical and easy to gather in the context of routine clinical care.Finally, we note that while we tested multiple machine learning algorithms, the possibilities for tuning of all hyper-parameters were not exhausted. It is possible that different hyper-parameter tuning may have led to altered predictions. Our analytic approach was selected to prioritize a straightforward model and reduce over-fitting and model complexity. Future research validating our machine learning models in an independent sample is warranted.## Limitations and future directionsWhile we believe this study offers a major contribution to the literature on adaptive behavior outcomes in autism, several limitations require further discussion. Because the design of the study was based on chart review within an opportunistic clinical sample, there was no control group consisting of children not receiving autism care, or children receiving different types or models of therapy. In comparison to the general population of autistic individuals, our population likely drew from families with more resources (i.e., access to commercial medical insurance), or who were more likely to seek out a specific type of clinical environment. The geographical distribution of the sample was also constrained by the location of centers in the Cortica Healthcare network. Nonetheless, even given these constraints, we were able to identify robust demographic predictors of outcome, including socioeconomic status.
Our decision to use VABS-3 standard scores as dependent variables within our LCGMM framework was driven primarily by considerations of comparability with previous research in this domain, which have also generally focused on standard scores [6, 8, 9, 11]. However, standard scores have limitations in their interpretation as indices of change. Further research should capitalize on metrics that may be more favorable for analyzing change, such as growth scale values or age-equivalent scores.
It is also important to note that our phenotypic data consisted almost entirely of parent-reported questionnaires, as opposed to psychometric assessments that are typically conducted by a clinician. While these questionnaires (such as the Autism Quotient, SNAP-IV, and ESSENCE-Q-REV) have been validated in a research context, it is arguably the case that clinician-administered assessments would provide more consistent and accurate phenotypic data. On the other hand, such assessments are time- and labor-intensive and are often not practical in clinical environments, especially given the severity of current bottlenecks in access to diagnosis and therapy for autism [44, 45]. The intake measures used in this study are practical and easy to gather in the context of routine clinical care.
Finally, we note that while we tested multiple machine learning algorithms, the possibilities for tuning of all hyper-parameters were not exhausted. It is possible that different hyper-parameter tuning may have led to altered predictions. Our analytic approach was selected to prioritize a straightforward model and reduce over-fitting and model complexity. Future research validating our machine learning models in an independent sample is warranted.## ConclusionThe current study showed that more than 60% of children receiving care at a network of community neurodevelopment centers with a comprehensive approach to autism care demonstrated improvement across multiple domains of adaptive behavior. We also described a set of clinical intake variables, including information about patients’ socio-demographic backgrounds and behavioral phenotypes, that can predict adaptive behavior trajectories with moderate accuracy. Of note, cumulative hours of behavioral and developmental therapy did not seem to contribute to the prediction of outcome trajectories. Our results add to a growing body of research that uses latent growth curve modelling to characterize adaptive behavior change, and machine learning models to predict treatment outcomes in neurodevelopmental populations.## MethodsOutcome variablesAdaptive behavior outcomesThe primary outcome measure used was the Vineland Adaptive Behavior Scales, Third Edition (VABS-3) Parent/Caregiver Form [18]. The parent report VABS-3 evaluates adaptive behaviors in five different domains: Social, Communication, Daily Living Skills, and Motor. Based on the summarized scores in each domain, an Adaptive Behavior Composite (ABC) is also calculated. Items are scored on a scale of 0 (never), 1 (sometimes), or 2 (usually) for the level at which the child can independently perform a skill. Each domain reflects a standard score based on a population mean of 100 and a standard deviation of 15. The ABC, Social, and Communication domains were included in the current analysis.Clinical intake predictor variablesSociodemographic variablesChild gender and age at initial assessment were gathered directly from Cortica’s medical record database. Income and level of education for the primary caregiver(s) were together used as a proxy for socioeconomic status (SES). Specifically, total years of education and total income were scaled and averaged to create a composite SES variable.Historical variablesCaregivers were asked to report on whether they experienced prenatal stress, prenatal depression, and/or post-partum depression. Responses were summed into a pre/perinatal mental health variable. We collected information about the age of each parent at the time of the child’s birth. Parents rated their child’s temperament as a baby on a three-point categorical scale (1 = “Easy baby/little crying”, 2 = “Average baby/average crying”, 3 = “Difficult baby/increased crying”). Finally, parents reported whether their child had lost previously attained developmental abilities (i.e., history of developmental regression).Clinical phenotyping variablesAt the time of patient intake, several clinical phenotyping variables were gathered. To assess sleep problems, the Bedtime Issues, Excessive Daytime Sleepiness, Night Awakenings, Regularity and Duration of Sleep, Snoring (BEARS) questionnaire [46] was administered. Attention deficit and hyperactivity disorder (ADHD) symptoms were evaluated using questions adapted from the Swanson, Nolan, and Pelham (SNAP-IV) questionnaire [40]. To measure autism symptoms, the Autism Quotient (AQ) [36] was administered. Sensory processing disorder (SPD) symptoms were measured using questions adapted from the Sensory Processing Scales (SPS) [47]. Finally, we administered the early symptomatic syndromes eliciting neurodevelopmental clinical examinations-questionnaire (ESSENCE-Q-REV) [48] which includes the following subset of concerns: general development, motor development, sensory reactivity, communication and language, impulsivity, attention, repetitive behavior, mood, and feeding. Parents rate their concerns on a scale of 1 (No Concern), 2 (Maybe/A Little Concern), 3 (Yes Concern).Conditional latent growth curve analysisAll latent class growth mixture model (LCGMM) analyses were conducted in Mplus Version 8.1 [49]. Full Information Maximum Likelihood (FIML) estimator was used to account for missing data in all LCGMM analyses yield unbiased estimates when data are missing at random (Muthen & Muthen 2012). Each LCGMM was initialized 200 times with 50 integrations for final stage of optimization. The best-fitting model was selected based on Bayesian information criterion (BIC), statistically significant Lo–Mendell–Rubin likelihood ratio test (LMR), and entropy values [50]. Lower BIC reflects better model fit while higher entropy values (closest to 1.0) indicate greater class separation and lower classification error [51]. Data were structured in a wide panel format, with each assessment timepoint (scheduled in 6-month increments) represented as a separate column. Time was parameterized in 1-year increments, with baseline set at 0 and subsequent assessments spaced at intervals of 0.5 (i.e., 6 months). This means that the slope estimates reflect the rate of change in the outcome variable per year rather than per assessment wave. Change was modeled with respect to clinical time-to-follow-up rather than chronological age, as the Vineland-3 standard scores are already age-normed. This approach ensures that the identified trajectories reflect variations in adaptive behavior over the course of clinical care rather than differences in age at assessment.Machine learning predictive analysisWe compared three machine learning algorithms to predict between the two LCGA growth trajectory groups. All models were run using the tidymodels package in R [52]. First we used penalized elastic-net logistic regression from the R package glmnet [53], followed by support vector machine (SVM) classifiers from the R package kernlab [52, 54], and lastly, random forest classification from the R package ranger [55]. Elastic net logistic regression supports sparse model development through feature selection. SVM employs a technique where data is projected into a higher-dimensional space, enabling the classes to be distinguished by a hyperplane. By moving the data into this augmented space, the classifier effectively addresses issues of class separation by selecting the class-separating hyperplane that maximizes margins between features. Finally, random forest uses bootstrapped aggregation (or “bagging”) to combine predictions from many tress where each tree is fit with a bootstrapped dataset.Feature engineeringData was preprocessed to optimize model performance. First, variables with missing data were imputed with k-nearest neighbor (kNN). This process is applied using the training set to impute missing data by considering the similarity from its k-nearest neighbor which contained non-missing values. Gower’s distance function is used as the primary metric for calculating distances between data points. Next, all variables were normalized and variables with near-zero variance and highly correlated variables were removed. Variables with a high degree of correlation (>0.90) were removed to avoid redundant information. Finally, we applied Synthetic Minority Over-sampling Technique (SMOTE) [56] from the themis R package [57] using an over-ratio of 0.5 to mitigate the impact of class imbalance. SMOTE counteracts bias stemming from underrepresented samples by generating synthetic instances of the minority class.Hyperparameter tuningUsing the transformed and quality-controlled feature variables, we then preformed hyperparameter tuning on each machine learning algorithm. Elastic net is tuned by optimizing the balance between feature selection and coefficient shrinkage from ridge and lasso regression and strength of regularization. SVN’s tuning parameters include optimizing margin hardness and size. Random forest tuning parameters include the number of features to consider at each split, the number of decision tress included in the forest, and the minimum number of data points in a node required for another split.A 30% holdout test dataset was created using a random split stratified by outcome group. Hyperparameters were optimized for each algorithm via grid search within stratified 10-fold cross-validation repeated 10 times [58]. The grid search was preformed iteratively using the stratified cross-validation folds. For each repetition, the test dataset was randomly split into 10 equally sized subsets, of which two were used as a training set to create the model and the hold out set was sued as the test set. To evaluate training performance of the model, area under the receiver operating curve (AUROC) and accuracy were aggregated across the cross-validation folds. The study selected the hyperparameter combination that yielded the best model performance as the final model.Model validationWe deployed the final model on the previously unseen holdout test data for model validation. To evaluate classification performance of the final model, ROCAUC, accuracy, precision, recall, and F1 score metrics were calculated. A confusion matrix and prediction plot were generated to compare the predicted values to true values of trajectory group membership.Variable importanceTo assess the significance of individual variables within the final model, we employed Shapley values. Originating from cooperative game theory, the Shapley method provides a model-agnostic approach to quantifying variable importance, aiming to estimate the contribution of each feature to the predictions generated by a machine learning model [59]. Shapley values were calculated using the ‘fastshap’ package in R. We conducted 100 Monte Carlo simulations to obtain robust estimates of the Shapley values. These values capture the weighted differences in model outcomes as features are systematically included or excluded for all possible permutations.## Adaptive behavior outcomesThe primary outcome measure used was the Vineland Adaptive Behavior Scales, Third Edition (VABS-3) Parent/Caregiver Form [18]. The parent report VABS-3 evaluates adaptive behaviors in five different domains: Social, Communication, Daily Living Skills, and Motor. Based on the summarized scores in each domain, an Adaptive Behavior Composite (ABC) is also calculated. Items are scored on a scale of 0 (never), 1 (sometimes), or 2 (usually) for the level at which the child can independently perform a skill. Each domain reflects a standard score based on a population mean of 100 and a standard deviation of 15. The ABC, Social, and Communication domains were included in the current analysis.## Sociodemographic variablesChild gender and age at initial assessment were gathered directly from Cortica’s medical record database. Income and level of education for the primary caregiver(s) were together used as a proxy for socioeconomic status (SES). Specifically, total years of education and total income were scaled and averaged to create a composite SES variable.## Historical variablesCaregivers were asked to report on whether they experienced prenatal stress, prenatal depression, and/or post-partum depression. Responses were summed into a pre/perinatal mental health variable. We collected information about the age of each parent at the time of the child’s birth. Parents rated their child’s temperament as a baby on a three-point categorical scale (1 = “Easy baby/little crying”, 2 = “Average baby/average crying”, 3 = “Difficult baby/increased crying”). Finally, parents reported whether their child had lost previously attained developmental abilities (i.e., history of developmental regression).## Clinical phenotyping variablesAt the time of patient intake, several clinical phenotyping variables were gathered. To assess sleep problems, the Bedtime Issues, Excessive Daytime Sleepiness, Night Awakenings, Regularity and Duration of Sleep, Snoring (BEARS) questionnaire [46] was administered. Attention deficit and hyperactivity disorder (ADHD) symptoms were evaluated using questions adapted from the Swanson, Nolan, and Pelham (SNAP-IV) questionnaire [40]. To measure autism symptoms, the Autism Quotient (AQ) [36] was administered. Sensory processing disorder (SPD) symptoms were measured using questions adapted from the Sensory Processing Scales (SPS) [47]. Finally, we administered the early symptomatic syndromes eliciting neurodevelopmental clinical examinations-questionnaire (ESSENCE-Q-REV) [48] which includes the following subset of concerns: general development, motor development, sensory reactivity, communication and language, impulsivity, attention, repetitive behavior, mood, and feeding. Parents rate their concerns on a scale of 1 (No Concern), 2 (Maybe/A Little Concern), 3 (Yes Concern).## Conditional latent growth curve analysisAll latent class growth mixture model (LCGMM) analyses were conducted in Mplus Version 8.1 [49]. Full Information Maximum Likelihood (FIML) estimator was used to account for missing data in all LCGMM analyses yield unbiased estimates when data are missing at random (Muthen & Muthen 2012). Each LCGMM was initialized 200 times with 50 integrations for final stage of optimization. The best-fitting model was selected based on Bayesian information criterion (BIC), statistically significant Lo–Mendell–Rubin likelihood ratio test (LMR), and entropy values [50]. Lower BIC reflects better model fit while higher entropy values (closest to 1.0) indicate greater class separation and lower classification error [51]. Data were structured in a wide panel format, with each assessment timepoint (scheduled in 6-month increments) represented as a separate column. Time was parameterized in 1-year increments, with baseline set at 0 and subsequent assessments spaced at intervals of 0.5 (i.e., 6 months). This means that the slope estimates reflect the rate of change in the outcome variable per year rather than per assessment wave. Change was modeled with respect to clinical time-to-follow-up rather than chronological age, as the Vineland-3 standard scores are already age-normed. This approach ensures that the identified trajectories reflect variations in adaptive behavior over the course of clinical care rather than differences in age at assessment.## Machine learning predictive analysisWe compared three machine learning algorithms to predict between the two LCGA growth trajectory groups. All models were run using the tidymodels package in R [52]. First we used penalized elastic-net logistic regression from the R package glmnet [53], followed by support vector machine (SVM) classifiers from the R package kernlab [52, 54], and lastly, random forest classification from the R package ranger [55]. Elastic net logistic regression supports sparse model development through feature selection. SVM employs a technique where data is projected into a higher-dimensional space, enabling the classes to be distinguished by a hyperplane. By moving the data into this augmented space, the classifier effectively addresses issues of class separation by selecting the class-separating hyperplane that maximizes margins between features. Finally, random forest uses bootstrapped aggregation (or “bagging”) to combine predictions from many tress where each tree is fit with a bootstrapped dataset.## Feature engineeringData was preprocessed to optimize model performance. First, variables with missing data were imputed with k-nearest neighbor (kNN). This process is applied using the training set to impute missing data by considering the similarity from its k-nearest neighbor which contained non-missing values. Gower’s distance function is used as the primary metric for calculating distances between data points. Next, all variables were normalized and variables with near-zero variance and highly correlated variables were removed. Variables with a high degree of correlation (>0.90) were removed to avoid redundant information. Finally, we applied Synthetic Minority Over-sampling Technique (SMOTE) [56] from the themis R package [57] using an over-ratio of 0.5 to mitigate the impact of class imbalance. SMOTE counteracts bias stemming from underrepresented samples by generating synthetic instances of the minority class.## Hyperparameter tuningUsing the transformed and quality-controlled feature variables, we then preformed hyperparameter tuning on each machine learning algorithm. Elastic net is tuned by optimizing the balance between feature selection and coefficient shrinkage from ridge and lasso regression and strength of regularization. SVN’s tuning parameters include optimizing margin hardness and size. Random forest tuning parameters include the number of features to consider at each split, the number of decision tress included in the forest, and the minimum number of data points in a node required for another split.
A 30% holdout test dataset was created using a random split stratified by outcome group. Hyperparameters were optimized for each algorithm via grid search within stratified 10-fold cross-validation repeated 10 times [58]. The grid search was preformed iteratively using the stratified cross-validation folds. For each repetition, the test dataset was randomly split into 10 equally sized subsets, of which two were used as a training set to create the model and the hold out set was sued as the test set. To evaluate training performance of the model, area under the receiver operating curve (AUROC) and accuracy were aggregated across the cross-validation folds. The study selected the hyperparameter combination that yielded the best model performance as the final model.## Model validationWe deployed the final model on the previously unseen holdout test data for model validation. To evaluate classification performance of the final model, ROCAUC, accuracy, precision, recall, and F1 score metrics were calculated. A confusion matrix and prediction plot were generated to compare the predicted values to true values of trajectory group membership.## Variable importanceTo assess the significance of individual variables within the final model, we employed Shapley values. Originating from cooperative game theory, the Shapley method provides a model-agnostic approach to quantifying variable importance, aiming to estimate the contribution of each feature to the predictions generated by a machine learning model [59]. Shapley values were calculated using the ‘fastshap’ package in R. We conducted 100 Monte Carlo simulations to obtain robust estimates of the Shapley values. These values capture the weighted differences in model outcomes as features are systematically included or excluded for all possible permutations.## Data availabilityThe datasets used in the current study are available from the corresponding author on reasonable request.## Author informationAuthors and AffiliationsCortica Healthcare, San Diego, CA, USAAnnie Aitken, Maia C. Lazerwitz, Ally Eash, Neil Hattangadi, Elysa J. Marco & Kevin A. ShapiroDepartment of Applied Psychology, New York University, New York, NY, USAAnnie AitkenUniversity of California, San Francisco, CA, USAPratik MukherjeeBoston College, Boston, MA, USAKevin A. ShapiroAuthorsAnnie AitkenView author publicationsSearch author on:PubMed Google ScholarMaia C. LazerwitzView author publicationsSearch author on:PubMed Google ScholarAlly EashView author publicationsSearch author on:PubMed Google ScholarNeil HattangadiView author publicationsSearch author on:PubMed Google ScholarPratik MukherjeeView author publicationsSearch author on:PubMed Google ScholarElysa J. MarcoView author publicationsSearch author on:PubMed Google ScholarKevin A. ShapiroView author publicationsSearch author on:PubMed Google ScholarContributionsAA proposed the hypothesis and approach, preformed analyses and wrote the manuscript; ML supported manuscript writing and editing; AE contributed to data acquisition and processing for the analysis; NH, PM, EM, and KS assisted with conceptual study development and manuscript writing. All authors contributed to manuscript revisions.Corresponding authorCorrespondence to
Annie Aitken.## Authors and AffiliationsCortica Healthcare, San Diego, CA, USAAnnie Aitken, Maia C. Lazerwitz, Ally Eash, Neil Hattangadi, Elysa J. Marco & Kevin A. ShapiroDepartment of Applied Psychology, New York University, New York, NY, USAAnnie AitkenUniversity of California, San Francisco, CA, USAPratik MukherjeeBoston College, Boston, MA, USAKevin A. Shapiro
AuthorsAnnie AitkenView author publicationsSearch author on:PubMed Google ScholarMaia C. LazerwitzView author publicationsSearch author on:PubMed Google ScholarAlly EashView author publicationsSearch author on:PubMed Google ScholarNeil HattangadiView author publicationsSearch author on:PubMed Google ScholarPratik MukherjeeView author publicationsSearch author on:PubMed Google ScholarElysa J. MarcoView author publicationsSearch author on:PubMed Google ScholarKevin A. ShapiroView author publicationsSearch author on:PubMed Google Scholar## ContributionsAA proposed the hypothesis and approach, preformed analyses and wrote the manuscript; ML supported manuscript writing and editing; AE contributed to data acquisition and processing for the analysis; NH, PM, EM, and KS assisted with conceptual study development and manuscript writing. All authors contributed to manuscript revisions.## Corresponding authorCorrespondence to
Annie Aitken.## Ethics declarationsCompeting interests
ML, AE, NH, EM and KS are employed by Cortica, AA received consultation fees from Cortica.
Ethics approval and consent to participate
The study was conducted according to principles outlined in the Declaration of Helsinki, and was approved by the WIRB-Copernicus Group, Institutional review board (protocol # 20224562). We received a waiver of informed consent from the institutional review board given that all aspects of this study were based on deidentified retrospective clinical data.## Competing interestsML, AE, NH, EM and KS are employed by Cortica, AA received consultation fees from Cortica.## Ethics approval and consent to participateThe study was conducted according to principles outlined in the Declaration of Helsinki, and was approved by the WIRB-Copernicus Group, Institutional review board (protocol # 20224562). We received a waiver of informed consent from the institutional review board given that all aspects of this study were based on deidentified retrospective clinical data.## Additional informationPublisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.## Supplementary informationSupplemental Material## Rights and permissionsOpen Access  This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License, which permits any non-commercial use, sharing, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if you modified the licensed material. You do not have permission under this licence to share adapted material derived from this article or parts of it. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by-nc-nd/4.0/.
Reprints and permissions## About this articleCite this articleAitken, A., Lazerwitz, M.C., Eash, A. et al. Predictive modeling of adaptive behavior trajectories in autism: insights from a clinical cohort study.
Transl Psychiatry 15, 398 (2025). https://doi.org/10.1038/s41398-025-03592-0Download citationReceived: 22 February 2024Revised: 26 June 2025Accepted: 01 September 2025Published: 10 October 2025DOI: https://doi.org/10.1038/s41398-025-03592-0Share this articleAnyone you share the following link with will be able to read this content:Get shareable linkSorry, a shareable link is not currently available for this article.Copy shareable link to clipboard
Provided by the Springer Nature SharedIt content-sharing initiative## Cite this articleAitken, A., Lazerwitz, M.C., Eash, A. et al. Predictive modeling of adaptive behavior trajectories in autism: insights from a clinical cohort study.
Transl Psychiatry 15, 398 (2025). https://doi.org/10.1038/s41398-025-03592-0
Download citation
Received: 22 February 2024Revised: 26 June 2025Accepted: 01 September 2025Published: 10 October 2025DOI: https://doi.org/10.1038/s41398-025-03592-0
Share this articleAnyone you share the following link with will be able to read this content:Get shareable linkSorry, a shareable link is not currently available for this article.Copy shareable link to clipboard
Provided by the Springer Nature SharedIt content-sharing initiative## Share this articleAnyone you share the following link with will be able to read this content:
Get shareable link
Sorry, a shareable link is not currently available for this article.
Copy shareable link to clipboard
Provided by the Springer Nature SharedIt content-sharing initiative---## Research Details**Source:** web_scraping
**Category:** comorbidity
**Scraping Date:** 2025-10-21T10:52:46.717632
**Scraped By:** agent_c
**Original URL:** https://doi.org/10.1038/s41398-025-03592-0*This paper was scraped from online sources and processed for the neurodevelopmental disorders knowledge base.*