---
title: '- professional'
authors:
- Brad Windsor, Brandon O'Shea, Mengxi Wu**Publication Date:** 2023-03-26
journal: ''
doi: 10.48550/arXiv.2303.14592
publication_date: ''
source: Processed from scraped content
processing_date: '2025-10-21T22:15:08.805210'
content_type: research_paper
conditions:
- related_disorders
topics:
- general
categories:
- related-disorders
reading_level: academic
audience:
- professional
- researcher
patient_friendly: false
search_priority: standard
keywords:
- quality
search_tags:
- related_disorders
- peer-reviewed
- general
- academic
- research
---

# - professional

**Authors:** Brad Windsor, Brandon O'Shea, Mengxi Wu**Publication Date:** 2023-03-26

**DOI:** 10.48550/arXiv.2303.14592

## Abstract

Abstract:
The Reinforcement Learning field is strong on achievements and weak on reapplication; a computer playing GO at a super-human level is still terrible at Tic-Tac-Toe. This paper asks whether the method of training networks improves their generalization. Specifically we explore core quality diversity algorithms, compare against two recent algorithms, and propose a new algorithm to deal with shortcomings in existing methods. Although results of these methods are well below the performance hoped for, our work raises important points about the choice of behavior criterion in quality diversity, the interaction of differential and evolutionary training methods, and the role of offline reinforcement learning and randomized learning in evolutionary search.---

---
audience:
- professional
- researcher
authors:
- Brad Windsor, Brandon O'Shea, Mengxi Wu
category: ''
content_type: research_paper
doi: 10.48550/arXiv.2303.14592
journal: ''
original_url: https://doi.org/10.48550/arXiv.2303.14592
patient_friendly: false
publication_date: '2023-03-26'
reading_level: academic
scraped_by: agent_c
scraping_date: '2025-10-21T10:56:25.406990'
source: web_scraping
title: Computer Science > Neural and Evolutionary Computing
type: research_paper
---
# Computer Science > Neural and Evolutionary ComputingThe Reinforcement Learning field is strong on achievements and weak on reapplication; a computer playing GO at a super-human level is still terrible at Tic-Tac-Toe. This paper asks whether the method of training networks improves their generalization. Specifically we explore core quality diversity algorithms, compare against two recent algorithms, and propose a new algorithm to deal with shortcomings in existing methods. Although results of these methods are well below the performance hoped for, our work raises important points about the choice of behavior criterion in quality diversity, the interaction of differential and evolutionary training methods, and the role of offline reinforcement learning and randomized learning in evolutionary search.---## Research Details**Source:** web_scraping
**Category:**
**Scraping Date:** 2025-10-21T10:56:25.406990
**Scraped By:** agent_c
**Original URL:** https://doi.org/10.48550/arXiv.2303.14592*This paper was scraped from online sources and processed for the neurodevelopmental disorders knowledge base.*